{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:43:12.790212Z",
     "start_time": "2024-12-08T13:43:12.783359Z"
    }
   },
   "outputs": [],
   "source": [
    "BLACKHOLE = False\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # fixes problem with graph\n",
    "\n",
    "\n",
    "if BLACKHOLE:\n",
    "    workspace_path = os.path.expandvars('$BLACKHOLE')\n",
    "    sys.path.append(workspace_path+'/DeepLearning/02456_news_project/src')\n",
    "    DATAPATH = Path(workspace_path+\"/DeepLearning/ebnerd_data\").expanduser()\n",
    "else:\n",
    "    DATAPATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "\n",
    "#DATASET = \"ebnerd_demo\"\n",
    "#DATASET = \"ebnerd_small\"\n",
    "DATASET = \"ebnerd_large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:43:14.502255Z",
     "start_time": "2024-12-08T13:43:12.826475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1+cu124\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "\n",
    "# Check gpu availability\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Test:\n",
    "#print(torch.zeros(1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:43:15.398626Z",
     "start_time": "2024-12-08T13:43:14.688197Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.data_handler import NewsDataset\n",
    "import from_ebrec._constants as cs\n",
    "\n",
    "SEED = 42\n",
    "HISTORY_SIZE = 100\n",
    "CANDITATE_SIZE = 5\n",
    "\n",
    "COLS = [\n",
    "    cs.DEFAULT_USER_COL,\n",
    "    cs.DEFAULT_IMPRESSION_ID_COL,\n",
    "    cs.DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    cs.DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    cs.DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "\n",
    "FRACTION = 0.001\n",
    "#FRACTION = 0.01\n",
    "#FRACTION = 0.1\n",
    "#FRACTION = 1\n",
    "\n",
    "# test\n",
    "dataset = NewsDataset()\n",
    "\n",
    "dataset.setup_df(dataset_path = DATAPATH, datasplit = DATASET, history_size = HISTORY_SIZE, columns = COLS, fraction = FRACTION, seed = SEED, candidate_size=CANDITATE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:44:39.537808Z",
     "start_time": "2024-12-08T13:43:15.405866Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers as huggingface\n",
    "from from_ebrec._nlp import get_transformers_word_embeddings\n",
    "from from_ebrec._polars import concat_str_columns\n",
    "from from_ebrec._articles import convert_text2encoding_with_transformers\n",
    "from from_ebrec._articles import create_article_id_to_value_mapping\n",
    "\n",
    "dataset.setup_articles_data(dataset_path = DATAPATH.joinpath(DATASET))\n",
    "\n",
    "df_articles = dataset.df_articles\n",
    "\n",
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-large\"\n",
    "TEXT_COLUMNS_TO_USE = [cs.DEFAULT_SUBTITLE_COL, cs.DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = huggingface.AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = huggingface.AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH)\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_articles, value_col=token_col_title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:44:39.744604Z",
     "start_time": "2024-12-08T13:44:39.646644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSModel(\n",
      "  (news_encoder): NewsEncoder(\n",
      "    (embedding): Embedding(250002, 1024)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (positional_encoder): PositionEncoder(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (dense_layers): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=2000, bias=True)\n",
      "      (1): LayerNorm((2000,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "      (5): LayerNorm((2000,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Dropout(p=0.3, inplace=False)\n",
      "      (8): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "      (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (att_layer): AttLayer2(\n",
      "      (attention_projection): Linear(in_features=1024, out_features=200, bias=True)\n",
      "      (query_vector): Linear(in_features=200, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (user_encoder): UserEncoder(\n",
      "    (news_encoder): NewsEncoder(\n",
      "      (embedding): Embedding(250002, 1024)\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (positional_encoder): PositionEncoder(\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (self_attention): SelfAttention(\n",
      "        (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (dense_layers): Sequential(\n",
      "        (0): Linear(in_features=1024, out_features=2000, bias=True)\n",
      "        (1): LayerNorm((2000,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "        (4): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "        (5): LayerNorm((2000,), eps=1e-05, elementwise_affine=True)\n",
      "        (6): GELU(approximate='none')\n",
      "        (7): Dropout(p=0.3, inplace=False)\n",
      "        (8): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "        (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (10): GELU(approximate='none')\n",
      "        (11): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (att_layer): AttLayer2(\n",
      "        (attention_projection): Linear(in_features=1024, out_features=200, bias=True)\n",
      "        (query_vector): Linear(in_features=200, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (att_layer): AttLayer2(\n",
      "      (attention_projection): Linear(in_features=1024, out_features=200, bias=True)\n",
      "      (query_vector): Linear(in_features=200, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (click_predictor): ClickPredictor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nrms import NRMSModel\n",
    "from hyperparameters import hparams_nrms\n",
    "\n",
    "hparams = hparams_nrms()\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# PARAMETERS\n",
    "hparams.title_size = MAX_TITLE_LENGTH\n",
    "hparams.history_size = HISTORY_SIZE\n",
    "hparams.batch_size = BATCH_SIZE\n",
    "hparams.candidate_size = CANDITATE_SIZE\n",
    "\n",
    "# MODEL ARCHITECTURE\n",
    "hparams.head_num = 32\n",
    "hparams.head_dim = 32\n",
    "hparams.attention_hidden_dim = 200\n",
    "hparams.linear_hidden_dim = 2000\n",
    "hparams.embedding_dim = word2vec_embedding.shape[1]\n",
    "\n",
    "hparams.use_positional_encoding = True\n",
    "\n",
    "hparams.use_time_embedding = False\n",
    "hparams.time_dim = 1\n",
    "hparams.time_embedding_dim = 32\n",
    "\n",
    "# MODEL OPTIMIZER:\n",
    "hparams.optimizer = \"adamw\"\n",
    "hparams.loss = \"cross_entropy_loss\"\n",
    "hparams.dropout = 0.3\n",
    "hparams.learning_rate = 1e-3\n",
    "hparams.weight_decay = 1e-4\n",
    "hparams.momentum = 0.9\n",
    "\n",
    "model = NRMSModel(hparams=hparams, word2vec_embedding=word2vec_embedding)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:44:39.752554Z",
     "start_time": "2024-12-08T13:44:39.748266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "print(\"GPU =\",torch.cuda.device_count())\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:44:40.160913Z",
     "start_time": "2024-12-08T13:44:39.862598Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "if hparams.loss == \"cross_entropy_loss\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "elif hparams.loss == \"mse_loss\":\n",
    "    criterion = nn.MSELoss()\n",
    "else:\n",
    "    raise ValueError(f\"Loss function {hparams.loss} not supported\")\n",
    "\n",
    "if hparams.optimizer == \"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hparams_nrms.learning_rate, weight_decay=hparams_nrms.weight_decay)\n",
    "elif hparams.optimizer == \"adamw\":\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=hparams_nrms.learning_rate, weight_decay=hparams_nrms.weight_decay)\n",
    "elif hparams.optimizer == \"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=hparams_nrms.learning_rate, momentum=hparams_nrms.momentum)\n",
    "else:\n",
    "    raise ValueError(f\"Optimizer {hparams.optimizer} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:44:41.067568Z",
     "start_time": "2024-12-08T13:44:40.165266Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import NRMSDataLoader\n",
    "\n",
    "\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors= dataset.df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column= cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors= dataset.df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column= cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:44:41.287608Z",
     "start_time": "2024-12-08T13:44:41.284790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dynamic learning rate\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',  # Minimizing validation loss\n",
    "    factor=0.3,  # Reduce the learning rate by half\n",
    "    patience=2,  # Wait 2 epochs without improvement\n",
    "    verbose=True  # Log the learning rate changes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:45:11.637226Z",
     "start_time": "2024-12-08T13:44:41.503914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train iteration 1/164: Loss = 1.6064\n",
      "Epoch 1/50, Train iteration 2/164: Loss = 1.6195\n",
      "Epoch 1/50, Train iteration 3/164: Loss = 1.6324\n",
      "Epoch 1/50, Train iteration 4/164: Loss = 1.6662\n",
      "Epoch 1/50, Train iteration 5/164: Loss = 1.6359\n",
      "Epoch 1/50, Train iteration 6/164: Loss = 1.6246\n",
      "Epoch 1/50, Train iteration 7/164: Loss = 1.6291\n",
      "Epoch 1/50, Train iteration 8/164: Loss = 1.6194\n",
      "Epoch 1/50, Train iteration 9/164: Loss = 1.5887\n",
      "Epoch 1/50, Train iteration 10/164: Loss = 1.6488\n",
      "Epoch 1/50, Train iteration 11/164: Loss = 1.7073\n",
      "Epoch 1/50, Train iteration 12/164: Loss = 1.6609\n",
      "Epoch 1/50, Train iteration 13/164: Loss = 1.6771\n",
      "Epoch 1/50, Train iteration 14/164: Loss = 1.6622\n",
      "Epoch 1/50, Train iteration 15/164: Loss = 1.6224\n",
      "Epoch 1/50, Train iteration 16/164: Loss = 1.6517\n",
      "Epoch 1/50, Train iteration 17/164: Loss = 1.6530\n",
      "Epoch 1/50, Train iteration 18/164: Loss = 1.6948\n",
      "Epoch 1/50, Train iteration 19/164: Loss = 1.6456\n",
      "Epoch 1/50, Train iteration 20/164: Loss = 1.6576\n",
      "Epoch 1/50, Train iteration 21/164: Loss = 1.6757\n",
      "Epoch 1/50, Train iteration 22/164: Loss = 1.6165\n",
      "Epoch 1/50, Train iteration 23/164: Loss = 1.6201\n",
      "Epoch 1/50, Train iteration 24/164: Loss = 1.7334\n",
      "Epoch 1/50, Train iteration 25/164: Loss = 1.6543\n",
      "Epoch 1/50, Train iteration 26/164: Loss = 1.6664\n",
      "Epoch 1/50, Train iteration 27/164: Loss = 1.6654\n",
      "Epoch 1/50, Train iteration 28/164: Loss = 1.6493\n",
      "Epoch 1/50, Train iteration 29/164: Loss = 1.6702\n",
      "Epoch 1/50, Train iteration 30/164: Loss = 1.6240\n",
      "Epoch 1/50, Train iteration 31/164: Loss = 1.6396\n",
      "Epoch 1/50, Train iteration 32/164: Loss = 1.6392\n",
      "Epoch 1/50, Train iteration 33/164: Loss = 1.6336\n",
      "Epoch 1/50, Train iteration 34/164: Loss = 1.6733\n",
      "Epoch 1/50, Train iteration 35/164: Loss = 1.6574\n",
      "Epoch 1/50, Train iteration 36/164: Loss = 1.6432\n",
      "Epoch 1/50, Train iteration 37/164: Loss = 1.7008\n",
      "Epoch 1/50, Train iteration 38/164: Loss = 1.6733\n",
      "Epoch 1/50, Train iteration 39/164: Loss = 1.5663\n",
      "Epoch 1/50, Train iteration 40/164: Loss = 1.6439\n",
      "Epoch 1/50, Train iteration 41/164: Loss = 1.6592\n",
      "Epoch 1/50, Train iteration 42/164: Loss = 1.6513\n",
      "Epoch 1/50, Train iteration 43/164: Loss = 1.6271\n",
      "Epoch 1/50, Train iteration 44/164: Loss = 1.6350\n",
      "Epoch 1/50, Train iteration 45/164: Loss = 1.6369\n",
      "Epoch 1/50, Train iteration 46/164: Loss = 1.5946\n",
      "Epoch 1/50, Train iteration 47/164: Loss = 1.6241\n",
      "Epoch 1/50, Train iteration 48/164: Loss = 1.6269\n",
      "Epoch 1/50, Train iteration 49/164: Loss = 1.5938\n",
      "Epoch 1/50, Train iteration 50/164: Loss = 1.7140\n",
      "Epoch 1/50, Train iteration 51/164: Loss = 1.6155\n",
      "Epoch 1/50, Train iteration 52/164: Loss = 1.6347\n",
      "Epoch 1/50, Train iteration 53/164: Loss = 1.6519\n",
      "Epoch 1/50, Train iteration 54/164: Loss = 1.6456\n",
      "Epoch 1/50, Train iteration 55/164: Loss = 1.6576\n",
      "Epoch 1/50, Train iteration 56/164: Loss = 1.6674\n",
      "Epoch 1/50, Train iteration 57/164: Loss = 1.6182\n",
      "Epoch 1/50, Train iteration 58/164: Loss = 1.6276\n",
      "Epoch 1/50, Train iteration 59/164: Loss = 1.6160\n",
      "Epoch 1/50, Train iteration 60/164: Loss = 1.6358\n",
      "Epoch 1/50, Train iteration 61/164: Loss = 1.6480\n",
      "Epoch 1/50, Train iteration 62/164: Loss = 1.6802\n",
      "Epoch 1/50, Train iteration 63/164: Loss = 1.6690\n",
      "Epoch 1/50, Train iteration 64/164: Loss = 1.5885\n",
      "Epoch 1/50, Train iteration 65/164: Loss = 1.6224\n",
      "Epoch 1/50, Train iteration 66/164: Loss = 1.6305\n",
      "Epoch 1/50, Train iteration 67/164: Loss = 1.5676\n",
      "Epoch 1/50, Train iteration 68/164: Loss = 1.6102\n",
      "Epoch 1/50, Train iteration 69/164: Loss = 1.6128\n",
      "Epoch 1/50, Train iteration 70/164: Loss = 1.6335\n",
      "Epoch 1/50, Train iteration 71/164: Loss = 1.6189\n",
      "Epoch 1/50, Train iteration 72/164: Loss = 1.6068\n",
      "Epoch 1/50, Train iteration 73/164: Loss = 1.6190\n",
      "Epoch 1/50, Train iteration 74/164: Loss = 1.6619\n",
      "Epoch 1/50, Train iteration 75/164: Loss = 1.6113\n",
      "Epoch 1/50, Train iteration 76/164: Loss = 1.6348\n",
      "Epoch 1/50, Train iteration 77/164: Loss = 1.6870\n",
      "Epoch 1/50, Train iteration 78/164: Loss = 1.5775\n",
      "Epoch 1/50, Train iteration 79/164: Loss = 1.6101\n",
      "Epoch 1/50, Train iteration 80/164: Loss = 1.6550\n",
      "Epoch 1/50, Train iteration 81/164: Loss = 1.6096\n",
      "Epoch 1/50, Train iteration 82/164: Loss = 1.5475\n",
      "Epoch 1/50, Train iteration 83/164: Loss = 1.5876\n",
      "Epoch 1/50, Train iteration 84/164: Loss = 1.6579\n",
      "Epoch 1/50, Train iteration 85/164: Loss = 1.6537\n",
      "Epoch 1/50, Train iteration 86/164: Loss = 1.6200\n",
      "Epoch 1/50, Train iteration 87/164: Loss = 1.6655\n",
      "Epoch 1/50, Train iteration 88/164: Loss = 1.6311\n",
      "Epoch 1/50, Train iteration 89/164: Loss = 1.5873\n",
      "Epoch 1/50, Train iteration 90/164: Loss = 1.5829\n",
      "Epoch 1/50, Train iteration 91/164: Loss = 1.6418\n",
      "Epoch 1/50, Train iteration 92/164: Loss = 1.6353\n",
      "Epoch 1/50, Train iteration 93/164: Loss = 1.6262\n",
      "Epoch 1/50, Train iteration 94/164: Loss = 1.6287\n",
      "Epoch 1/50, Train iteration 95/164: Loss = 1.5803\n",
      "Epoch 1/50, Train iteration 96/164: Loss = 1.6134\n",
      "Epoch 1/50, Train iteration 97/164: Loss = 1.6190\n",
      "Epoch 1/50, Train iteration 98/164: Loss = 1.6476\n",
      "Epoch 1/50, Train iteration 99/164: Loss = 1.6054\n",
      "Epoch 1/50, Train iteration 100/164: Loss = 1.6153\n",
      "Epoch 1/50, Train iteration 101/164: Loss = 1.5996\n",
      "Epoch 1/50, Train iteration 102/164: Loss = 1.5377\n",
      "Epoch 1/50, Train iteration 103/164: Loss = 1.6546\n",
      "Epoch 1/50, Train iteration 104/164: Loss = 1.5870\n",
      "Epoch 1/50, Train iteration 105/164: Loss = 1.6432\n",
      "Epoch 1/50, Train iteration 106/164: Loss = 1.6201\n",
      "Epoch 1/50, Train iteration 107/164: Loss = 1.5867\n",
      "Epoch 1/50, Train iteration 108/164: Loss = 1.6145\n",
      "Epoch 1/50, Train iteration 109/164: Loss = 1.5964\n",
      "Epoch 1/50, Train iteration 110/164: Loss = 1.6406\n",
      "Epoch 1/50, Train iteration 111/164: Loss = 1.6275\n",
      "Epoch 1/50, Train iteration 112/164: Loss = 1.6531\n",
      "Epoch 1/50, Train iteration 113/164: Loss = 1.6291\n",
      "Epoch 1/50, Train iteration 114/164: Loss = 1.6222\n",
      "Epoch 1/50, Train iteration 115/164: Loss = 1.5978\n",
      "Epoch 1/50, Train iteration 116/164: Loss = 1.6147\n",
      "Epoch 1/50, Train iteration 117/164: Loss = 1.5928\n",
      "Epoch 1/50, Train iteration 118/164: Loss = 1.6276\n",
      "Epoch 1/50, Train iteration 119/164: Loss = 1.6040\n",
      "Epoch 1/50, Train iteration 120/164: Loss = 1.6256\n",
      "Epoch 1/50, Train iteration 121/164: Loss = 1.6385\n",
      "Epoch 1/50, Train iteration 122/164: Loss = 1.6517\n",
      "Epoch 1/50, Train iteration 123/164: Loss = 1.6528\n",
      "Epoch 1/50, Train iteration 124/164: Loss = 1.6530\n",
      "Epoch 1/50, Train iteration 125/164: Loss = 1.5977\n",
      "Epoch 1/50, Train iteration 126/164: Loss = 1.5931\n",
      "Epoch 1/50, Train iteration 127/164: Loss = 1.6472\n",
      "Epoch 1/50, Train iteration 128/164: Loss = 1.5956\n",
      "Epoch 1/50, Train iteration 129/164: Loss = 1.5863\n",
      "Epoch 1/50, Train iteration 130/164: Loss = 1.6326\n",
      "Epoch 1/50, Train iteration 131/164: Loss = 1.6232\n",
      "Epoch 1/50, Train iteration 132/164: Loss = 1.5991\n",
      "Epoch 1/50, Train iteration 133/164: Loss = 1.6250\n",
      "Epoch 1/50, Train iteration 134/164: Loss = 1.5926\n",
      "Epoch 1/50, Train iteration 135/164: Loss = 1.6068\n",
      "Epoch 1/50, Train iteration 136/164: Loss = 1.6520\n",
      "Epoch 1/50, Train iteration 137/164: Loss = 1.6254\n",
      "Epoch 1/50, Train iteration 138/164: Loss = 1.6121\n",
      "Epoch 1/50, Train iteration 139/164: Loss = 1.6353\n",
      "Epoch 1/50, Train iteration 140/164: Loss = 1.6106\n",
      "Epoch 1/50, Train iteration 141/164: Loss = 1.6253\n",
      "Epoch 1/50, Train iteration 142/164: Loss = 1.6249\n",
      "Epoch 1/50, Train iteration 143/164: Loss = 1.6022\n",
      "Epoch 1/50, Train iteration 144/164: Loss = 1.6007\n",
      "Epoch 1/50, Train iteration 145/164: Loss = 1.5993\n",
      "Epoch 1/50, Train iteration 146/164: Loss = 1.6034\n",
      "Epoch 1/50, Train iteration 147/164: Loss = 1.6355\n",
      "Epoch 1/50, Train iteration 148/164: Loss = 1.6206\n",
      "Epoch 1/50, Train iteration 149/164: Loss = 1.5970\n",
      "Epoch 1/50, Train iteration 150/164: Loss = 1.6418\n",
      "Epoch 1/50, Train iteration 151/164: Loss = 1.6153\n",
      "Epoch 1/50, Train iteration 152/164: Loss = 1.6007\n",
      "Epoch 1/50, Train iteration 153/164: Loss = 1.6463\n",
      "Epoch 1/50, Train iteration 154/164: Loss = 1.6222\n",
      "Epoch 1/50, Train iteration 155/164: Loss = 1.6022\n",
      "Epoch 1/50, Train iteration 156/164: Loss = 1.6082\n",
      "Epoch 1/50, Train iteration 157/164: Loss = 1.5729\n",
      "Epoch 1/50, Train iteration 158/164: Loss = 1.6099\n",
      "Epoch 1/50, Train iteration 159/164: Loss = 1.6146\n",
      "Epoch 1/50, Train iteration 160/164: Loss = 1.6221\n",
      "Epoch 1/50, Train iteration 161/164: Loss = 1.6266\n",
      "Epoch 1/50, Train iteration 162/164: Loss = 1.5992\n",
      "Epoch 1/50, Train iteration 163/164: Loss = 1.6103\n",
      "Epoch 1/50, Train iteration 164/164: Loss = 1.5857\n",
      "Epoch 1/50, Val iteration 1/27: Loss = 1.6119\n",
      "Epoch 1/50, Val iteration 2/27: Loss = 1.6138\n",
      "Epoch 1/50, Val iteration 3/27: Loss = 1.6105\n",
      "Epoch 1/50, Val iteration 4/27: Loss = 1.6060\n",
      "Epoch 1/50, Val iteration 5/27: Loss = 1.6066\n",
      "Epoch 1/50, Val iteration 6/27: Loss = 1.6118\n",
      "Epoch 1/50, Val iteration 7/27: Loss = 1.5993\n",
      "Epoch 1/50, Val iteration 8/27: Loss = 1.6113\n",
      "Epoch 1/50, Val iteration 9/27: Loss = 1.5989\n",
      "Epoch 1/50, Val iteration 10/27: Loss = 1.5993\n",
      "Epoch 1/50, Val iteration 11/27: Loss = 1.5964\n",
      "Epoch 1/50, Val iteration 12/27: Loss = 1.6021\n",
      "Epoch 1/50, Val iteration 13/27: Loss = 1.5984\n",
      "Epoch 1/50, Val iteration 14/27: Loss = 1.6083\n",
      "Epoch 1/50, Val iteration 15/27: Loss = 1.6021\n",
      "Epoch 1/50, Val iteration 16/27: Loss = 1.6071\n",
      "Epoch 1/50, Val iteration 17/27: Loss = 1.6052\n",
      "Epoch 1/50, Val iteration 18/27: Loss = 1.6014\n",
      "Epoch 1/50, Val iteration 19/27: Loss = 1.5977\n",
      "Epoch 1/50, Val iteration 20/27: Loss = 1.5993\n",
      "Epoch 1/50, Val iteration 21/27: Loss = 1.6021\n",
      "Epoch 1/50, Val iteration 22/27: Loss = 1.6052\n",
      "Epoch 1/50, Val iteration 23/27: Loss = 1.5804\n",
      "Epoch 1/50, Val iteration 24/27: Loss = 1.6035\n",
      "Epoch 1/50, Val iteration 25/27: Loss = 1.5988\n",
      "Epoch 1/50, Val iteration 26/27: Loss = 1.6112\n",
      "Epoch 1/50, Val iteration 27/27: Loss = 1.6007\n",
      "Epoch 1/50: Train Loss = 1.6279, Val Loss = 1.6033\n",
      "Current learning rate: 0.0001\n",
      "Epoch 2/50, Train iteration 1/164: Loss = 1.6020\n",
      "Epoch 2/50, Train iteration 2/164: Loss = 1.6008\n",
      "Epoch 2/50, Train iteration 3/164: Loss = 1.5807\n",
      "Epoch 2/50, Train iteration 4/164: Loss = 1.5921\n",
      "Epoch 2/50, Train iteration 5/164: Loss = 1.6301\n",
      "Epoch 2/50, Train iteration 6/164: Loss = 1.6307\n",
      "Epoch 2/50, Train iteration 7/164: Loss = 1.6154\n",
      "Epoch 2/50, Train iteration 8/164: Loss = 1.6152\n",
      "Epoch 2/50, Train iteration 9/164: Loss = 1.5789\n",
      "Epoch 2/50, Train iteration 10/164: Loss = 1.6144\n",
      "Epoch 2/50, Train iteration 11/164: Loss = 1.5779\n",
      "Epoch 2/50, Train iteration 12/164: Loss = 1.6335\n",
      "Epoch 2/50, Train iteration 13/164: Loss = 1.5977\n",
      "Epoch 2/50, Train iteration 14/164: Loss = 1.5923\n",
      "Epoch 2/50, Train iteration 15/164: Loss = 1.6319\n",
      "Epoch 2/50, Train iteration 16/164: Loss = 1.6160\n",
      "Epoch 2/50, Train iteration 17/164: Loss = 1.6093\n",
      "Epoch 2/50, Train iteration 18/164: Loss = 1.5835\n",
      "Epoch 2/50, Train iteration 19/164: Loss = 1.6048\n",
      "Epoch 2/50, Train iteration 20/164: Loss = 1.6204\n",
      "Epoch 2/50, Train iteration 21/164: Loss = 1.6123\n",
      "Epoch 2/50, Train iteration 22/164: Loss = 1.6097\n",
      "Epoch 2/50, Train iteration 23/164: Loss = 1.6411\n",
      "Epoch 2/50, Train iteration 24/164: Loss = 1.6003\n",
      "Epoch 2/50, Train iteration 25/164: Loss = 1.6218\n",
      "Epoch 2/50, Train iteration 26/164: Loss = 1.6343\n",
      "Epoch 2/50, Train iteration 27/164: Loss = 1.6189\n",
      "Epoch 2/50, Train iteration 28/164: Loss = 1.6055\n",
      "Epoch 2/50, Train iteration 29/164: Loss = 1.6052\n",
      "Epoch 2/50, Train iteration 30/164: Loss = 1.6455\n",
      "Epoch 2/50, Train iteration 31/164: Loss = 1.5901\n",
      "Epoch 2/50, Train iteration 32/164: Loss = 1.6255\n",
      "Epoch 2/50, Train iteration 33/164: Loss = 1.6008\n",
      "Epoch 2/50, Train iteration 34/164: Loss = 1.6069\n",
      "Epoch 2/50, Train iteration 35/164: Loss = 1.6070\n",
      "Epoch 2/50, Train iteration 36/164: Loss = 1.6385\n",
      "Epoch 2/50, Train iteration 37/164: Loss = 1.6047\n",
      "Epoch 2/50, Train iteration 38/164: Loss = 1.5798\n",
      "Epoch 2/50, Train iteration 39/164: Loss = 1.5846\n",
      "Epoch 2/50, Train iteration 40/164: Loss = 1.5995\n",
      "Epoch 2/50, Train iteration 41/164: Loss = 1.5797\n",
      "Epoch 2/50, Train iteration 42/164: Loss = 1.6055\n",
      "Epoch 2/50, Train iteration 43/164: Loss = 1.6158\n",
      "Epoch 2/50, Train iteration 44/164: Loss = 1.5892\n",
      "Epoch 2/50, Train iteration 45/164: Loss = 1.6033\n",
      "Epoch 2/50, Train iteration 46/164: Loss = 1.6464\n",
      "Epoch 2/50, Train iteration 47/164: Loss = 1.6538\n",
      "Epoch 2/50, Train iteration 48/164: Loss = 1.6343\n",
      "Epoch 2/50, Train iteration 49/164: Loss = 1.5951\n",
      "Epoch 2/50, Train iteration 50/164: Loss = 1.6434\n",
      "Epoch 2/50, Train iteration 51/164: Loss = 1.6124\n",
      "Epoch 2/50, Train iteration 52/164: Loss = 1.5993\n",
      "Epoch 2/50, Train iteration 53/164: Loss = 1.6148\n",
      "Epoch 2/50, Train iteration 54/164: Loss = 1.5847\n",
      "Epoch 2/50, Train iteration 55/164: Loss = 1.5964\n",
      "Epoch 2/50, Train iteration 56/164: Loss = 1.6117\n",
      "Epoch 2/50, Train iteration 57/164: Loss = 1.6293\n",
      "Epoch 2/50, Train iteration 58/164: Loss = 1.6124\n",
      "Epoch 2/50, Train iteration 59/164: Loss = 1.5994\n",
      "Epoch 2/50, Train iteration 60/164: Loss = 1.6544\n",
      "Epoch 2/50, Train iteration 61/164: Loss = 1.6069\n",
      "Epoch 2/50, Train iteration 62/164: Loss = 1.5989\n",
      "Epoch 2/50, Train iteration 63/164: Loss = 1.6233\n",
      "Epoch 2/50, Train iteration 64/164: Loss = 1.5944\n",
      "Epoch 2/50, Train iteration 65/164: Loss = 1.6229\n",
      "Epoch 2/50, Train iteration 66/164: Loss = 1.6012\n",
      "Epoch 2/50, Train iteration 67/164: Loss = 1.5953\n",
      "Epoch 2/50, Train iteration 68/164: Loss = 1.6085\n",
      "Epoch 2/50, Train iteration 69/164: Loss = 1.5826\n",
      "Epoch 2/50, Train iteration 70/164: Loss = 1.5951\n",
      "Epoch 2/50, Train iteration 71/164: Loss = 1.6292\n",
      "Epoch 2/50, Train iteration 72/164: Loss = 1.6296\n",
      "Epoch 2/50, Train iteration 73/164: Loss = 1.6141\n",
      "Epoch 2/50, Train iteration 74/164: Loss = 1.6032\n",
      "Epoch 2/50, Train iteration 75/164: Loss = 1.5909\n",
      "Epoch 2/50, Train iteration 76/164: Loss = 1.5861\n",
      "Epoch 2/50, Train iteration 77/164: Loss = 1.5883\n",
      "Epoch 2/50, Train iteration 78/164: Loss = 1.5927\n",
      "Epoch 2/50, Train iteration 79/164: Loss = 1.5983\n",
      "Epoch 2/50, Train iteration 80/164: Loss = 1.6233\n",
      "Epoch 2/50, Train iteration 81/164: Loss = 1.5960\n",
      "Epoch 2/50, Train iteration 82/164: Loss = 1.6158\n",
      "Epoch 2/50, Train iteration 83/164: Loss = 1.5905\n",
      "Epoch 2/50, Train iteration 84/164: Loss = 1.5532\n",
      "Epoch 2/50, Train iteration 85/164: Loss = 1.6532\n",
      "Epoch 2/50, Train iteration 86/164: Loss = 1.5636\n",
      "Epoch 2/50, Train iteration 87/164: Loss = 1.5959\n",
      "Epoch 2/50, Train iteration 88/164: Loss = 1.6086\n",
      "Epoch 2/50, Train iteration 89/164: Loss = 1.6141\n",
      "Epoch 2/50, Train iteration 90/164: Loss = 1.5722\n",
      "Epoch 2/50, Train iteration 91/164: Loss = 1.6295\n",
      "Epoch 2/50, Train iteration 92/164: Loss = 1.5831\n",
      "Epoch 2/50, Train iteration 93/164: Loss = 1.6108\n",
      "Epoch 2/50, Train iteration 94/164: Loss = 1.5880\n",
      "Epoch 2/50, Train iteration 95/164: Loss = 1.5887\n",
      "Epoch 2/50, Train iteration 96/164: Loss = 1.5675\n",
      "Epoch 2/50, Train iteration 97/164: Loss = 1.6062\n",
      "Epoch 2/50, Train iteration 98/164: Loss = 1.6204\n",
      "Epoch 2/50, Train iteration 99/164: Loss = 1.6280\n",
      "Epoch 2/50, Train iteration 100/164: Loss = 1.6237\n",
      "Epoch 2/50, Train iteration 101/164: Loss = 1.5884\n",
      "Epoch 2/50, Train iteration 102/164: Loss = 1.5923\n",
      "Epoch 2/50, Train iteration 103/164: Loss = 1.5809\n",
      "Epoch 2/50, Train iteration 104/164: Loss = 1.5967\n",
      "Epoch 2/50, Train iteration 105/164: Loss = 1.6354\n",
      "Epoch 2/50, Train iteration 106/164: Loss = 1.6161\n",
      "Epoch 2/50, Train iteration 107/164: Loss = 1.6123\n",
      "Epoch 2/50, Train iteration 108/164: Loss = 1.6413\n",
      "Epoch 2/50, Train iteration 109/164: Loss = 1.5958\n",
      "Epoch 2/50, Train iteration 110/164: Loss = 1.5909\n",
      "Epoch 2/50, Train iteration 111/164: Loss = 1.6127\n",
      "Epoch 2/50, Train iteration 112/164: Loss = 1.6022\n",
      "Epoch 2/50, Train iteration 113/164: Loss = 1.5962\n",
      "Epoch 2/50, Train iteration 114/164: Loss = 1.5886\n",
      "Epoch 2/50, Train iteration 115/164: Loss = 1.6301\n",
      "Epoch 2/50, Train iteration 116/164: Loss = 1.6202\n",
      "Epoch 2/50, Train iteration 117/164: Loss = 1.5925\n",
      "Epoch 2/50, Train iteration 118/164: Loss = 1.6183\n",
      "Epoch 2/50, Train iteration 119/164: Loss = 1.6194\n",
      "Epoch 2/50, Train iteration 120/164: Loss = 1.6206\n",
      "Epoch 2/50, Train iteration 121/164: Loss = 1.6051\n",
      "Epoch 2/50, Train iteration 122/164: Loss = 1.6068\n",
      "Epoch 2/50, Train iteration 123/164: Loss = 1.5889\n",
      "Epoch 2/50, Train iteration 124/164: Loss = 1.5932\n",
      "Epoch 2/50, Train iteration 125/164: Loss = 1.6207\n",
      "Epoch 2/50, Train iteration 126/164: Loss = 1.5955\n",
      "Epoch 2/50, Train iteration 127/164: Loss = 1.6444\n",
      "Epoch 2/50, Train iteration 128/164: Loss = 1.6035\n",
      "Epoch 2/50, Train iteration 129/164: Loss = 1.6220\n",
      "Epoch 2/50, Train iteration 130/164: Loss = 1.5942\n",
      "Epoch 2/50, Train iteration 131/164: Loss = 1.6264\n",
      "Epoch 2/50, Train iteration 132/164: Loss = 1.6139\n",
      "Epoch 2/50, Train iteration 133/164: Loss = 1.6174\n",
      "Epoch 2/50, Train iteration 134/164: Loss = 1.5989\n",
      "Epoch 2/50, Train iteration 135/164: Loss = 1.6237\n",
      "Epoch 2/50, Train iteration 136/164: Loss = 1.6317\n",
      "Epoch 2/50, Train iteration 137/164: Loss = 1.6007\n",
      "Epoch 2/50, Train iteration 138/164: Loss = 1.6326\n",
      "Epoch 2/50, Train iteration 139/164: Loss = 1.6088\n",
      "Epoch 2/50, Train iteration 140/164: Loss = 1.6266\n",
      "Epoch 2/50, Train iteration 141/164: Loss = 1.6253\n",
      "Epoch 2/50, Train iteration 142/164: Loss = 1.5944\n",
      "Epoch 2/50, Train iteration 143/164: Loss = 1.5709\n",
      "Epoch 2/50, Train iteration 144/164: Loss = 1.6147\n",
      "Epoch 2/50, Train iteration 145/164: Loss = 1.6123\n",
      "Epoch 2/50, Train iteration 146/164: Loss = 1.6329\n",
      "Epoch 2/50, Train iteration 147/164: Loss = 1.6122\n",
      "Epoch 2/50, Train iteration 148/164: Loss = 1.5772\n",
      "Epoch 2/50, Train iteration 149/164: Loss = 1.5894\n",
      "Epoch 2/50, Train iteration 150/164: Loss = 1.6166\n",
      "Epoch 2/50, Train iteration 151/164: Loss = 1.6296\n",
      "Epoch 2/50, Train iteration 152/164: Loss = 1.6049\n",
      "Epoch 2/50, Train iteration 153/164: Loss = 1.6115\n",
      "Epoch 2/50, Train iteration 154/164: Loss = 1.6460\n",
      "Epoch 2/50, Train iteration 155/164: Loss = 1.5732\n",
      "Epoch 2/50, Train iteration 156/164: Loss = 1.6048\n",
      "Epoch 2/50, Train iteration 157/164: Loss = 1.5946\n",
      "Epoch 2/50, Train iteration 158/164: Loss = 1.6170\n",
      "Epoch 2/50, Train iteration 159/164: Loss = 1.5746\n",
      "Epoch 2/50, Train iteration 160/164: Loss = 1.6116\n",
      "Epoch 2/50, Train iteration 161/164: Loss = 1.6179\n",
      "Epoch 2/50, Train iteration 162/164: Loss = 1.6009\n",
      "Epoch 2/50, Train iteration 163/164: Loss = 1.6439\n",
      "Epoch 2/50, Train iteration 164/164: Loss = 1.6065\n",
      "Epoch 2/50, Val iteration 1/27: Loss = 1.6136\n",
      "Epoch 2/50, Val iteration 2/27: Loss = 1.6211\n",
      "Epoch 2/50, Val iteration 3/27: Loss = 1.6142\n",
      "Epoch 2/50, Val iteration 4/27: Loss = 1.6033\n",
      "Epoch 2/50, Val iteration 5/27: Loss = 1.6049\n",
      "Epoch 2/50, Val iteration 6/27: Loss = 1.6100\n",
      "Epoch 2/50, Val iteration 7/27: Loss = 1.5949\n",
      "Epoch 2/50, Val iteration 8/27: Loss = 1.6050\n",
      "Epoch 2/50, Val iteration 9/27: Loss = 1.5915\n",
      "Epoch 2/50, Val iteration 10/27: Loss = 1.5909\n",
      "Epoch 2/50, Val iteration 11/27: Loss = 1.5917\n",
      "Epoch 2/50, Val iteration 12/27: Loss = 1.5947\n",
      "Epoch 2/50, Val iteration 13/27: Loss = 1.5919\n",
      "Epoch 2/50, Val iteration 14/27: Loss = 1.6112\n",
      "Epoch 2/50, Val iteration 15/27: Loss = 1.5961\n",
      "Epoch 2/50, Val iteration 16/27: Loss = 1.6051\n",
      "Epoch 2/50, Val iteration 17/27: Loss = 1.5961\n",
      "Epoch 2/50, Val iteration 18/27: Loss = 1.5967\n",
      "Epoch 2/50, Val iteration 19/27: Loss = 1.5891\n",
      "Epoch 2/50, Val iteration 20/27: Loss = 1.5876\n",
      "Epoch 2/50, Val iteration 21/27: Loss = 1.5991\n",
      "Epoch 2/50, Val iteration 22/27: Loss = 1.6057\n",
      "Epoch 2/50, Val iteration 23/27: Loss = 1.5585\n",
      "Epoch 2/50, Val iteration 24/27: Loss = 1.5915\n",
      "Epoch 2/50, Val iteration 25/27: Loss = 1.5957\n",
      "Epoch 2/50, Val iteration 26/27: Loss = 1.6108\n",
      "Epoch 2/50, Val iteration 27/27: Loss = 1.5902\n",
      "Epoch 2/50: Train Loss = 1.6081, Val Loss = 1.5986\n",
      "Current learning rate: 0.0001\n",
      "Epoch 3/50, Train iteration 1/164: Loss = 1.5980\n",
      "Epoch 3/50, Train iteration 2/164: Loss = 1.5948\n",
      "Epoch 3/50, Train iteration 3/164: Loss = 1.5700\n",
      "Epoch 3/50, Train iteration 4/164: Loss = 1.6167\n",
      "Epoch 3/50, Train iteration 5/164: Loss = 1.6014\n",
      "Epoch 3/50, Train iteration 6/164: Loss = 1.6249\n",
      "Epoch 3/50, Train iteration 7/164: Loss = 1.6234\n",
      "Epoch 3/50, Train iteration 8/164: Loss = 1.5594\n",
      "Epoch 3/50, Train iteration 9/164: Loss = 1.6014\n",
      "Epoch 3/50, Train iteration 10/164: Loss = 1.6216\n",
      "Epoch 3/50, Train iteration 11/164: Loss = 1.6272\n",
      "Epoch 3/50, Train iteration 12/164: Loss = 1.6129\n",
      "Epoch 3/50, Train iteration 13/164: Loss = 1.5737\n",
      "Epoch 3/50, Train iteration 14/164: Loss = 1.6250\n",
      "Epoch 3/50, Train iteration 15/164: Loss = 1.6344\n",
      "Epoch 3/50, Train iteration 16/164: Loss = 1.6187\n",
      "Epoch 3/50, Train iteration 17/164: Loss = 1.5991\n",
      "Epoch 3/50, Train iteration 18/164: Loss = 1.5865\n",
      "Epoch 3/50, Train iteration 19/164: Loss = 1.5940\n",
      "Epoch 3/50, Train iteration 20/164: Loss = 1.5729\n",
      "Epoch 3/50, Train iteration 21/164: Loss = 1.6046\n",
      "Epoch 3/50, Train iteration 22/164: Loss = 1.6040\n",
      "Epoch 3/50, Train iteration 23/164: Loss = 1.5925\n",
      "Epoch 3/50, Train iteration 24/164: Loss = 1.6277\n",
      "Epoch 3/50, Train iteration 25/164: Loss = 1.5850\n",
      "Epoch 3/50, Train iteration 26/164: Loss = 1.5997\n",
      "Epoch 3/50, Train iteration 27/164: Loss = 1.5974\n",
      "Epoch 3/50, Train iteration 28/164: Loss = 1.5846\n",
      "Epoch 3/50, Train iteration 29/164: Loss = 1.6015\n",
      "Epoch 3/50, Train iteration 30/164: Loss = 1.6394\n",
      "Epoch 3/50, Train iteration 31/164: Loss = 1.5447\n",
      "Epoch 3/50, Train iteration 32/164: Loss = 1.6103\n",
      "Epoch 3/50, Train iteration 33/164: Loss = 1.6186\n",
      "Epoch 3/50, Train iteration 34/164: Loss = 1.6242\n",
      "Epoch 3/50, Train iteration 35/164: Loss = 1.5995\n",
      "Epoch 3/50, Train iteration 36/164: Loss = 1.6184\n",
      "Epoch 3/50, Train iteration 37/164: Loss = 1.5981\n",
      "Epoch 3/50, Train iteration 38/164: Loss = 1.5746\n",
      "Epoch 3/50, Train iteration 39/164: Loss = 1.6184\n",
      "Epoch 3/50, Train iteration 40/164: Loss = 1.6244\n",
      "Epoch 3/50, Train iteration 41/164: Loss = 1.6022\n",
      "Epoch 3/50, Train iteration 42/164: Loss = 1.6217\n",
      "Epoch 3/50, Train iteration 43/164: Loss = 1.6308\n",
      "Epoch 3/50, Train iteration 44/164: Loss = 1.5538\n",
      "Epoch 3/50, Train iteration 45/164: Loss = 1.5660\n",
      "Epoch 3/50, Train iteration 46/164: Loss = 1.6265\n",
      "Epoch 3/50, Train iteration 47/164: Loss = 1.6299\n",
      "Epoch 3/50, Train iteration 48/164: Loss = 1.5877\n",
      "Epoch 3/50, Train iteration 49/164: Loss = 1.5902\n",
      "Epoch 3/50, Train iteration 50/164: Loss = 1.6483\n",
      "Epoch 3/50, Train iteration 51/164: Loss = 1.5430\n",
      "Epoch 3/50, Train iteration 52/164: Loss = 1.6029\n",
      "Epoch 3/50, Train iteration 53/164: Loss = 1.6103\n",
      "Epoch 3/50, Train iteration 54/164: Loss = 1.6244\n",
      "Epoch 3/50, Train iteration 55/164: Loss = 1.5846\n",
      "Epoch 3/50, Train iteration 56/164: Loss = 1.6220\n",
      "Epoch 3/50, Train iteration 57/164: Loss = 1.5784\n",
      "Epoch 3/50, Train iteration 58/164: Loss = 1.6177\n",
      "Epoch 3/50, Train iteration 59/164: Loss = 1.6085\n",
      "Epoch 3/50, Train iteration 60/164: Loss = 1.5768\n",
      "Epoch 3/50, Train iteration 61/164: Loss = 1.5574\n",
      "Epoch 3/50, Train iteration 62/164: Loss = 1.5734\n",
      "Epoch 3/50, Train iteration 63/164: Loss = 1.6059\n",
      "Epoch 3/50, Train iteration 64/164: Loss = 1.6263\n",
      "Epoch 3/50, Train iteration 65/164: Loss = 1.5843\n",
      "Epoch 3/50, Train iteration 66/164: Loss = 1.5928\n",
      "Epoch 3/50, Train iteration 67/164: Loss = 1.5937\n",
      "Epoch 3/50, Train iteration 68/164: Loss = 1.5928\n",
      "Epoch 3/50, Train iteration 69/164: Loss = 1.6071\n",
      "Epoch 3/50, Train iteration 70/164: Loss = 1.5529\n",
      "Epoch 3/50, Train iteration 71/164: Loss = 1.6294\n",
      "Epoch 3/50, Train iteration 72/164: Loss = 1.6166\n",
      "Epoch 3/50, Train iteration 73/164: Loss = 1.5827\n",
      "Epoch 3/50, Train iteration 74/164: Loss = 1.6445\n",
      "Epoch 3/50, Train iteration 75/164: Loss = 1.5628\n",
      "Epoch 3/50, Train iteration 76/164: Loss = 1.5837\n",
      "Epoch 3/50, Train iteration 77/164: Loss = 1.5996\n",
      "Epoch 3/50, Train iteration 78/164: Loss = 1.5877\n",
      "Epoch 3/50, Train iteration 79/164: Loss = 1.5988\n",
      "Epoch 3/50, Train iteration 80/164: Loss = 1.6175\n",
      "Epoch 3/50, Train iteration 81/164: Loss = 1.6095\n",
      "Epoch 3/50, Train iteration 82/164: Loss = 1.6024\n",
      "Epoch 3/50, Train iteration 83/164: Loss = 1.5938\n",
      "Epoch 3/50, Train iteration 84/164: Loss = 1.5904\n",
      "Epoch 3/50, Train iteration 85/164: Loss = 1.6658\n",
      "Epoch 3/50, Train iteration 86/164: Loss = 1.5448\n",
      "Epoch 3/50, Train iteration 87/164: Loss = 1.6133\n",
      "Epoch 3/50, Train iteration 88/164: Loss = 1.6557\n",
      "Epoch 3/50, Train iteration 89/164: Loss = 1.5696\n",
      "Epoch 3/50, Train iteration 90/164: Loss = 1.5855\n",
      "Epoch 3/50, Train iteration 91/164: Loss = 1.5985\n",
      "Epoch 3/50, Train iteration 92/164: Loss = 1.6144\n",
      "Epoch 3/50, Train iteration 93/164: Loss = 1.5916\n",
      "Epoch 3/50, Train iteration 94/164: Loss = 1.5693\n",
      "Epoch 3/50, Train iteration 95/164: Loss = 1.5820\n",
      "Epoch 3/50, Train iteration 96/164: Loss = 1.5954\n",
      "Epoch 3/50, Train iteration 97/164: Loss = 1.5595\n",
      "Epoch 3/50, Train iteration 98/164: Loss = 1.6318\n",
      "Epoch 3/50, Train iteration 99/164: Loss = 1.5804\n",
      "Epoch 3/50, Train iteration 100/164: Loss = 1.5938\n",
      "Epoch 3/50, Train iteration 101/164: Loss = 1.5689\n",
      "Epoch 3/50, Train iteration 102/164: Loss = 1.6239\n",
      "Epoch 3/50, Train iteration 103/164: Loss = 1.5876\n",
      "Epoch 3/50, Train iteration 104/164: Loss = 1.5831\n",
      "Epoch 3/50, Train iteration 105/164: Loss = 1.6282\n",
      "Epoch 3/50, Train iteration 106/164: Loss = 1.5880\n",
      "Epoch 3/50, Train iteration 107/164: Loss = 1.6065\n",
      "Epoch 3/50, Train iteration 108/164: Loss = 1.6129\n",
      "Epoch 3/50, Train iteration 109/164: Loss = 1.6437\n",
      "Epoch 3/50, Train iteration 110/164: Loss = 1.5239\n",
      "Epoch 3/50, Train iteration 111/164: Loss = 1.6031\n",
      "Epoch 3/50, Train iteration 112/164: Loss = 1.5967\n",
      "Epoch 3/50, Train iteration 113/164: Loss = 1.5752\n",
      "Epoch 3/50, Train iteration 114/164: Loss = 1.5694\n",
      "Epoch 3/50, Train iteration 115/164: Loss = 1.6295\n",
      "Epoch 3/50, Train iteration 116/164: Loss = 1.6185\n",
      "Epoch 3/50, Train iteration 117/164: Loss = 1.5723\n",
      "Epoch 3/50, Train iteration 118/164: Loss = 1.5986\n",
      "Epoch 3/50, Train iteration 119/164: Loss = 1.5940\n",
      "Epoch 3/50, Train iteration 120/164: Loss = 1.6012\n",
      "Epoch 3/50, Train iteration 121/164: Loss = 1.6176\n",
      "Epoch 3/50, Train iteration 122/164: Loss = 1.5249\n",
      "Epoch 3/50, Train iteration 123/164: Loss = 1.6219\n",
      "Epoch 3/50, Train iteration 124/164: Loss = 1.5872\n",
      "Epoch 3/50, Train iteration 125/164: Loss = 1.6120\n",
      "Epoch 3/50, Train iteration 126/164: Loss = 1.5812\n",
      "Epoch 3/50, Train iteration 127/164: Loss = 1.6518\n",
      "Epoch 3/50, Train iteration 128/164: Loss = 1.5922\n",
      "Epoch 3/50, Train iteration 129/164: Loss = 1.6435\n",
      "Epoch 3/50, Train iteration 130/164: Loss = 1.5917\n",
      "Epoch 3/50, Train iteration 131/164: Loss = 1.5918\n",
      "Epoch 3/50, Train iteration 132/164: Loss = 1.6042\n",
      "Epoch 3/50, Train iteration 133/164: Loss = 1.6038\n",
      "Epoch 3/50, Train iteration 134/164: Loss = 1.5683\n",
      "Epoch 3/50, Train iteration 135/164: Loss = 1.6269\n",
      "Epoch 3/50, Train iteration 136/164: Loss = 1.5996\n",
      "Epoch 3/50, Train iteration 137/164: Loss = 1.6055\n",
      "Epoch 3/50, Train iteration 138/164: Loss = 1.6290\n",
      "Epoch 3/50, Train iteration 139/164: Loss = 1.5434\n",
      "Epoch 3/50, Train iteration 140/164: Loss = 1.5765\n",
      "Epoch 3/50, Train iteration 141/164: Loss = 1.6228\n",
      "Epoch 3/50, Train iteration 142/164: Loss = 1.6004\n",
      "Epoch 3/50, Train iteration 143/164: Loss = 1.5747\n",
      "Epoch 3/50, Train iteration 144/164: Loss = 1.6109\n",
      "Epoch 3/50, Train iteration 145/164: Loss = 1.5720\n",
      "Epoch 3/50, Train iteration 146/164: Loss = 1.5399\n",
      "Epoch 3/50, Train iteration 147/164: Loss = 1.5782\n",
      "Epoch 3/50, Train iteration 148/164: Loss = 1.5812\n",
      "Epoch 3/50, Train iteration 149/164: Loss = 1.5923\n",
      "Epoch 3/50, Train iteration 150/164: Loss = 1.6389\n",
      "Epoch 3/50, Train iteration 151/164: Loss = 1.6265\n",
      "Epoch 3/50, Train iteration 152/164: Loss = 1.5212\n",
      "Epoch 3/50, Train iteration 153/164: Loss = 1.6114\n",
      "Epoch 3/50, Train iteration 154/164: Loss = 1.6302\n",
      "Epoch 3/50, Train iteration 155/164: Loss = 1.6092\n",
      "Epoch 3/50, Train iteration 156/164: Loss = 1.5716\n",
      "Epoch 3/50, Train iteration 157/164: Loss = 1.5966\n",
      "Epoch 3/50, Train iteration 158/164: Loss = 1.5893\n",
      "Epoch 3/50, Train iteration 159/164: Loss = 1.6376\n",
      "Epoch 3/50, Train iteration 160/164: Loss = 1.6238\n",
      "Epoch 3/50, Train iteration 161/164: Loss = 1.6177\n",
      "Epoch 3/50, Train iteration 162/164: Loss = 1.6250\n",
      "Epoch 3/50, Train iteration 163/164: Loss = 1.6002\n",
      "Epoch 3/50, Train iteration 164/164: Loss = 1.6001\n",
      "Epoch 3/50, Val iteration 1/27: Loss = 1.6141\n",
      "Epoch 3/50, Val iteration 2/27: Loss = 1.6278\n",
      "Epoch 3/50, Val iteration 3/27: Loss = 1.6171\n",
      "Epoch 3/50, Val iteration 4/27: Loss = 1.5927\n",
      "Epoch 3/50, Val iteration 5/27: Loss = 1.6010\n",
      "Epoch 3/50, Val iteration 6/27: Loss = 1.6068\n",
      "Epoch 3/50, Val iteration 7/27: Loss = 1.5744\n",
      "Epoch 3/50, Val iteration 8/27: Loss = 1.6008\n",
      "Epoch 3/50, Val iteration 9/27: Loss = 1.5733\n",
      "Epoch 3/50, Val iteration 10/27: Loss = 1.5846\n",
      "Epoch 3/50, Val iteration 11/27: Loss = 1.5792\n",
      "Epoch 3/50, Val iteration 12/27: Loss = 1.5795\n",
      "Epoch 3/50, Val iteration 13/27: Loss = 1.5877\n",
      "Epoch 3/50, Val iteration 14/27: Loss = 1.6037\n",
      "Epoch 3/50, Val iteration 15/27: Loss = 1.5910\n",
      "Epoch 3/50, Val iteration 16/27: Loss = 1.5951\n",
      "Epoch 3/50, Val iteration 17/27: Loss = 1.5839\n",
      "Epoch 3/50, Val iteration 18/27: Loss = 1.5864\n",
      "Epoch 3/50, Val iteration 19/27: Loss = 1.5815\n",
      "Epoch 3/50, Val iteration 20/27: Loss = 1.5894\n",
      "Epoch 3/50, Val iteration 21/27: Loss = 1.6016\n",
      "Epoch 3/50, Val iteration 22/27: Loss = 1.5994\n",
      "Epoch 3/50, Val iteration 23/27: Loss = 1.5256\n",
      "Epoch 3/50, Val iteration 24/27: Loss = 1.5836\n",
      "Epoch 3/50, Val iteration 25/27: Loss = 1.5961\n",
      "Epoch 3/50, Val iteration 26/27: Loss = 1.6123\n",
      "Epoch 3/50, Val iteration 27/27: Loss = 1.5804\n",
      "Epoch 3/50: Train Loss = 1.5993, Val Loss = 1.5914\n",
      "Current learning rate: 0.0001\n",
      "Epoch 4/50, Train iteration 1/164: Loss = 1.5731\n",
      "Epoch 4/50, Train iteration 2/164: Loss = 1.5784\n",
      "Epoch 4/50, Train iteration 3/164: Loss = 1.5990\n",
      "Epoch 4/50, Train iteration 4/164: Loss = 1.6064\n",
      "Epoch 4/50, Train iteration 5/164: Loss = 1.5939\n",
      "Epoch 4/50, Train iteration 6/164: Loss = 1.6166\n",
      "Epoch 4/50, Train iteration 7/164: Loss = 1.6379\n",
      "Epoch 4/50, Train iteration 8/164: Loss = 1.5369\n",
      "Epoch 4/50, Train iteration 9/164: Loss = 1.6008\n",
      "Epoch 4/50, Train iteration 10/164: Loss = 1.6047\n",
      "Epoch 4/50, Train iteration 11/164: Loss = 1.6140\n",
      "Epoch 4/50, Train iteration 12/164: Loss = 1.6142\n",
      "Epoch 4/50, Train iteration 13/164: Loss = 1.5072\n",
      "Epoch 4/50, Train iteration 14/164: Loss = 1.5732\n",
      "Epoch 4/50, Train iteration 15/164: Loss = 1.6124\n",
      "Epoch 4/50, Train iteration 16/164: Loss = 1.6024\n",
      "Epoch 4/50, Train iteration 17/164: Loss = 1.5665\n",
      "Epoch 4/50, Train iteration 18/164: Loss = 1.5516\n",
      "Epoch 4/50, Train iteration 19/164: Loss = 1.6301\n",
      "Epoch 4/50, Train iteration 20/164: Loss = 1.5758\n",
      "Epoch 4/50, Train iteration 21/164: Loss = 1.5794\n",
      "Epoch 4/50, Train iteration 22/164: Loss = 1.6101\n",
      "Epoch 4/50, Train iteration 23/164: Loss = 1.5913\n",
      "Epoch 4/50, Train iteration 24/164: Loss = 1.6176\n",
      "Epoch 4/50, Train iteration 25/164: Loss = 1.6240\n",
      "Epoch 4/50, Train iteration 26/164: Loss = 1.6091\n",
      "Epoch 4/50, Train iteration 27/164: Loss = 1.6098\n",
      "Epoch 4/50, Train iteration 28/164: Loss = 1.5988\n",
      "Epoch 4/50, Train iteration 29/164: Loss = 1.6022\n",
      "Epoch 4/50, Train iteration 30/164: Loss = 1.6481\n",
      "Epoch 4/50, Train iteration 31/164: Loss = 1.5705\n",
      "Epoch 4/50, Train iteration 32/164: Loss = 1.5708\n",
      "Epoch 4/50, Train iteration 33/164: Loss = 1.5987\n",
      "Epoch 4/50, Train iteration 34/164: Loss = 1.6197\n",
      "Epoch 4/50, Train iteration 35/164: Loss = 1.5721\n",
      "Epoch 4/50, Train iteration 36/164: Loss = 1.6060\n",
      "Epoch 4/50, Train iteration 37/164: Loss = 1.6063\n",
      "Epoch 4/50, Train iteration 38/164: Loss = 1.5935\n",
      "Epoch 4/50, Train iteration 39/164: Loss = 1.6197\n",
      "Epoch 4/50, Train iteration 40/164: Loss = 1.5965\n",
      "Epoch 4/50, Train iteration 41/164: Loss = 1.5882\n",
      "Epoch 4/50, Train iteration 42/164: Loss = 1.5968\n",
      "Epoch 4/50, Train iteration 43/164: Loss = 1.6255\n",
      "Epoch 4/50, Train iteration 44/164: Loss = 1.6010\n",
      "Epoch 4/50, Train iteration 45/164: Loss = 1.5887\n",
      "Epoch 4/50, Train iteration 46/164: Loss = 1.6369\n",
      "Epoch 4/50, Train iteration 47/164: Loss = 1.6281\n",
      "Epoch 4/50, Train iteration 48/164: Loss = 1.5911\n",
      "Epoch 4/50, Train iteration 49/164: Loss = 1.5896\n",
      "Epoch 4/50, Train iteration 50/164: Loss = 1.6217\n",
      "Epoch 4/50, Train iteration 51/164: Loss = 1.5411\n",
      "Epoch 4/50, Train iteration 52/164: Loss = 1.5378\n",
      "Epoch 4/50, Train iteration 53/164: Loss = 1.6039\n",
      "Epoch 4/50, Train iteration 54/164: Loss = 1.5688\n",
      "Epoch 4/50, Train iteration 55/164: Loss = 1.5821\n",
      "Epoch 4/50, Train iteration 56/164: Loss = 1.5770\n",
      "Epoch 4/50, Train iteration 57/164: Loss = 1.5637\n",
      "Epoch 4/50, Train iteration 58/164: Loss = 1.6204\n",
      "Epoch 4/50, Train iteration 59/164: Loss = 1.6490\n",
      "Epoch 4/50, Train iteration 60/164: Loss = 1.6095\n",
      "Epoch 4/50, Train iteration 61/164: Loss = 1.5737\n",
      "Epoch 4/50, Train iteration 62/164: Loss = 1.5691\n",
      "Epoch 4/50, Train iteration 63/164: Loss = 1.5897\n",
      "Epoch 4/50, Train iteration 64/164: Loss = 1.5878\n",
      "Epoch 4/50, Train iteration 65/164: Loss = 1.5570\n",
      "Epoch 4/50, Train iteration 66/164: Loss = 1.6050\n",
      "Epoch 4/50, Train iteration 67/164: Loss = 1.6050\n",
      "Epoch 4/50, Train iteration 68/164: Loss = 1.5738\n",
      "Epoch 4/50, Train iteration 69/164: Loss = 1.5833\n",
      "Epoch 4/50, Train iteration 70/164: Loss = 1.6000\n",
      "Epoch 4/50, Train iteration 71/164: Loss = 1.6144\n",
      "Epoch 4/50, Train iteration 72/164: Loss = 1.6044\n",
      "Epoch 4/50, Train iteration 73/164: Loss = 1.5908\n",
      "Epoch 4/50, Train iteration 74/164: Loss = 1.6112\n",
      "Epoch 4/50, Train iteration 75/164: Loss = 1.5763\n",
      "Epoch 4/50, Train iteration 76/164: Loss = 1.5641\n",
      "Epoch 4/50, Train iteration 77/164: Loss = 1.6102\n",
      "Epoch 4/50, Train iteration 78/164: Loss = 1.5892\n",
      "Epoch 4/50, Train iteration 79/164: Loss = 1.5805\n",
      "Epoch 4/50, Train iteration 80/164: Loss = 1.6146\n",
      "Epoch 4/50, Train iteration 81/164: Loss = 1.5570\n",
      "Epoch 4/50, Train iteration 82/164: Loss = 1.5898\n",
      "Epoch 4/50, Train iteration 83/164: Loss = 1.6010\n",
      "Epoch 4/50, Train iteration 84/164: Loss = 1.6012\n",
      "Epoch 4/50, Train iteration 85/164: Loss = 1.6544\n",
      "Epoch 4/50, Train iteration 86/164: Loss = 1.5094\n",
      "Epoch 4/50, Train iteration 87/164: Loss = 1.5803\n",
      "Epoch 4/50, Train iteration 88/164: Loss = 1.6336\n",
      "Epoch 4/50, Train iteration 89/164: Loss = 1.5686\n",
      "Epoch 4/50, Train iteration 90/164: Loss = 1.5781\n",
      "Epoch 4/50, Train iteration 91/164: Loss = 1.6166\n",
      "Epoch 4/50, Train iteration 92/164: Loss = 1.5847\n",
      "Epoch 4/50, Train iteration 93/164: Loss = 1.6136\n",
      "Epoch 4/50, Train iteration 94/164: Loss = 1.5870\n",
      "Epoch 4/50, Train iteration 95/164: Loss = 1.5746\n",
      "Epoch 4/50, Train iteration 96/164: Loss = 1.6154\n",
      "Epoch 4/50, Train iteration 97/164: Loss = 1.5607\n",
      "Epoch 4/50, Train iteration 98/164: Loss = 1.5761\n",
      "Epoch 4/50, Train iteration 99/164: Loss = 1.5962\n",
      "Epoch 4/50, Train iteration 100/164: Loss = 1.6104\n",
      "Epoch 4/50, Train iteration 101/164: Loss = 1.5229\n",
      "Epoch 4/50, Train iteration 102/164: Loss = 1.5921\n",
      "Epoch 4/50, Train iteration 103/164: Loss = 1.6287\n",
      "Epoch 4/50, Train iteration 104/164: Loss = 1.5613\n",
      "Epoch 4/50, Train iteration 105/164: Loss = 1.6012\n",
      "Epoch 4/50, Train iteration 106/164: Loss = 1.6077\n",
      "Epoch 4/50, Train iteration 107/164: Loss = 1.5867\n",
      "Epoch 4/50, Train iteration 108/164: Loss = 1.6149\n",
      "Epoch 4/50, Train iteration 109/164: Loss = 1.6464\n",
      "Epoch 4/50, Train iteration 110/164: Loss = 1.5295\n",
      "Epoch 4/50, Train iteration 111/164: Loss = 1.6091\n",
      "Epoch 4/50, Train iteration 112/164: Loss = 1.5903\n",
      "Epoch 4/50, Train iteration 113/164: Loss = 1.5999\n",
      "Epoch 4/50, Train iteration 114/164: Loss = 1.5782\n",
      "Epoch 4/50, Train iteration 115/164: Loss = 1.5933\n",
      "Epoch 4/50, Train iteration 116/164: Loss = 1.5747\n",
      "Epoch 4/50, Train iteration 117/164: Loss = 1.5453\n",
      "Epoch 4/50, Train iteration 118/164: Loss = 1.6156\n",
      "Epoch 4/50, Train iteration 119/164: Loss = 1.5765\n",
      "Epoch 4/50, Train iteration 120/164: Loss = 1.5967\n",
      "Epoch 4/50, Train iteration 121/164: Loss = 1.5962\n",
      "Epoch 4/50, Train iteration 122/164: Loss = 1.5580\n",
      "Epoch 4/50, Train iteration 123/164: Loss = 1.5754\n",
      "Epoch 4/50, Train iteration 124/164: Loss = 1.5714\n",
      "Epoch 4/50, Train iteration 125/164: Loss = 1.5824\n",
      "Epoch 4/50, Train iteration 126/164: Loss = 1.5480\n",
      "Epoch 4/50, Train iteration 127/164: Loss = 1.5976\n",
      "Epoch 4/50, Train iteration 128/164: Loss = 1.5894\n",
      "Epoch 4/50, Train iteration 129/164: Loss = 1.6464\n",
      "Epoch 4/50, Train iteration 130/164: Loss = 1.5836\n",
      "Epoch 4/50, Train iteration 131/164: Loss = 1.5935\n",
      "Epoch 4/50, Train iteration 132/164: Loss = 1.5920\n",
      "Epoch 4/50, Train iteration 133/164: Loss = 1.6315\n",
      "Epoch 4/50, Train iteration 134/164: Loss = 1.5905\n",
      "Epoch 4/50, Train iteration 135/164: Loss = 1.6222\n",
      "Epoch 4/50, Train iteration 136/164: Loss = 1.6116\n",
      "Epoch 4/50, Train iteration 137/164: Loss = 1.6081\n",
      "Epoch 4/50, Train iteration 138/164: Loss = 1.6170\n",
      "Epoch 4/50, Train iteration 139/164: Loss = 1.5996\n",
      "Epoch 4/50, Train iteration 140/164: Loss = 1.5874\n",
      "Epoch 4/50, Train iteration 141/164: Loss = 1.5979\n",
      "Epoch 4/50, Train iteration 142/164: Loss = 1.5828\n",
      "Epoch 4/50, Train iteration 143/164: Loss = 1.5505\n",
      "Epoch 4/50, Train iteration 144/164: Loss = 1.6000\n",
      "Epoch 4/50, Train iteration 145/164: Loss = 1.5752\n",
      "Epoch 4/50, Train iteration 146/164: Loss = 1.5722\n",
      "Epoch 4/50, Train iteration 147/164: Loss = 1.5939\n",
      "Epoch 4/50, Train iteration 148/164: Loss = 1.5562\n",
      "Epoch 4/50, Train iteration 149/164: Loss = 1.6034\n",
      "Epoch 4/50, Train iteration 150/164: Loss = 1.6134\n",
      "Epoch 4/50, Train iteration 151/164: Loss = 1.6120\n",
      "Epoch 4/50, Train iteration 152/164: Loss = 1.5707\n",
      "Epoch 4/50, Train iteration 153/164: Loss = 1.5786\n",
      "Epoch 4/50, Train iteration 154/164: Loss = 1.6145\n",
      "Epoch 4/50, Train iteration 155/164: Loss = 1.5770\n",
      "Epoch 4/50, Train iteration 156/164: Loss = 1.6160\n",
      "Epoch 4/50, Train iteration 157/164: Loss = 1.5725\n",
      "Epoch 4/50, Train iteration 158/164: Loss = 1.6297\n",
      "Epoch 4/50, Train iteration 159/164: Loss = 1.6248\n",
      "Epoch 4/50, Train iteration 160/164: Loss = 1.6038\n",
      "Epoch 4/50, Train iteration 161/164: Loss = 1.5974\n",
      "Epoch 4/50, Train iteration 162/164: Loss = 1.6317\n",
      "Epoch 4/50, Train iteration 163/164: Loss = 1.5918\n",
      "Epoch 4/50, Train iteration 164/164: Loss = 1.5252\n",
      "Epoch 4/50, Val iteration 1/27: Loss = 1.6114\n",
      "Epoch 4/50, Val iteration 2/27: Loss = 1.6109\n",
      "Epoch 4/50, Val iteration 3/27: Loss = 1.6112\n",
      "Epoch 4/50, Val iteration 4/27: Loss = 1.5920\n",
      "Epoch 4/50, Val iteration 5/27: Loss = 1.5972\n",
      "Epoch 4/50, Val iteration 6/27: Loss = 1.6011\n",
      "Epoch 4/50, Val iteration 7/27: Loss = 1.5717\n",
      "Epoch 4/50, Val iteration 8/27: Loss = 1.5991\n",
      "Epoch 4/50, Val iteration 9/27: Loss = 1.5819\n",
      "Epoch 4/50, Val iteration 10/27: Loss = 1.5898\n",
      "Epoch 4/50, Val iteration 11/27: Loss = 1.5891\n",
      "Epoch 4/50, Val iteration 12/27: Loss = 1.5833\n",
      "Epoch 4/50, Val iteration 13/27: Loss = 1.5962\n",
      "Epoch 4/50, Val iteration 14/27: Loss = 1.5903\n",
      "Epoch 4/50, Val iteration 15/27: Loss = 1.5859\n",
      "Epoch 4/50, Val iteration 16/27: Loss = 1.5881\n",
      "Epoch 4/50, Val iteration 17/27: Loss = 1.5848\n",
      "Epoch 4/50, Val iteration 18/27: Loss = 1.5832\n",
      "Epoch 4/50, Val iteration 19/27: Loss = 1.5817\n",
      "Epoch 4/50, Val iteration 20/27: Loss = 1.6004\n",
      "Epoch 4/50, Val iteration 21/27: Loss = 1.5978\n",
      "Epoch 4/50, Val iteration 22/27: Loss = 1.5929\n",
      "Epoch 4/50, Val iteration 23/27: Loss = 1.5441\n",
      "Epoch 4/50, Val iteration 24/27: Loss = 1.5895\n",
      "Epoch 4/50, Val iteration 25/27: Loss = 1.5930\n",
      "Epoch 4/50, Val iteration 26/27: Loss = 1.6058\n",
      "Epoch 4/50, Val iteration 27/27: Loss = 1.5931\n",
      "Epoch 4/50: Train Loss = 1.5929, Val Loss = 1.5913\n",
      "Current learning rate: 0.0001\n",
      "Epoch 5/50, Train iteration 1/164: Loss = 1.5908\n",
      "Epoch 5/50, Train iteration 2/164: Loss = 1.5836\n",
      "Epoch 5/50, Train iteration 3/164: Loss = 1.6106\n",
      "Epoch 5/50, Train iteration 4/164: Loss = 1.5999\n",
      "Epoch 5/50, Train iteration 5/164: Loss = 1.5796\n",
      "Epoch 5/50, Train iteration 6/164: Loss = 1.6463\n",
      "Epoch 5/50, Train iteration 7/164: Loss = 1.6419\n",
      "Epoch 5/50, Train iteration 8/164: Loss = 1.5584\n",
      "Epoch 5/50, Train iteration 9/164: Loss = 1.5967\n",
      "Epoch 5/50, Train iteration 10/164: Loss = 1.6183\n",
      "Epoch 5/50, Train iteration 11/164: Loss = 1.6077\n",
      "Epoch 5/50, Train iteration 12/164: Loss = 1.5882\n",
      "Epoch 5/50, Train iteration 13/164: Loss = 1.5722\n",
      "Epoch 5/50, Train iteration 14/164: Loss = 1.5938\n",
      "Epoch 5/50, Train iteration 15/164: Loss = 1.6200\n",
      "Epoch 5/50, Train iteration 16/164: Loss = 1.6545\n",
      "Epoch 5/50, Train iteration 17/164: Loss = 1.6144\n",
      "Epoch 5/50, Train iteration 18/164: Loss = 1.5767\n",
      "Epoch 5/50, Train iteration 19/164: Loss = 1.6141\n",
      "Epoch 5/50, Train iteration 20/164: Loss = 1.5970\n",
      "Epoch 5/50, Train iteration 21/164: Loss = 1.5898\n",
      "Epoch 5/50, Train iteration 22/164: Loss = 1.6025\n",
      "Epoch 5/50, Train iteration 23/164: Loss = 1.5857\n",
      "Epoch 5/50, Train iteration 24/164: Loss = 1.5910\n",
      "Epoch 5/50, Train iteration 25/164: Loss = 1.5735\n",
      "Epoch 5/50, Train iteration 26/164: Loss = 1.6017\n",
      "Epoch 5/50, Train iteration 27/164: Loss = 1.5736\n",
      "Epoch 5/50, Train iteration 28/164: Loss = 1.5902\n",
      "Epoch 5/50, Train iteration 29/164: Loss = 1.5777\n",
      "Epoch 5/50, Train iteration 30/164: Loss = 1.6198\n",
      "Epoch 5/50, Train iteration 31/164: Loss = 1.5519\n",
      "Epoch 5/50, Train iteration 32/164: Loss = 1.5842\n",
      "Epoch 5/50, Train iteration 33/164: Loss = 1.5919\n",
      "Epoch 5/50, Train iteration 34/164: Loss = 1.5868\n",
      "Epoch 5/50, Train iteration 35/164: Loss = 1.6125\n",
      "Epoch 5/50, Train iteration 36/164: Loss = 1.6029\n",
      "Epoch 5/50, Train iteration 37/164: Loss = 1.5834\n",
      "Epoch 5/50, Train iteration 38/164: Loss = 1.5379\n",
      "Epoch 5/50, Train iteration 39/164: Loss = 1.5946\n",
      "Epoch 5/50, Train iteration 40/164: Loss = 1.5824\n",
      "Epoch 5/50, Train iteration 41/164: Loss = 1.5683\n",
      "Epoch 5/50, Train iteration 42/164: Loss = 1.6061\n",
      "Epoch 5/50, Train iteration 43/164: Loss = 1.5856\n",
      "Epoch 5/50, Train iteration 44/164: Loss = 1.5604\n",
      "Epoch 5/50, Train iteration 45/164: Loss = 1.5563\n",
      "Epoch 5/50, Train iteration 46/164: Loss = 1.6260\n",
      "Epoch 5/50, Train iteration 47/164: Loss = 1.6156\n",
      "Epoch 5/50, Train iteration 48/164: Loss = 1.5800\n",
      "Epoch 5/50, Train iteration 49/164: Loss = 1.5445\n",
      "Epoch 5/50, Train iteration 50/164: Loss = 1.6323\n",
      "Epoch 5/50, Train iteration 51/164: Loss = 1.5087\n",
      "Epoch 5/50, Train iteration 52/164: Loss = 1.5977\n",
      "Epoch 5/50, Train iteration 53/164: Loss = 1.6019\n",
      "Epoch 5/50, Train iteration 54/164: Loss = 1.5446\n",
      "Epoch 5/50, Train iteration 55/164: Loss = 1.5774\n",
      "Epoch 5/50, Train iteration 56/164: Loss = 1.5716\n",
      "Epoch 5/50, Train iteration 57/164: Loss = 1.6079\n",
      "Epoch 5/50, Train iteration 58/164: Loss = 1.6186\n",
      "Epoch 5/50, Train iteration 59/164: Loss = 1.5672\n",
      "Epoch 5/50, Train iteration 60/164: Loss = 1.6635\n",
      "Epoch 5/50, Train iteration 61/164: Loss = 1.6022\n",
      "Epoch 5/50, Train iteration 62/164: Loss = 1.5213\n",
      "Epoch 5/50, Train iteration 63/164: Loss = 1.6152\n",
      "Epoch 5/50, Train iteration 64/164: Loss = 1.6100\n",
      "Epoch 5/50, Train iteration 65/164: Loss = 1.5482\n",
      "Epoch 5/50, Train iteration 66/164: Loss = 1.5577\n",
      "Epoch 5/50, Train iteration 67/164: Loss = 1.5476\n",
      "Epoch 5/50, Train iteration 68/164: Loss = 1.5905\n",
      "Epoch 5/50, Train iteration 69/164: Loss = 1.6177\n",
      "Epoch 5/50, Train iteration 70/164: Loss = 1.5892\n",
      "Epoch 5/50, Train iteration 71/164: Loss = 1.5913\n",
      "Epoch 5/50, Train iteration 72/164: Loss = 1.6360\n",
      "Epoch 5/50, Train iteration 73/164: Loss = 1.6019\n",
      "Epoch 5/50, Train iteration 74/164: Loss = 1.6602\n",
      "Epoch 5/50, Train iteration 75/164: Loss = 1.5411\n",
      "Epoch 5/50, Train iteration 76/164: Loss = 1.6034\n",
      "Epoch 5/50, Train iteration 77/164: Loss = 1.6306\n",
      "Epoch 5/50, Train iteration 78/164: Loss = 1.5919\n",
      "Epoch 5/50, Train iteration 79/164: Loss = 1.6143\n",
      "Epoch 5/50, Train iteration 80/164: Loss = 1.5919\n",
      "Epoch 5/50, Train iteration 81/164: Loss = 1.5935\n",
      "Epoch 5/50, Train iteration 82/164: Loss = 1.5729\n",
      "Epoch 5/50, Train iteration 83/164: Loss = 1.5807\n",
      "Epoch 5/50, Train iteration 84/164: Loss = 1.5987\n",
      "Epoch 5/50, Train iteration 85/164: Loss = 1.6251\n",
      "Epoch 5/50, Train iteration 86/164: Loss = 1.5067\n",
      "Epoch 5/50, Train iteration 87/164: Loss = 1.6299\n",
      "Epoch 5/50, Train iteration 88/164: Loss = 1.6122\n",
      "Epoch 5/50, Train iteration 89/164: Loss = 1.5912\n",
      "Epoch 5/50, Train iteration 90/164: Loss = 1.5901\n",
      "Epoch 5/50, Train iteration 91/164: Loss = 1.5839\n",
      "Epoch 5/50, Train iteration 92/164: Loss = 1.5934\n",
      "Epoch 5/50, Train iteration 93/164: Loss = 1.6308\n",
      "Epoch 5/50, Train iteration 94/164: Loss = 1.6141\n",
      "Epoch 5/50, Train iteration 95/164: Loss = 1.5746\n",
      "Epoch 5/50, Train iteration 96/164: Loss = 1.6377\n",
      "Epoch 5/50, Train iteration 97/164: Loss = 1.5795\n",
      "Epoch 5/50, Train iteration 98/164: Loss = 1.6251\n",
      "Epoch 5/50, Train iteration 99/164: Loss = 1.5825\n",
      "Epoch 5/50, Train iteration 100/164: Loss = 1.5908\n",
      "Epoch 5/50, Train iteration 101/164: Loss = 1.5664\n",
      "Epoch 5/50, Train iteration 102/164: Loss = 1.5841\n",
      "Epoch 5/50, Train iteration 103/164: Loss = 1.6031\n",
      "Epoch 5/50, Train iteration 104/164: Loss = 1.5381\n",
      "Epoch 5/50, Train iteration 105/164: Loss = 1.6243\n",
      "Epoch 5/50, Train iteration 106/164: Loss = 1.6051\n",
      "Epoch 5/50, Train iteration 107/164: Loss = 1.5841\n",
      "Epoch 5/50, Train iteration 108/164: Loss = 1.5704\n",
      "Epoch 5/50, Train iteration 109/164: Loss = 1.6521\n",
      "Epoch 5/50, Train iteration 110/164: Loss = 1.5647\n",
      "Epoch 5/50, Train iteration 111/164: Loss = 1.5976\n",
      "Epoch 5/50, Train iteration 112/164: Loss = 1.5805\n",
      "Epoch 5/50, Train iteration 113/164: Loss = 1.5887\n",
      "Epoch 5/50, Train iteration 114/164: Loss = 1.5414\n",
      "Epoch 5/50, Train iteration 115/164: Loss = 1.6164\n",
      "Epoch 5/50, Train iteration 116/164: Loss = 1.5651\n",
      "Epoch 5/50, Train iteration 117/164: Loss = 1.5589\n",
      "Epoch 5/50, Train iteration 118/164: Loss = 1.6117\n",
      "Epoch 5/50, Train iteration 119/164: Loss = 1.5704\n",
      "Epoch 5/50, Train iteration 120/164: Loss = 1.5635\n",
      "Epoch 5/50, Train iteration 121/164: Loss = 1.6014\n",
      "Epoch 5/50, Train iteration 122/164: Loss = 1.5336\n",
      "Epoch 5/50, Train iteration 123/164: Loss = 1.6191\n",
      "Epoch 5/50, Train iteration 124/164: Loss = 1.6046\n",
      "Epoch 5/50, Train iteration 125/164: Loss = 1.5961\n",
      "Epoch 5/50, Train iteration 126/164: Loss = 1.5357\n",
      "Epoch 5/50, Train iteration 127/164: Loss = 1.6040\n",
      "Epoch 5/50, Train iteration 128/164: Loss = 1.5678\n",
      "Epoch 5/50, Train iteration 129/164: Loss = 1.5923\n",
      "Epoch 5/50, Train iteration 130/164: Loss = 1.5355\n",
      "Epoch 5/50, Train iteration 131/164: Loss = 1.5814\n",
      "Epoch 5/50, Train iteration 132/164: Loss = 1.5929\n",
      "Epoch 5/50, Train iteration 133/164: Loss = 1.5911\n",
      "Epoch 5/50, Train iteration 134/164: Loss = 1.5646\n",
      "Epoch 5/50, Train iteration 135/164: Loss = 1.5657\n",
      "Epoch 5/50, Train iteration 136/164: Loss = 1.6358\n",
      "Epoch 5/50, Train iteration 137/164: Loss = 1.5857\n",
      "Epoch 5/50, Train iteration 138/164: Loss = 1.5996\n",
      "Epoch 5/50, Train iteration 139/164: Loss = 1.5789\n",
      "Epoch 5/50, Train iteration 140/164: Loss = 1.5655\n",
      "Epoch 5/50, Train iteration 141/164: Loss = 1.5704\n",
      "Epoch 5/50, Train iteration 142/164: Loss = 1.5883\n",
      "Epoch 5/50, Train iteration 143/164: Loss = 1.5187\n",
      "Epoch 5/50, Train iteration 144/164: Loss = 1.5955\n",
      "Epoch 5/50, Train iteration 145/164: Loss = 1.5711\n",
      "Epoch 5/50, Train iteration 146/164: Loss = 1.5374\n",
      "Epoch 5/50, Train iteration 147/164: Loss = 1.5590\n",
      "Epoch 5/50, Train iteration 148/164: Loss = 1.5389\n",
      "Epoch 5/50, Train iteration 149/164: Loss = 1.5781\n",
      "Epoch 5/50, Train iteration 150/164: Loss = 1.6033\n",
      "Epoch 5/50, Train iteration 151/164: Loss = 1.6369\n",
      "Epoch 5/50, Train iteration 152/164: Loss = 1.5410\n",
      "Epoch 5/50, Train iteration 153/164: Loss = 1.5783\n",
      "Epoch 5/50, Train iteration 154/164: Loss = 1.6133\n",
      "Epoch 5/50, Train iteration 155/164: Loss = 1.5955\n",
      "Epoch 5/50, Train iteration 156/164: Loss = 1.5162\n",
      "Epoch 5/50, Train iteration 157/164: Loss = 1.5935\n",
      "Epoch 5/50, Train iteration 158/164: Loss = 1.6250\n",
      "Epoch 5/50, Train iteration 159/164: Loss = 1.6101\n",
      "Epoch 5/50, Train iteration 160/164: Loss = 1.6314\n",
      "Epoch 5/50, Train iteration 161/164: Loss = 1.6293\n",
      "Epoch 5/50, Train iteration 162/164: Loss = 1.6004\n",
      "Epoch 5/50, Train iteration 163/164: Loss = 1.5938\n",
      "Epoch 5/50, Train iteration 164/164: Loss = 1.5500\n",
      "Epoch 5/50, Val iteration 1/27: Loss = 1.6059\n",
      "Epoch 5/50, Val iteration 2/27: Loss = 1.6083\n",
      "Epoch 5/50, Val iteration 3/27: Loss = 1.6064\n",
      "Epoch 5/50, Val iteration 4/27: Loss = 1.5930\n",
      "Epoch 5/50, Val iteration 5/27: Loss = 1.5941\n",
      "Epoch 5/50, Val iteration 6/27: Loss = 1.5980\n",
      "Epoch 5/50, Val iteration 7/27: Loss = 1.5578\n",
      "Epoch 5/50, Val iteration 8/27: Loss = 1.6067\n",
      "Epoch 5/50, Val iteration 9/27: Loss = 1.5766\n",
      "Epoch 5/50, Val iteration 10/27: Loss = 1.5869\n",
      "Epoch 5/50, Val iteration 11/27: Loss = 1.5860\n",
      "Epoch 5/50, Val iteration 12/27: Loss = 1.5756\n",
      "Epoch 5/50, Val iteration 13/27: Loss = 1.5930\n",
      "Epoch 5/50, Val iteration 14/27: Loss = 1.5881\n",
      "Epoch 5/50, Val iteration 15/27: Loss = 1.5891\n",
      "Epoch 5/50, Val iteration 16/27: Loss = 1.5798\n",
      "Epoch 5/50, Val iteration 17/27: Loss = 1.5828\n",
      "Epoch 5/50, Val iteration 18/27: Loss = 1.5790\n",
      "Epoch 5/50, Val iteration 19/27: Loss = 1.5773\n",
      "Epoch 5/50, Val iteration 20/27: Loss = 1.6088\n",
      "Epoch 5/50, Val iteration 21/27: Loss = 1.6005\n",
      "Epoch 5/50, Val iteration 22/27: Loss = 1.5873\n",
      "Epoch 5/50, Val iteration 23/27: Loss = 1.5340\n",
      "Epoch 5/50, Val iteration 24/27: Loss = 1.5871\n",
      "Epoch 5/50, Val iteration 25/27: Loss = 1.5937\n",
      "Epoch 5/50, Val iteration 26/27: Loss = 1.6110\n",
      "Epoch 5/50, Val iteration 27/27: Loss = 1.5933\n",
      "Epoch 5/50: Train Loss = 1.5892, Val Loss = 1.5889\n",
      "Current learning rate: 0.0001\n",
      "Epoch 6/50, Train iteration 1/164: Loss = 1.5501\n",
      "Epoch 6/50, Train iteration 2/164: Loss = 1.5870\n",
      "Epoch 6/50, Train iteration 3/164: Loss = 1.5784\n",
      "Epoch 6/50, Train iteration 4/164: Loss = 1.5902\n",
      "Epoch 6/50, Train iteration 5/164: Loss = 1.5978\n",
      "Epoch 6/50, Train iteration 6/164: Loss = 1.6064\n",
      "Epoch 6/50, Train iteration 7/164: Loss = 1.5822\n",
      "Epoch 6/50, Train iteration 8/164: Loss = 1.5715\n",
      "Epoch 6/50, Train iteration 9/164: Loss = 1.5938\n",
      "Epoch 6/50, Train iteration 10/164: Loss = 1.6023\n",
      "Epoch 6/50, Train iteration 11/164: Loss = 1.5697\n",
      "Epoch 6/50, Train iteration 12/164: Loss = 1.6024\n",
      "Epoch 6/50, Train iteration 13/164: Loss = 1.5659\n",
      "Epoch 6/50, Train iteration 14/164: Loss = 1.6137\n",
      "Epoch 6/50, Train iteration 15/164: Loss = 1.5819\n",
      "Epoch 6/50, Train iteration 16/164: Loss = 1.5780\n",
      "Epoch 6/50, Train iteration 17/164: Loss = 1.6223\n",
      "Epoch 6/50, Train iteration 18/164: Loss = 1.5700\n",
      "Epoch 6/50, Train iteration 19/164: Loss = 1.5644\n",
      "Epoch 6/50, Train iteration 20/164: Loss = 1.5912\n",
      "Epoch 6/50, Train iteration 21/164: Loss = 1.5896\n",
      "Epoch 6/50, Train iteration 22/164: Loss = 1.6090\n",
      "Epoch 6/50, Train iteration 23/164: Loss = 1.5664\n",
      "Epoch 6/50, Train iteration 24/164: Loss = 1.6130\n",
      "Epoch 6/50, Train iteration 25/164: Loss = 1.6043\n",
      "Epoch 6/50, Train iteration 26/164: Loss = 1.5836\n",
      "Epoch 6/50, Train iteration 27/164: Loss = 1.6237\n",
      "Epoch 6/50, Train iteration 28/164: Loss = 1.5342\n",
      "Epoch 6/50, Train iteration 29/164: Loss = 1.5636\n",
      "Epoch 6/50, Train iteration 30/164: Loss = 1.6222\n",
      "Epoch 6/50, Train iteration 31/164: Loss = 1.5357\n",
      "Epoch 6/50, Train iteration 32/164: Loss = 1.5763\n",
      "Epoch 6/50, Train iteration 33/164: Loss = 1.5752\n",
      "Epoch 6/50, Train iteration 34/164: Loss = 1.6141\n",
      "Epoch 6/50, Train iteration 35/164: Loss = 1.5597\n",
      "Epoch 6/50, Train iteration 36/164: Loss = 1.6001\n",
      "Epoch 6/50, Train iteration 37/164: Loss = 1.6024\n",
      "Epoch 6/50, Train iteration 38/164: Loss = 1.5635\n",
      "Epoch 6/50, Train iteration 39/164: Loss = 1.5780\n",
      "Epoch 6/50, Train iteration 40/164: Loss = 1.5480\n",
      "Epoch 6/50, Train iteration 41/164: Loss = 1.5341\n",
      "Epoch 6/50, Train iteration 42/164: Loss = 1.6327\n",
      "Epoch 6/50, Train iteration 43/164: Loss = 1.6019\n",
      "Epoch 6/50, Train iteration 44/164: Loss = 1.5531\n",
      "Epoch 6/50, Train iteration 45/164: Loss = 1.5782\n",
      "Epoch 6/50, Train iteration 46/164: Loss = 1.6345\n",
      "Epoch 6/50, Train iteration 47/164: Loss = 1.6189\n",
      "Epoch 6/50, Train iteration 48/164: Loss = 1.5762\n",
      "Epoch 6/50, Train iteration 49/164: Loss = 1.6062\n",
      "Epoch 6/50, Train iteration 50/164: Loss = 1.6050\n",
      "Epoch 6/50, Train iteration 51/164: Loss = 1.5711\n",
      "Epoch 6/50, Train iteration 52/164: Loss = 1.5452\n",
      "Epoch 6/50, Train iteration 53/164: Loss = 1.5643\n",
      "Epoch 6/50, Train iteration 54/164: Loss = 1.5254\n",
      "Epoch 6/50, Train iteration 55/164: Loss = 1.5789\n",
      "Epoch 6/50, Train iteration 56/164: Loss = 1.6358\n",
      "Epoch 6/50, Train iteration 57/164: Loss = 1.5981\n",
      "Epoch 6/50, Train iteration 58/164: Loss = 1.6080\n",
      "Epoch 6/50, Train iteration 59/164: Loss = 1.6300\n",
      "Epoch 6/50, Train iteration 60/164: Loss = 1.5997\n",
      "Epoch 6/50, Train iteration 61/164: Loss = 1.5853\n",
      "Epoch 6/50, Train iteration 62/164: Loss = 1.5431\n",
      "Epoch 6/50, Train iteration 63/164: Loss = 1.5962\n",
      "Epoch 6/50, Train iteration 64/164: Loss = 1.6206\n",
      "Epoch 6/50, Train iteration 65/164: Loss = 1.5444\n",
      "Epoch 6/50, Train iteration 66/164: Loss = 1.6072\n",
      "Epoch 6/50, Train iteration 67/164: Loss = 1.5466\n",
      "Epoch 6/50, Train iteration 68/164: Loss = 1.5506\n",
      "Epoch 6/50, Train iteration 69/164: Loss = 1.5865\n",
      "Epoch 6/50, Train iteration 70/164: Loss = 1.6130\n",
      "Epoch 6/50, Train iteration 71/164: Loss = 1.6180\n",
      "Epoch 6/50, Train iteration 72/164: Loss = 1.6157\n",
      "Epoch 6/50, Train iteration 73/164: Loss = 1.5895\n",
      "Epoch 6/50, Train iteration 74/164: Loss = 1.6231\n",
      "Epoch 6/50, Train iteration 75/164: Loss = 1.5347\n",
      "Epoch 6/50, Train iteration 76/164: Loss = 1.5957\n",
      "Epoch 6/50, Train iteration 77/164: Loss = 1.6105\n",
      "Epoch 6/50, Train iteration 78/164: Loss = 1.5764\n",
      "Epoch 6/50, Train iteration 79/164: Loss = 1.5790\n",
      "Epoch 6/50, Train iteration 80/164: Loss = 1.6136\n",
      "Epoch 6/50, Train iteration 81/164: Loss = 1.5659\n",
      "Epoch 6/50, Train iteration 82/164: Loss = 1.5693\n",
      "Epoch 6/50, Train iteration 83/164: Loss = 1.6042\n",
      "Epoch 6/50, Train iteration 84/164: Loss = 1.5694\n",
      "Epoch 6/50, Train iteration 85/164: Loss = 1.6642\n",
      "Epoch 6/50, Train iteration 86/164: Loss = 1.5089\n",
      "Epoch 6/50, Train iteration 87/164: Loss = 1.5861\n",
      "Epoch 6/50, Train iteration 88/164: Loss = 1.5809\n",
      "Epoch 6/50, Train iteration 89/164: Loss = 1.6115\n",
      "Epoch 6/50, Train iteration 90/164: Loss = 1.5674\n",
      "Epoch 6/50, Train iteration 91/164: Loss = 1.5956\n",
      "Epoch 6/50, Train iteration 92/164: Loss = 1.5911\n",
      "Epoch 6/50, Train iteration 93/164: Loss = 1.6135\n",
      "Epoch 6/50, Train iteration 94/164: Loss = 1.6123\n",
      "Epoch 6/50, Train iteration 95/164: Loss = 1.5575\n",
      "Epoch 6/50, Train iteration 96/164: Loss = 1.6309\n",
      "Epoch 6/50, Train iteration 97/164: Loss = 1.5831\n",
      "Epoch 6/50, Train iteration 98/164: Loss = 1.5563\n",
      "Epoch 6/50, Train iteration 99/164: Loss = 1.5319\n",
      "Epoch 6/50, Train iteration 100/164: Loss = 1.5617\n",
      "Epoch 6/50, Train iteration 101/164: Loss = 1.5531\n",
      "Epoch 6/50, Train iteration 102/164: Loss = 1.5930\n",
      "Epoch 6/50, Train iteration 103/164: Loss = 1.5870\n",
      "Epoch 6/50, Train iteration 104/164: Loss = 1.5857\n",
      "Epoch 6/50, Train iteration 105/164: Loss = 1.6348\n",
      "Epoch 6/50, Train iteration 106/164: Loss = 1.5921\n",
      "Epoch 6/50, Train iteration 107/164: Loss = 1.6071\n",
      "Epoch 6/50, Train iteration 108/164: Loss = 1.5590\n",
      "Epoch 6/50, Train iteration 109/164: Loss = 1.5905\n",
      "Epoch 6/50, Train iteration 110/164: Loss = 1.5643\n",
      "Epoch 6/50, Train iteration 111/164: Loss = 1.5755\n",
      "Epoch 6/50, Train iteration 112/164: Loss = 1.5430\n",
      "Epoch 6/50, Train iteration 113/164: Loss = 1.5676\n",
      "Epoch 6/50, Train iteration 114/164: Loss = 1.5656\n",
      "Epoch 6/50, Train iteration 115/164: Loss = 1.6200\n",
      "Epoch 6/50, Train iteration 116/164: Loss = 1.5898\n",
      "Epoch 6/50, Train iteration 117/164: Loss = 1.5307\n",
      "Epoch 6/50, Train iteration 118/164: Loss = 1.6105\n",
      "Epoch 6/50, Train iteration 119/164: Loss = 1.5813\n",
      "Epoch 6/50, Train iteration 120/164: Loss = 1.5600\n",
      "Epoch 6/50, Train iteration 121/164: Loss = 1.5970\n",
      "Epoch 6/50, Train iteration 122/164: Loss = 1.5545\n",
      "Epoch 6/50, Train iteration 123/164: Loss = 1.5400\n",
      "Epoch 6/50, Train iteration 124/164: Loss = 1.6206\n",
      "Epoch 6/50, Train iteration 125/164: Loss = 1.5823\n",
      "Epoch 6/50, Train iteration 126/164: Loss = 1.5605\n",
      "Epoch 6/50, Train iteration 127/164: Loss = 1.6377\n",
      "Epoch 6/50, Train iteration 128/164: Loss = 1.5876\n",
      "Epoch 6/50, Train iteration 129/164: Loss = 1.6205\n",
      "Epoch 6/50, Train iteration 130/164: Loss = 1.5672\n",
      "Epoch 6/50, Train iteration 131/164: Loss = 1.6083\n",
      "Epoch 6/50, Train iteration 132/164: Loss = 1.5609\n",
      "Epoch 6/50, Train iteration 133/164: Loss = 1.5829\n",
      "Epoch 6/50, Train iteration 134/164: Loss = 1.5429\n",
      "Epoch 6/50, Train iteration 135/164: Loss = 1.5932\n",
      "Epoch 6/50, Train iteration 136/164: Loss = 1.5812\n",
      "Epoch 6/50, Train iteration 137/164: Loss = 1.5551\n",
      "Epoch 6/50, Train iteration 138/164: Loss = 1.6252\n",
      "Epoch 6/50, Train iteration 139/164: Loss = 1.6547\n",
      "Epoch 6/50, Train iteration 140/164: Loss = 1.5920\n",
      "Epoch 6/50, Train iteration 141/164: Loss = 1.5594\n",
      "Epoch 6/50, Train iteration 142/164: Loss = 1.5969\n",
      "Epoch 6/50, Train iteration 143/164: Loss = 1.5476\n",
      "Epoch 6/50, Train iteration 144/164: Loss = 1.5640\n",
      "Epoch 6/50, Train iteration 145/164: Loss = 1.5834\n",
      "Epoch 6/50, Train iteration 146/164: Loss = 1.5547\n",
      "Epoch 6/50, Train iteration 147/164: Loss = 1.5701\n",
      "Epoch 6/50, Train iteration 148/164: Loss = 1.5609\n",
      "Epoch 6/50, Train iteration 149/164: Loss = 1.6148\n",
      "Epoch 6/50, Train iteration 150/164: Loss = 1.5852\n",
      "Epoch 6/50, Train iteration 151/164: Loss = 1.5799\n",
      "Epoch 6/50, Train iteration 152/164: Loss = 1.5648\n",
      "Epoch 6/50, Train iteration 153/164: Loss = 1.5844\n",
      "Epoch 6/50, Train iteration 154/164: Loss = 1.5918\n",
      "Epoch 6/50, Train iteration 155/164: Loss = 1.6299\n",
      "Epoch 6/50, Train iteration 156/164: Loss = 1.5340\n",
      "Epoch 6/50, Train iteration 157/164: Loss = 1.6252\n",
      "Epoch 6/50, Train iteration 158/164: Loss = 1.6109\n",
      "Epoch 6/50, Train iteration 159/164: Loss = 1.5991\n",
      "Epoch 6/50, Train iteration 160/164: Loss = 1.6163\n",
      "Epoch 6/50, Train iteration 161/164: Loss = 1.6568\n",
      "Epoch 6/50, Train iteration 162/164: Loss = 1.6017\n",
      "Epoch 6/50, Train iteration 163/164: Loss = 1.5715\n",
      "Epoch 6/50, Train iteration 164/164: Loss = 1.3692\n",
      "Epoch 6/50, Val iteration 1/27: Loss = 1.6064\n",
      "Epoch 6/50, Val iteration 2/27: Loss = 1.6060\n",
      "Epoch 6/50, Val iteration 3/27: Loss = 1.6077\n",
      "Epoch 6/50, Val iteration 4/27: Loss = 1.5955\n",
      "Epoch 6/50, Val iteration 5/27: Loss = 1.5972\n",
      "Epoch 6/50, Val iteration 6/27: Loss = 1.5958\n",
      "Epoch 6/50, Val iteration 7/27: Loss = 1.5670\n",
      "Epoch 6/50, Val iteration 8/27: Loss = 1.6058\n",
      "Epoch 6/50, Val iteration 9/27: Loss = 1.5828\n",
      "Epoch 6/50, Val iteration 10/27: Loss = 1.5851\n",
      "Epoch 6/50, Val iteration 11/27: Loss = 1.5928\n",
      "Epoch 6/50, Val iteration 12/27: Loss = 1.5833\n",
      "Epoch 6/50, Val iteration 13/27: Loss = 1.5901\n",
      "Epoch 6/50, Val iteration 14/27: Loss = 1.5832\n",
      "Epoch 6/50, Val iteration 15/27: Loss = 1.5875\n",
      "Epoch 6/50, Val iteration 16/27: Loss = 1.5836\n",
      "Epoch 6/50, Val iteration 17/27: Loss = 1.5827\n",
      "Epoch 6/50, Val iteration 18/27: Loss = 1.5781\n",
      "Epoch 6/50, Val iteration 19/27: Loss = 1.5761\n",
      "Epoch 6/50, Val iteration 20/27: Loss = 1.6044\n",
      "Epoch 6/50, Val iteration 21/27: Loss = 1.5987\n",
      "Epoch 6/50, Val iteration 22/27: Loss = 1.5896\n",
      "Epoch 6/50, Val iteration 23/27: Loss = 1.5388\n",
      "Epoch 6/50, Val iteration 24/27: Loss = 1.5842\n",
      "Epoch 6/50, Val iteration 25/27: Loss = 1.5897\n",
      "Epoch 6/50, Val iteration 26/27: Loss = 1.6096\n",
      "Epoch 6/50, Val iteration 27/27: Loss = 1.5970\n",
      "Epoch 6/50: Train Loss = 1.5844, Val Loss = 1.5896\n",
      "Current learning rate: 0.0001\n",
      "Epoch 7/50, Train iteration 1/164: Loss = 1.5897\n",
      "Epoch 7/50, Train iteration 2/164: Loss = 1.5765\n",
      "Epoch 7/50, Train iteration 3/164: Loss = 1.5824\n",
      "Epoch 7/50, Train iteration 4/164: Loss = 1.5603\n",
      "Epoch 7/50, Train iteration 5/164: Loss = 1.5500\n",
      "Epoch 7/50, Train iteration 6/164: Loss = 1.6040\n",
      "Epoch 7/50, Train iteration 7/164: Loss = 1.5945\n",
      "Epoch 7/50, Train iteration 8/164: Loss = 1.5360\n",
      "Epoch 7/50, Train iteration 9/164: Loss = 1.5349\n",
      "Epoch 7/50, Train iteration 10/164: Loss = 1.6001\n",
      "Epoch 7/50, Train iteration 11/164: Loss = 1.6320\n",
      "Epoch 7/50, Train iteration 12/164: Loss = 1.5760\n",
      "Epoch 7/50, Train iteration 13/164: Loss = 1.5090\n",
      "Epoch 7/50, Train iteration 14/164: Loss = 1.5790\n",
      "Epoch 7/50, Train iteration 15/164: Loss = 1.5574\n",
      "Epoch 7/50, Train iteration 16/164: Loss = 1.5937\n",
      "Epoch 7/50, Train iteration 17/164: Loss = 1.5640\n",
      "Epoch 7/50, Train iteration 18/164: Loss = 1.5983\n",
      "Epoch 7/50, Train iteration 19/164: Loss = 1.5733\n",
      "Epoch 7/50, Train iteration 20/164: Loss = 1.5561\n",
      "Epoch 7/50, Train iteration 21/164: Loss = 1.5459\n",
      "Epoch 7/50, Train iteration 22/164: Loss = 1.5985\n",
      "Epoch 7/50, Train iteration 23/164: Loss = 1.5770\n",
      "Epoch 7/50, Train iteration 24/164: Loss = 1.6167\n",
      "Epoch 7/50, Train iteration 25/164: Loss = 1.6351\n",
      "Epoch 7/50, Train iteration 26/164: Loss = 1.6141\n",
      "Epoch 7/50, Train iteration 27/164: Loss = 1.6002\n",
      "Epoch 7/50, Train iteration 28/164: Loss = 1.5689\n",
      "Epoch 7/50, Train iteration 29/164: Loss = 1.5831\n",
      "Epoch 7/50, Train iteration 30/164: Loss = 1.5954\n",
      "Epoch 7/50, Train iteration 31/164: Loss = 1.5122\n",
      "Epoch 7/50, Train iteration 32/164: Loss = 1.5999\n",
      "Epoch 7/50, Train iteration 33/164: Loss = 1.5464\n",
      "Epoch 7/50, Train iteration 34/164: Loss = 1.5864\n",
      "Epoch 7/50, Train iteration 35/164: Loss = 1.5634\n",
      "Epoch 7/50, Train iteration 36/164: Loss = 1.6163\n",
      "Epoch 7/50, Train iteration 37/164: Loss = 1.5943\n",
      "Epoch 7/50, Train iteration 38/164: Loss = 1.5825\n",
      "Epoch 7/50, Train iteration 39/164: Loss = 1.5158\n",
      "Epoch 7/50, Train iteration 40/164: Loss = 1.5403\n",
      "Epoch 7/50, Train iteration 41/164: Loss = 1.5612\n",
      "Epoch 7/50, Train iteration 42/164: Loss = 1.6121\n",
      "Epoch 7/50, Train iteration 43/164: Loss = 1.5400\n",
      "Epoch 7/50, Train iteration 44/164: Loss = 1.5525\n",
      "Epoch 7/50, Train iteration 45/164: Loss = 1.5780\n",
      "Epoch 7/50, Train iteration 46/164: Loss = 1.5842\n",
      "Epoch 7/50, Train iteration 47/164: Loss = 1.6026\n",
      "Epoch 7/50, Train iteration 48/164: Loss = 1.5702\n",
      "Epoch 7/50, Train iteration 49/164: Loss = 1.5668\n",
      "Epoch 7/50, Train iteration 50/164: Loss = 1.6010\n",
      "Epoch 7/50, Train iteration 51/164: Loss = 1.5421\n",
      "Epoch 7/50, Train iteration 52/164: Loss = 1.5328\n",
      "Epoch 7/50, Train iteration 53/164: Loss = 1.5591\n",
      "Epoch 7/50, Train iteration 54/164: Loss = 1.5551\n",
      "Epoch 7/50, Train iteration 55/164: Loss = 1.5514\n",
      "Epoch 7/50, Train iteration 56/164: Loss = 1.5708\n",
      "Epoch 7/50, Train iteration 57/164: Loss = 1.6095\n",
      "Epoch 7/50, Train iteration 58/164: Loss = 1.5954\n",
      "Epoch 7/50, Train iteration 59/164: Loss = 1.5820\n",
      "Epoch 7/50, Train iteration 60/164: Loss = 1.5366\n",
      "Epoch 7/50, Train iteration 61/164: Loss = 1.5673\n",
      "Epoch 7/50, Train iteration 62/164: Loss = 1.5366\n",
      "Epoch 7/50, Train iteration 63/164: Loss = 1.6636\n",
      "Epoch 7/50, Train iteration 64/164: Loss = 1.5686\n",
      "Epoch 7/50, Train iteration 65/164: Loss = 1.4914\n",
      "Epoch 7/50, Train iteration 66/164: Loss = 1.5416\n",
      "Epoch 7/50, Train iteration 67/164: Loss = 1.5534\n",
      "Epoch 7/50, Train iteration 68/164: Loss = 1.5179\n",
      "Epoch 7/50, Train iteration 69/164: Loss = 1.5916\n",
      "Epoch 7/50, Train iteration 70/164: Loss = 1.5882\n",
      "Epoch 7/50, Train iteration 71/164: Loss = 1.6107\n",
      "Epoch 7/50, Train iteration 72/164: Loss = 1.6117\n",
      "Epoch 7/50, Train iteration 73/164: Loss = 1.6385\n",
      "Epoch 7/50, Train iteration 74/164: Loss = 1.5927\n",
      "Epoch 7/50, Train iteration 75/164: Loss = 1.5909\n",
      "Epoch 7/50, Train iteration 76/164: Loss = 1.5888\n",
      "Epoch 7/50, Train iteration 77/164: Loss = 1.5921\n",
      "Epoch 7/50, Train iteration 78/164: Loss = 1.5755\n",
      "Epoch 7/50, Train iteration 79/164: Loss = 1.6034\n",
      "Epoch 7/50, Train iteration 80/164: Loss = 1.5716\n",
      "Epoch 7/50, Train iteration 81/164: Loss = 1.5658\n",
      "Epoch 7/50, Train iteration 82/164: Loss = 1.5624\n",
      "Epoch 7/50, Train iteration 83/164: Loss = 1.5842\n",
      "Epoch 7/50, Train iteration 84/164: Loss = 1.5677\n",
      "Epoch 7/50, Train iteration 85/164: Loss = 1.6037\n",
      "Epoch 7/50, Train iteration 86/164: Loss = 1.4898\n",
      "Epoch 7/50, Train iteration 87/164: Loss = 1.5091\n",
      "Epoch 7/50, Train iteration 88/164: Loss = 1.6201\n",
      "Epoch 7/50, Train iteration 89/164: Loss = 1.5856\n",
      "Epoch 7/50, Train iteration 90/164: Loss = 1.5661\n",
      "Epoch 7/50, Train iteration 91/164: Loss = 1.5955\n",
      "Epoch 7/50, Train iteration 92/164: Loss = 1.5513\n",
      "Epoch 7/50, Train iteration 93/164: Loss = 1.5685\n",
      "Epoch 7/50, Train iteration 94/164: Loss = 1.6044\n",
      "Epoch 7/50, Train iteration 95/164: Loss = 1.5817\n",
      "Epoch 7/50, Train iteration 96/164: Loss = 1.6255\n",
      "Epoch 7/50, Train iteration 97/164: Loss = 1.5843\n",
      "Epoch 7/50, Train iteration 98/164: Loss = 1.6150\n",
      "Epoch 7/50, Train iteration 99/164: Loss = 1.5517\n",
      "Epoch 7/50, Train iteration 100/164: Loss = 1.5536\n",
      "Epoch 7/50, Train iteration 101/164: Loss = 1.5241\n",
      "Epoch 7/50, Train iteration 102/164: Loss = 1.5733\n",
      "Epoch 7/50, Train iteration 103/164: Loss = 1.5551\n",
      "Epoch 7/50, Train iteration 104/164: Loss = 1.5649\n",
      "Epoch 7/50, Train iteration 105/164: Loss = 1.6288\n",
      "Epoch 7/50, Train iteration 106/164: Loss = 1.6213\n",
      "Epoch 7/50, Train iteration 107/164: Loss = 1.5511\n",
      "Epoch 7/50, Train iteration 108/164: Loss = 1.5912\n",
      "Epoch 7/50, Train iteration 109/164: Loss = 1.6402\n",
      "Epoch 7/50, Train iteration 110/164: Loss = 1.5988\n",
      "Epoch 7/50, Train iteration 111/164: Loss = 1.5855\n",
      "Epoch 7/50, Train iteration 112/164: Loss = 1.5837\n",
      "Epoch 7/50, Train iteration 113/164: Loss = 1.5770\n",
      "Epoch 7/50, Train iteration 114/164: Loss = 1.5599\n",
      "Epoch 7/50, Train iteration 115/164: Loss = 1.5387\n",
      "Epoch 7/50, Train iteration 116/164: Loss = 1.5866\n",
      "Epoch 7/50, Train iteration 117/164: Loss = 1.5526\n",
      "Epoch 7/50, Train iteration 118/164: Loss = 1.5673\n",
      "Epoch 7/50, Train iteration 119/164: Loss = 1.6051\n",
      "Epoch 7/50, Train iteration 120/164: Loss = 1.6098\n",
      "Epoch 7/50, Train iteration 121/164: Loss = 1.5610\n",
      "Epoch 7/50, Train iteration 122/164: Loss = 1.5259\n",
      "Epoch 7/50, Train iteration 123/164: Loss = 1.6085\n",
      "Epoch 7/50, Train iteration 124/164: Loss = 1.5661\n",
      "Epoch 7/50, Train iteration 125/164: Loss = 1.5903\n",
      "Epoch 7/50, Train iteration 126/164: Loss = 1.5736\n",
      "Epoch 7/50, Train iteration 127/164: Loss = 1.6246\n",
      "Epoch 7/50, Train iteration 128/164: Loss = 1.5561\n",
      "Epoch 7/50, Train iteration 129/164: Loss = 1.5959\n",
      "Epoch 7/50, Train iteration 130/164: Loss = 1.5554\n",
      "Epoch 7/50, Train iteration 131/164: Loss = 1.6102\n",
      "Epoch 7/50, Train iteration 132/164: Loss = 1.5467\n",
      "Epoch 7/50, Train iteration 133/164: Loss = 1.5308\n",
      "Epoch 7/50, Train iteration 134/164: Loss = 1.5846\n",
      "Epoch 7/50, Train iteration 135/164: Loss = 1.5963\n",
      "Epoch 7/50, Train iteration 136/164: Loss = 1.5958\n",
      "Epoch 7/50, Train iteration 137/164: Loss = 1.5673\n",
      "Epoch 7/50, Train iteration 138/164: Loss = 1.5715\n",
      "Epoch 7/50, Train iteration 139/164: Loss = 1.6383\n",
      "Epoch 7/50, Train iteration 140/164: Loss = 1.5384\n",
      "Epoch 7/50, Train iteration 141/164: Loss = 1.5561\n",
      "Epoch 7/50, Train iteration 142/164: Loss = 1.6437\n",
      "Epoch 7/50, Train iteration 143/164: Loss = 1.5175\n",
      "Epoch 7/50, Train iteration 144/164: Loss = 1.6080\n",
      "Epoch 7/50, Train iteration 145/164: Loss = 1.5873\n",
      "Epoch 7/50, Train iteration 146/164: Loss = 1.5985\n",
      "Epoch 7/50, Train iteration 147/164: Loss = 1.5896\n",
      "Epoch 7/50, Train iteration 148/164: Loss = 1.5581\n",
      "Epoch 7/50, Train iteration 149/164: Loss = 1.5681\n",
      "Epoch 7/50, Train iteration 150/164: Loss = 1.6021\n",
      "Epoch 7/50, Train iteration 151/164: Loss = 1.5785\n",
      "Epoch 7/50, Train iteration 152/164: Loss = 1.5436\n",
      "Epoch 7/50, Train iteration 153/164: Loss = 1.5702\n",
      "Epoch 7/50, Train iteration 154/164: Loss = 1.5969\n",
      "Epoch 7/50, Train iteration 155/164: Loss = 1.5380\n",
      "Epoch 7/50, Train iteration 156/164: Loss = 1.6076\n",
      "Epoch 7/50, Train iteration 157/164: Loss = 1.5927\n",
      "Epoch 7/50, Train iteration 158/164: Loss = 1.6073\n",
      "Epoch 7/50, Train iteration 159/164: Loss = 1.6034\n",
      "Epoch 7/50, Train iteration 160/164: Loss = 1.5904\n",
      "Epoch 7/50, Train iteration 161/164: Loss = 1.6120\n",
      "Epoch 7/50, Train iteration 162/164: Loss = 1.5882\n",
      "Epoch 7/50, Train iteration 163/164: Loss = 1.5701\n",
      "Epoch 7/50, Train iteration 164/164: Loss = 1.4962\n",
      "Epoch 7/50, Val iteration 1/27: Loss = 1.6048\n",
      "Epoch 7/50, Val iteration 2/27: Loss = 1.6158\n",
      "Epoch 7/50, Val iteration 3/27: Loss = 1.6058\n",
      "Epoch 7/50, Val iteration 4/27: Loss = 1.5920\n",
      "Epoch 7/50, Val iteration 5/27: Loss = 1.6002\n",
      "Epoch 7/50, Val iteration 6/27: Loss = 1.5859\n",
      "Epoch 7/50, Val iteration 7/27: Loss = 1.5689\n",
      "Epoch 7/50, Val iteration 8/27: Loss = 1.6018\n",
      "Epoch 7/50, Val iteration 9/27: Loss = 1.5857\n",
      "Epoch 7/50, Val iteration 10/27: Loss = 1.5909\n",
      "Epoch 7/50, Val iteration 11/27: Loss = 1.5923\n",
      "Epoch 7/50, Val iteration 12/27: Loss = 1.5789\n",
      "Epoch 7/50, Val iteration 13/27: Loss = 1.5959\n",
      "Epoch 7/50, Val iteration 14/27: Loss = 1.5779\n",
      "Epoch 7/50, Val iteration 15/27: Loss = 1.5845\n",
      "Epoch 7/50, Val iteration 16/27: Loss = 1.5775\n",
      "Epoch 7/50, Val iteration 17/27: Loss = 1.5811\n",
      "Epoch 7/50, Val iteration 18/27: Loss = 1.5732\n",
      "Epoch 7/50, Val iteration 19/27: Loss = 1.5653\n",
      "Epoch 7/50, Val iteration 20/27: Loss = 1.6021\n",
      "Epoch 7/50, Val iteration 21/27: Loss = 1.5992\n",
      "Epoch 7/50, Val iteration 22/27: Loss = 1.5864\n",
      "Epoch 7/50, Val iteration 23/27: Loss = 1.5338\n",
      "Epoch 7/50, Val iteration 24/27: Loss = 1.5818\n",
      "Epoch 7/50, Val iteration 25/27: Loss = 1.5860\n",
      "Epoch 7/50, Val iteration 26/27: Loss = 1.6054\n",
      "Epoch 7/50, Val iteration 27/27: Loss = 1.5871\n",
      "Epoch 7/50: Train Loss = 1.5770, Val Loss = 1.5874\n",
      "Current learning rate: 0.0001\n",
      "Epoch 8/50, Train iteration 1/164: Loss = 1.5737\n",
      "Epoch 8/50, Train iteration 2/164: Loss = 1.5915\n",
      "Epoch 8/50, Train iteration 3/164: Loss = 1.5831\n",
      "Epoch 8/50, Train iteration 4/164: Loss = 1.5642\n",
      "Epoch 8/50, Train iteration 5/164: Loss = 1.5978\n",
      "Epoch 8/50, Train iteration 6/164: Loss = 1.5909\n",
      "Epoch 8/50, Train iteration 7/164: Loss = 1.5872\n",
      "Epoch 8/50, Train iteration 8/164: Loss = 1.5008\n",
      "Epoch 8/50, Train iteration 9/164: Loss = 1.6065\n",
      "Epoch 8/50, Train iteration 10/164: Loss = 1.6267\n",
      "Epoch 8/50, Train iteration 11/164: Loss = 1.5528\n",
      "Epoch 8/50, Train iteration 12/164: Loss = 1.5784\n",
      "Epoch 8/50, Train iteration 13/164: Loss = 1.4997\n",
      "Epoch 8/50, Train iteration 14/164: Loss = 1.6507\n",
      "Epoch 8/50, Train iteration 15/164: Loss = 1.5693\n",
      "Epoch 8/50, Train iteration 16/164: Loss = 1.5745\n",
      "Epoch 8/50, Train iteration 17/164: Loss = 1.6005\n",
      "Epoch 8/50, Train iteration 18/164: Loss = 1.5678\n",
      "Epoch 8/50, Train iteration 19/164: Loss = 1.5944\n",
      "Epoch 8/50, Train iteration 20/164: Loss = 1.5408\n",
      "Epoch 8/50, Train iteration 21/164: Loss = 1.5824\n",
      "Epoch 8/50, Train iteration 22/164: Loss = 1.5697\n",
      "Epoch 8/50, Train iteration 23/164: Loss = 1.5852\n",
      "Epoch 8/50, Train iteration 24/164: Loss = 1.6053\n",
      "Epoch 8/50, Train iteration 25/164: Loss = 1.6007\n",
      "Epoch 8/50, Train iteration 26/164: Loss = 1.6125\n",
      "Epoch 8/50, Train iteration 27/164: Loss = 1.5877\n",
      "Epoch 8/50, Train iteration 28/164: Loss = 1.5228\n",
      "Epoch 8/50, Train iteration 29/164: Loss = 1.5772\n",
      "Epoch 8/50, Train iteration 30/164: Loss = 1.5986\n",
      "Epoch 8/50, Train iteration 31/164: Loss = 1.5256\n",
      "Epoch 8/50, Train iteration 32/164: Loss = 1.5469\n",
      "Epoch 8/50, Train iteration 33/164: Loss = 1.6004\n",
      "Epoch 8/50, Train iteration 34/164: Loss = 1.5589\n",
      "Epoch 8/50, Train iteration 35/164: Loss = 1.5416\n",
      "Epoch 8/50, Train iteration 36/164: Loss = 1.5471\n",
      "Epoch 8/50, Train iteration 37/164: Loss = 1.6484\n",
      "Epoch 8/50, Train iteration 38/164: Loss = 1.5663\n",
      "Epoch 8/50, Train iteration 39/164: Loss = 1.5802\n",
      "Epoch 8/50, Train iteration 40/164: Loss = 1.5559\n",
      "Epoch 8/50, Train iteration 41/164: Loss = 1.5567\n",
      "Epoch 8/50, Train iteration 42/164: Loss = 1.6122\n",
      "Epoch 8/50, Train iteration 43/164: Loss = 1.5427\n",
      "Epoch 8/50, Train iteration 44/164: Loss = 1.5331\n",
      "Epoch 8/50, Train iteration 45/164: Loss = 1.5994\n",
      "Epoch 8/50, Train iteration 46/164: Loss = 1.6044\n",
      "Epoch 8/50, Train iteration 47/164: Loss = 1.5727\n",
      "Epoch 8/50, Train iteration 48/164: Loss = 1.5751\n",
      "Epoch 8/50, Train iteration 49/164: Loss = 1.5717\n",
      "Epoch 8/50, Train iteration 50/164: Loss = 1.6131\n",
      "Epoch 8/50, Train iteration 51/164: Loss = 1.5318\n",
      "Epoch 8/50, Train iteration 52/164: Loss = 1.5758\n",
      "Epoch 8/50, Train iteration 53/164: Loss = 1.5580\n",
      "Epoch 8/50, Train iteration 54/164: Loss = 1.5773\n",
      "Epoch 8/50, Train iteration 55/164: Loss = 1.5328\n",
      "Epoch 8/50, Train iteration 56/164: Loss = 1.6059\n",
      "Epoch 8/50, Train iteration 57/164: Loss = 1.5916\n",
      "Epoch 8/50, Train iteration 58/164: Loss = 1.6288\n",
      "Epoch 8/50, Train iteration 59/164: Loss = 1.5652\n",
      "Epoch 8/50, Train iteration 60/164: Loss = 1.5734\n",
      "Epoch 8/50, Train iteration 61/164: Loss = 1.5417\n",
      "Epoch 8/50, Train iteration 62/164: Loss = 1.5262\n",
      "Epoch 8/50, Train iteration 63/164: Loss = 1.5940\n",
      "Epoch 8/50, Train iteration 64/164: Loss = 1.5210\n",
      "Epoch 8/50, Train iteration 65/164: Loss = 1.5282\n",
      "Epoch 8/50, Train iteration 66/164: Loss = 1.5167\n",
      "Epoch 8/50, Train iteration 67/164: Loss = 1.5483\n",
      "Epoch 8/50, Train iteration 68/164: Loss = 1.5964\n",
      "Epoch 8/50, Train iteration 69/164: Loss = 1.6171\n",
      "Epoch 8/50, Train iteration 70/164: Loss = 1.5912\n",
      "Epoch 8/50, Train iteration 71/164: Loss = 1.6508\n",
      "Epoch 8/50, Train iteration 72/164: Loss = 1.5938\n",
      "Epoch 8/50, Train iteration 73/164: Loss = 1.5708\n",
      "Epoch 8/50, Train iteration 74/164: Loss = 1.5972\n",
      "Epoch 8/50, Train iteration 75/164: Loss = 1.5472\n",
      "Epoch 8/50, Train iteration 76/164: Loss = 1.5710\n",
      "Epoch 8/50, Train iteration 77/164: Loss = 1.5924\n",
      "Epoch 8/50, Train iteration 78/164: Loss = 1.5213\n",
      "Epoch 8/50, Train iteration 79/164: Loss = 1.6137\n",
      "Epoch 8/50, Train iteration 80/164: Loss = 1.5802\n",
      "Epoch 8/50, Train iteration 81/164: Loss = 1.5915\n",
      "Epoch 8/50, Train iteration 82/164: Loss = 1.5405\n",
      "Epoch 8/50, Train iteration 83/164: Loss = 1.5699\n",
      "Epoch 8/50, Train iteration 84/164: Loss = 1.5425\n",
      "Epoch 8/50, Train iteration 85/164: Loss = 1.6266\n",
      "Epoch 8/50, Train iteration 86/164: Loss = 1.5003\n",
      "Epoch 8/50, Train iteration 87/164: Loss = 1.5910\n",
      "Epoch 8/50, Train iteration 88/164: Loss = 1.6101\n",
      "Epoch 8/50, Train iteration 89/164: Loss = 1.5656\n",
      "Epoch 8/50, Train iteration 90/164: Loss = 1.5844\n",
      "Epoch 8/50, Train iteration 91/164: Loss = 1.6378\n",
      "Epoch 8/50, Train iteration 92/164: Loss = 1.5201\n",
      "Epoch 8/50, Train iteration 93/164: Loss = 1.5726\n",
      "Epoch 8/50, Train iteration 94/164: Loss = 1.6071\n",
      "Epoch 8/50, Train iteration 95/164: Loss = 1.5401\n",
      "Epoch 8/50, Train iteration 96/164: Loss = 1.5849\n",
      "Epoch 8/50, Train iteration 97/164: Loss = 1.5740\n",
      "Epoch 8/50, Train iteration 98/164: Loss = 1.6125\n",
      "Epoch 8/50, Train iteration 99/164: Loss = 1.5434\n",
      "Epoch 8/50, Train iteration 100/164: Loss = 1.5896\n",
      "Epoch 8/50, Train iteration 101/164: Loss = 1.5384\n",
      "Epoch 8/50, Train iteration 102/164: Loss = 1.5634\n",
      "Epoch 8/50, Train iteration 103/164: Loss = 1.6025\n",
      "Epoch 8/50, Train iteration 104/164: Loss = 1.6086\n",
      "Epoch 8/50, Train iteration 105/164: Loss = 1.6035\n",
      "Epoch 8/50, Train iteration 106/164: Loss = 1.5778\n",
      "Epoch 8/50, Train iteration 107/164: Loss = 1.5913\n",
      "Epoch 8/50, Train iteration 108/164: Loss = 1.5766\n",
      "Epoch 8/50, Train iteration 109/164: Loss = 1.6342\n",
      "Epoch 8/50, Train iteration 110/164: Loss = 1.5701\n",
      "Epoch 8/50, Train iteration 111/164: Loss = 1.5839\n",
      "Epoch 8/50, Train iteration 112/164: Loss = 1.5742\n",
      "Epoch 8/50, Train iteration 113/164: Loss = 1.5803\n",
      "Epoch 8/50, Train iteration 114/164: Loss = 1.5399\n",
      "Epoch 8/50, Train iteration 115/164: Loss = 1.5592\n",
      "Epoch 8/50, Train iteration 116/164: Loss = 1.5498\n",
      "Epoch 8/50, Train iteration 117/164: Loss = 1.5343\n",
      "Epoch 8/50, Train iteration 118/164: Loss = 1.5789\n",
      "Epoch 8/50, Train iteration 119/164: Loss = 1.5913\n",
      "Epoch 8/50, Train iteration 120/164: Loss = 1.5710\n",
      "Epoch 8/50, Train iteration 121/164: Loss = 1.5678\n",
      "Epoch 8/50, Train iteration 122/164: Loss = 1.5590\n",
      "Epoch 8/50, Train iteration 123/164: Loss = 1.5958\n",
      "Epoch 8/50, Train iteration 124/164: Loss = 1.5605\n",
      "Epoch 8/50, Train iteration 125/164: Loss = 1.5278\n",
      "Epoch 8/50, Train iteration 126/164: Loss = 1.5154\n",
      "Epoch 8/50, Train iteration 127/164: Loss = 1.5942\n",
      "Epoch 8/50, Train iteration 128/164: Loss = 1.5525\n",
      "Epoch 8/50, Train iteration 129/164: Loss = 1.6093\n",
      "Epoch 8/50, Train iteration 130/164: Loss = 1.5584\n",
      "Epoch 8/50, Train iteration 131/164: Loss = 1.6598\n",
      "Epoch 8/50, Train iteration 132/164: Loss = 1.5028\n",
      "Epoch 8/50, Train iteration 133/164: Loss = 1.5896\n",
      "Epoch 8/50, Train iteration 134/164: Loss = 1.5373\n",
      "Epoch 8/50, Train iteration 135/164: Loss = 1.5974\n",
      "Epoch 8/50, Train iteration 136/164: Loss = 1.5458\n",
      "Epoch 8/50, Train iteration 137/164: Loss = 1.5435\n",
      "Epoch 8/50, Train iteration 138/164: Loss = 1.5615\n",
      "Epoch 8/50, Train iteration 139/164: Loss = 1.6304\n",
      "Epoch 8/50, Train iteration 140/164: Loss = 1.5543\n",
      "Epoch 8/50, Train iteration 141/164: Loss = 1.5539\n",
      "Epoch 8/50, Train iteration 142/164: Loss = 1.5474\n",
      "Epoch 8/50, Train iteration 143/164: Loss = 1.5631\n",
      "Epoch 8/50, Train iteration 144/164: Loss = 1.5985\n",
      "Epoch 8/50, Train iteration 145/164: Loss = 1.5510\n",
      "Epoch 8/50, Train iteration 146/164: Loss = 1.5697\n",
      "Epoch 8/50, Train iteration 147/164: Loss = 1.5675\n",
      "Epoch 8/50, Train iteration 148/164: Loss = 1.5633\n",
      "Epoch 8/50, Train iteration 149/164: Loss = 1.5527\n",
      "Epoch 8/50, Train iteration 150/164: Loss = 1.6228\n",
      "Epoch 8/50, Train iteration 151/164: Loss = 1.5717\n",
      "Epoch 8/50, Train iteration 152/164: Loss = 1.5448\n",
      "Epoch 8/50, Train iteration 153/164: Loss = 1.5408\n",
      "Epoch 8/50, Train iteration 154/164: Loss = 1.5850\n",
      "Epoch 8/50, Train iteration 155/164: Loss = 1.6066\n",
      "Epoch 8/50, Train iteration 156/164: Loss = 1.5752\n",
      "Epoch 8/50, Train iteration 157/164: Loss = 1.6165\n",
      "Epoch 8/50, Train iteration 158/164: Loss = 1.6235\n",
      "Epoch 8/50, Train iteration 159/164: Loss = 1.6242\n",
      "Epoch 8/50, Train iteration 160/164: Loss = 1.5813\n",
      "Epoch 8/50, Train iteration 161/164: Loss = 1.6289\n",
      "Epoch 8/50, Train iteration 162/164: Loss = 1.6004\n",
      "Epoch 8/50, Train iteration 163/164: Loss = 1.5923\n",
      "Epoch 8/50, Train iteration 164/164: Loss = 1.2878\n",
      "Epoch 8/50, Val iteration 1/27: Loss = 1.6003\n",
      "Epoch 8/50, Val iteration 2/27: Loss = 1.6109\n",
      "Epoch 8/50, Val iteration 3/27: Loss = 1.6038\n",
      "Epoch 8/50, Val iteration 4/27: Loss = 1.6006\n",
      "Epoch 8/50, Val iteration 5/27: Loss = 1.5980\n",
      "Epoch 8/50, Val iteration 6/27: Loss = 1.5909\n",
      "Epoch 8/50, Val iteration 7/27: Loss = 1.5648\n",
      "Epoch 8/50, Val iteration 8/27: Loss = 1.6015\n",
      "Epoch 8/50, Val iteration 9/27: Loss = 1.5821\n",
      "Epoch 8/50, Val iteration 10/27: Loss = 1.5887\n",
      "Epoch 8/50, Val iteration 11/27: Loss = 1.6033\n",
      "Epoch 8/50, Val iteration 12/27: Loss = 1.5749\n",
      "Epoch 8/50, Val iteration 13/27: Loss = 1.5920\n",
      "Epoch 8/50, Val iteration 14/27: Loss = 1.5775\n",
      "Epoch 8/50, Val iteration 15/27: Loss = 1.5900\n",
      "Epoch 8/50, Val iteration 16/27: Loss = 1.5757\n",
      "Epoch 8/50, Val iteration 17/27: Loss = 1.5829\n",
      "Epoch 8/50, Val iteration 18/27: Loss = 1.5749\n",
      "Epoch 8/50, Val iteration 19/27: Loss = 1.5750\n",
      "Epoch 8/50, Val iteration 20/27: Loss = 1.6029\n",
      "Epoch 8/50, Val iteration 21/27: Loss = 1.5978\n",
      "Epoch 8/50, Val iteration 22/27: Loss = 1.5889\n",
      "Epoch 8/50, Val iteration 23/27: Loss = 1.5309\n",
      "Epoch 8/50, Val iteration 24/27: Loss = 1.5734\n",
      "Epoch 8/50, Val iteration 25/27: Loss = 1.5849\n",
      "Epoch 8/50, Val iteration 26/27: Loss = 1.6004\n",
      "Epoch 8/50, Val iteration 27/27: Loss = 1.5978\n",
      "Epoch 8/50: Train Loss = 1.5736, Val Loss = 1.5876\n",
      "Current learning rate: 0.0001\n",
      "Epoch 9/50, Train iteration 1/164: Loss = 1.5543\n",
      "Epoch 9/50, Train iteration 2/164: Loss = 1.5659\n",
      "Epoch 9/50, Train iteration 3/164: Loss = 1.6213\n",
      "Epoch 9/50, Train iteration 4/164: Loss = 1.5910\n",
      "Epoch 9/50, Train iteration 5/164: Loss = 1.5855\n",
      "Epoch 9/50, Train iteration 6/164: Loss = 1.6139\n",
      "Epoch 9/50, Train iteration 7/164: Loss = 1.6221\n",
      "Epoch 9/50, Train iteration 8/164: Loss = 1.4957\n",
      "Epoch 9/50, Train iteration 9/164: Loss = 1.5669\n",
      "Epoch 9/50, Train iteration 10/164: Loss = 1.6331\n",
      "Epoch 9/50, Train iteration 11/164: Loss = 1.5849\n",
      "Epoch 9/50, Train iteration 12/164: Loss = 1.6073\n",
      "Epoch 9/50, Train iteration 13/164: Loss = 1.5547\n",
      "Epoch 9/50, Train iteration 14/164: Loss = 1.5798\n",
      "Epoch 9/50, Train iteration 15/164: Loss = 1.5830\n",
      "Epoch 9/50, Train iteration 16/164: Loss = 1.6329\n",
      "Epoch 9/50, Train iteration 17/164: Loss = 1.5835\n",
      "Epoch 9/50, Train iteration 18/164: Loss = 1.5798\n",
      "Epoch 9/50, Train iteration 19/164: Loss = 1.5488\n",
      "Epoch 9/50, Train iteration 20/164: Loss = 1.6005\n",
      "Epoch 9/50, Train iteration 21/164: Loss = 1.6081\n",
      "Epoch 9/50, Train iteration 22/164: Loss = 1.5484\n",
      "Epoch 9/50, Train iteration 23/164: Loss = 1.5378\n",
      "Epoch 9/50, Train iteration 24/164: Loss = 1.6079\n",
      "Epoch 9/50, Train iteration 25/164: Loss = 1.6075\n",
      "Epoch 9/50, Train iteration 26/164: Loss = 1.5645\n",
      "Epoch 9/50, Train iteration 27/164: Loss = 1.5763\n",
      "Epoch 9/50, Train iteration 28/164: Loss = 1.5429\n",
      "Epoch 9/50, Train iteration 29/164: Loss = 1.5837\n",
      "Epoch 9/50, Train iteration 30/164: Loss = 1.5557\n",
      "Epoch 9/50, Train iteration 31/164: Loss = 1.5610\n",
      "Epoch 9/50, Train iteration 32/164: Loss = 1.5211\n",
      "Epoch 9/50, Train iteration 33/164: Loss = 1.5660\n",
      "Epoch 9/50, Train iteration 34/164: Loss = 1.5879\n",
      "Epoch 9/50, Train iteration 35/164: Loss = 1.5855\n",
      "Epoch 9/50, Train iteration 36/164: Loss = 1.5379\n",
      "Epoch 9/50, Train iteration 37/164: Loss = 1.5827\n",
      "Epoch 9/50, Train iteration 38/164: Loss = 1.5276\n",
      "Epoch 9/50, Train iteration 39/164: Loss = 1.5850\n",
      "Epoch 9/50, Train iteration 40/164: Loss = 1.5079\n",
      "Epoch 9/50, Train iteration 41/164: Loss = 1.5431\n",
      "Epoch 9/50, Train iteration 42/164: Loss = 1.6305\n",
      "Epoch 9/50, Train iteration 43/164: Loss = 1.5676\n",
      "Epoch 9/50, Train iteration 44/164: Loss = 1.4906\n",
      "Epoch 9/50, Train iteration 45/164: Loss = 1.6145\n",
      "Epoch 9/50, Train iteration 46/164: Loss = 1.5937\n",
      "Epoch 9/50, Train iteration 47/164: Loss = 1.6088\n",
      "Epoch 9/50, Train iteration 48/164: Loss = 1.5763\n",
      "Epoch 9/50, Train iteration 49/164: Loss = 1.5659\n",
      "Epoch 9/50, Train iteration 50/164: Loss = 1.5498\n",
      "Epoch 9/50, Train iteration 51/164: Loss = 1.5212\n",
      "Epoch 9/50, Train iteration 52/164: Loss = 1.5818\n",
      "Epoch 9/50, Train iteration 53/164: Loss = 1.6043\n",
      "Epoch 9/50, Train iteration 54/164: Loss = 1.5644\n",
      "Epoch 9/50, Train iteration 55/164: Loss = 1.5669\n",
      "Epoch 9/50, Train iteration 56/164: Loss = 1.6085\n",
      "Epoch 9/50, Train iteration 57/164: Loss = 1.6174\n",
      "Epoch 9/50, Train iteration 58/164: Loss = 1.5922\n",
      "Epoch 9/50, Train iteration 59/164: Loss = 1.5326\n",
      "Epoch 9/50, Train iteration 60/164: Loss = 1.5577\n",
      "Epoch 9/50, Train iteration 61/164: Loss = 1.5102\n",
      "Epoch 9/50, Train iteration 62/164: Loss = 1.5067\n",
      "Epoch 9/50, Train iteration 63/164: Loss = 1.5900\n",
      "Epoch 9/50, Train iteration 64/164: Loss = 1.5931\n",
      "Epoch 9/50, Train iteration 65/164: Loss = 1.5283\n",
      "Epoch 9/50, Train iteration 66/164: Loss = 1.5474\n",
      "Epoch 9/50, Train iteration 67/164: Loss = 1.5341\n",
      "Epoch 9/50, Train iteration 68/164: Loss = 1.5477\n",
      "Epoch 9/50, Train iteration 69/164: Loss = 1.5574\n",
      "Epoch 9/50, Train iteration 70/164: Loss = 1.5616\n",
      "Epoch 9/50, Train iteration 71/164: Loss = 1.6286\n",
      "Epoch 9/50, Train iteration 72/164: Loss = 1.6188\n",
      "Epoch 9/50, Train iteration 73/164: Loss = 1.6375\n",
      "Epoch 9/50, Train iteration 74/164: Loss = 1.5700\n",
      "Epoch 9/50, Train iteration 75/164: Loss = 1.5305\n",
      "Epoch 9/50, Train iteration 76/164: Loss = 1.6225\n",
      "Epoch 9/50, Train iteration 77/164: Loss = 1.5964\n",
      "Epoch 9/50, Train iteration 78/164: Loss = 1.5756\n",
      "Epoch 9/50, Train iteration 79/164: Loss = 1.5461\n",
      "Epoch 9/50, Train iteration 80/164: Loss = 1.5878\n",
      "Epoch 9/50, Train iteration 81/164: Loss = 1.5448\n",
      "Epoch 9/50, Train iteration 82/164: Loss = 1.5715\n",
      "Epoch 9/50, Train iteration 83/164: Loss = 1.5805\n",
      "Epoch 9/50, Train iteration 84/164: Loss = 1.5838\n",
      "Epoch 9/50, Train iteration 85/164: Loss = 1.6508\n",
      "Epoch 9/50, Train iteration 86/164: Loss = 1.5096\n",
      "Epoch 9/50, Train iteration 87/164: Loss = 1.5340\n",
      "Epoch 9/50, Train iteration 88/164: Loss = 1.5998\n",
      "Epoch 9/50, Train iteration 89/164: Loss = 1.5783\n",
      "Epoch 9/50, Train iteration 90/164: Loss = 1.4948\n",
      "Epoch 9/50, Train iteration 91/164: Loss = 1.5615\n",
      "Epoch 9/50, Train iteration 92/164: Loss = 1.5741\n",
      "Epoch 9/50, Train iteration 93/164: Loss = 1.5978\n",
      "Epoch 9/50, Train iteration 94/164: Loss = 1.6280\n",
      "Epoch 9/50, Train iteration 95/164: Loss = 1.5556\n",
      "Epoch 9/50, Train iteration 96/164: Loss = 1.6042\n",
      "Epoch 9/50, Train iteration 97/164: Loss = 1.5342\n",
      "Epoch 9/50, Train iteration 98/164: Loss = 1.5518\n",
      "Epoch 9/50, Train iteration 99/164: Loss = 1.5507\n",
      "Epoch 9/50, Train iteration 100/164: Loss = 1.5590\n",
      "Epoch 9/50, Train iteration 101/164: Loss = 1.5245\n",
      "Epoch 9/50, Train iteration 102/164: Loss = 1.5955\n",
      "Epoch 9/50, Train iteration 103/164: Loss = 1.6027\n",
      "Epoch 9/50, Train iteration 104/164: Loss = 1.6134\n",
      "Epoch 9/50, Train iteration 105/164: Loss = 1.5802\n",
      "Epoch 9/50, Train iteration 106/164: Loss = 1.5702\n",
      "Epoch 9/50, Train iteration 107/164: Loss = 1.5873\n",
      "Epoch 9/50, Train iteration 108/164: Loss = 1.5421\n",
      "Epoch 9/50, Train iteration 109/164: Loss = 1.6008\n",
      "Epoch 9/50, Train iteration 110/164: Loss = 1.5804\n",
      "Epoch 9/50, Train iteration 111/164: Loss = 1.5960\n",
      "Epoch 9/50, Train iteration 112/164: Loss = 1.5552\n",
      "Epoch 9/50, Train iteration 113/164: Loss = 1.5342\n",
      "Epoch 9/50, Train iteration 114/164: Loss = 1.5265\n",
      "Epoch 9/50, Train iteration 115/164: Loss = 1.5604\n",
      "Epoch 9/50, Train iteration 116/164: Loss = 1.5467\n",
      "Epoch 9/50, Train iteration 117/164: Loss = 1.5375\n",
      "Epoch 9/50, Train iteration 118/164: Loss = 1.6206\n",
      "Epoch 9/50, Train iteration 119/164: Loss = 1.5452\n",
      "Epoch 9/50, Train iteration 120/164: Loss = 1.5827\n",
      "Epoch 9/50, Train iteration 121/164: Loss = 1.5884\n",
      "Epoch 9/50, Train iteration 122/164: Loss = 1.4858\n",
      "Epoch 9/50, Train iteration 123/164: Loss = 1.6050\n",
      "Epoch 9/50, Train iteration 124/164: Loss = 1.5328\n",
      "Epoch 9/50, Train iteration 125/164: Loss = 1.5851\n",
      "Epoch 9/50, Train iteration 126/164: Loss = 1.5575\n",
      "Epoch 9/50, Train iteration 127/164: Loss = 1.6078\n",
      "Epoch 9/50, Train iteration 128/164: Loss = 1.5486\n",
      "Epoch 9/50, Train iteration 129/164: Loss = 1.5614\n",
      "Epoch 9/50, Train iteration 130/164: Loss = 1.6088\n",
      "Epoch 9/50, Train iteration 131/164: Loss = 1.6288\n",
      "Epoch 9/50, Train iteration 132/164: Loss = 1.5158\n",
      "Epoch 9/50, Train iteration 133/164: Loss = 1.5605\n",
      "Epoch 9/50, Train iteration 134/164: Loss = 1.5379\n",
      "Epoch 9/50, Train iteration 135/164: Loss = 1.5611\n",
      "Epoch 9/50, Train iteration 136/164: Loss = 1.6172\n",
      "Epoch 9/50, Train iteration 137/164: Loss = 1.5466\n",
      "Epoch 9/50, Train iteration 138/164: Loss = 1.5621\n",
      "Epoch 9/50, Train iteration 139/164: Loss = 1.6087\n",
      "Epoch 9/50, Train iteration 140/164: Loss = 1.5396\n",
      "Epoch 9/50, Train iteration 141/164: Loss = 1.5665\n",
      "Epoch 9/50, Train iteration 142/164: Loss = 1.6091\n",
      "Epoch 9/50, Train iteration 143/164: Loss = 1.5371\n",
      "Epoch 9/50, Train iteration 144/164: Loss = 1.6010\n",
      "Epoch 9/50, Train iteration 145/164: Loss = 1.5799\n",
      "Epoch 9/50, Train iteration 146/164: Loss = 1.5608\n",
      "Epoch 9/50, Train iteration 147/164: Loss = 1.5711\n",
      "Epoch 9/50, Train iteration 148/164: Loss = 1.5683\n",
      "Epoch 9/50, Train iteration 149/164: Loss = 1.5660\n",
      "Epoch 9/50, Train iteration 150/164: Loss = 1.5871\n",
      "Epoch 9/50, Train iteration 151/164: Loss = 1.5788\n",
      "Epoch 9/50, Train iteration 152/164: Loss = 1.5923\n",
      "Epoch 9/50, Train iteration 153/164: Loss = 1.5847\n",
      "Epoch 9/50, Train iteration 154/164: Loss = 1.6001\n",
      "Epoch 9/50, Train iteration 155/164: Loss = 1.5627\n",
      "Epoch 9/50, Train iteration 156/164: Loss = 1.5911\n",
      "Epoch 9/50, Train iteration 157/164: Loss = 1.6086\n",
      "Epoch 9/50, Train iteration 158/164: Loss = 1.5710\n",
      "Epoch 9/50, Train iteration 159/164: Loss = 1.6110\n",
      "Epoch 9/50, Train iteration 160/164: Loss = 1.5887\n",
      "Epoch 9/50, Train iteration 161/164: Loss = 1.5937\n",
      "Epoch 9/50, Train iteration 162/164: Loss = 1.6056\n",
      "Epoch 9/50, Train iteration 163/164: Loss = 1.5583\n",
      "Epoch 9/50, Train iteration 164/164: Loss = 1.4649\n",
      "Epoch 9/50, Val iteration 1/27: Loss = 1.6037\n",
      "Epoch 9/50, Val iteration 2/27: Loss = 1.6086\n",
      "Epoch 9/50, Val iteration 3/27: Loss = 1.6006\n",
      "Epoch 9/50, Val iteration 4/27: Loss = 1.5957\n",
      "Epoch 9/50, Val iteration 5/27: Loss = 1.6062\n",
      "Epoch 9/50, Val iteration 6/27: Loss = 1.5884\n",
      "Epoch 9/50, Val iteration 7/27: Loss = 1.5721\n",
      "Epoch 9/50, Val iteration 8/27: Loss = 1.5959\n",
      "Epoch 9/50, Val iteration 9/27: Loss = 1.5873\n",
      "Epoch 9/50, Val iteration 10/27: Loss = 1.5859\n",
      "Epoch 9/50, Val iteration 11/27: Loss = 1.6013\n",
      "Epoch 9/50, Val iteration 12/27: Loss = 1.5799\n",
      "Epoch 9/50, Val iteration 13/27: Loss = 1.5964\n",
      "Epoch 9/50, Val iteration 14/27: Loss = 1.5697\n",
      "Epoch 9/50, Val iteration 15/27: Loss = 1.5859\n",
      "Epoch 9/50, Val iteration 16/27: Loss = 1.5818\n",
      "Epoch 9/50, Val iteration 17/27: Loss = 1.5831\n",
      "Epoch 9/50, Val iteration 18/27: Loss = 1.5721\n",
      "Epoch 9/50, Val iteration 19/27: Loss = 1.5751\n",
      "Epoch 9/50, Val iteration 20/27: Loss = 1.6013\n",
      "Epoch 9/50, Val iteration 21/27: Loss = 1.5896\n",
      "Epoch 9/50, Val iteration 22/27: Loss = 1.5899\n",
      "Epoch 9/50, Val iteration 23/27: Loss = 1.5418\n",
      "Epoch 9/50, Val iteration 24/27: Loss = 1.5785\n",
      "Epoch 9/50, Val iteration 25/27: Loss = 1.5858\n",
      "Epoch 9/50, Val iteration 26/27: Loss = 1.6027\n",
      "Epoch 9/50, Val iteration 27/27: Loss = 1.5841\n",
      "Epoch 9/50: Train Loss = 1.5723, Val Loss = 1.5875\n",
      "Current learning rate: 0.0001\n",
      "Epoch 10/50, Train iteration 1/164: Loss = 1.5539\n",
      "Epoch 10/50, Train iteration 2/164: Loss = 1.5640\n",
      "Epoch 10/50, Train iteration 3/164: Loss = 1.5984\n",
      "Epoch 10/50, Train iteration 4/164: Loss = 1.6064\n",
      "Epoch 10/50, Train iteration 5/164: Loss = 1.5555\n",
      "Epoch 10/50, Train iteration 6/164: Loss = 1.5852\n",
      "Epoch 10/50, Train iteration 7/164: Loss = 1.6227\n",
      "Epoch 10/50, Train iteration 8/164: Loss = 1.5396\n",
      "Epoch 10/50, Train iteration 9/164: Loss = 1.5789\n",
      "Epoch 10/50, Train iteration 10/164: Loss = 1.6066\n",
      "Epoch 10/50, Train iteration 11/164: Loss = 1.5462\n",
      "Epoch 10/50, Train iteration 12/164: Loss = 1.5985\n",
      "Epoch 10/50, Train iteration 13/164: Loss = 1.5296\n",
      "Epoch 10/50, Train iteration 14/164: Loss = 1.5566\n",
      "Epoch 10/50, Train iteration 15/164: Loss = 1.5875\n",
      "Epoch 10/50, Train iteration 16/164: Loss = 1.6026\n",
      "Epoch 10/50, Train iteration 17/164: Loss = 1.5537\n",
      "Epoch 10/50, Train iteration 18/164: Loss = 1.5397\n",
      "Epoch 10/50, Train iteration 19/164: Loss = 1.5724\n",
      "Epoch 10/50, Train iteration 20/164: Loss = 1.6024\n",
      "Epoch 10/50, Train iteration 21/164: Loss = 1.5577\n",
      "Epoch 10/50, Train iteration 22/164: Loss = 1.5840\n",
      "Epoch 10/50, Train iteration 23/164: Loss = 1.5499\n",
      "Epoch 10/50, Train iteration 24/164: Loss = 1.6001\n",
      "Epoch 10/50, Train iteration 25/164: Loss = 1.6132\n",
      "Epoch 10/50, Train iteration 26/164: Loss = 1.5274\n",
      "Epoch 10/50, Train iteration 27/164: Loss = 1.6068\n",
      "Epoch 10/50, Train iteration 28/164: Loss = 1.5681\n",
      "Epoch 10/50, Train iteration 29/164: Loss = 1.5566\n",
      "Epoch 10/50, Train iteration 30/164: Loss = 1.5887\n",
      "Epoch 10/50, Train iteration 31/164: Loss = 1.4819\n",
      "Epoch 10/50, Train iteration 32/164: Loss = 1.5744\n",
      "Epoch 10/50, Train iteration 33/164: Loss = 1.6310\n",
      "Epoch 10/50, Train iteration 34/164: Loss = 1.5541\n",
      "Epoch 10/50, Train iteration 35/164: Loss = 1.6109\n",
      "Epoch 10/50, Train iteration 36/164: Loss = 1.5732\n",
      "Epoch 10/50, Train iteration 37/164: Loss = 1.5525\n",
      "Epoch 10/50, Train iteration 38/164: Loss = 1.5595\n",
      "Epoch 10/50, Train iteration 39/164: Loss = 1.5440\n",
      "Epoch 10/50, Train iteration 40/164: Loss = 1.5232\n",
      "Epoch 10/50, Train iteration 41/164: Loss = 1.5386\n",
      "Epoch 10/50, Train iteration 42/164: Loss = 1.6130\n",
      "Epoch 10/50, Train iteration 43/164: Loss = 1.5418\n",
      "Epoch 10/50, Train iteration 44/164: Loss = 1.5212\n",
      "Epoch 10/50, Train iteration 45/164: Loss = 1.5689\n",
      "Epoch 10/50, Train iteration 46/164: Loss = 1.6361\n",
      "Epoch 10/50, Train iteration 47/164: Loss = 1.5834\n",
      "Epoch 10/50, Train iteration 48/164: Loss = 1.5362\n",
      "Epoch 10/50, Train iteration 49/164: Loss = 1.5364\n",
      "Epoch 10/50, Train iteration 50/164: Loss = 1.5604\n",
      "Epoch 10/50, Train iteration 51/164: Loss = 1.4700\n",
      "Epoch 10/50, Train iteration 52/164: Loss = 1.5113\n",
      "Epoch 10/50, Train iteration 53/164: Loss = 1.5635\n",
      "Epoch 10/50, Train iteration 54/164: Loss = 1.5026\n",
      "Epoch 10/50, Train iteration 55/164: Loss = 1.5887\n",
      "Epoch 10/50, Train iteration 56/164: Loss = 1.6080\n",
      "Epoch 10/50, Train iteration 57/164: Loss = 1.5682\n",
      "Epoch 10/50, Train iteration 58/164: Loss = 1.5977\n",
      "Epoch 10/50, Train iteration 59/164: Loss = 1.5824\n",
      "Epoch 10/50, Train iteration 60/164: Loss = 1.5379\n",
      "Epoch 10/50, Train iteration 61/164: Loss = 1.5343\n",
      "Epoch 10/50, Train iteration 62/164: Loss = 1.5612\n",
      "Epoch 10/50, Train iteration 63/164: Loss = 1.6152\n",
      "Epoch 10/50, Train iteration 64/164: Loss = 1.6117\n",
      "Epoch 10/50, Train iteration 65/164: Loss = 1.5354\n",
      "Epoch 10/50, Train iteration 66/164: Loss = 1.4823\n",
      "Epoch 10/50, Train iteration 67/164: Loss = 1.5737\n",
      "Epoch 10/50, Train iteration 68/164: Loss = 1.5394\n",
      "Epoch 10/50, Train iteration 69/164: Loss = 1.5609\n",
      "Epoch 10/50, Train iteration 70/164: Loss = 1.5606\n",
      "Epoch 10/50, Train iteration 71/164: Loss = 1.6045\n",
      "Epoch 10/50, Train iteration 72/164: Loss = 1.6128\n",
      "Epoch 10/50, Train iteration 73/164: Loss = 1.6068\n",
      "Epoch 10/50, Train iteration 74/164: Loss = 1.5378\n",
      "Epoch 10/50, Train iteration 75/164: Loss = 1.5408\n",
      "Epoch 10/50, Train iteration 76/164: Loss = 1.5636\n",
      "Epoch 10/50, Train iteration 77/164: Loss = 1.5947\n",
      "Epoch 10/50, Train iteration 78/164: Loss = 1.5998\n",
      "Epoch 10/50, Train iteration 79/164: Loss = 1.5733\n",
      "Epoch 10/50, Train iteration 80/164: Loss = 1.5972\n",
      "Epoch 10/50, Train iteration 81/164: Loss = 1.5175\n",
      "Epoch 10/50, Train iteration 82/164: Loss = 1.5930\n",
      "Epoch 10/50, Train iteration 83/164: Loss = 1.6104\n",
      "Epoch 10/50, Train iteration 84/164: Loss = 1.5161\n",
      "Epoch 10/50, Train iteration 85/164: Loss = 1.6239\n",
      "Epoch 10/50, Train iteration 86/164: Loss = 1.4860\n",
      "Epoch 10/50, Train iteration 87/164: Loss = 1.5202\n",
      "Epoch 10/50, Train iteration 88/164: Loss = 1.5531\n",
      "Epoch 10/50, Train iteration 89/164: Loss = 1.5181\n",
      "Epoch 10/50, Train iteration 90/164: Loss = 1.5888\n",
      "Epoch 10/50, Train iteration 91/164: Loss = 1.6166\n",
      "Epoch 10/50, Train iteration 92/164: Loss = 1.5772\n",
      "Epoch 10/50, Train iteration 93/164: Loss = 1.5285\n",
      "Epoch 10/50, Train iteration 94/164: Loss = 1.5514\n",
      "Epoch 10/50, Train iteration 95/164: Loss = 1.5089\n",
      "Epoch 10/50, Train iteration 96/164: Loss = 1.5598\n",
      "Epoch 10/50, Train iteration 97/164: Loss = 1.5542\n",
      "Epoch 10/50, Train iteration 98/164: Loss = 1.5715\n",
      "Epoch 10/50, Train iteration 99/164: Loss = 1.5280\n",
      "Epoch 10/50, Train iteration 100/164: Loss = 1.5159\n",
      "Epoch 10/50, Train iteration 101/164: Loss = 1.6054\n",
      "Epoch 10/50, Train iteration 102/164: Loss = 1.5586\n",
      "Epoch 10/50, Train iteration 103/164: Loss = 1.6160\n",
      "Epoch 10/50, Train iteration 104/164: Loss = 1.5854\n",
      "Epoch 10/50, Train iteration 105/164: Loss = 1.6126\n",
      "Epoch 10/50, Train iteration 106/164: Loss = 1.5853\n",
      "Epoch 10/50, Train iteration 107/164: Loss = 1.5497\n",
      "Epoch 10/50, Train iteration 108/164: Loss = 1.5578\n",
      "Epoch 10/50, Train iteration 109/164: Loss = 1.5802\n",
      "Epoch 10/50, Train iteration 110/164: Loss = 1.5818\n",
      "Epoch 10/50, Train iteration 111/164: Loss = 1.5786\n",
      "Epoch 10/50, Train iteration 112/164: Loss = 1.5703\n",
      "Epoch 10/50, Train iteration 113/164: Loss = 1.5957\n",
      "Epoch 10/50, Train iteration 114/164: Loss = 1.5312\n",
      "Epoch 10/50, Train iteration 115/164: Loss = 1.5205\n",
      "Epoch 10/50, Train iteration 116/164: Loss = 1.5215\n",
      "Epoch 10/50, Train iteration 117/164: Loss = 1.5548\n",
      "Epoch 10/50, Train iteration 118/164: Loss = 1.5921\n",
      "Epoch 10/50, Train iteration 119/164: Loss = 1.5533\n",
      "Epoch 10/50, Train iteration 120/164: Loss = 1.5295\n",
      "Epoch 10/50, Train iteration 121/164: Loss = 1.5935\n",
      "Epoch 10/50, Train iteration 122/164: Loss = 1.4146\n",
      "Epoch 10/50, Train iteration 123/164: Loss = 1.5606\n",
      "Epoch 10/50, Train iteration 124/164: Loss = 1.5660\n",
      "Epoch 10/50, Train iteration 125/164: Loss = 1.5525\n",
      "Epoch 10/50, Train iteration 126/164: Loss = 1.5102\n",
      "Epoch 10/50, Train iteration 127/164: Loss = 1.5991\n",
      "Epoch 10/50, Train iteration 128/164: Loss = 1.4822\n",
      "Epoch 10/50, Train iteration 129/164: Loss = 1.5386\n",
      "Epoch 10/50, Train iteration 130/164: Loss = 1.5442\n",
      "Epoch 10/50, Train iteration 131/164: Loss = 1.5598\n",
      "Epoch 10/50, Train iteration 132/164: Loss = 1.5557\n",
      "Epoch 10/50, Train iteration 133/164: Loss = 1.6122\n",
      "Epoch 10/50, Train iteration 134/164: Loss = 1.5501\n",
      "Epoch 10/50, Train iteration 135/164: Loss = 1.6007\n",
      "Epoch 10/50, Train iteration 136/164: Loss = 1.6102\n",
      "Epoch 10/50, Train iteration 137/164: Loss = 1.5548\n",
      "Epoch 10/50, Train iteration 138/164: Loss = 1.5601\n",
      "Epoch 10/50, Train iteration 139/164: Loss = 1.6310\n",
      "Epoch 10/50, Train iteration 140/164: Loss = 1.5061\n",
      "Epoch 10/50, Train iteration 141/164: Loss = 1.5519\n",
      "Epoch 10/50, Train iteration 142/164: Loss = 1.6182\n",
      "Epoch 10/50, Train iteration 143/164: Loss = 1.5212\n",
      "Epoch 10/50, Train iteration 144/164: Loss = 1.5933\n",
      "Epoch 10/50, Train iteration 145/164: Loss = 1.5336\n",
      "Epoch 10/50, Train iteration 146/164: Loss = 1.5715\n",
      "Epoch 10/50, Train iteration 147/164: Loss = 1.5782\n",
      "Epoch 10/50, Train iteration 148/164: Loss = 1.5318\n",
      "Epoch 10/50, Train iteration 149/164: Loss = 1.5598\n",
      "Epoch 10/50, Train iteration 150/164: Loss = 1.5913\n",
      "Epoch 10/50, Train iteration 151/164: Loss = 1.6348\n",
      "Epoch 10/50, Train iteration 152/164: Loss = 1.5407\n",
      "Epoch 10/50, Train iteration 153/164: Loss = 1.5802\n",
      "Epoch 10/50, Train iteration 154/164: Loss = 1.5409\n",
      "Epoch 10/50, Train iteration 155/164: Loss = 1.5600\n",
      "Epoch 10/50, Train iteration 156/164: Loss = 1.5271\n",
      "Epoch 10/50, Train iteration 157/164: Loss = 1.6192\n",
      "Epoch 10/50, Train iteration 158/164: Loss = 1.6192\n",
      "Epoch 10/50, Train iteration 159/164: Loss = 1.5907\n",
      "Epoch 10/50, Train iteration 160/164: Loss = 1.5924\n",
      "Epoch 10/50, Train iteration 161/164: Loss = 1.6025\n",
      "Epoch 10/50, Train iteration 162/164: Loss = 1.5708\n",
      "Epoch 10/50, Train iteration 163/164: Loss = 1.5454\n",
      "Epoch 10/50, Train iteration 164/164: Loss = 1.5462\n",
      "Epoch 10/50, Val iteration 1/27: Loss = 1.6052\n",
      "Epoch 10/50, Val iteration 2/27: Loss = 1.6017\n",
      "Epoch 10/50, Val iteration 3/27: Loss = 1.6011\n",
      "Epoch 10/50, Val iteration 4/27: Loss = 1.5974\n",
      "Epoch 10/50, Val iteration 5/27: Loss = 1.6012\n",
      "Epoch 10/50, Val iteration 6/27: Loss = 1.5863\n",
      "Epoch 10/50, Val iteration 7/27: Loss = 1.5630\n",
      "Epoch 10/50, Val iteration 8/27: Loss = 1.6001\n",
      "Epoch 10/50, Val iteration 9/27: Loss = 1.5813\n",
      "Epoch 10/50, Val iteration 10/27: Loss = 1.5838\n",
      "Epoch 10/50, Val iteration 11/27: Loss = 1.5978\n",
      "Epoch 10/50, Val iteration 12/27: Loss = 1.5711\n",
      "Epoch 10/50, Val iteration 13/27: Loss = 1.5947\n",
      "Epoch 10/50, Val iteration 14/27: Loss = 1.5674\n",
      "Epoch 10/50, Val iteration 15/27: Loss = 1.5816\n",
      "Epoch 10/50, Val iteration 16/27: Loss = 1.5821\n",
      "Epoch 10/50, Val iteration 17/27: Loss = 1.5843\n",
      "Epoch 10/50, Val iteration 18/27: Loss = 1.5664\n",
      "Epoch 10/50, Val iteration 19/27: Loss = 1.5754\n",
      "Epoch 10/50, Val iteration 20/27: Loss = 1.6033\n",
      "Epoch 10/50, Val iteration 21/27: Loss = 1.5966\n",
      "Epoch 10/50, Val iteration 22/27: Loss = 1.5883\n",
      "Epoch 10/50, Val iteration 23/27: Loss = 1.5130\n",
      "Epoch 10/50, Val iteration 24/27: Loss = 1.5738\n",
      "Epoch 10/50, Val iteration 25/27: Loss = 1.5900\n",
      "Epoch 10/50, Val iteration 26/27: Loss = 1.5998\n",
      "Epoch 10/50, Val iteration 27/27: Loss = 1.5950\n",
      "Epoch 10/50: Train Loss = 1.5651, Val Loss = 1.5853\n",
      "Current learning rate: 0.0001\n",
      "Epoch 11/50, Train iteration 1/164: Loss = 1.5732\n",
      "Epoch 11/50, Train iteration 2/164: Loss = 1.5280\n",
      "Epoch 11/50, Train iteration 3/164: Loss = 1.6157\n",
      "Epoch 11/50, Train iteration 4/164: Loss = 1.5366\n",
      "Epoch 11/50, Train iteration 5/164: Loss = 1.5712\n",
      "Epoch 11/50, Train iteration 6/164: Loss = 1.5807\n",
      "Epoch 11/50, Train iteration 7/164: Loss = 1.5903\n",
      "Epoch 11/50, Train iteration 8/164: Loss = 1.5327\n",
      "Epoch 11/50, Train iteration 9/164: Loss = 1.5642\n",
      "Epoch 11/50, Train iteration 10/164: Loss = 1.6033\n",
      "Epoch 11/50, Train iteration 11/164: Loss = 1.5997\n",
      "Epoch 11/50, Train iteration 12/164: Loss = 1.5813\n",
      "Epoch 11/50, Train iteration 13/164: Loss = 1.5330\n",
      "Epoch 11/50, Train iteration 14/164: Loss = 1.5878\n",
      "Epoch 11/50, Train iteration 15/164: Loss = 1.6025\n",
      "Epoch 11/50, Train iteration 16/164: Loss = 1.5899\n",
      "Epoch 11/50, Train iteration 17/164: Loss = 1.5346\n",
      "Epoch 11/50, Train iteration 18/164: Loss = 1.5218\n",
      "Epoch 11/50, Train iteration 19/164: Loss = 1.5820\n",
      "Epoch 11/50, Train iteration 20/164: Loss = 1.5634\n",
      "Epoch 11/50, Train iteration 21/164: Loss = 1.5529\n",
      "Epoch 11/50, Train iteration 22/164: Loss = 1.5896\n",
      "Epoch 11/50, Train iteration 23/164: Loss = 1.5584\n",
      "Epoch 11/50, Train iteration 24/164: Loss = 1.5795\n",
      "Epoch 11/50, Train iteration 25/164: Loss = 1.5610\n",
      "Epoch 11/50, Train iteration 26/164: Loss = 1.5576\n",
      "Epoch 11/50, Train iteration 27/164: Loss = 1.5456\n",
      "Epoch 11/50, Train iteration 28/164: Loss = 1.5576\n",
      "Epoch 11/50, Train iteration 29/164: Loss = 1.5899\n",
      "Epoch 11/50, Train iteration 30/164: Loss = 1.6099\n",
      "Epoch 11/50, Train iteration 31/164: Loss = 1.4953\n",
      "Epoch 11/50, Train iteration 32/164: Loss = 1.5459\n",
      "Epoch 11/50, Train iteration 33/164: Loss = 1.6009\n",
      "Epoch 11/50, Train iteration 34/164: Loss = 1.5519\n",
      "Epoch 11/50, Train iteration 35/164: Loss = 1.5521\n",
      "Epoch 11/50, Train iteration 36/164: Loss = 1.5255\n",
      "Epoch 11/50, Train iteration 37/164: Loss = 1.6222\n",
      "Epoch 11/50, Train iteration 38/164: Loss = 1.5831\n",
      "Epoch 11/50, Train iteration 39/164: Loss = 1.5218\n",
      "Epoch 11/50, Train iteration 40/164: Loss = 1.5597\n",
      "Epoch 11/50, Train iteration 41/164: Loss = 1.5483\n",
      "Epoch 11/50, Train iteration 42/164: Loss = 1.5897\n",
      "Epoch 11/50, Train iteration 43/164: Loss = 1.5867\n",
      "Epoch 11/50, Train iteration 44/164: Loss = 1.5308\n",
      "Epoch 11/50, Train iteration 45/164: Loss = 1.5611\n",
      "Epoch 11/50, Train iteration 46/164: Loss = 1.5669\n",
      "Epoch 11/50, Train iteration 47/164: Loss = 1.5476\n",
      "Epoch 11/50, Train iteration 48/164: Loss = 1.5771\n",
      "Epoch 11/50, Train iteration 49/164: Loss = 1.5590\n",
      "Epoch 11/50, Train iteration 50/164: Loss = 1.5670\n",
      "Epoch 11/50, Train iteration 51/164: Loss = 1.5366\n",
      "Epoch 11/50, Train iteration 52/164: Loss = 1.5487\n",
      "Epoch 11/50, Train iteration 53/164: Loss = 1.5557\n",
      "Epoch 11/50, Train iteration 54/164: Loss = 1.5039\n",
      "Epoch 11/50, Train iteration 55/164: Loss = 1.5414\n",
      "Epoch 11/50, Train iteration 56/164: Loss = 1.6065\n",
      "Epoch 11/50, Train iteration 57/164: Loss = 1.6289\n",
      "Epoch 11/50, Train iteration 58/164: Loss = 1.6195\n",
      "Epoch 11/50, Train iteration 59/164: Loss = 1.5875\n",
      "Epoch 11/50, Train iteration 60/164: Loss = 1.5742\n",
      "Epoch 11/50, Train iteration 61/164: Loss = 1.5425\n",
      "Epoch 11/50, Train iteration 62/164: Loss = 1.5729\n",
      "Epoch 11/50, Train iteration 63/164: Loss = 1.5994\n",
      "Epoch 11/50, Train iteration 64/164: Loss = 1.5573\n",
      "Epoch 11/50, Train iteration 65/164: Loss = 1.5830\n",
      "Epoch 11/50, Train iteration 66/164: Loss = 1.5400\n",
      "Epoch 11/50, Train iteration 67/164: Loss = 1.4941\n",
      "Epoch 11/50, Train iteration 68/164: Loss = 1.5478\n",
      "Epoch 11/50, Train iteration 69/164: Loss = 1.5585\n",
      "Epoch 11/50, Train iteration 70/164: Loss = 1.5669\n",
      "Epoch 11/50, Train iteration 71/164: Loss = 1.6028\n",
      "Epoch 11/50, Train iteration 72/164: Loss = 1.5795\n",
      "Epoch 11/50, Train iteration 73/164: Loss = 1.5821\n",
      "Epoch 11/50, Train iteration 74/164: Loss = 1.6195\n",
      "Epoch 11/50, Train iteration 75/164: Loss = 1.5227\n",
      "Epoch 11/50, Train iteration 76/164: Loss = 1.5663\n",
      "Epoch 11/50, Train iteration 77/164: Loss = 1.5733\n",
      "Epoch 11/50, Train iteration 78/164: Loss = 1.5713\n",
      "Epoch 11/50, Train iteration 79/164: Loss = 1.5539\n",
      "Epoch 11/50, Train iteration 80/164: Loss = 1.5470\n",
      "Epoch 11/50, Train iteration 81/164: Loss = 1.5853\n",
      "Epoch 11/50, Train iteration 82/164: Loss = 1.5677\n",
      "Epoch 11/50, Train iteration 83/164: Loss = 1.5694\n",
      "Epoch 11/50, Train iteration 84/164: Loss = 1.5224\n",
      "Epoch 11/50, Train iteration 85/164: Loss = 1.6690\n",
      "Epoch 11/50, Train iteration 86/164: Loss = 1.5274\n",
      "Epoch 11/50, Train iteration 87/164: Loss = 1.5870\n",
      "Epoch 11/50, Train iteration 88/164: Loss = 1.5812\n",
      "Epoch 11/50, Train iteration 89/164: Loss = 1.5759\n",
      "Epoch 11/50, Train iteration 90/164: Loss = 1.5423\n",
      "Epoch 11/50, Train iteration 91/164: Loss = 1.5319\n",
      "Epoch 11/50, Train iteration 92/164: Loss = 1.5376\n",
      "Epoch 11/50, Train iteration 93/164: Loss = 1.5673\n",
      "Epoch 11/50, Train iteration 94/164: Loss = 1.5754\n",
      "Epoch 11/50, Train iteration 95/164: Loss = 1.5496\n",
      "Epoch 11/50, Train iteration 96/164: Loss = 1.6148\n",
      "Epoch 11/50, Train iteration 97/164: Loss = 1.5393\n",
      "Epoch 11/50, Train iteration 98/164: Loss = 1.5813\n",
      "Epoch 11/50, Train iteration 99/164: Loss = 1.5411\n",
      "Epoch 11/50, Train iteration 100/164: Loss = 1.5606\n",
      "Epoch 11/50, Train iteration 101/164: Loss = 1.5597\n",
      "Epoch 11/50, Train iteration 102/164: Loss = 1.5564\n",
      "Epoch 11/50, Train iteration 103/164: Loss = 1.6228\n",
      "Epoch 11/50, Train iteration 104/164: Loss = 1.6131\n",
      "Epoch 11/50, Train iteration 105/164: Loss = 1.5414\n",
      "Epoch 11/50, Train iteration 106/164: Loss = 1.4960\n",
      "Epoch 11/50, Train iteration 107/164: Loss = 1.5621\n",
      "Epoch 11/50, Train iteration 108/164: Loss = 1.5887\n",
      "Epoch 11/50, Train iteration 109/164: Loss = 1.5415\n",
      "Epoch 11/50, Train iteration 110/164: Loss = 1.5591\n",
      "Epoch 11/50, Train iteration 111/164: Loss = 1.5885\n",
      "Epoch 11/50, Train iteration 112/164: Loss = 1.5709\n",
      "Epoch 11/50, Train iteration 113/164: Loss = 1.5551\n",
      "Epoch 11/50, Train iteration 114/164: Loss = 1.5295\n",
      "Epoch 11/50, Train iteration 115/164: Loss = 1.5773\n",
      "Epoch 11/50, Train iteration 116/164: Loss = 1.5503\n",
      "Epoch 11/50, Train iteration 117/164: Loss = 1.4967\n",
      "Epoch 11/50, Train iteration 118/164: Loss = 1.5922\n",
      "Epoch 11/50, Train iteration 119/164: Loss = 1.5484\n",
      "Epoch 11/50, Train iteration 120/164: Loss = 1.5761\n",
      "Epoch 11/50, Train iteration 121/164: Loss = 1.5724\n",
      "Epoch 11/50, Train iteration 122/164: Loss = 1.4790\n",
      "Epoch 11/50, Train iteration 123/164: Loss = 1.5817\n",
      "Epoch 11/50, Train iteration 124/164: Loss = 1.5765\n",
      "Epoch 11/50, Train iteration 125/164: Loss = 1.5329\n",
      "Epoch 11/50, Train iteration 126/164: Loss = 1.5405\n",
      "Epoch 11/50, Train iteration 127/164: Loss = 1.5733\n",
      "Epoch 11/50, Train iteration 128/164: Loss = 1.4868\n",
      "Epoch 11/50, Train iteration 129/164: Loss = 1.5518\n",
      "Epoch 11/50, Train iteration 130/164: Loss = 1.5509\n",
      "Epoch 11/50, Train iteration 131/164: Loss = 1.6070\n",
      "Epoch 11/50, Train iteration 132/164: Loss = 1.5632\n",
      "Epoch 11/50, Train iteration 133/164: Loss = 1.5570\n",
      "Epoch 11/50, Train iteration 134/164: Loss = 1.4763\n",
      "Epoch 11/50, Train iteration 135/164: Loss = 1.6209\n",
      "Epoch 11/50, Train iteration 136/164: Loss = 1.5839\n",
      "Epoch 11/50, Train iteration 137/164: Loss = 1.5143\n",
      "Epoch 11/50, Train iteration 138/164: Loss = 1.5971\n",
      "Epoch 11/50, Train iteration 139/164: Loss = 1.5964\n",
      "Epoch 11/50, Train iteration 140/164: Loss = 1.5564\n",
      "Epoch 11/50, Train iteration 141/164: Loss = 1.5476\n",
      "Epoch 11/50, Train iteration 142/164: Loss = 1.5799\n",
      "Epoch 11/50, Train iteration 143/164: Loss = 1.5336\n",
      "Epoch 11/50, Train iteration 144/164: Loss = 1.6182\n",
      "Epoch 11/50, Train iteration 145/164: Loss = 1.5569\n",
      "Epoch 11/50, Train iteration 146/164: Loss = 1.5507\n",
      "Epoch 11/50, Train iteration 147/164: Loss = 1.6035\n",
      "Epoch 11/50, Train iteration 148/164: Loss = 1.5705\n",
      "Epoch 11/50, Train iteration 149/164: Loss = 1.5953\n",
      "Epoch 11/50, Train iteration 150/164: Loss = 1.5879\n",
      "Epoch 11/50, Train iteration 151/164: Loss = 1.5367\n",
      "Epoch 11/50, Train iteration 152/164: Loss = 1.5483\n",
      "Epoch 11/50, Train iteration 153/164: Loss = 1.5455\n",
      "Epoch 11/50, Train iteration 154/164: Loss = 1.5319\n",
      "Epoch 11/50, Train iteration 155/164: Loss = 1.5466\n",
      "Epoch 11/50, Train iteration 156/164: Loss = 1.5365\n",
      "Epoch 11/50, Train iteration 157/164: Loss = 1.5476\n",
      "Epoch 11/50, Train iteration 158/164: Loss = 1.5892\n",
      "Epoch 11/50, Train iteration 159/164: Loss = 1.5903\n",
      "Epoch 11/50, Train iteration 160/164: Loss = 1.5634\n",
      "Epoch 11/50, Train iteration 161/164: Loss = 1.6262\n",
      "Epoch 11/50, Train iteration 162/164: Loss = 1.6008\n",
      "Epoch 11/50, Train iteration 163/164: Loss = 1.5433\n",
      "Epoch 11/50, Train iteration 164/164: Loss = 1.3663\n",
      "Epoch 11/50, Val iteration 1/27: Loss = 1.6078\n",
      "Epoch 11/50, Val iteration 2/27: Loss = 1.6059\n",
      "Epoch 11/50, Val iteration 3/27: Loss = 1.5977\n",
      "Epoch 11/50, Val iteration 4/27: Loss = 1.5875\n",
      "Epoch 11/50, Val iteration 5/27: Loss = 1.6028\n",
      "Epoch 11/50, Val iteration 6/27: Loss = 1.5880\n",
      "Epoch 11/50, Val iteration 7/27: Loss = 1.5550\n",
      "Epoch 11/50, Val iteration 8/27: Loss = 1.5919\n",
      "Epoch 11/50, Val iteration 9/27: Loss = 1.5830\n",
      "Epoch 11/50, Val iteration 10/27: Loss = 1.5749\n",
      "Epoch 11/50, Val iteration 11/27: Loss = 1.5992\n",
      "Epoch 11/50, Val iteration 12/27: Loss = 1.5671\n",
      "Epoch 11/50, Val iteration 13/27: Loss = 1.5751\n",
      "Epoch 11/50, Val iteration 14/27: Loss = 1.5542\n",
      "Epoch 11/50, Val iteration 15/27: Loss = 1.5728\n",
      "Epoch 11/50, Val iteration 16/27: Loss = 1.5752\n",
      "Epoch 11/50, Val iteration 17/27: Loss = 1.5791\n",
      "Epoch 11/50, Val iteration 18/27: Loss = 1.5628\n",
      "Epoch 11/50, Val iteration 19/27: Loss = 1.5703\n",
      "Epoch 11/50, Val iteration 20/27: Loss = 1.5870\n",
      "Epoch 11/50, Val iteration 21/27: Loss = 1.5881\n",
      "Epoch 11/50, Val iteration 22/27: Loss = 1.5904\n",
      "Epoch 11/50, Val iteration 23/27: Loss = 1.5095\n",
      "Epoch 11/50, Val iteration 24/27: Loss = 1.5685\n",
      "Epoch 11/50, Val iteration 25/27: Loss = 1.5786\n",
      "Epoch 11/50, Val iteration 26/27: Loss = 1.5887\n",
      "Epoch 11/50, Val iteration 27/27: Loss = 1.5773\n",
      "Epoch 11/50: Train Loss = 1.5632, Val Loss = 1.5792\n",
      "Current learning rate: 0.0001\n",
      "Epoch 12/50, Train iteration 1/164: Loss = 1.5696\n",
      "Epoch 12/50, Train iteration 2/164: Loss = 1.5647\n",
      "Epoch 12/50, Train iteration 3/164: Loss = 1.5791\n",
      "Epoch 12/50, Train iteration 4/164: Loss = 1.5578\n",
      "Epoch 12/50, Train iteration 5/164: Loss = 1.5861\n",
      "Epoch 12/50, Train iteration 6/164: Loss = 1.6326\n",
      "Epoch 12/50, Train iteration 7/164: Loss = 1.5884\n",
      "Epoch 12/50, Train iteration 8/164: Loss = 1.5383\n",
      "Epoch 12/50, Train iteration 9/164: Loss = 1.5642\n",
      "Epoch 12/50, Train iteration 10/164: Loss = 1.5773\n",
      "Epoch 12/50, Train iteration 11/164: Loss = 1.5965\n",
      "Epoch 12/50, Train iteration 12/164: Loss = 1.5364\n",
      "Epoch 12/50, Train iteration 13/164: Loss = 1.4858\n",
      "Epoch 12/50, Train iteration 14/164: Loss = 1.5771\n",
      "Epoch 12/50, Train iteration 15/164: Loss = 1.5182\n",
      "Epoch 12/50, Train iteration 16/164: Loss = 1.5832\n",
      "Epoch 12/50, Train iteration 17/164: Loss = 1.5644\n",
      "Epoch 12/50, Train iteration 18/164: Loss = 1.5425\n",
      "Epoch 12/50, Train iteration 19/164: Loss = 1.5603\n",
      "Epoch 12/50, Train iteration 20/164: Loss = 1.5736\n",
      "Epoch 12/50, Train iteration 21/164: Loss = 1.5365\n",
      "Epoch 12/50, Train iteration 22/164: Loss = 1.5479\n",
      "Epoch 12/50, Train iteration 23/164: Loss = 1.5447\n",
      "Epoch 12/50, Train iteration 24/164: Loss = 1.5797\n",
      "Epoch 12/50, Train iteration 25/164: Loss = 1.5990\n",
      "Epoch 12/50, Train iteration 26/164: Loss = 1.5940\n",
      "Epoch 12/50, Train iteration 27/164: Loss = 1.5912\n",
      "Epoch 12/50, Train iteration 28/164: Loss = 1.5400\n",
      "Epoch 12/50, Train iteration 29/164: Loss = 1.5467\n",
      "Epoch 12/50, Train iteration 30/164: Loss = 1.5874\n",
      "Epoch 12/50, Train iteration 31/164: Loss = 1.5124\n",
      "Epoch 12/50, Train iteration 32/164: Loss = 1.5323\n",
      "Epoch 12/50, Train iteration 33/164: Loss = 1.5996\n",
      "Epoch 12/50, Train iteration 34/164: Loss = 1.4998\n",
      "Epoch 12/50, Train iteration 35/164: Loss = 1.5629\n",
      "Epoch 12/50, Train iteration 36/164: Loss = 1.5476\n",
      "Epoch 12/50, Train iteration 37/164: Loss = 1.5985\n",
      "Epoch 12/50, Train iteration 38/164: Loss = 1.5282\n",
      "Epoch 12/50, Train iteration 39/164: Loss = 1.5501\n",
      "Epoch 12/50, Train iteration 40/164: Loss = 1.5386\n",
      "Epoch 12/50, Train iteration 41/164: Loss = 1.5498\n",
      "Epoch 12/50, Train iteration 42/164: Loss = 1.5814\n",
      "Epoch 12/50, Train iteration 43/164: Loss = 1.5366\n",
      "Epoch 12/50, Train iteration 44/164: Loss = 1.6243\n",
      "Epoch 12/50, Train iteration 45/164: Loss = 1.5834\n",
      "Epoch 12/50, Train iteration 46/164: Loss = 1.5437\n",
      "Epoch 12/50, Train iteration 47/164: Loss = 1.5654\n",
      "Epoch 12/50, Train iteration 48/164: Loss = 1.5262\n",
      "Epoch 12/50, Train iteration 49/164: Loss = 1.4974\n",
      "Epoch 12/50, Train iteration 50/164: Loss = 1.5605\n",
      "Epoch 12/50, Train iteration 51/164: Loss = 1.5138\n",
      "Epoch 12/50, Train iteration 52/164: Loss = 1.5117\n",
      "Epoch 12/50, Train iteration 53/164: Loss = 1.5656\n",
      "Epoch 12/50, Train iteration 54/164: Loss = 1.6135\n",
      "Epoch 12/50, Train iteration 55/164: Loss = 1.5974\n",
      "Epoch 12/50, Train iteration 56/164: Loss = 1.5677\n",
      "Epoch 12/50, Train iteration 57/164: Loss = 1.5440\n",
      "Epoch 12/50, Train iteration 58/164: Loss = 1.5656\n",
      "Epoch 12/50, Train iteration 59/164: Loss = 1.5057\n",
      "Epoch 12/50, Train iteration 60/164: Loss = 1.5598\n",
      "Epoch 12/50, Train iteration 61/164: Loss = 1.4871\n",
      "Epoch 12/50, Train iteration 62/164: Loss = 1.5536\n",
      "Epoch 12/50, Train iteration 63/164: Loss = 1.6021\n",
      "Epoch 12/50, Train iteration 64/164: Loss = 1.5334\n",
      "Epoch 12/50, Train iteration 65/164: Loss = 1.4971\n",
      "Epoch 12/50, Train iteration 66/164: Loss = 1.5060\n",
      "Epoch 12/50, Train iteration 67/164: Loss = 1.4625\n",
      "Epoch 12/50, Train iteration 68/164: Loss = 1.5780\n",
      "Epoch 12/50, Train iteration 69/164: Loss = 1.6138\n",
      "Epoch 12/50, Train iteration 70/164: Loss = 1.5325\n",
      "Epoch 12/50, Train iteration 71/164: Loss = 1.5558\n",
      "Epoch 12/50, Train iteration 72/164: Loss = 1.6213\n",
      "Epoch 12/50, Train iteration 73/164: Loss = 1.6399\n",
      "Epoch 12/50, Train iteration 74/164: Loss = 1.5659\n",
      "Epoch 12/50, Train iteration 75/164: Loss = 1.5310\n",
      "Epoch 12/50, Train iteration 76/164: Loss = 1.5153\n",
      "Epoch 12/50, Train iteration 77/164: Loss = 1.5704\n",
      "Epoch 12/50, Train iteration 78/164: Loss = 1.5909\n",
      "Epoch 12/50, Train iteration 79/164: Loss = 1.5893\n",
      "Epoch 12/50, Train iteration 80/164: Loss = 1.5724\n",
      "Epoch 12/50, Train iteration 81/164: Loss = 1.5138\n",
      "Epoch 12/50, Train iteration 82/164: Loss = 1.6372\n",
      "Epoch 12/50, Train iteration 83/164: Loss = 1.6021\n",
      "Epoch 12/50, Train iteration 84/164: Loss = 1.5729\n",
      "Epoch 12/50, Train iteration 85/164: Loss = 1.6483\n",
      "Epoch 12/50, Train iteration 86/164: Loss = 1.4938\n",
      "Epoch 12/50, Train iteration 87/164: Loss = 1.5542\n",
      "Epoch 12/50, Train iteration 88/164: Loss = 1.6286\n",
      "Epoch 12/50, Train iteration 89/164: Loss = 1.5387\n",
      "Epoch 12/50, Train iteration 90/164: Loss = 1.5625\n",
      "Epoch 12/50, Train iteration 91/164: Loss = 1.5913\n",
      "Epoch 12/50, Train iteration 92/164: Loss = 1.5474\n",
      "Epoch 12/50, Train iteration 93/164: Loss = 1.5492\n",
      "Epoch 12/50, Train iteration 94/164: Loss = 1.5955\n",
      "Epoch 12/50, Train iteration 95/164: Loss = 1.5637\n",
      "Epoch 12/50, Train iteration 96/164: Loss = 1.5871\n",
      "Epoch 12/50, Train iteration 97/164: Loss = 1.5604\n",
      "Epoch 12/50, Train iteration 98/164: Loss = 1.5720\n",
      "Epoch 12/50, Train iteration 99/164: Loss = 1.5252\n",
      "Epoch 12/50, Train iteration 100/164: Loss = 1.5484\n",
      "Epoch 12/50, Train iteration 101/164: Loss = 1.5404\n",
      "Epoch 12/50, Train iteration 102/164: Loss = 1.5569\n",
      "Epoch 12/50, Train iteration 103/164: Loss = 1.6115\n",
      "Epoch 12/50, Train iteration 104/164: Loss = 1.5924\n",
      "Epoch 12/50, Train iteration 105/164: Loss = 1.6390\n",
      "Epoch 12/50, Train iteration 106/164: Loss = 1.5907\n",
      "Epoch 12/50, Train iteration 107/164: Loss = 1.5447\n",
      "Epoch 12/50, Train iteration 108/164: Loss = 1.5435\n",
      "Epoch 12/50, Train iteration 109/164: Loss = 1.5906\n",
      "Epoch 12/50, Train iteration 110/164: Loss = 1.5498\n",
      "Epoch 12/50, Train iteration 111/164: Loss = 1.5542\n",
      "Epoch 12/50, Train iteration 112/164: Loss = 1.5459\n",
      "Epoch 12/50, Train iteration 113/164: Loss = 1.4956\n",
      "Epoch 12/50, Train iteration 114/164: Loss = 1.5266\n",
      "Epoch 12/50, Train iteration 115/164: Loss = 1.5563\n",
      "Epoch 12/50, Train iteration 116/164: Loss = 1.5684\n",
      "Epoch 12/50, Train iteration 117/164: Loss = 1.5239\n",
      "Epoch 12/50, Train iteration 118/164: Loss = 1.5974\n",
      "Epoch 12/50, Train iteration 119/164: Loss = 1.5815\n",
      "Epoch 12/50, Train iteration 120/164: Loss = 1.5227\n",
      "Epoch 12/50, Train iteration 121/164: Loss = 1.5476\n",
      "Epoch 12/50, Train iteration 122/164: Loss = 1.4259\n",
      "Epoch 12/50, Train iteration 123/164: Loss = 1.5783\n",
      "Epoch 12/50, Train iteration 124/164: Loss = 1.5188\n",
      "Epoch 12/50, Train iteration 125/164: Loss = 1.5663\n",
      "Epoch 12/50, Train iteration 126/164: Loss = 1.5278\n",
      "Epoch 12/50, Train iteration 127/164: Loss = 1.5902\n",
      "Epoch 12/50, Train iteration 128/164: Loss = 1.4978\n",
      "Epoch 12/50, Train iteration 129/164: Loss = 1.5157\n",
      "Epoch 12/50, Train iteration 130/164: Loss = 1.5729\n",
      "Epoch 12/50, Train iteration 131/164: Loss = 1.6261\n",
      "Epoch 12/50, Train iteration 132/164: Loss = 1.5282\n",
      "Epoch 12/50, Train iteration 133/164: Loss = 1.5712\n",
      "Epoch 12/50, Train iteration 134/164: Loss = 1.5567\n",
      "Epoch 12/50, Train iteration 135/164: Loss = 1.5697\n",
      "Epoch 12/50, Train iteration 136/164: Loss = 1.5631\n",
      "Epoch 12/50, Train iteration 137/164: Loss = 1.5561\n",
      "Epoch 12/50, Train iteration 138/164: Loss = 1.6113\n",
      "Epoch 12/50, Train iteration 139/164: Loss = 1.5851\n",
      "Epoch 12/50, Train iteration 140/164: Loss = 1.5664\n",
      "Epoch 12/50, Train iteration 141/164: Loss = 1.5009\n",
      "Epoch 12/50, Train iteration 142/164: Loss = 1.6084\n",
      "Epoch 12/50, Train iteration 143/164: Loss = 1.5033\n",
      "Epoch 12/50, Train iteration 144/164: Loss = 1.6295\n",
      "Epoch 12/50, Train iteration 145/164: Loss = 1.5441\n",
      "Epoch 12/50, Train iteration 146/164: Loss = 1.5963\n",
      "Epoch 12/50, Train iteration 147/164: Loss = 1.5259\n",
      "Epoch 12/50, Train iteration 148/164: Loss = 1.5672\n",
      "Epoch 12/50, Train iteration 149/164: Loss = 1.5737\n",
      "Epoch 12/50, Train iteration 150/164: Loss = 1.5928\n",
      "Epoch 12/50, Train iteration 151/164: Loss = 1.5687\n",
      "Epoch 12/50, Train iteration 152/164: Loss = 1.5121\n",
      "Epoch 12/50, Train iteration 153/164: Loss = 1.6280\n",
      "Epoch 12/50, Train iteration 154/164: Loss = 1.6014\n",
      "Epoch 12/50, Train iteration 155/164: Loss = 1.5685\n",
      "Epoch 12/50, Train iteration 156/164: Loss = 1.5119\n",
      "Epoch 12/50, Train iteration 157/164: Loss = 1.5369\n",
      "Epoch 12/50, Train iteration 158/164: Loss = 1.5608\n",
      "Epoch 12/50, Train iteration 159/164: Loss = 1.5467\n",
      "Epoch 12/50, Train iteration 160/164: Loss = 1.5558\n",
      "Epoch 12/50, Train iteration 161/164: Loss = 1.6147\n",
      "Epoch 12/50, Train iteration 162/164: Loss = 1.5744\n",
      "Epoch 12/50, Train iteration 163/164: Loss = 1.5557\n",
      "Epoch 12/50, Train iteration 164/164: Loss = 1.3671\n",
      "Epoch 12/50, Val iteration 1/27: Loss = 1.6101\n",
      "Epoch 12/50, Val iteration 2/27: Loss = 1.6145\n",
      "Epoch 12/50, Val iteration 3/27: Loss = 1.6005\n",
      "Epoch 12/50, Val iteration 4/27: Loss = 1.5934\n",
      "Epoch 12/50, Val iteration 5/27: Loss = 1.6037\n",
      "Epoch 12/50, Val iteration 6/27: Loss = 1.5822\n",
      "Epoch 12/50, Val iteration 7/27: Loss = 1.5473\n",
      "Epoch 12/50, Val iteration 8/27: Loss = 1.6017\n",
      "Epoch 12/50, Val iteration 9/27: Loss = 1.5902\n",
      "Epoch 12/50, Val iteration 10/27: Loss = 1.5687\n",
      "Epoch 12/50, Val iteration 11/27: Loss = 1.6005\n",
      "Epoch 12/50, Val iteration 12/27: Loss = 1.5587\n",
      "Epoch 12/50, Val iteration 13/27: Loss = 1.5644\n",
      "Epoch 12/50, Val iteration 14/27: Loss = 1.5565\n",
      "Epoch 12/50, Val iteration 15/27: Loss = 1.5767\n",
      "Epoch 12/50, Val iteration 16/27: Loss = 1.5732\n",
      "Epoch 12/50, Val iteration 17/27: Loss = 1.5849\n",
      "Epoch 12/50, Val iteration 18/27: Loss = 1.5534\n",
      "Epoch 12/50, Val iteration 19/27: Loss = 1.5672\n",
      "Epoch 12/50, Val iteration 20/27: Loss = 1.5977\n",
      "Epoch 12/50, Val iteration 21/27: Loss = 1.5940\n",
      "Epoch 12/50, Val iteration 22/27: Loss = 1.5883\n",
      "Epoch 12/50, Val iteration 23/27: Loss = 1.4896\n",
      "Epoch 12/50, Val iteration 24/27: Loss = 1.5632\n",
      "Epoch 12/50, Val iteration 25/27: Loss = 1.5808\n",
      "Epoch 12/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 12/50, Val iteration 27/27: Loss = 1.5841\n",
      "Epoch 12/50: Train Loss = 1.5592, Val Loss = 1.5792\n",
      "Current learning rate: 0.0001\n",
      "Epoch 13/50, Train iteration 1/164: Loss = 1.5716\n",
      "Epoch 13/50, Train iteration 2/164: Loss = 1.5333\n",
      "Epoch 13/50, Train iteration 3/164: Loss = 1.5943\n",
      "Epoch 13/50, Train iteration 4/164: Loss = 1.6288\n",
      "Epoch 13/50, Train iteration 5/164: Loss = 1.5944\n",
      "Epoch 13/50, Train iteration 6/164: Loss = 1.6194\n",
      "Epoch 13/50, Train iteration 7/164: Loss = 1.6053\n",
      "Epoch 13/50, Train iteration 8/164: Loss = 1.5065\n",
      "Epoch 13/50, Train iteration 9/164: Loss = 1.5660\n",
      "Epoch 13/50, Train iteration 10/164: Loss = 1.6102\n",
      "Epoch 13/50, Train iteration 11/164: Loss = 1.6052\n",
      "Epoch 13/50, Train iteration 12/164: Loss = 1.5725\n",
      "Epoch 13/50, Train iteration 13/164: Loss = 1.5311\n",
      "Epoch 13/50, Train iteration 14/164: Loss = 1.5371\n",
      "Epoch 13/50, Train iteration 15/164: Loss = 1.5502\n",
      "Epoch 13/50, Train iteration 16/164: Loss = 1.5579\n",
      "Epoch 13/50, Train iteration 17/164: Loss = 1.5454\n",
      "Epoch 13/50, Train iteration 18/164: Loss = 1.5292\n",
      "Epoch 13/50, Train iteration 19/164: Loss = 1.5587\n",
      "Epoch 13/50, Train iteration 20/164: Loss = 1.5605\n",
      "Epoch 13/50, Train iteration 21/164: Loss = 1.5445\n",
      "Epoch 13/50, Train iteration 22/164: Loss = 1.5978\n",
      "Epoch 13/50, Train iteration 23/164: Loss = 1.5243\n",
      "Epoch 13/50, Train iteration 24/164: Loss = 1.6308\n",
      "Epoch 13/50, Train iteration 25/164: Loss = 1.5907\n",
      "Epoch 13/50, Train iteration 26/164: Loss = 1.5175\n",
      "Epoch 13/50, Train iteration 27/164: Loss = 1.5729\n",
      "Epoch 13/50, Train iteration 28/164: Loss = 1.5527\n",
      "Epoch 13/50, Train iteration 29/164: Loss = 1.5504\n",
      "Epoch 13/50, Train iteration 30/164: Loss = 1.6187\n",
      "Epoch 13/50, Train iteration 31/164: Loss = 1.4814\n",
      "Epoch 13/50, Train iteration 32/164: Loss = 1.5765\n",
      "Epoch 13/50, Train iteration 33/164: Loss = 1.5397\n",
      "Epoch 13/50, Train iteration 34/164: Loss = 1.5369\n",
      "Epoch 13/50, Train iteration 35/164: Loss = 1.5707\n",
      "Epoch 13/50, Train iteration 36/164: Loss = 1.5331\n",
      "Epoch 13/50, Train iteration 37/164: Loss = 1.5761\n",
      "Epoch 13/50, Train iteration 38/164: Loss = 1.5581\n",
      "Epoch 13/50, Train iteration 39/164: Loss = 1.5738\n",
      "Epoch 13/50, Train iteration 40/164: Loss = 1.5321\n",
      "Epoch 13/50, Train iteration 41/164: Loss = 1.5231\n",
      "Epoch 13/50, Train iteration 42/164: Loss = 1.6189\n",
      "Epoch 13/50, Train iteration 43/164: Loss = 1.5644\n",
      "Epoch 13/50, Train iteration 44/164: Loss = 1.5085\n",
      "Epoch 13/50, Train iteration 45/164: Loss = 1.5777\n",
      "Epoch 13/50, Train iteration 46/164: Loss = 1.5766\n",
      "Epoch 13/50, Train iteration 47/164: Loss = 1.5893\n",
      "Epoch 13/50, Train iteration 48/164: Loss = 1.6104\n",
      "Epoch 13/50, Train iteration 49/164: Loss = 1.4787\n",
      "Epoch 13/50, Train iteration 50/164: Loss = 1.6416\n",
      "Epoch 13/50, Train iteration 51/164: Loss = 1.5336\n",
      "Epoch 13/50, Train iteration 52/164: Loss = 1.4978\n",
      "Epoch 13/50, Train iteration 53/164: Loss = 1.5352\n",
      "Epoch 13/50, Train iteration 54/164: Loss = 1.5359\n",
      "Epoch 13/50, Train iteration 55/164: Loss = 1.5370\n",
      "Epoch 13/50, Train iteration 56/164: Loss = 1.6148\n",
      "Epoch 13/50, Train iteration 57/164: Loss = 1.5562\n",
      "Epoch 13/50, Train iteration 58/164: Loss = 1.6284\n",
      "Epoch 13/50, Train iteration 59/164: Loss = 1.5327\n",
      "Epoch 13/50, Train iteration 60/164: Loss = 1.5755\n",
      "Epoch 13/50, Train iteration 61/164: Loss = 1.5304\n",
      "Epoch 13/50, Train iteration 62/164: Loss = 1.5190\n",
      "Epoch 13/50, Train iteration 63/164: Loss = 1.6002\n",
      "Epoch 13/50, Train iteration 64/164: Loss = 1.5541\n",
      "Epoch 13/50, Train iteration 65/164: Loss = 1.5574\n",
      "Epoch 13/50, Train iteration 66/164: Loss = 1.5465\n",
      "Epoch 13/50, Train iteration 67/164: Loss = 1.5283\n",
      "Epoch 13/50, Train iteration 68/164: Loss = 1.5249\n",
      "Epoch 13/50, Train iteration 69/164: Loss = 1.5741\n",
      "Epoch 13/50, Train iteration 70/164: Loss = 1.5788\n",
      "Epoch 13/50, Train iteration 71/164: Loss = 1.5849\n",
      "Epoch 13/50, Train iteration 72/164: Loss = 1.5655\n",
      "Epoch 13/50, Train iteration 73/164: Loss = 1.6268\n",
      "Epoch 13/50, Train iteration 74/164: Loss = 1.6226\n",
      "Epoch 13/50, Train iteration 75/164: Loss = 1.5365\n",
      "Epoch 13/50, Train iteration 76/164: Loss = 1.5481\n",
      "Epoch 13/50, Train iteration 77/164: Loss = 1.5576\n",
      "Epoch 13/50, Train iteration 78/164: Loss = 1.5772\n",
      "Epoch 13/50, Train iteration 79/164: Loss = 1.5613\n",
      "Epoch 13/50, Train iteration 80/164: Loss = 1.5658\n",
      "Epoch 13/50, Train iteration 81/164: Loss = 1.5803\n",
      "Epoch 13/50, Train iteration 82/164: Loss = 1.5247\n",
      "Epoch 13/50, Train iteration 83/164: Loss = 1.5544\n",
      "Epoch 13/50, Train iteration 84/164: Loss = 1.5323\n",
      "Epoch 13/50, Train iteration 85/164: Loss = 1.5958\n",
      "Epoch 13/50, Train iteration 86/164: Loss = 1.4745\n",
      "Epoch 13/50, Train iteration 87/164: Loss = 1.5344\n",
      "Epoch 13/50, Train iteration 88/164: Loss = 1.6428\n",
      "Epoch 13/50, Train iteration 89/164: Loss = 1.5906\n",
      "Epoch 13/50, Train iteration 90/164: Loss = 1.5467\n",
      "Epoch 13/50, Train iteration 91/164: Loss = 1.6612\n",
      "Epoch 13/50, Train iteration 92/164: Loss = 1.5776\n",
      "Epoch 13/50, Train iteration 93/164: Loss = 1.5537\n",
      "Epoch 13/50, Train iteration 94/164: Loss = 1.5012\n",
      "Epoch 13/50, Train iteration 95/164: Loss = 1.5540\n",
      "Epoch 13/50, Train iteration 96/164: Loss = 1.5891\n",
      "Epoch 13/50, Train iteration 97/164: Loss = 1.5640\n",
      "Epoch 13/50, Train iteration 98/164: Loss = 1.5421\n",
      "Epoch 13/50, Train iteration 99/164: Loss = 1.5085\n",
      "Epoch 13/50, Train iteration 100/164: Loss = 1.5586\n",
      "Epoch 13/50, Train iteration 101/164: Loss = 1.5237\n",
      "Epoch 13/50, Train iteration 102/164: Loss = 1.5337\n",
      "Epoch 13/50, Train iteration 103/164: Loss = 1.5959\n",
      "Epoch 13/50, Train iteration 104/164: Loss = 1.5750\n",
      "Epoch 13/50, Train iteration 105/164: Loss = 1.6030\n",
      "Epoch 13/50, Train iteration 106/164: Loss = 1.6106\n",
      "Epoch 13/50, Train iteration 107/164: Loss = 1.5460\n",
      "Epoch 13/50, Train iteration 108/164: Loss = 1.5855\n",
      "Epoch 13/50, Train iteration 109/164: Loss = 1.5587\n",
      "Epoch 13/50, Train iteration 110/164: Loss = 1.5427\n",
      "Epoch 13/50, Train iteration 111/164: Loss = 1.6057\n",
      "Epoch 13/50, Train iteration 112/164: Loss = 1.5741\n",
      "Epoch 13/50, Train iteration 113/164: Loss = 1.5496\n",
      "Epoch 13/50, Train iteration 114/164: Loss = 1.4914\n",
      "Epoch 13/50, Train iteration 115/164: Loss = 1.5332\n",
      "Epoch 13/50, Train iteration 116/164: Loss = 1.5340\n",
      "Epoch 13/50, Train iteration 117/164: Loss = 1.4804\n",
      "Epoch 13/50, Train iteration 118/164: Loss = 1.5555\n",
      "Epoch 13/50, Train iteration 119/164: Loss = 1.5837\n",
      "Epoch 13/50, Train iteration 120/164: Loss = 1.5483\n",
      "Epoch 13/50, Train iteration 121/164: Loss = 1.5476\n",
      "Epoch 13/50, Train iteration 122/164: Loss = 1.4917\n",
      "Epoch 13/50, Train iteration 123/164: Loss = 1.5826\n",
      "Epoch 13/50, Train iteration 124/164: Loss = 1.5457\n",
      "Epoch 13/50, Train iteration 125/164: Loss = 1.5811\n",
      "Epoch 13/50, Train iteration 126/164: Loss = 1.5484\n",
      "Epoch 13/50, Train iteration 127/164: Loss = 1.5775\n",
      "Epoch 13/50, Train iteration 128/164: Loss = 1.4951\n",
      "Epoch 13/50, Train iteration 129/164: Loss = 1.5404\n",
      "Epoch 13/50, Train iteration 130/164: Loss = 1.5869\n",
      "Epoch 13/50, Train iteration 131/164: Loss = 1.5537\n",
      "Epoch 13/50, Train iteration 132/164: Loss = 1.5282\n",
      "Epoch 13/50, Train iteration 133/164: Loss = 1.5909\n",
      "Epoch 13/50, Train iteration 134/164: Loss = 1.5282\n",
      "Epoch 13/50, Train iteration 135/164: Loss = 1.5585\n",
      "Epoch 13/50, Train iteration 136/164: Loss = 1.5880\n",
      "Epoch 13/50, Train iteration 137/164: Loss = 1.5182\n",
      "Epoch 13/50, Train iteration 138/164: Loss = 1.5790\n",
      "Epoch 13/50, Train iteration 139/164: Loss = 1.5863\n",
      "Epoch 13/50, Train iteration 140/164: Loss = 1.5879\n",
      "Epoch 13/50, Train iteration 141/164: Loss = 1.5347\n",
      "Epoch 13/50, Train iteration 142/164: Loss = 1.6079\n",
      "Epoch 13/50, Train iteration 143/164: Loss = 1.4804\n",
      "Epoch 13/50, Train iteration 144/164: Loss = 1.6279\n",
      "Epoch 13/50, Train iteration 145/164: Loss = 1.5682\n",
      "Epoch 13/50, Train iteration 146/164: Loss = 1.5549\n",
      "Epoch 13/50, Train iteration 147/164: Loss = 1.5945\n",
      "Epoch 13/50, Train iteration 148/164: Loss = 1.5109\n",
      "Epoch 13/50, Train iteration 149/164: Loss = 1.5257\n",
      "Epoch 13/50, Train iteration 150/164: Loss = 1.5577\n",
      "Epoch 13/50, Train iteration 151/164: Loss = 1.5615\n",
      "Epoch 13/50, Train iteration 152/164: Loss = 1.5692\n",
      "Epoch 13/50, Train iteration 153/164: Loss = 1.5771\n",
      "Epoch 13/50, Train iteration 154/164: Loss = 1.5375\n",
      "Epoch 13/50, Train iteration 155/164: Loss = 1.5708\n",
      "Epoch 13/50, Train iteration 156/164: Loss = 1.5474\n",
      "Epoch 13/50, Train iteration 157/164: Loss = 1.5583\n",
      "Epoch 13/50, Train iteration 158/164: Loss = 1.5848\n",
      "Epoch 13/50, Train iteration 159/164: Loss = 1.6395\n",
      "Epoch 13/50, Train iteration 160/164: Loss = 1.5636\n",
      "Epoch 13/50, Train iteration 161/164: Loss = 1.6150\n",
      "Epoch 13/50, Train iteration 162/164: Loss = 1.5407\n",
      "Epoch 13/50, Train iteration 163/164: Loss = 1.5239\n",
      "Epoch 13/50, Train iteration 164/164: Loss = 1.6211\n",
      "Epoch 13/50, Val iteration 1/27: Loss = 1.6037\n",
      "Epoch 13/50, Val iteration 2/27: Loss = 1.6153\n",
      "Epoch 13/50, Val iteration 3/27: Loss = 1.5995\n",
      "Epoch 13/50, Val iteration 4/27: Loss = 1.5910\n",
      "Epoch 13/50, Val iteration 5/27: Loss = 1.6089\n",
      "Epoch 13/50, Val iteration 6/27: Loss = 1.5869\n",
      "Epoch 13/50, Val iteration 7/27: Loss = 1.5646\n",
      "Epoch 13/50, Val iteration 8/27: Loss = 1.6037\n",
      "Epoch 13/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 13/50, Val iteration 10/27: Loss = 1.5722\n",
      "Epoch 13/50, Val iteration 11/27: Loss = 1.5988\n",
      "Epoch 13/50, Val iteration 12/27: Loss = 1.5675\n",
      "Epoch 13/50, Val iteration 13/27: Loss = 1.5811\n",
      "Epoch 13/50, Val iteration 14/27: Loss = 1.5648\n",
      "Epoch 13/50, Val iteration 15/27: Loss = 1.5876\n",
      "Epoch 13/50, Val iteration 16/27: Loss = 1.5871\n",
      "Epoch 13/50, Val iteration 17/27: Loss = 1.5870\n",
      "Epoch 13/50, Val iteration 18/27: Loss = 1.5631\n",
      "Epoch 13/50, Val iteration 19/27: Loss = 1.5695\n",
      "Epoch 13/50, Val iteration 20/27: Loss = 1.5945\n",
      "Epoch 13/50, Val iteration 21/27: Loss = 1.5919\n",
      "Epoch 13/50, Val iteration 22/27: Loss = 1.5882\n",
      "Epoch 13/50, Val iteration 23/27: Loss = 1.5035\n",
      "Epoch 13/50, Val iteration 24/27: Loss = 1.5678\n",
      "Epoch 13/50, Val iteration 25/27: Loss = 1.5809\n",
      "Epoch 13/50, Val iteration 26/27: Loss = 1.5996\n",
      "Epoch 13/50, Val iteration 27/27: Loss = 1.5906\n",
      "Epoch 13/50: Train Loss = 1.5613, Val Loss = 1.5836\n",
      "Current learning rate: 0.0001\n",
      "Epoch 14/50, Train iteration 1/164: Loss = 1.5671\n",
      "Epoch 14/50, Train iteration 2/164: Loss = 1.5639\n",
      "Epoch 14/50, Train iteration 3/164: Loss = 1.5940\n",
      "Epoch 14/50, Train iteration 4/164: Loss = 1.5444\n",
      "Epoch 14/50, Train iteration 5/164: Loss = 1.5936\n",
      "Epoch 14/50, Train iteration 6/164: Loss = 1.6113\n",
      "Epoch 14/50, Train iteration 7/164: Loss = 1.5978\n",
      "Epoch 14/50, Train iteration 8/164: Loss = 1.5181\n",
      "Epoch 14/50, Train iteration 9/164: Loss = 1.5648\n",
      "Epoch 14/50, Train iteration 10/164: Loss = 1.5851\n",
      "Epoch 14/50, Train iteration 11/164: Loss = 1.5787\n",
      "Epoch 14/50, Train iteration 12/164: Loss = 1.5573\n",
      "Epoch 14/50, Train iteration 13/164: Loss = 1.5181\n",
      "Epoch 14/50, Train iteration 14/164: Loss = 1.5726\n",
      "Epoch 14/50, Train iteration 15/164: Loss = 1.5771\n",
      "Epoch 14/50, Train iteration 16/164: Loss = 1.5857\n",
      "Epoch 14/50, Train iteration 17/164: Loss = 1.5402\n",
      "Epoch 14/50, Train iteration 18/164: Loss = 1.5612\n",
      "Epoch 14/50, Train iteration 19/164: Loss = 1.5118\n",
      "Epoch 14/50, Train iteration 20/164: Loss = 1.5482\n",
      "Epoch 14/50, Train iteration 21/164: Loss = 1.5374\n",
      "Epoch 14/50, Train iteration 22/164: Loss = 1.6059\n",
      "Epoch 14/50, Train iteration 23/164: Loss = 1.5967\n",
      "Epoch 14/50, Train iteration 24/164: Loss = 1.5514\n",
      "Epoch 14/50, Train iteration 25/164: Loss = 1.5510\n",
      "Epoch 14/50, Train iteration 26/164: Loss = 1.5406\n",
      "Epoch 14/50, Train iteration 27/164: Loss = 1.5766\n",
      "Epoch 14/50, Train iteration 28/164: Loss = 1.5747\n",
      "Epoch 14/50, Train iteration 29/164: Loss = 1.5688\n",
      "Epoch 14/50, Train iteration 30/164: Loss = 1.6213\n",
      "Epoch 14/50, Train iteration 31/164: Loss = 1.4686\n",
      "Epoch 14/50, Train iteration 32/164: Loss = 1.5580\n",
      "Epoch 14/50, Train iteration 33/164: Loss = 1.5400\n",
      "Epoch 14/50, Train iteration 34/164: Loss = 1.5626\n",
      "Epoch 14/50, Train iteration 35/164: Loss = 1.5212\n",
      "Epoch 14/50, Train iteration 36/164: Loss = 1.5814\n",
      "Epoch 14/50, Train iteration 37/164: Loss = 1.5877\n",
      "Epoch 14/50, Train iteration 38/164: Loss = 1.5253\n",
      "Epoch 14/50, Train iteration 39/164: Loss = 1.5176\n",
      "Epoch 14/50, Train iteration 40/164: Loss = 1.5086\n",
      "Epoch 14/50, Train iteration 41/164: Loss = 1.5173\n",
      "Epoch 14/50, Train iteration 42/164: Loss = 1.5916\n",
      "Epoch 14/50, Train iteration 43/164: Loss = 1.6019\n",
      "Epoch 14/50, Train iteration 44/164: Loss = 1.5070\n",
      "Epoch 14/50, Train iteration 45/164: Loss = 1.5330\n",
      "Epoch 14/50, Train iteration 46/164: Loss = 1.5892\n",
      "Epoch 14/50, Train iteration 47/164: Loss = 1.5795\n",
      "Epoch 14/50, Train iteration 48/164: Loss = 1.5495\n",
      "Epoch 14/50, Train iteration 49/164: Loss = 1.5728\n",
      "Epoch 14/50, Train iteration 50/164: Loss = 1.6325\n",
      "Epoch 14/50, Train iteration 51/164: Loss = 1.5431\n",
      "Epoch 14/50, Train iteration 52/164: Loss = 1.5398\n",
      "Epoch 14/50, Train iteration 53/164: Loss = 1.5633\n",
      "Epoch 14/50, Train iteration 54/164: Loss = 1.5254\n",
      "Epoch 14/50, Train iteration 55/164: Loss = 1.4976\n",
      "Epoch 14/50, Train iteration 56/164: Loss = 1.5972\n",
      "Epoch 14/50, Train iteration 57/164: Loss = 1.5652\n",
      "Epoch 14/50, Train iteration 58/164: Loss = 1.6017\n",
      "Epoch 14/50, Train iteration 59/164: Loss = 1.5431\n",
      "Epoch 14/50, Train iteration 60/164: Loss = 1.4857\n",
      "Epoch 14/50, Train iteration 61/164: Loss = 1.5284\n",
      "Epoch 14/50, Train iteration 62/164: Loss = 1.5251\n",
      "Epoch 14/50, Train iteration 63/164: Loss = 1.6190\n",
      "Epoch 14/50, Train iteration 64/164: Loss = 1.5121\n",
      "Epoch 14/50, Train iteration 65/164: Loss = 1.5394\n",
      "Epoch 14/50, Train iteration 66/164: Loss = 1.5141\n",
      "Epoch 14/50, Train iteration 67/164: Loss = 1.5819\n",
      "Epoch 14/50, Train iteration 68/164: Loss = 1.5332\n",
      "Epoch 14/50, Train iteration 69/164: Loss = 1.5906\n",
      "Epoch 14/50, Train iteration 70/164: Loss = 1.4976\n",
      "Epoch 14/50, Train iteration 71/164: Loss = 1.5291\n",
      "Epoch 14/50, Train iteration 72/164: Loss = 1.6694\n",
      "Epoch 14/50, Train iteration 73/164: Loss = 1.6198\n",
      "Epoch 14/50, Train iteration 74/164: Loss = 1.6076\n",
      "Epoch 14/50, Train iteration 75/164: Loss = 1.4634\n",
      "Epoch 14/50, Train iteration 76/164: Loss = 1.5676\n",
      "Epoch 14/50, Train iteration 77/164: Loss = 1.6302\n",
      "Epoch 14/50, Train iteration 78/164: Loss = 1.5345\n",
      "Epoch 14/50, Train iteration 79/164: Loss = 1.5549\n",
      "Epoch 14/50, Train iteration 80/164: Loss = 1.5490\n",
      "Epoch 14/50, Train iteration 81/164: Loss = 1.5520\n",
      "Epoch 14/50, Train iteration 82/164: Loss = 1.5820\n",
      "Epoch 14/50, Train iteration 83/164: Loss = 1.5713\n",
      "Epoch 14/50, Train iteration 84/164: Loss = 1.5324\n",
      "Epoch 14/50, Train iteration 85/164: Loss = 1.5950\n",
      "Epoch 14/50, Train iteration 86/164: Loss = 1.4610\n",
      "Epoch 14/50, Train iteration 87/164: Loss = 1.5594\n",
      "Epoch 14/50, Train iteration 88/164: Loss = 1.5998\n",
      "Epoch 14/50, Train iteration 89/164: Loss = 1.5913\n",
      "Epoch 14/50, Train iteration 90/164: Loss = 1.5131\n",
      "Epoch 14/50, Train iteration 91/164: Loss = 1.6351\n",
      "Epoch 14/50, Train iteration 92/164: Loss = 1.5686\n",
      "Epoch 14/50, Train iteration 93/164: Loss = 1.5560\n",
      "Epoch 14/50, Train iteration 94/164: Loss = 1.5483\n",
      "Epoch 14/50, Train iteration 95/164: Loss = 1.5339\n",
      "Epoch 14/50, Train iteration 96/164: Loss = 1.6137\n",
      "Epoch 14/50, Train iteration 97/164: Loss = 1.5734\n",
      "Epoch 14/50, Train iteration 98/164: Loss = 1.5854\n",
      "Epoch 14/50, Train iteration 99/164: Loss = 1.5143\n",
      "Epoch 14/50, Train iteration 100/164: Loss = 1.5274\n",
      "Epoch 14/50, Train iteration 101/164: Loss = 1.5395\n",
      "Epoch 14/50, Train iteration 102/164: Loss = 1.5738\n",
      "Epoch 14/50, Train iteration 103/164: Loss = 1.5608\n",
      "Epoch 14/50, Train iteration 104/164: Loss = 1.5870\n",
      "Epoch 14/50, Train iteration 105/164: Loss = 1.5726\n",
      "Epoch 14/50, Train iteration 106/164: Loss = 1.5898\n",
      "Epoch 14/50, Train iteration 107/164: Loss = 1.5644\n",
      "Epoch 14/50, Train iteration 108/164: Loss = 1.5449\n",
      "Epoch 14/50, Train iteration 109/164: Loss = 1.5768\n",
      "Epoch 14/50, Train iteration 110/164: Loss = 1.5568\n",
      "Epoch 14/50, Train iteration 111/164: Loss = 1.5751\n",
      "Epoch 14/50, Train iteration 112/164: Loss = 1.5441\n",
      "Epoch 14/50, Train iteration 113/164: Loss = 1.5142\n",
      "Epoch 14/50, Train iteration 114/164: Loss = 1.5257\n",
      "Epoch 14/50, Train iteration 115/164: Loss = 1.5646\n",
      "Epoch 14/50, Train iteration 116/164: Loss = 1.5790\n",
      "Epoch 14/50, Train iteration 117/164: Loss = 1.5314\n",
      "Epoch 14/50, Train iteration 118/164: Loss = 1.5984\n",
      "Epoch 14/50, Train iteration 119/164: Loss = 1.5739\n",
      "Epoch 14/50, Train iteration 120/164: Loss = 1.5522\n",
      "Epoch 14/50, Train iteration 121/164: Loss = 1.5829\n",
      "Epoch 14/50, Train iteration 122/164: Loss = 1.4569\n",
      "Epoch 14/50, Train iteration 123/164: Loss = 1.5085\n",
      "Epoch 14/50, Train iteration 124/164: Loss = 1.5215\n",
      "Epoch 14/50, Train iteration 125/164: Loss = 1.5038\n",
      "Epoch 14/50, Train iteration 126/164: Loss = 1.5502\n",
      "Epoch 14/50, Train iteration 127/164: Loss = 1.5929\n",
      "Epoch 14/50, Train iteration 128/164: Loss = 1.4718\n",
      "Epoch 14/50, Train iteration 129/164: Loss = 1.5486\n",
      "Epoch 14/50, Train iteration 130/164: Loss = 1.5734\n",
      "Epoch 14/50, Train iteration 131/164: Loss = 1.5391\n",
      "Epoch 14/50, Train iteration 132/164: Loss = 1.5390\n",
      "Epoch 14/50, Train iteration 133/164: Loss = 1.5577\n",
      "Epoch 14/50, Train iteration 134/164: Loss = 1.5594\n",
      "Epoch 14/50, Train iteration 135/164: Loss = 1.5681\n",
      "Epoch 14/50, Train iteration 136/164: Loss = 1.5568\n",
      "Epoch 14/50, Train iteration 137/164: Loss = 1.5445\n",
      "Epoch 14/50, Train iteration 138/164: Loss = 1.5565\n",
      "Epoch 14/50, Train iteration 139/164: Loss = 1.6299\n",
      "Epoch 14/50, Train iteration 140/164: Loss = 1.5536\n",
      "Epoch 14/50, Train iteration 141/164: Loss = 1.5318\n",
      "Epoch 14/50, Train iteration 142/164: Loss = 1.5990\n",
      "Epoch 14/50, Train iteration 143/164: Loss = 1.5120\n",
      "Epoch 14/50, Train iteration 144/164: Loss = 1.5654\n",
      "Epoch 14/50, Train iteration 145/164: Loss = 1.5380\n",
      "Epoch 14/50, Train iteration 146/164: Loss = 1.5396\n",
      "Epoch 14/50, Train iteration 147/164: Loss = 1.5711\n",
      "Epoch 14/50, Train iteration 148/164: Loss = 1.5205\n",
      "Epoch 14/50, Train iteration 149/164: Loss = 1.5630\n",
      "Epoch 14/50, Train iteration 150/164: Loss = 1.5824\n",
      "Epoch 14/50, Train iteration 151/164: Loss = 1.5395\n",
      "Epoch 14/50, Train iteration 152/164: Loss = 1.5412\n",
      "Epoch 14/50, Train iteration 153/164: Loss = 1.5238\n",
      "Epoch 14/50, Train iteration 154/164: Loss = 1.5211\n",
      "Epoch 14/50, Train iteration 155/164: Loss = 1.4934\n",
      "Epoch 14/50, Train iteration 156/164: Loss = 1.5668\n",
      "Epoch 14/50, Train iteration 157/164: Loss = 1.5809\n",
      "Epoch 14/50, Train iteration 158/164: Loss = 1.6140\n",
      "Epoch 14/50, Train iteration 159/164: Loss = 1.5428\n",
      "Epoch 14/50, Train iteration 160/164: Loss = 1.5484\n",
      "Epoch 14/50, Train iteration 161/164: Loss = 1.5790\n",
      "Epoch 14/50, Train iteration 162/164: Loss = 1.5575\n",
      "Epoch 14/50, Train iteration 163/164: Loss = 1.5451\n",
      "Epoch 14/50, Train iteration 164/164: Loss = 1.4346\n",
      "Epoch 14/50, Val iteration 1/27: Loss = 1.6191\n",
      "Epoch 14/50, Val iteration 2/27: Loss = 1.6274\n",
      "Epoch 14/50, Val iteration 3/27: Loss = 1.5913\n",
      "Epoch 14/50, Val iteration 4/27: Loss = 1.5964\n",
      "Epoch 14/50, Val iteration 5/27: Loss = 1.6210\n",
      "Epoch 14/50, Val iteration 6/27: Loss = 1.5870\n",
      "Epoch 14/50, Val iteration 7/27: Loss = 1.5530\n",
      "Epoch 14/50, Val iteration 8/27: Loss = 1.6127\n",
      "Epoch 14/50, Val iteration 9/27: Loss = 1.5872\n",
      "Epoch 14/50, Val iteration 10/27: Loss = 1.5725\n",
      "Epoch 14/50, Val iteration 11/27: Loss = 1.5990\n",
      "Epoch 14/50, Val iteration 12/27: Loss = 1.5577\n",
      "Epoch 14/50, Val iteration 13/27: Loss = 1.5732\n",
      "Epoch 14/50, Val iteration 14/27: Loss = 1.5455\n",
      "Epoch 14/50, Val iteration 15/27: Loss = 1.5916\n",
      "Epoch 14/50, Val iteration 16/27: Loss = 1.5753\n",
      "Epoch 14/50, Val iteration 17/27: Loss = 1.5896\n",
      "Epoch 14/50, Val iteration 18/27: Loss = 1.5506\n",
      "Epoch 14/50, Val iteration 19/27: Loss = 1.5621\n",
      "Epoch 14/50, Val iteration 20/27: Loss = 1.5953\n",
      "Epoch 14/50, Val iteration 21/27: Loss = 1.5869\n",
      "Epoch 14/50, Val iteration 22/27: Loss = 1.5985\n",
      "Epoch 14/50, Val iteration 23/27: Loss = 1.4930\n",
      "Epoch 14/50, Val iteration 24/27: Loss = 1.5545\n",
      "Epoch 14/50, Val iteration 25/27: Loss = 1.5824\n",
      "Epoch 14/50, Val iteration 26/27: Loss = 1.5861\n",
      "Epoch 14/50, Val iteration 27/27: Loss = 1.5977\n",
      "Epoch 14/50: Train Loss = 1.5558, Val Loss = 1.5817\n",
      "Current learning rate: 3e-05\n",
      "Epoch 15/50, Train iteration 1/164: Loss = 1.4959\n",
      "Epoch 15/50, Train iteration 2/164: Loss = 1.6368\n",
      "Epoch 15/50, Train iteration 3/164: Loss = 1.5964\n",
      "Epoch 15/50, Train iteration 4/164: Loss = 1.5396\n",
      "Epoch 15/50, Train iteration 5/164: Loss = 1.6003\n",
      "Epoch 15/50, Train iteration 6/164: Loss = 1.6218\n",
      "Epoch 15/50, Train iteration 7/164: Loss = 1.5979\n",
      "Epoch 15/50, Train iteration 8/164: Loss = 1.4515\n",
      "Epoch 15/50, Train iteration 9/164: Loss = 1.5655\n",
      "Epoch 15/50, Train iteration 10/164: Loss = 1.6174\n",
      "Epoch 15/50, Train iteration 11/164: Loss = 1.6124\n",
      "Epoch 15/50, Train iteration 12/164: Loss = 1.6115\n",
      "Epoch 15/50, Train iteration 13/164: Loss = 1.5100\n",
      "Epoch 15/50, Train iteration 14/164: Loss = 1.6050\n",
      "Epoch 15/50, Train iteration 15/164: Loss = 1.6147\n",
      "Epoch 15/50, Train iteration 16/164: Loss = 1.5535\n",
      "Epoch 15/50, Train iteration 17/164: Loss = 1.5290\n",
      "Epoch 15/50, Train iteration 18/164: Loss = 1.5053\n",
      "Epoch 15/50, Train iteration 19/164: Loss = 1.5479\n",
      "Epoch 15/50, Train iteration 20/164: Loss = 1.5336\n",
      "Epoch 15/50, Train iteration 21/164: Loss = 1.6176\n",
      "Epoch 15/50, Train iteration 22/164: Loss = 1.6085\n",
      "Epoch 15/50, Train iteration 23/164: Loss = 1.5909\n",
      "Epoch 15/50, Train iteration 24/164: Loss = 1.5451\n",
      "Epoch 15/50, Train iteration 25/164: Loss = 1.6329\n",
      "Epoch 15/50, Train iteration 26/164: Loss = 1.6024\n",
      "Epoch 15/50, Train iteration 27/164: Loss = 1.5498\n",
      "Epoch 15/50, Train iteration 28/164: Loss = 1.5856\n",
      "Epoch 15/50, Train iteration 29/164: Loss = 1.5128\n",
      "Epoch 15/50, Train iteration 30/164: Loss = 1.6022\n",
      "Epoch 15/50, Train iteration 31/164: Loss = 1.4939\n",
      "Epoch 15/50, Train iteration 32/164: Loss = 1.5621\n",
      "Epoch 15/50, Train iteration 33/164: Loss = 1.5555\n",
      "Epoch 15/50, Train iteration 34/164: Loss = 1.5098\n",
      "Epoch 15/50, Train iteration 35/164: Loss = 1.5956\n",
      "Epoch 15/50, Train iteration 36/164: Loss = 1.5383\n",
      "Epoch 15/50, Train iteration 37/164: Loss = 1.5708\n",
      "Epoch 15/50, Train iteration 38/164: Loss = 1.5863\n",
      "Epoch 15/50, Train iteration 39/164: Loss = 1.5361\n",
      "Epoch 15/50, Train iteration 40/164: Loss = 1.4684\n",
      "Epoch 15/50, Train iteration 41/164: Loss = 1.5129\n",
      "Epoch 15/50, Train iteration 42/164: Loss = 1.5468\n",
      "Epoch 15/50, Train iteration 43/164: Loss = 1.5846\n",
      "Epoch 15/50, Train iteration 44/164: Loss = 1.4995\n",
      "Epoch 15/50, Train iteration 45/164: Loss = 1.5978\n",
      "Epoch 15/50, Train iteration 46/164: Loss = 1.5591\n",
      "Epoch 15/50, Train iteration 47/164: Loss = 1.5470\n",
      "Epoch 15/50, Train iteration 48/164: Loss = 1.6072\n",
      "Epoch 15/50, Train iteration 49/164: Loss = 1.4720\n",
      "Epoch 15/50, Train iteration 50/164: Loss = 1.5500\n",
      "Epoch 15/50, Train iteration 51/164: Loss = 1.5081\n",
      "Epoch 15/50, Train iteration 52/164: Loss = 1.5190\n",
      "Epoch 15/50, Train iteration 53/164: Loss = 1.5515\n",
      "Epoch 15/50, Train iteration 54/164: Loss = 1.5657\n",
      "Epoch 15/50, Train iteration 55/164: Loss = 1.5243\n",
      "Epoch 15/50, Train iteration 56/164: Loss = 1.5976\n",
      "Epoch 15/50, Train iteration 57/164: Loss = 1.5593\n",
      "Epoch 15/50, Train iteration 58/164: Loss = 1.5831\n",
      "Epoch 15/50, Train iteration 59/164: Loss = 1.5154\n",
      "Epoch 15/50, Train iteration 60/164: Loss = 1.5331\n",
      "Epoch 15/50, Train iteration 61/164: Loss = 1.5390\n",
      "Epoch 15/50, Train iteration 62/164: Loss = 1.5225\n",
      "Epoch 15/50, Train iteration 63/164: Loss = 1.6025\n",
      "Epoch 15/50, Train iteration 64/164: Loss = 1.5126\n",
      "Epoch 15/50, Train iteration 65/164: Loss = 1.5237\n",
      "Epoch 15/50, Train iteration 66/164: Loss = 1.5077\n",
      "Epoch 15/50, Train iteration 67/164: Loss = 1.4982\n",
      "Epoch 15/50, Train iteration 68/164: Loss = 1.5125\n",
      "Epoch 15/50, Train iteration 69/164: Loss = 1.6123\n",
      "Epoch 15/50, Train iteration 70/164: Loss = 1.5116\n",
      "Epoch 15/50, Train iteration 71/164: Loss = 1.5266\n",
      "Epoch 15/50, Train iteration 72/164: Loss = 1.6179\n",
      "Epoch 15/50, Train iteration 73/164: Loss = 1.5711\n",
      "Epoch 15/50, Train iteration 74/164: Loss = 1.5245\n",
      "Epoch 15/50, Train iteration 75/164: Loss = 1.4812\n",
      "Epoch 15/50, Train iteration 76/164: Loss = 1.5061\n",
      "Epoch 15/50, Train iteration 77/164: Loss = 1.5657\n",
      "Epoch 15/50, Train iteration 78/164: Loss = 1.5506\n",
      "Epoch 15/50, Train iteration 79/164: Loss = 1.5744\n",
      "Epoch 15/50, Train iteration 80/164: Loss = 1.5660\n",
      "Epoch 15/50, Train iteration 81/164: Loss = 1.4725\n",
      "Epoch 15/50, Train iteration 82/164: Loss = 1.5721\n",
      "Epoch 15/50, Train iteration 83/164: Loss = 1.5464\n",
      "Epoch 15/50, Train iteration 84/164: Loss = 1.5393\n",
      "Epoch 15/50, Train iteration 85/164: Loss = 1.6441\n",
      "Epoch 15/50, Train iteration 86/164: Loss = 1.3897\n",
      "Epoch 15/50, Train iteration 87/164: Loss = 1.5324\n",
      "Epoch 15/50, Train iteration 88/164: Loss = 1.6418\n",
      "Epoch 15/50, Train iteration 89/164: Loss = 1.5737\n",
      "Epoch 15/50, Train iteration 90/164: Loss = 1.5370\n",
      "Epoch 15/50, Train iteration 91/164: Loss = 1.6157\n",
      "Epoch 15/50, Train iteration 92/164: Loss = 1.5245\n",
      "Epoch 15/50, Train iteration 93/164: Loss = 1.5758\n",
      "Epoch 15/50, Train iteration 94/164: Loss = 1.6167\n",
      "Epoch 15/50, Train iteration 95/164: Loss = 1.5299\n",
      "Epoch 15/50, Train iteration 96/164: Loss = 1.5725\n",
      "Epoch 15/50, Train iteration 97/164: Loss = 1.5981\n",
      "Epoch 15/50, Train iteration 98/164: Loss = 1.5421\n",
      "Epoch 15/50, Train iteration 99/164: Loss = 1.5000\n",
      "Epoch 15/50, Train iteration 100/164: Loss = 1.4820\n",
      "Epoch 15/50, Train iteration 101/164: Loss = 1.4799\n",
      "Epoch 15/50, Train iteration 102/164: Loss = 1.5874\n",
      "Epoch 15/50, Train iteration 103/164: Loss = 1.6069\n",
      "Epoch 15/50, Train iteration 104/164: Loss = 1.5580\n",
      "Epoch 15/50, Train iteration 105/164: Loss = 1.5569\n",
      "Epoch 15/50, Train iteration 106/164: Loss = 1.5565\n",
      "Epoch 15/50, Train iteration 107/164: Loss = 1.5047\n",
      "Epoch 15/50, Train iteration 108/164: Loss = 1.5297\n",
      "Epoch 15/50, Train iteration 109/164: Loss = 1.5628\n",
      "Epoch 15/50, Train iteration 110/164: Loss = 1.5108\n",
      "Epoch 15/50, Train iteration 111/164: Loss = 1.5892\n",
      "Epoch 15/50, Train iteration 112/164: Loss = 1.5546\n",
      "Epoch 15/50, Train iteration 113/164: Loss = 1.4890\n",
      "Epoch 15/50, Train iteration 114/164: Loss = 1.4464\n",
      "Epoch 15/50, Train iteration 115/164: Loss = 1.5520\n",
      "Epoch 15/50, Train iteration 116/164: Loss = 1.5089\n",
      "Epoch 15/50, Train iteration 117/164: Loss = 1.5192\n",
      "Epoch 15/50, Train iteration 118/164: Loss = 1.5953\n",
      "Epoch 15/50, Train iteration 119/164: Loss = 1.5558\n",
      "Epoch 15/50, Train iteration 120/164: Loss = 1.5587\n",
      "Epoch 15/50, Train iteration 121/164: Loss = 1.5423\n",
      "Epoch 15/50, Train iteration 122/164: Loss = 1.4708\n",
      "Epoch 15/50, Train iteration 123/164: Loss = 1.5045\n",
      "Epoch 15/50, Train iteration 124/164: Loss = 1.5234\n",
      "Epoch 15/50, Train iteration 125/164: Loss = 1.4915\n",
      "Epoch 15/50, Train iteration 126/164: Loss = 1.4864\n",
      "Epoch 15/50, Train iteration 127/164: Loss = 1.6253\n",
      "Epoch 15/50, Train iteration 128/164: Loss = 1.4565\n",
      "Epoch 15/50, Train iteration 129/164: Loss = 1.5533\n",
      "Epoch 15/50, Train iteration 130/164: Loss = 1.5194\n",
      "Epoch 15/50, Train iteration 131/164: Loss = 1.6329\n",
      "Epoch 15/50, Train iteration 132/164: Loss = 1.4581\n",
      "Epoch 15/50, Train iteration 133/164: Loss = 1.5237\n",
      "Epoch 15/50, Train iteration 134/164: Loss = 1.5363\n",
      "Epoch 15/50, Train iteration 135/164: Loss = 1.6029\n",
      "Epoch 15/50, Train iteration 136/164: Loss = 1.5589\n",
      "Epoch 15/50, Train iteration 137/164: Loss = 1.4977\n",
      "Epoch 15/50, Train iteration 138/164: Loss = 1.5409\n",
      "Epoch 15/50, Train iteration 139/164: Loss = 1.5720\n",
      "Epoch 15/50, Train iteration 140/164: Loss = 1.5300\n",
      "Epoch 15/50, Train iteration 141/164: Loss = 1.5774\n",
      "Epoch 15/50, Train iteration 142/164: Loss = 1.6078\n",
      "Epoch 15/50, Train iteration 143/164: Loss = 1.5183\n",
      "Epoch 15/50, Train iteration 144/164: Loss = 1.5596\n",
      "Epoch 15/50, Train iteration 145/164: Loss = 1.5136\n",
      "Epoch 15/50, Train iteration 146/164: Loss = 1.5308\n",
      "Epoch 15/50, Train iteration 147/164: Loss = 1.5223\n",
      "Epoch 15/50, Train iteration 148/164: Loss = 1.5060\n",
      "Epoch 15/50, Train iteration 149/164: Loss = 1.5512\n",
      "Epoch 15/50, Train iteration 150/164: Loss = 1.5780\n",
      "Epoch 15/50, Train iteration 151/164: Loss = 1.5535\n",
      "Epoch 15/50, Train iteration 152/164: Loss = 1.4608\n",
      "Epoch 15/50, Train iteration 153/164: Loss = 1.5617\n",
      "Epoch 15/50, Train iteration 154/164: Loss = 1.5392\n",
      "Epoch 15/50, Train iteration 155/164: Loss = 1.5310\n",
      "Epoch 15/50, Train iteration 156/164: Loss = 1.5732\n",
      "Epoch 15/50, Train iteration 157/164: Loss = 1.5716\n",
      "Epoch 15/50, Train iteration 158/164: Loss = 1.6066\n",
      "Epoch 15/50, Train iteration 159/164: Loss = 1.5576\n",
      "Epoch 15/50, Train iteration 160/164: Loss = 1.5498\n",
      "Epoch 15/50, Train iteration 161/164: Loss = 1.5959\n",
      "Epoch 15/50, Train iteration 162/164: Loss = 1.5409\n",
      "Epoch 15/50, Train iteration 163/164: Loss = 1.6187\n",
      "Epoch 15/50, Train iteration 164/164: Loss = 1.1245\n",
      "Epoch 15/50, Val iteration 1/27: Loss = 1.6131\n",
      "Epoch 15/50, Val iteration 2/27: Loss = 1.6212\n",
      "Epoch 15/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 15/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 15/50, Val iteration 5/27: Loss = 1.6163\n",
      "Epoch 15/50, Val iteration 6/27: Loss = 1.5848\n",
      "Epoch 15/50, Val iteration 7/27: Loss = 1.5576\n",
      "Epoch 15/50, Val iteration 8/27: Loss = 1.6093\n",
      "Epoch 15/50, Val iteration 9/27: Loss = 1.5863\n",
      "Epoch 15/50, Val iteration 10/27: Loss = 1.5758\n",
      "Epoch 15/50, Val iteration 11/27: Loss = 1.5924\n",
      "Epoch 15/50, Val iteration 12/27: Loss = 1.5619\n",
      "Epoch 15/50, Val iteration 13/27: Loss = 1.5710\n",
      "Epoch 15/50, Val iteration 14/27: Loss = 1.5552\n",
      "Epoch 15/50, Val iteration 15/27: Loss = 1.5919\n",
      "Epoch 15/50, Val iteration 16/27: Loss = 1.5807\n",
      "Epoch 15/50, Val iteration 17/27: Loss = 1.5862\n",
      "Epoch 15/50, Val iteration 18/27: Loss = 1.5588\n",
      "Epoch 15/50, Val iteration 19/27: Loss = 1.5677\n",
      "Epoch 15/50, Val iteration 20/27: Loss = 1.5942\n",
      "Epoch 15/50, Val iteration 21/27: Loss = 1.5863\n",
      "Epoch 15/50, Val iteration 22/27: Loss = 1.5957\n",
      "Epoch 15/50, Val iteration 23/27: Loss = 1.4926\n",
      "Epoch 15/50, Val iteration 24/27: Loss = 1.5559\n",
      "Epoch 15/50, Val iteration 25/27: Loss = 1.5798\n",
      "Epoch 15/50, Val iteration 26/27: Loss = 1.5916\n",
      "Epoch 15/50, Val iteration 27/27: Loss = 1.5944\n",
      "Epoch 15/50: Train Loss = 1.5468, Val Loss = 1.5817\n",
      "Current learning rate: 3e-05\n",
      "Epoch 16/50, Train iteration 1/164: Loss = 1.5498\n",
      "Epoch 16/50, Train iteration 2/164: Loss = 1.5767\n",
      "Epoch 16/50, Train iteration 3/164: Loss = 1.5629\n",
      "Epoch 16/50, Train iteration 4/164: Loss = 1.5629\n",
      "Epoch 16/50, Train iteration 5/164: Loss = 1.5760\n",
      "Epoch 16/50, Train iteration 6/164: Loss = 1.5921\n",
      "Epoch 16/50, Train iteration 7/164: Loss = 1.6022\n",
      "Epoch 16/50, Train iteration 8/164: Loss = 1.5115\n",
      "Epoch 16/50, Train iteration 9/164: Loss = 1.5719\n",
      "Epoch 16/50, Train iteration 10/164: Loss = 1.5730\n",
      "Epoch 16/50, Train iteration 11/164: Loss = 1.5496\n",
      "Epoch 16/50, Train iteration 12/164: Loss = 1.5698\n",
      "Epoch 16/50, Train iteration 13/164: Loss = 1.5249\n",
      "Epoch 16/50, Train iteration 14/164: Loss = 1.5353\n",
      "Epoch 16/50, Train iteration 15/164: Loss = 1.5731\n",
      "Epoch 16/50, Train iteration 16/164: Loss = 1.5882\n",
      "Epoch 16/50, Train iteration 17/164: Loss = 1.5048\n",
      "Epoch 16/50, Train iteration 18/164: Loss = 1.5367\n",
      "Epoch 16/50, Train iteration 19/164: Loss = 1.5274\n",
      "Epoch 16/50, Train iteration 20/164: Loss = 1.5805\n",
      "Epoch 16/50, Train iteration 21/164: Loss = 1.5846\n",
      "Epoch 16/50, Train iteration 22/164: Loss = 1.5752\n",
      "Epoch 16/50, Train iteration 23/164: Loss = 1.5647\n",
      "Epoch 16/50, Train iteration 24/164: Loss = 1.5624\n",
      "Epoch 16/50, Train iteration 25/164: Loss = 1.5811\n",
      "Epoch 16/50, Train iteration 26/164: Loss = 1.5560\n",
      "Epoch 16/50, Train iteration 27/164: Loss = 1.6061\n",
      "Epoch 16/50, Train iteration 28/164: Loss = 1.5520\n",
      "Epoch 16/50, Train iteration 29/164: Loss = 1.5371\n",
      "Epoch 16/50, Train iteration 30/164: Loss = 1.5686\n",
      "Epoch 16/50, Train iteration 31/164: Loss = 1.4826\n",
      "Epoch 16/50, Train iteration 32/164: Loss = 1.5613\n",
      "Epoch 16/50, Train iteration 33/164: Loss = 1.5670\n",
      "Epoch 16/50, Train iteration 34/164: Loss = 1.5143\n",
      "Epoch 16/50, Train iteration 35/164: Loss = 1.5597\n",
      "Epoch 16/50, Train iteration 36/164: Loss = 1.4939\n",
      "Epoch 16/50, Train iteration 37/164: Loss = 1.5543\n",
      "Epoch 16/50, Train iteration 38/164: Loss = 1.5553\n",
      "Epoch 16/50, Train iteration 39/164: Loss = 1.5862\n",
      "Epoch 16/50, Train iteration 40/164: Loss = 1.4995\n",
      "Epoch 16/50, Train iteration 41/164: Loss = 1.4645\n",
      "Epoch 16/50, Train iteration 42/164: Loss = 1.5101\n",
      "Epoch 16/50, Train iteration 43/164: Loss = 1.5436\n",
      "Epoch 16/50, Train iteration 44/164: Loss = 1.5319\n",
      "Epoch 16/50, Train iteration 45/164: Loss = 1.5573\n",
      "Epoch 16/50, Train iteration 46/164: Loss = 1.5302\n",
      "Epoch 16/50, Train iteration 47/164: Loss = 1.6076\n",
      "Epoch 16/50, Train iteration 48/164: Loss = 1.5710\n",
      "Epoch 16/50, Train iteration 49/164: Loss = 1.5676\n",
      "Epoch 16/50, Train iteration 50/164: Loss = 1.6133\n",
      "Epoch 16/50, Train iteration 51/164: Loss = 1.5047\n",
      "Epoch 16/50, Train iteration 52/164: Loss = 1.5163\n",
      "Epoch 16/50, Train iteration 53/164: Loss = 1.5677\n",
      "Epoch 16/50, Train iteration 54/164: Loss = 1.5206\n",
      "Epoch 16/50, Train iteration 55/164: Loss = 1.5057\n",
      "Epoch 16/50, Train iteration 56/164: Loss = 1.5883\n",
      "Epoch 16/50, Train iteration 57/164: Loss = 1.5582\n",
      "Epoch 16/50, Train iteration 58/164: Loss = 1.6072\n",
      "Epoch 16/50, Train iteration 59/164: Loss = 1.5885\n",
      "Epoch 16/50, Train iteration 60/164: Loss = 1.5548\n",
      "Epoch 16/50, Train iteration 61/164: Loss = 1.5215\n",
      "Epoch 16/50, Train iteration 62/164: Loss = 1.4959\n",
      "Epoch 16/50, Train iteration 63/164: Loss = 1.6375\n",
      "Epoch 16/50, Train iteration 64/164: Loss = 1.5471\n",
      "Epoch 16/50, Train iteration 65/164: Loss = 1.5096\n",
      "Epoch 16/50, Train iteration 66/164: Loss = 1.4525\n",
      "Epoch 16/50, Train iteration 67/164: Loss = 1.4927\n",
      "Epoch 16/50, Train iteration 68/164: Loss = 1.5731\n",
      "Epoch 16/50, Train iteration 69/164: Loss = 1.4993\n",
      "Epoch 16/50, Train iteration 70/164: Loss = 1.5949\n",
      "Epoch 16/50, Train iteration 71/164: Loss = 1.5451\n",
      "Epoch 16/50, Train iteration 72/164: Loss = 1.5477\n",
      "Epoch 16/50, Train iteration 73/164: Loss = 1.6031\n",
      "Epoch 16/50, Train iteration 74/164: Loss = 1.6009\n",
      "Epoch 16/50, Train iteration 75/164: Loss = 1.4986\n",
      "Epoch 16/50, Train iteration 76/164: Loss = 1.5404\n",
      "Epoch 16/50, Train iteration 77/164: Loss = 1.6301\n",
      "Epoch 16/50, Train iteration 78/164: Loss = 1.5344\n",
      "Epoch 16/50, Train iteration 79/164: Loss = 1.6000\n",
      "Epoch 16/50, Train iteration 80/164: Loss = 1.5332\n",
      "Epoch 16/50, Train iteration 81/164: Loss = 1.5560\n",
      "Epoch 16/50, Train iteration 82/164: Loss = 1.5354\n",
      "Epoch 16/50, Train iteration 83/164: Loss = 1.5646\n",
      "Epoch 16/50, Train iteration 84/164: Loss = 1.5098\n",
      "Epoch 16/50, Train iteration 85/164: Loss = 1.6436\n",
      "Epoch 16/50, Train iteration 86/164: Loss = 1.4199\n",
      "Epoch 16/50, Train iteration 87/164: Loss = 1.5447\n",
      "Epoch 16/50, Train iteration 88/164: Loss = 1.6080\n",
      "Epoch 16/50, Train iteration 89/164: Loss = 1.5684\n",
      "Epoch 16/50, Train iteration 90/164: Loss = 1.5057\n",
      "Epoch 16/50, Train iteration 91/164: Loss = 1.5912\n",
      "Epoch 16/50, Train iteration 92/164: Loss = 1.5419\n",
      "Epoch 16/50, Train iteration 93/164: Loss = 1.5431\n",
      "Epoch 16/50, Train iteration 94/164: Loss = 1.5938\n",
      "Epoch 16/50, Train iteration 95/164: Loss = 1.5013\n",
      "Epoch 16/50, Train iteration 96/164: Loss = 1.4983\n",
      "Epoch 16/50, Train iteration 97/164: Loss = 1.5648\n",
      "Epoch 16/50, Train iteration 98/164: Loss = 1.5451\n",
      "Epoch 16/50, Train iteration 99/164: Loss = 1.4635\n",
      "Epoch 16/50, Train iteration 100/164: Loss = 1.5521\n",
      "Epoch 16/50, Train iteration 101/164: Loss = 1.5254\n",
      "Epoch 16/50, Train iteration 102/164: Loss = 1.6018\n",
      "Epoch 16/50, Train iteration 103/164: Loss = 1.5504\n",
      "Epoch 16/50, Train iteration 104/164: Loss = 1.5996\n",
      "Epoch 16/50, Train iteration 105/164: Loss = 1.5508\n",
      "Epoch 16/50, Train iteration 106/164: Loss = 1.5394\n",
      "Epoch 16/50, Train iteration 107/164: Loss = 1.5207\n",
      "Epoch 16/50, Train iteration 108/164: Loss = 1.5803\n",
      "Epoch 16/50, Train iteration 109/164: Loss = 1.5284\n",
      "Epoch 16/50, Train iteration 110/164: Loss = 1.5560\n",
      "Epoch 16/50, Train iteration 111/164: Loss = 1.5924\n",
      "Epoch 16/50, Train iteration 112/164: Loss = 1.5175\n",
      "Epoch 16/50, Train iteration 113/164: Loss = 1.5050\n",
      "Epoch 16/50, Train iteration 114/164: Loss = 1.4620\n",
      "Epoch 16/50, Train iteration 115/164: Loss = 1.5688\n",
      "Epoch 16/50, Train iteration 116/164: Loss = 1.5144\n",
      "Epoch 16/50, Train iteration 117/164: Loss = 1.4707\n",
      "Epoch 16/50, Train iteration 118/164: Loss = 1.5377\n",
      "Epoch 16/50, Train iteration 119/164: Loss = 1.5455\n",
      "Epoch 16/50, Train iteration 120/164: Loss = 1.4949\n",
      "Epoch 16/50, Train iteration 121/164: Loss = 1.5489\n",
      "Epoch 16/50, Train iteration 122/164: Loss = 1.4677\n",
      "Epoch 16/50, Train iteration 123/164: Loss = 1.5399\n",
      "Epoch 16/50, Train iteration 124/164: Loss = 1.5645\n",
      "Epoch 16/50, Train iteration 125/164: Loss = 1.5156\n",
      "Epoch 16/50, Train iteration 126/164: Loss = 1.4642\n",
      "Epoch 16/50, Train iteration 127/164: Loss = 1.6031\n",
      "Epoch 16/50, Train iteration 128/164: Loss = 1.4757\n",
      "Epoch 16/50, Train iteration 129/164: Loss = 1.5508\n",
      "Epoch 16/50, Train iteration 130/164: Loss = 1.5371\n",
      "Epoch 16/50, Train iteration 131/164: Loss = 1.5997\n",
      "Epoch 16/50, Train iteration 132/164: Loss = 1.5553\n",
      "Epoch 16/50, Train iteration 133/164: Loss = 1.5690\n",
      "Epoch 16/50, Train iteration 134/164: Loss = 1.4598\n",
      "Epoch 16/50, Train iteration 135/164: Loss = 1.5407\n",
      "Epoch 16/50, Train iteration 136/164: Loss = 1.6042\n",
      "Epoch 16/50, Train iteration 137/164: Loss = 1.5411\n",
      "Epoch 16/50, Train iteration 138/164: Loss = 1.5474\n",
      "Epoch 16/50, Train iteration 139/164: Loss = 1.6248\n",
      "Epoch 16/50, Train iteration 140/164: Loss = 1.5514\n",
      "Epoch 16/50, Train iteration 141/164: Loss = 1.5727\n",
      "Epoch 16/50, Train iteration 142/164: Loss = 1.5611\n",
      "Epoch 16/50, Train iteration 143/164: Loss = 1.4832\n",
      "Epoch 16/50, Train iteration 144/164: Loss = 1.5936\n",
      "Epoch 16/50, Train iteration 145/164: Loss = 1.5548\n",
      "Epoch 16/50, Train iteration 146/164: Loss = 1.5344\n",
      "Epoch 16/50, Train iteration 147/164: Loss = 1.5241\n",
      "Epoch 16/50, Train iteration 148/164: Loss = 1.5220\n",
      "Epoch 16/50, Train iteration 149/164: Loss = 1.5509\n",
      "Epoch 16/50, Train iteration 150/164: Loss = 1.5647\n",
      "Epoch 16/50, Train iteration 151/164: Loss = 1.5712\n",
      "Epoch 16/50, Train iteration 152/164: Loss = 1.5545\n",
      "Epoch 16/50, Train iteration 153/164: Loss = 1.5395\n",
      "Epoch 16/50, Train iteration 154/164: Loss = 1.5374\n",
      "Epoch 16/50, Train iteration 155/164: Loss = 1.5339\n",
      "Epoch 16/50, Train iteration 156/164: Loss = 1.4864\n",
      "Epoch 16/50, Train iteration 157/164: Loss = 1.5970\n",
      "Epoch 16/50, Train iteration 158/164: Loss = 1.6128\n",
      "Epoch 16/50, Train iteration 159/164: Loss = 1.5957\n",
      "Epoch 16/50, Train iteration 160/164: Loss = 1.5773\n",
      "Epoch 16/50, Train iteration 161/164: Loss = 1.6210\n",
      "Epoch 16/50, Train iteration 162/164: Loss = 1.5445\n",
      "Epoch 16/50, Train iteration 163/164: Loss = 1.5242\n",
      "Epoch 16/50, Train iteration 164/164: Loss = 1.3658\n",
      "Epoch 16/50, Val iteration 1/27: Loss = 1.6075\n",
      "Epoch 16/50, Val iteration 2/27: Loss = 1.6192\n",
      "Epoch 16/50, Val iteration 3/27: Loss = 1.5928\n",
      "Epoch 16/50, Val iteration 4/27: Loss = 1.5956\n",
      "Epoch 16/50, Val iteration 5/27: Loss = 1.6091\n",
      "Epoch 16/50, Val iteration 6/27: Loss = 1.5783\n",
      "Epoch 16/50, Val iteration 7/27: Loss = 1.5555\n",
      "Epoch 16/50, Val iteration 8/27: Loss = 1.6115\n",
      "Epoch 16/50, Val iteration 9/27: Loss = 1.5899\n",
      "Epoch 16/50, Val iteration 10/27: Loss = 1.5796\n",
      "Epoch 16/50, Val iteration 11/27: Loss = 1.5919\n",
      "Epoch 16/50, Val iteration 12/27: Loss = 1.5648\n",
      "Epoch 16/50, Val iteration 13/27: Loss = 1.5751\n",
      "Epoch 16/50, Val iteration 14/27: Loss = 1.5551\n",
      "Epoch 16/50, Val iteration 15/27: Loss = 1.5927\n",
      "Epoch 16/50, Val iteration 16/27: Loss = 1.5801\n",
      "Epoch 16/50, Val iteration 17/27: Loss = 1.5864\n",
      "Epoch 16/50, Val iteration 18/27: Loss = 1.5599\n",
      "Epoch 16/50, Val iteration 19/27: Loss = 1.5731\n",
      "Epoch 16/50, Val iteration 20/27: Loss = 1.5984\n",
      "Epoch 16/50, Val iteration 21/27: Loss = 1.5922\n",
      "Epoch 16/50, Val iteration 22/27: Loss = 1.5926\n",
      "Epoch 16/50, Val iteration 23/27: Loss = 1.4984\n",
      "Epoch 16/50, Val iteration 24/27: Loss = 1.5590\n",
      "Epoch 16/50, Val iteration 25/27: Loss = 1.5786\n",
      "Epoch 16/50, Val iteration 26/27: Loss = 1.5976\n",
      "Epoch 16/50, Val iteration 27/27: Loss = 1.6022\n",
      "Epoch 16/50: Train Loss = 1.5475, Val Loss = 1.5829\n",
      "Current learning rate: 3e-05\n",
      "Epoch 17/50, Train iteration 1/164: Loss = 1.5519\n",
      "Epoch 17/50, Train iteration 2/164: Loss = 1.5856\n",
      "Epoch 17/50, Train iteration 3/164: Loss = 1.5424\n",
      "Epoch 17/50, Train iteration 4/164: Loss = 1.5574\n",
      "Epoch 17/50, Train iteration 5/164: Loss = 1.5820\n",
      "Epoch 17/50, Train iteration 6/164: Loss = 1.6186\n",
      "Epoch 17/50, Train iteration 7/164: Loss = 1.6020\n",
      "Epoch 17/50, Train iteration 8/164: Loss = 1.4667\n",
      "Epoch 17/50, Train iteration 9/164: Loss = 1.5914\n",
      "Epoch 17/50, Train iteration 10/164: Loss = 1.5939\n",
      "Epoch 17/50, Train iteration 11/164: Loss = 1.5782\n",
      "Epoch 17/50, Train iteration 12/164: Loss = 1.5579\n",
      "Epoch 17/50, Train iteration 13/164: Loss = 1.4913\n",
      "Epoch 17/50, Train iteration 14/164: Loss = 1.5201\n",
      "Epoch 17/50, Train iteration 15/164: Loss = 1.4917\n",
      "Epoch 17/50, Train iteration 16/164: Loss = 1.5237\n",
      "Epoch 17/50, Train iteration 17/164: Loss = 1.5512\n",
      "Epoch 17/50, Train iteration 18/164: Loss = 1.5664\n",
      "Epoch 17/50, Train iteration 19/164: Loss = 1.5351\n",
      "Epoch 17/50, Train iteration 20/164: Loss = 1.5375\n",
      "Epoch 17/50, Train iteration 21/164: Loss = 1.6304\n",
      "Epoch 17/50, Train iteration 22/164: Loss = 1.5820\n",
      "Epoch 17/50, Train iteration 23/164: Loss = 1.5248\n",
      "Epoch 17/50, Train iteration 24/164: Loss = 1.5546\n",
      "Epoch 17/50, Train iteration 25/164: Loss = 1.6040\n",
      "Epoch 17/50, Train iteration 26/164: Loss = 1.5627\n",
      "Epoch 17/50, Train iteration 27/164: Loss = 1.5709\n",
      "Epoch 17/50, Train iteration 28/164: Loss = 1.5621\n",
      "Epoch 17/50, Train iteration 29/164: Loss = 1.5392\n",
      "Epoch 17/50, Train iteration 30/164: Loss = 1.5698\n",
      "Epoch 17/50, Train iteration 31/164: Loss = 1.4785\n",
      "Epoch 17/50, Train iteration 32/164: Loss = 1.5216\n",
      "Epoch 17/50, Train iteration 33/164: Loss = 1.5990\n",
      "Epoch 17/50, Train iteration 34/164: Loss = 1.4845\n",
      "Epoch 17/50, Train iteration 35/164: Loss = 1.5993\n",
      "Epoch 17/50, Train iteration 36/164: Loss = 1.4953\n",
      "Epoch 17/50, Train iteration 37/164: Loss = 1.6057\n",
      "Epoch 17/50, Train iteration 38/164: Loss = 1.5369\n",
      "Epoch 17/50, Train iteration 39/164: Loss = 1.4820\n",
      "Epoch 17/50, Train iteration 40/164: Loss = 1.5105\n",
      "Epoch 17/50, Train iteration 41/164: Loss = 1.5487\n",
      "Epoch 17/50, Train iteration 42/164: Loss = 1.5368\n",
      "Epoch 17/50, Train iteration 43/164: Loss = 1.5760\n",
      "Epoch 17/50, Train iteration 44/164: Loss = 1.5134\n",
      "Epoch 17/50, Train iteration 45/164: Loss = 1.5830\n",
      "Epoch 17/50, Train iteration 46/164: Loss = 1.5496\n",
      "Epoch 17/50, Train iteration 47/164: Loss = 1.5703\n",
      "Epoch 17/50, Train iteration 48/164: Loss = 1.5152\n",
      "Epoch 17/50, Train iteration 49/164: Loss = 1.5005\n",
      "Epoch 17/50, Train iteration 50/164: Loss = 1.5937\n",
      "Epoch 17/50, Train iteration 51/164: Loss = 1.5067\n",
      "Epoch 17/50, Train iteration 52/164: Loss = 1.5369\n",
      "Epoch 17/50, Train iteration 53/164: Loss = 1.5082\n",
      "Epoch 17/50, Train iteration 54/164: Loss = 1.5745\n",
      "Epoch 17/50, Train iteration 55/164: Loss = 1.5297\n",
      "Epoch 17/50, Train iteration 56/164: Loss = 1.5503\n",
      "Epoch 17/50, Train iteration 57/164: Loss = 1.5299\n",
      "Epoch 17/50, Train iteration 58/164: Loss = 1.5696\n",
      "Epoch 17/50, Train iteration 59/164: Loss = 1.5752\n",
      "Epoch 17/50, Train iteration 60/164: Loss = 1.5109\n",
      "Epoch 17/50, Train iteration 61/164: Loss = 1.5540\n",
      "Epoch 17/50, Train iteration 62/164: Loss = 1.5131\n",
      "Epoch 17/50, Train iteration 63/164: Loss = 1.5759\n",
      "Epoch 17/50, Train iteration 64/164: Loss = 1.5317\n",
      "Epoch 17/50, Train iteration 65/164: Loss = 1.5449\n",
      "Epoch 17/50, Train iteration 66/164: Loss = 1.4587\n",
      "Epoch 17/50, Train iteration 67/164: Loss = 1.4965\n",
      "Epoch 17/50, Train iteration 68/164: Loss = 1.5257\n",
      "Epoch 17/50, Train iteration 69/164: Loss = 1.5841\n",
      "Epoch 17/50, Train iteration 70/164: Loss = 1.5391\n",
      "Epoch 17/50, Train iteration 71/164: Loss = 1.5859\n",
      "Epoch 17/50, Train iteration 72/164: Loss = 1.5871\n",
      "Epoch 17/50, Train iteration 73/164: Loss = 1.5680\n",
      "Epoch 17/50, Train iteration 74/164: Loss = 1.4987\n",
      "Epoch 17/50, Train iteration 75/164: Loss = 1.4974\n",
      "Epoch 17/50, Train iteration 76/164: Loss = 1.5430\n",
      "Epoch 17/50, Train iteration 77/164: Loss = 1.5989\n",
      "Epoch 17/50, Train iteration 78/164: Loss = 1.5586\n",
      "Epoch 17/50, Train iteration 79/164: Loss = 1.5543\n",
      "Epoch 17/50, Train iteration 80/164: Loss = 1.5310\n",
      "Epoch 17/50, Train iteration 81/164: Loss = 1.5306\n",
      "Epoch 17/50, Train iteration 82/164: Loss = 1.5612\n",
      "Epoch 17/50, Train iteration 83/164: Loss = 1.5866\n",
      "Epoch 17/50, Train iteration 84/164: Loss = 1.4364\n",
      "Epoch 17/50, Train iteration 85/164: Loss = 1.6080\n",
      "Epoch 17/50, Train iteration 86/164: Loss = 1.4338\n",
      "Epoch 17/50, Train iteration 87/164: Loss = 1.5380\n",
      "Epoch 17/50, Train iteration 88/164: Loss = 1.5861\n",
      "Epoch 17/50, Train iteration 89/164: Loss = 1.5255\n",
      "Epoch 17/50, Train iteration 90/164: Loss = 1.4796\n",
      "Epoch 17/50, Train iteration 91/164: Loss = 1.6027\n",
      "Epoch 17/50, Train iteration 92/164: Loss = 1.5458\n",
      "Epoch 17/50, Train iteration 93/164: Loss = 1.5498\n",
      "Epoch 17/50, Train iteration 94/164: Loss = 1.5954\n",
      "Epoch 17/50, Train iteration 95/164: Loss = 1.4982\n",
      "Epoch 17/50, Train iteration 96/164: Loss = 1.5753\n",
      "Epoch 17/50, Train iteration 97/164: Loss = 1.5497\n",
      "Epoch 17/50, Train iteration 98/164: Loss = 1.5692\n",
      "Epoch 17/50, Train iteration 99/164: Loss = 1.5196\n",
      "Epoch 17/50, Train iteration 100/164: Loss = 1.4970\n",
      "Epoch 17/50, Train iteration 101/164: Loss = 1.5477\n",
      "Epoch 17/50, Train iteration 102/164: Loss = 1.5426\n",
      "Epoch 17/50, Train iteration 103/164: Loss = 1.5963\n",
      "Epoch 17/50, Train iteration 104/164: Loss = 1.5574\n",
      "Epoch 17/50, Train iteration 105/164: Loss = 1.5310\n",
      "Epoch 17/50, Train iteration 106/164: Loss = 1.5489\n",
      "Epoch 17/50, Train iteration 107/164: Loss = 1.4886\n",
      "Epoch 17/50, Train iteration 108/164: Loss = 1.5374\n",
      "Epoch 17/50, Train iteration 109/164: Loss = 1.5728\n",
      "Epoch 17/50, Train iteration 110/164: Loss = 1.5139\n",
      "Epoch 17/50, Train iteration 111/164: Loss = 1.5767\n",
      "Epoch 17/50, Train iteration 112/164: Loss = 1.5666\n",
      "Epoch 17/50, Train iteration 113/164: Loss = 1.4910\n",
      "Epoch 17/50, Train iteration 114/164: Loss = 1.4479\n",
      "Epoch 17/50, Train iteration 115/164: Loss = 1.5477\n",
      "Epoch 17/50, Train iteration 116/164: Loss = 1.5244\n",
      "Epoch 17/50, Train iteration 117/164: Loss = 1.5078\n",
      "Epoch 17/50, Train iteration 118/164: Loss = 1.5816\n",
      "Epoch 17/50, Train iteration 119/164: Loss = 1.5801\n",
      "Epoch 17/50, Train iteration 120/164: Loss = 1.5010\n",
      "Epoch 17/50, Train iteration 121/164: Loss = 1.5234\n",
      "Epoch 17/50, Train iteration 122/164: Loss = 1.4701\n",
      "Epoch 17/50, Train iteration 123/164: Loss = 1.5139\n",
      "Epoch 17/50, Train iteration 124/164: Loss = 1.5540\n",
      "Epoch 17/50, Train iteration 125/164: Loss = 1.4848\n",
      "Epoch 17/50, Train iteration 126/164: Loss = 1.4950\n",
      "Epoch 17/50, Train iteration 127/164: Loss = 1.5487\n",
      "Epoch 17/50, Train iteration 128/164: Loss = 1.4726\n",
      "Epoch 17/50, Train iteration 129/164: Loss = 1.5230\n",
      "Epoch 17/50, Train iteration 130/164: Loss = 1.5177\n",
      "Epoch 17/50, Train iteration 131/164: Loss = 1.5093\n",
      "Epoch 17/50, Train iteration 132/164: Loss = 1.5183\n",
      "Epoch 17/50, Train iteration 133/164: Loss = 1.5938\n",
      "Epoch 17/50, Train iteration 134/164: Loss = 1.5219\n",
      "Epoch 17/50, Train iteration 135/164: Loss = 1.5809\n",
      "Epoch 17/50, Train iteration 136/164: Loss = 1.5812\n",
      "Epoch 17/50, Train iteration 137/164: Loss = 1.5239\n",
      "Epoch 17/50, Train iteration 138/164: Loss = 1.5103\n",
      "Epoch 17/50, Train iteration 139/164: Loss = 1.5469\n",
      "Epoch 17/50, Train iteration 140/164: Loss = 1.5252\n",
      "Epoch 17/50, Train iteration 141/164: Loss = 1.5401\n",
      "Epoch 17/50, Train iteration 142/164: Loss = 1.6179\n",
      "Epoch 17/50, Train iteration 143/164: Loss = 1.4717\n",
      "Epoch 17/50, Train iteration 144/164: Loss = 1.5516\n",
      "Epoch 17/50, Train iteration 145/164: Loss = 1.5250\n",
      "Epoch 17/50, Train iteration 146/164: Loss = 1.5087\n",
      "Epoch 17/50, Train iteration 147/164: Loss = 1.5000\n",
      "Epoch 17/50, Train iteration 148/164: Loss = 1.5032\n",
      "Epoch 17/50, Train iteration 149/164: Loss = 1.5169\n",
      "Epoch 17/50, Train iteration 150/164: Loss = 1.5415\n",
      "Epoch 17/50, Train iteration 151/164: Loss = 1.5413\n",
      "Epoch 17/50, Train iteration 152/164: Loss = 1.5558\n",
      "Epoch 17/50, Train iteration 153/164: Loss = 1.4959\n",
      "Epoch 17/50, Train iteration 154/164: Loss = 1.5608\n",
      "Epoch 17/50, Train iteration 155/164: Loss = 1.4873\n",
      "Epoch 17/50, Train iteration 156/164: Loss = 1.4916\n",
      "Epoch 17/50, Train iteration 157/164: Loss = 1.5754\n",
      "Epoch 17/50, Train iteration 158/164: Loss = 1.5865\n",
      "Epoch 17/50, Train iteration 159/164: Loss = 1.5367\n",
      "Epoch 17/50, Train iteration 160/164: Loss = 1.5422\n",
      "Epoch 17/50, Train iteration 161/164: Loss = 1.5991\n",
      "Epoch 17/50, Train iteration 162/164: Loss = 1.5782\n",
      "Epoch 17/50, Train iteration 163/164: Loss = 1.5846\n",
      "Epoch 17/50, Train iteration 164/164: Loss = 1.3579\n",
      "Epoch 17/50, Val iteration 1/27: Loss = 1.6180\n",
      "Epoch 17/50, Val iteration 2/27: Loss = 1.6244\n",
      "Epoch 17/50, Val iteration 3/27: Loss = 1.5913\n",
      "Epoch 17/50, Val iteration 4/27: Loss = 1.5965\n",
      "Epoch 17/50, Val iteration 5/27: Loss = 1.6170\n",
      "Epoch 17/50, Val iteration 6/27: Loss = 1.5824\n",
      "Epoch 17/50, Val iteration 7/27: Loss = 1.5551\n",
      "Epoch 17/50, Val iteration 8/27: Loss = 1.6151\n",
      "Epoch 17/50, Val iteration 9/27: Loss = 1.5874\n",
      "Epoch 17/50, Val iteration 10/27: Loss = 1.5771\n",
      "Epoch 17/50, Val iteration 11/27: Loss = 1.5985\n",
      "Epoch 17/50, Val iteration 12/27: Loss = 1.5647\n",
      "Epoch 17/50, Val iteration 13/27: Loss = 1.5728\n",
      "Epoch 17/50, Val iteration 14/27: Loss = 1.5449\n",
      "Epoch 17/50, Val iteration 15/27: Loss = 1.5912\n",
      "Epoch 17/50, Val iteration 16/27: Loss = 1.5812\n",
      "Epoch 17/50, Val iteration 17/27: Loss = 1.5939\n",
      "Epoch 17/50, Val iteration 18/27: Loss = 1.5571\n",
      "Epoch 17/50, Val iteration 19/27: Loss = 1.5763\n",
      "Epoch 17/50, Val iteration 20/27: Loss = 1.5971\n",
      "Epoch 17/50, Val iteration 21/27: Loss = 1.5873\n",
      "Epoch 17/50, Val iteration 22/27: Loss = 1.6032\n",
      "Epoch 17/50, Val iteration 23/27: Loss = 1.4861\n",
      "Epoch 17/50, Val iteration 24/27: Loss = 1.5561\n",
      "Epoch 17/50, Val iteration 25/27: Loss = 1.5849\n",
      "Epoch 17/50, Val iteration 26/27: Loss = 1.5937\n",
      "Epoch 17/50, Val iteration 27/27: Loss = 1.6062\n",
      "Epoch 17/50: Train Loss = 1.5404, Val Loss = 1.5837\n",
      "Current learning rate: 9e-06\n",
      "Epoch 18/50, Train iteration 1/164: Loss = 1.5319\n",
      "Epoch 18/50, Train iteration 2/164: Loss = 1.5756\n",
      "Epoch 18/50, Train iteration 3/164: Loss = 1.5916\n",
      "Epoch 18/50, Train iteration 4/164: Loss = 1.5526\n",
      "Epoch 18/50, Train iteration 5/164: Loss = 1.5657\n",
      "Epoch 18/50, Train iteration 6/164: Loss = 1.5949\n",
      "Epoch 18/50, Train iteration 7/164: Loss = 1.5946\n",
      "Epoch 18/50, Train iteration 8/164: Loss = 1.4851\n",
      "Epoch 18/50, Train iteration 9/164: Loss = 1.5839\n",
      "Epoch 18/50, Train iteration 10/164: Loss = 1.5830\n",
      "Epoch 18/50, Train iteration 11/164: Loss = 1.6050\n",
      "Epoch 18/50, Train iteration 12/164: Loss = 1.5415\n",
      "Epoch 18/50, Train iteration 13/164: Loss = 1.4514\n",
      "Epoch 18/50, Train iteration 14/164: Loss = 1.5656\n",
      "Epoch 18/50, Train iteration 15/164: Loss = 1.4829\n",
      "Epoch 18/50, Train iteration 16/164: Loss = 1.5089\n",
      "Epoch 18/50, Train iteration 17/164: Loss = 1.5178\n",
      "Epoch 18/50, Train iteration 18/164: Loss = 1.5522\n",
      "Epoch 18/50, Train iteration 19/164: Loss = 1.5161\n",
      "Epoch 18/50, Train iteration 20/164: Loss = 1.5371\n",
      "Epoch 18/50, Train iteration 21/164: Loss = 1.5542\n",
      "Epoch 18/50, Train iteration 22/164: Loss = 1.5570\n",
      "Epoch 18/50, Train iteration 23/164: Loss = 1.5495\n",
      "Epoch 18/50, Train iteration 24/164: Loss = 1.5602\n",
      "Epoch 18/50, Train iteration 25/164: Loss = 1.5907\n",
      "Epoch 18/50, Train iteration 26/164: Loss = 1.5294\n",
      "Epoch 18/50, Train iteration 27/164: Loss = 1.5490\n",
      "Epoch 18/50, Train iteration 28/164: Loss = 1.5964\n",
      "Epoch 18/50, Train iteration 29/164: Loss = 1.5502\n",
      "Epoch 18/50, Train iteration 30/164: Loss = 1.5728\n",
      "Epoch 18/50, Train iteration 31/164: Loss = 1.5109\n",
      "Epoch 18/50, Train iteration 32/164: Loss = 1.5217\n",
      "Epoch 18/50, Train iteration 33/164: Loss = 1.6175\n",
      "Epoch 18/50, Train iteration 34/164: Loss = 1.5238\n",
      "Epoch 18/50, Train iteration 35/164: Loss = 1.5958\n",
      "Epoch 18/50, Train iteration 36/164: Loss = 1.5116\n",
      "Epoch 18/50, Train iteration 37/164: Loss = 1.6173\n",
      "Epoch 18/50, Train iteration 38/164: Loss = 1.5136\n",
      "Epoch 18/50, Train iteration 39/164: Loss = 1.5184\n",
      "Epoch 18/50, Train iteration 40/164: Loss = 1.4836\n",
      "Epoch 18/50, Train iteration 41/164: Loss = 1.4403\n",
      "Epoch 18/50, Train iteration 42/164: Loss = 1.5570\n",
      "Epoch 18/50, Train iteration 43/164: Loss = 1.5545\n",
      "Epoch 18/50, Train iteration 44/164: Loss = 1.5542\n",
      "Epoch 18/50, Train iteration 45/164: Loss = 1.5273\n",
      "Epoch 18/50, Train iteration 46/164: Loss = 1.5624\n",
      "Epoch 18/50, Train iteration 47/164: Loss = 1.5437\n",
      "Epoch 18/50, Train iteration 48/164: Loss = 1.4905\n",
      "Epoch 18/50, Train iteration 49/164: Loss = 1.4633\n",
      "Epoch 18/50, Train iteration 50/164: Loss = 1.5863\n",
      "Epoch 18/50, Train iteration 51/164: Loss = 1.5376\n",
      "Epoch 18/50, Train iteration 52/164: Loss = 1.5087\n",
      "Epoch 18/50, Train iteration 53/164: Loss = 1.5239\n",
      "Epoch 18/50, Train iteration 54/164: Loss = 1.5167\n",
      "Epoch 18/50, Train iteration 55/164: Loss = 1.5084\n",
      "Epoch 18/50, Train iteration 56/164: Loss = 1.5716\n",
      "Epoch 18/50, Train iteration 57/164: Loss = 1.5618\n",
      "Epoch 18/50, Train iteration 58/164: Loss = 1.5340\n",
      "Epoch 18/50, Train iteration 59/164: Loss = 1.5171\n",
      "Epoch 18/50, Train iteration 60/164: Loss = 1.5438\n",
      "Epoch 18/50, Train iteration 61/164: Loss = 1.4852\n",
      "Epoch 18/50, Train iteration 62/164: Loss = 1.5380\n",
      "Epoch 18/50, Train iteration 63/164: Loss = 1.6038\n",
      "Epoch 18/50, Train iteration 64/164: Loss = 1.5326\n",
      "Epoch 18/50, Train iteration 65/164: Loss = 1.5432\n",
      "Epoch 18/50, Train iteration 66/164: Loss = 1.4739\n",
      "Epoch 18/50, Train iteration 67/164: Loss = 1.5263\n",
      "Epoch 18/50, Train iteration 68/164: Loss = 1.5007\n",
      "Epoch 18/50, Train iteration 69/164: Loss = 1.5737\n",
      "Epoch 18/50, Train iteration 70/164: Loss = 1.5798\n",
      "Epoch 18/50, Train iteration 71/164: Loss = 1.5810\n",
      "Epoch 18/50, Train iteration 72/164: Loss = 1.5814\n",
      "Epoch 18/50, Train iteration 73/164: Loss = 1.5638\n",
      "Epoch 18/50, Train iteration 74/164: Loss = 1.5050\n",
      "Epoch 18/50, Train iteration 75/164: Loss = 1.4812\n",
      "Epoch 18/50, Train iteration 76/164: Loss = 1.5367\n",
      "Epoch 18/50, Train iteration 77/164: Loss = 1.5670\n",
      "Epoch 18/50, Train iteration 78/164: Loss = 1.5624\n",
      "Epoch 18/50, Train iteration 79/164: Loss = 1.5919\n",
      "Epoch 18/50, Train iteration 80/164: Loss = 1.5492\n",
      "Epoch 18/50, Train iteration 81/164: Loss = 1.5139\n",
      "Epoch 18/50, Train iteration 82/164: Loss = 1.5425\n",
      "Epoch 18/50, Train iteration 83/164: Loss = 1.5408\n",
      "Epoch 18/50, Train iteration 84/164: Loss = 1.4909\n",
      "Epoch 18/50, Train iteration 85/164: Loss = 1.6286\n",
      "Epoch 18/50, Train iteration 86/164: Loss = 1.4530\n",
      "Epoch 18/50, Train iteration 87/164: Loss = 1.5486\n",
      "Epoch 18/50, Train iteration 88/164: Loss = 1.6155\n",
      "Epoch 18/50, Train iteration 89/164: Loss = 1.5731\n",
      "Epoch 18/50, Train iteration 90/164: Loss = 1.5239\n",
      "Epoch 18/50, Train iteration 91/164: Loss = 1.5756\n",
      "Epoch 18/50, Train iteration 92/164: Loss = 1.5783\n",
      "Epoch 18/50, Train iteration 93/164: Loss = 1.5467\n",
      "Epoch 18/50, Train iteration 94/164: Loss = 1.6112\n",
      "Epoch 18/50, Train iteration 95/164: Loss = 1.5071\n",
      "Epoch 18/50, Train iteration 96/164: Loss = 1.5948\n",
      "Epoch 18/50, Train iteration 97/164: Loss = 1.5140\n",
      "Epoch 18/50, Train iteration 98/164: Loss = 1.4877\n",
      "Epoch 18/50, Train iteration 99/164: Loss = 1.4722\n",
      "Epoch 18/50, Train iteration 100/164: Loss = 1.4560\n",
      "Epoch 18/50, Train iteration 101/164: Loss = 1.5551\n",
      "Epoch 18/50, Train iteration 102/164: Loss = 1.5241\n",
      "Epoch 18/50, Train iteration 103/164: Loss = 1.5224\n",
      "Epoch 18/50, Train iteration 104/164: Loss = 1.5868\n",
      "Epoch 18/50, Train iteration 105/164: Loss = 1.5814\n",
      "Epoch 18/50, Train iteration 106/164: Loss = 1.5212\n",
      "Epoch 18/50, Train iteration 107/164: Loss = 1.6015\n",
      "Epoch 18/50, Train iteration 108/164: Loss = 1.5584\n",
      "Epoch 18/50, Train iteration 109/164: Loss = 1.5600\n",
      "Epoch 18/50, Train iteration 110/164: Loss = 1.5673\n",
      "Epoch 18/50, Train iteration 111/164: Loss = 1.5499\n",
      "Epoch 18/50, Train iteration 112/164: Loss = 1.5592\n",
      "Epoch 18/50, Train iteration 113/164: Loss = 1.5346\n",
      "Epoch 18/50, Train iteration 114/164: Loss = 1.4792\n",
      "Epoch 18/50, Train iteration 115/164: Loss = 1.5255\n",
      "Epoch 18/50, Train iteration 116/164: Loss = 1.5020\n",
      "Epoch 18/50, Train iteration 117/164: Loss = 1.4981\n",
      "Epoch 18/50, Train iteration 118/164: Loss = 1.5792\n",
      "Epoch 18/50, Train iteration 119/164: Loss = 1.5767\n",
      "Epoch 18/50, Train iteration 120/164: Loss = 1.5157\n",
      "Epoch 18/50, Train iteration 121/164: Loss = 1.4816\n",
      "Epoch 18/50, Train iteration 122/164: Loss = 1.4612\n",
      "Epoch 18/50, Train iteration 123/164: Loss = 1.5135\n",
      "Epoch 18/50, Train iteration 124/164: Loss = 1.5550\n",
      "Epoch 18/50, Train iteration 125/164: Loss = 1.5124\n",
      "Epoch 18/50, Train iteration 126/164: Loss = 1.5231\n",
      "Epoch 18/50, Train iteration 127/164: Loss = 1.6016\n",
      "Epoch 18/50, Train iteration 128/164: Loss = 1.4570\n",
      "Epoch 18/50, Train iteration 129/164: Loss = 1.5090\n",
      "Epoch 18/50, Train iteration 130/164: Loss = 1.5297\n",
      "Epoch 18/50, Train iteration 131/164: Loss = 1.5696\n",
      "Epoch 18/50, Train iteration 132/164: Loss = 1.5196\n",
      "Epoch 18/50, Train iteration 133/164: Loss = 1.5651\n",
      "Epoch 18/50, Train iteration 134/164: Loss = 1.5520\n",
      "Epoch 18/50, Train iteration 135/164: Loss = 1.5199\n",
      "Epoch 18/50, Train iteration 136/164: Loss = 1.5306\n",
      "Epoch 18/50, Train iteration 137/164: Loss = 1.5176\n",
      "Epoch 18/50, Train iteration 138/164: Loss = 1.5896\n",
      "Epoch 18/50, Train iteration 139/164: Loss = 1.5963\n",
      "Epoch 18/50, Train iteration 140/164: Loss = 1.5347\n",
      "Epoch 18/50, Train iteration 141/164: Loss = 1.5438\n",
      "Epoch 18/50, Train iteration 142/164: Loss = 1.5601\n",
      "Epoch 18/50, Train iteration 143/164: Loss = 1.5257\n",
      "Epoch 18/50, Train iteration 144/164: Loss = 1.5650\n",
      "Epoch 18/50, Train iteration 145/164: Loss = 1.5263\n",
      "Epoch 18/50, Train iteration 146/164: Loss = 1.5482\n",
      "Epoch 18/50, Train iteration 147/164: Loss = 1.5512\n",
      "Epoch 18/50, Train iteration 148/164: Loss = 1.5193\n",
      "Epoch 18/50, Train iteration 149/164: Loss = 1.5822\n",
      "Epoch 18/50, Train iteration 150/164: Loss = 1.5795\n",
      "Epoch 18/50, Train iteration 151/164: Loss = 1.5721\n",
      "Epoch 18/50, Train iteration 152/164: Loss = 1.5308\n",
      "Epoch 18/50, Train iteration 153/164: Loss = 1.5635\n",
      "Epoch 18/50, Train iteration 154/164: Loss = 1.5188\n",
      "Epoch 18/50, Train iteration 155/164: Loss = 1.5188\n",
      "Epoch 18/50, Train iteration 156/164: Loss = 1.5419\n",
      "Epoch 18/50, Train iteration 157/164: Loss = 1.5344\n",
      "Epoch 18/50, Train iteration 158/164: Loss = 1.6045\n",
      "Epoch 18/50, Train iteration 159/164: Loss = 1.5422\n",
      "Epoch 18/50, Train iteration 160/164: Loss = 1.5571\n",
      "Epoch 18/50, Train iteration 161/164: Loss = 1.6412\n",
      "Epoch 18/50, Train iteration 162/164: Loss = 1.5763\n",
      "Epoch 18/50, Train iteration 163/164: Loss = 1.5428\n",
      "Epoch 18/50, Train iteration 164/164: Loss = 1.2883\n",
      "Epoch 18/50, Val iteration 1/27: Loss = 1.6110\n",
      "Epoch 18/50, Val iteration 2/27: Loss = 1.6220\n",
      "Epoch 18/50, Val iteration 3/27: Loss = 1.5921\n",
      "Epoch 18/50, Val iteration 4/27: Loss = 1.5942\n",
      "Epoch 18/50, Val iteration 5/27: Loss = 1.6131\n",
      "Epoch 18/50, Val iteration 6/27: Loss = 1.5802\n",
      "Epoch 18/50, Val iteration 7/27: Loss = 1.5576\n",
      "Epoch 18/50, Val iteration 8/27: Loss = 1.6106\n",
      "Epoch 18/50, Val iteration 9/27: Loss = 1.5862\n",
      "Epoch 18/50, Val iteration 10/27: Loss = 1.5791\n",
      "Epoch 18/50, Val iteration 11/27: Loss = 1.5981\n",
      "Epoch 18/50, Val iteration 12/27: Loss = 1.5680\n",
      "Epoch 18/50, Val iteration 13/27: Loss = 1.5760\n",
      "Epoch 18/50, Val iteration 14/27: Loss = 1.5508\n",
      "Epoch 18/50, Val iteration 15/27: Loss = 1.5899\n",
      "Epoch 18/50, Val iteration 16/27: Loss = 1.5831\n",
      "Epoch 18/50, Val iteration 17/27: Loss = 1.5915\n",
      "Epoch 18/50, Val iteration 18/27: Loss = 1.5588\n",
      "Epoch 18/50, Val iteration 19/27: Loss = 1.5753\n",
      "Epoch 18/50, Val iteration 20/27: Loss = 1.5961\n",
      "Epoch 18/50, Val iteration 21/27: Loss = 1.5875\n",
      "Epoch 18/50, Val iteration 22/27: Loss = 1.5989\n",
      "Epoch 18/50, Val iteration 23/27: Loss = 1.4917\n",
      "Epoch 18/50, Val iteration 24/27: Loss = 1.5579\n",
      "Epoch 18/50, Val iteration 25/27: Loss = 1.5821\n",
      "Epoch 18/50, Val iteration 26/27: Loss = 1.5977\n",
      "Epoch 18/50, Val iteration 27/27: Loss = 1.6008\n",
      "Epoch 18/50: Train Loss = 1.5414, Val Loss = 1.5833\n",
      "Current learning rate: 9e-06\n",
      "Epoch 19/50, Train iteration 1/164: Loss = 1.5758\n",
      "Epoch 19/50, Train iteration 2/164: Loss = 1.5373\n",
      "Epoch 19/50, Train iteration 3/164: Loss = 1.5577\n",
      "Epoch 19/50, Train iteration 4/164: Loss = 1.5197\n",
      "Epoch 19/50, Train iteration 5/164: Loss = 1.5809\n",
      "Epoch 19/50, Train iteration 6/164: Loss = 1.5863\n",
      "Epoch 19/50, Train iteration 7/164: Loss = 1.6039\n",
      "Epoch 19/50, Train iteration 8/164: Loss = 1.4856\n",
      "Epoch 19/50, Train iteration 9/164: Loss = 1.5998\n",
      "Epoch 19/50, Train iteration 10/164: Loss = 1.5861\n",
      "Epoch 19/50, Train iteration 11/164: Loss = 1.5178\n",
      "Epoch 19/50, Train iteration 12/164: Loss = 1.5638\n",
      "Epoch 19/50, Train iteration 13/164: Loss = 1.5122\n",
      "Epoch 19/50, Train iteration 14/164: Loss = 1.5734\n",
      "Epoch 19/50, Train iteration 15/164: Loss = 1.5278\n",
      "Epoch 19/50, Train iteration 16/164: Loss = 1.5841\n",
      "Epoch 19/50, Train iteration 17/164: Loss = 1.5594\n",
      "Epoch 19/50, Train iteration 18/164: Loss = 1.5676\n",
      "Epoch 19/50, Train iteration 19/164: Loss = 1.5490\n",
      "Epoch 19/50, Train iteration 20/164: Loss = 1.5440\n",
      "Epoch 19/50, Train iteration 21/164: Loss = 1.5404\n",
      "Epoch 19/50, Train iteration 22/164: Loss = 1.5339\n",
      "Epoch 19/50, Train iteration 23/164: Loss = 1.5463\n",
      "Epoch 19/50, Train iteration 24/164: Loss = 1.5734\n",
      "Epoch 19/50, Train iteration 25/164: Loss = 1.5508\n",
      "Epoch 19/50, Train iteration 26/164: Loss = 1.5304\n",
      "Epoch 19/50, Train iteration 27/164: Loss = 1.5469\n",
      "Epoch 19/50, Train iteration 28/164: Loss = 1.5262\n",
      "Epoch 19/50, Train iteration 29/164: Loss = 1.4898\n",
      "Epoch 19/50, Train iteration 30/164: Loss = 1.5584\n",
      "Epoch 19/50, Train iteration 31/164: Loss = 1.5194\n",
      "Epoch 19/50, Train iteration 32/164: Loss = 1.4638\n",
      "Epoch 19/50, Train iteration 33/164: Loss = 1.5481\n",
      "Epoch 19/50, Train iteration 34/164: Loss = 1.4716\n",
      "Epoch 19/50, Train iteration 35/164: Loss = 1.5341\n",
      "Epoch 19/50, Train iteration 36/164: Loss = 1.4807\n",
      "Epoch 19/50, Train iteration 37/164: Loss = 1.5751\n",
      "Epoch 19/50, Train iteration 38/164: Loss = 1.5452\n",
      "Epoch 19/50, Train iteration 39/164: Loss = 1.5384\n",
      "Epoch 19/50, Train iteration 40/164: Loss = 1.5119\n",
      "Epoch 19/50, Train iteration 41/164: Loss = 1.4570\n",
      "Epoch 19/50, Train iteration 42/164: Loss = 1.5226\n",
      "Epoch 19/50, Train iteration 43/164: Loss = 1.5559\n",
      "Epoch 19/50, Train iteration 44/164: Loss = 1.5345\n",
      "Epoch 19/50, Train iteration 45/164: Loss = 1.5819\n",
      "Epoch 19/50, Train iteration 46/164: Loss = 1.5792\n",
      "Epoch 19/50, Train iteration 47/164: Loss = 1.5522\n",
      "Epoch 19/50, Train iteration 48/164: Loss = 1.5391\n",
      "Epoch 19/50, Train iteration 49/164: Loss = 1.5060\n",
      "Epoch 19/50, Train iteration 50/164: Loss = 1.5415\n",
      "Epoch 19/50, Train iteration 51/164: Loss = 1.4515\n",
      "Epoch 19/50, Train iteration 52/164: Loss = 1.5204\n",
      "Epoch 19/50, Train iteration 53/164: Loss = 1.5368\n",
      "Epoch 19/50, Train iteration 54/164: Loss = 1.5135\n",
      "Epoch 19/50, Train iteration 55/164: Loss = 1.4877\n",
      "Epoch 19/50, Train iteration 56/164: Loss = 1.5659\n",
      "Epoch 19/50, Train iteration 57/164: Loss = 1.5168\n",
      "Epoch 19/50, Train iteration 58/164: Loss = 1.5591\n",
      "Epoch 19/50, Train iteration 59/164: Loss = 1.5197\n",
      "Epoch 19/50, Train iteration 60/164: Loss = 1.4566\n",
      "Epoch 19/50, Train iteration 61/164: Loss = 1.4942\n",
      "Epoch 19/50, Train iteration 62/164: Loss = 1.4937\n",
      "Epoch 19/50, Train iteration 63/164: Loss = 1.5974\n",
      "Epoch 19/50, Train iteration 64/164: Loss = 1.5355\n",
      "Epoch 19/50, Train iteration 65/164: Loss = 1.4973\n",
      "Epoch 19/50, Train iteration 66/164: Loss = 1.4554\n",
      "Epoch 19/50, Train iteration 67/164: Loss = 1.5023\n",
      "Epoch 19/50, Train iteration 68/164: Loss = 1.5199\n",
      "Epoch 19/50, Train iteration 69/164: Loss = 1.5439\n",
      "Epoch 19/50, Train iteration 70/164: Loss = 1.5084\n",
      "Epoch 19/50, Train iteration 71/164: Loss = 1.5313\n",
      "Epoch 19/50, Train iteration 72/164: Loss = 1.5908\n",
      "Epoch 19/50, Train iteration 73/164: Loss = 1.5681\n",
      "Epoch 19/50, Train iteration 74/164: Loss = 1.5362\n",
      "Epoch 19/50, Train iteration 75/164: Loss = 1.4936\n",
      "Epoch 19/50, Train iteration 76/164: Loss = 1.6036\n",
      "Epoch 19/50, Train iteration 77/164: Loss = 1.5813\n",
      "Epoch 19/50, Train iteration 78/164: Loss = 1.5031\n",
      "Epoch 19/50, Train iteration 79/164: Loss = 1.5483\n",
      "Epoch 19/50, Train iteration 80/164: Loss = 1.5657\n",
      "Epoch 19/50, Train iteration 81/164: Loss = 1.5214\n",
      "Epoch 19/50, Train iteration 82/164: Loss = 1.5317\n",
      "Epoch 19/50, Train iteration 83/164: Loss = 1.5890\n",
      "Epoch 19/50, Train iteration 84/164: Loss = 1.5557\n",
      "Epoch 19/50, Train iteration 85/164: Loss = 1.6587\n",
      "Epoch 19/50, Train iteration 86/164: Loss = 1.4720\n",
      "Epoch 19/50, Train iteration 87/164: Loss = 1.5840\n",
      "Epoch 19/50, Train iteration 88/164: Loss = 1.5909\n",
      "Epoch 19/50, Train iteration 89/164: Loss = 1.5132\n",
      "Epoch 19/50, Train iteration 90/164: Loss = 1.4817\n",
      "Epoch 19/50, Train iteration 91/164: Loss = 1.5898\n",
      "Epoch 19/50, Train iteration 92/164: Loss = 1.5607\n",
      "Epoch 19/50, Train iteration 93/164: Loss = 1.5754\n",
      "Epoch 19/50, Train iteration 94/164: Loss = 1.6006\n",
      "Epoch 19/50, Train iteration 95/164: Loss = 1.4851\n",
      "Epoch 19/50, Train iteration 96/164: Loss = 1.5615\n",
      "Epoch 19/50, Train iteration 97/164: Loss = 1.5567\n",
      "Epoch 19/50, Train iteration 98/164: Loss = 1.5630\n",
      "Epoch 19/50, Train iteration 99/164: Loss = 1.5062\n",
      "Epoch 19/50, Train iteration 100/164: Loss = 1.5031\n",
      "Epoch 19/50, Train iteration 101/164: Loss = 1.4989\n",
      "Epoch 19/50, Train iteration 102/164: Loss = 1.5291\n",
      "Epoch 19/50, Train iteration 103/164: Loss = 1.5677\n",
      "Epoch 19/50, Train iteration 104/164: Loss = 1.5915\n",
      "Epoch 19/50, Train iteration 105/164: Loss = 1.5578\n",
      "Epoch 19/50, Train iteration 106/164: Loss = 1.5752\n",
      "Epoch 19/50, Train iteration 107/164: Loss = 1.5108\n",
      "Epoch 19/50, Train iteration 108/164: Loss = 1.5623\n",
      "Epoch 19/50, Train iteration 109/164: Loss = 1.5826\n",
      "Epoch 19/50, Train iteration 110/164: Loss = 1.5313\n",
      "Epoch 19/50, Train iteration 111/164: Loss = 1.5460\n",
      "Epoch 19/50, Train iteration 112/164: Loss = 1.5080\n",
      "Epoch 19/50, Train iteration 113/164: Loss = 1.5413\n",
      "Epoch 19/50, Train iteration 114/164: Loss = 1.4333\n",
      "Epoch 19/50, Train iteration 115/164: Loss = 1.5395\n",
      "Epoch 19/50, Train iteration 116/164: Loss = 1.4792\n",
      "Epoch 19/50, Train iteration 117/164: Loss = 1.5035\n",
      "Epoch 19/50, Train iteration 118/164: Loss = 1.5964\n",
      "Epoch 19/50, Train iteration 119/164: Loss = 1.5299\n",
      "Epoch 19/50, Train iteration 120/164: Loss = 1.5307\n",
      "Epoch 19/50, Train iteration 121/164: Loss = 1.5588\n",
      "Epoch 19/50, Train iteration 122/164: Loss = 1.4685\n",
      "Epoch 19/50, Train iteration 123/164: Loss = 1.4763\n",
      "Epoch 19/50, Train iteration 124/164: Loss = 1.5191\n",
      "Epoch 19/50, Train iteration 125/164: Loss = 1.4804\n",
      "Epoch 19/50, Train iteration 126/164: Loss = 1.4820\n",
      "Epoch 19/50, Train iteration 127/164: Loss = 1.5751\n",
      "Epoch 19/50, Train iteration 128/164: Loss = 1.4777\n",
      "Epoch 19/50, Train iteration 129/164: Loss = 1.5443\n",
      "Epoch 19/50, Train iteration 130/164: Loss = 1.5895\n",
      "Epoch 19/50, Train iteration 131/164: Loss = 1.5849\n",
      "Epoch 19/50, Train iteration 132/164: Loss = 1.4642\n",
      "Epoch 19/50, Train iteration 133/164: Loss = 1.5446\n",
      "Epoch 19/50, Train iteration 134/164: Loss = 1.5256\n",
      "Epoch 19/50, Train iteration 135/164: Loss = 1.5638\n",
      "Epoch 19/50, Train iteration 136/164: Loss = 1.5713\n",
      "Epoch 19/50, Train iteration 137/164: Loss = 1.5234\n",
      "Epoch 19/50, Train iteration 138/164: Loss = 1.5485\n",
      "Epoch 19/50, Train iteration 139/164: Loss = 1.5694\n",
      "Epoch 19/50, Train iteration 140/164: Loss = 1.5585\n",
      "Epoch 19/50, Train iteration 141/164: Loss = 1.5342\n",
      "Epoch 19/50, Train iteration 142/164: Loss = 1.5413\n",
      "Epoch 19/50, Train iteration 143/164: Loss = 1.4927\n",
      "Epoch 19/50, Train iteration 144/164: Loss = 1.5627\n",
      "Epoch 19/50, Train iteration 145/164: Loss = 1.5059\n",
      "Epoch 19/50, Train iteration 146/164: Loss = 1.4879\n",
      "Epoch 19/50, Train iteration 147/164: Loss = 1.5222\n",
      "Epoch 19/50, Train iteration 148/164: Loss = 1.4621\n",
      "Epoch 19/50, Train iteration 149/164: Loss = 1.5532\n",
      "Epoch 19/50, Train iteration 150/164: Loss = 1.5910\n",
      "Epoch 19/50, Train iteration 151/164: Loss = 1.5426\n",
      "Epoch 19/50, Train iteration 152/164: Loss = 1.5250\n",
      "Epoch 19/50, Train iteration 153/164: Loss = 1.5448\n",
      "Epoch 19/50, Train iteration 154/164: Loss = 1.5626\n",
      "Epoch 19/50, Train iteration 155/164: Loss = 1.4934\n",
      "Epoch 19/50, Train iteration 156/164: Loss = 1.5662\n",
      "Epoch 19/50, Train iteration 157/164: Loss = 1.5498\n",
      "Epoch 19/50, Train iteration 158/164: Loss = 1.5721\n",
      "Epoch 19/50, Train iteration 159/164: Loss = 1.5485\n",
      "Epoch 19/50, Train iteration 160/164: Loss = 1.5394\n",
      "Epoch 19/50, Train iteration 161/164: Loss = 1.6324\n",
      "Epoch 19/50, Train iteration 162/164: Loss = 1.5289\n",
      "Epoch 19/50, Train iteration 163/164: Loss = 1.5110\n",
      "Epoch 19/50, Train iteration 164/164: Loss = 1.3711\n",
      "Epoch 19/50, Val iteration 1/27: Loss = 1.6166\n",
      "Epoch 19/50, Val iteration 2/27: Loss = 1.6225\n",
      "Epoch 19/50, Val iteration 3/27: Loss = 1.5902\n",
      "Epoch 19/50, Val iteration 4/27: Loss = 1.5961\n",
      "Epoch 19/50, Val iteration 5/27: Loss = 1.6164\n",
      "Epoch 19/50, Val iteration 6/27: Loss = 1.5823\n",
      "Epoch 19/50, Val iteration 7/27: Loss = 1.5554\n",
      "Epoch 19/50, Val iteration 8/27: Loss = 1.6140\n",
      "Epoch 19/50, Val iteration 9/27: Loss = 1.5872\n",
      "Epoch 19/50, Val iteration 10/27: Loss = 1.5772\n",
      "Epoch 19/50, Val iteration 11/27: Loss = 1.5991\n",
      "Epoch 19/50, Val iteration 12/27: Loss = 1.5653\n",
      "Epoch 19/50, Val iteration 13/27: Loss = 1.5721\n",
      "Epoch 19/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 19/50, Val iteration 15/27: Loss = 1.5908\n",
      "Epoch 19/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 19/50, Val iteration 17/27: Loss = 1.5953\n",
      "Epoch 19/50, Val iteration 18/27: Loss = 1.5568\n",
      "Epoch 19/50, Val iteration 19/27: Loss = 1.5766\n",
      "Epoch 19/50, Val iteration 20/27: Loss = 1.5975\n",
      "Epoch 19/50, Val iteration 21/27: Loss = 1.5867\n",
      "Epoch 19/50, Val iteration 22/27: Loss = 1.6051\n",
      "Epoch 19/50, Val iteration 23/27: Loss = 1.4850\n",
      "Epoch 19/50, Val iteration 24/27: Loss = 1.5571\n",
      "Epoch 19/50, Val iteration 25/27: Loss = 1.5865\n",
      "Epoch 19/50, Val iteration 26/27: Loss = 1.5931\n",
      "Epoch 19/50, Val iteration 27/27: Loss = 1.6071\n",
      "Epoch 19/50: Train Loss = 1.5364, Val Loss = 1.5836\n",
      "Current learning rate: 9e-06\n",
      "Epoch 20/50, Train iteration 1/164: Loss = 1.5420\n",
      "Epoch 20/50, Train iteration 2/164: Loss = 1.5576\n",
      "Epoch 20/50, Train iteration 3/164: Loss = 1.5397\n",
      "Epoch 20/50, Train iteration 4/164: Loss = 1.5967\n",
      "Epoch 20/50, Train iteration 5/164: Loss = 1.5811\n",
      "Epoch 20/50, Train iteration 6/164: Loss = 1.6144\n",
      "Epoch 20/50, Train iteration 7/164: Loss = 1.6041\n",
      "Epoch 20/50, Train iteration 8/164: Loss = 1.4527\n",
      "Epoch 20/50, Train iteration 9/164: Loss = 1.5723\n",
      "Epoch 20/50, Train iteration 10/164: Loss = 1.6236\n",
      "Epoch 20/50, Train iteration 11/164: Loss = 1.5662\n",
      "Epoch 20/50, Train iteration 12/164: Loss = 1.5297\n",
      "Epoch 20/50, Train iteration 13/164: Loss = 1.5153\n",
      "Epoch 20/50, Train iteration 14/164: Loss = 1.5905\n",
      "Epoch 20/50, Train iteration 15/164: Loss = 1.5700\n",
      "Epoch 20/50, Train iteration 16/164: Loss = 1.6017\n",
      "Epoch 20/50, Train iteration 17/164: Loss = 1.5105\n",
      "Epoch 20/50, Train iteration 18/164: Loss = 1.5004\n",
      "Epoch 20/50, Train iteration 19/164: Loss = 1.5227\n",
      "Epoch 20/50, Train iteration 20/164: Loss = 1.5181\n",
      "Epoch 20/50, Train iteration 21/164: Loss = 1.5823\n",
      "Epoch 20/50, Train iteration 22/164: Loss = 1.5639\n",
      "Epoch 20/50, Train iteration 23/164: Loss = 1.5580\n",
      "Epoch 20/50, Train iteration 24/164: Loss = 1.5759\n",
      "Epoch 20/50, Train iteration 25/164: Loss = 1.5840\n",
      "Epoch 20/50, Train iteration 26/164: Loss = 1.4697\n",
      "Epoch 20/50, Train iteration 27/164: Loss = 1.5177\n",
      "Epoch 20/50, Train iteration 28/164: Loss = 1.5297\n",
      "Epoch 20/50, Train iteration 29/164: Loss = 1.5553\n",
      "Epoch 20/50, Train iteration 30/164: Loss = 1.5413\n",
      "Epoch 20/50, Train iteration 31/164: Loss = 1.5067\n",
      "Epoch 20/50, Train iteration 32/164: Loss = 1.5283\n",
      "Epoch 20/50, Train iteration 33/164: Loss = 1.5829\n",
      "Epoch 20/50, Train iteration 34/164: Loss = 1.5177\n",
      "Epoch 20/50, Train iteration 35/164: Loss = 1.5029\n",
      "Epoch 20/50, Train iteration 36/164: Loss = 1.5416\n",
      "Epoch 20/50, Train iteration 37/164: Loss = 1.5602\n",
      "Epoch 20/50, Train iteration 38/164: Loss = 1.5195\n",
      "Epoch 20/50, Train iteration 39/164: Loss = 1.5209\n",
      "Epoch 20/50, Train iteration 40/164: Loss = 1.4931\n",
      "Epoch 20/50, Train iteration 41/164: Loss = 1.5394\n",
      "Epoch 20/50, Train iteration 42/164: Loss = 1.5480\n",
      "Epoch 20/50, Train iteration 43/164: Loss = 1.5407\n",
      "Epoch 20/50, Train iteration 44/164: Loss = 1.5465\n",
      "Epoch 20/50, Train iteration 45/164: Loss = 1.5584\n",
      "Epoch 20/50, Train iteration 46/164: Loss = 1.6156\n",
      "Epoch 20/50, Train iteration 47/164: Loss = 1.5220\n",
      "Epoch 20/50, Train iteration 48/164: Loss = 1.5368\n",
      "Epoch 20/50, Train iteration 49/164: Loss = 1.5371\n",
      "Epoch 20/50, Train iteration 50/164: Loss = 1.5903\n",
      "Epoch 20/50, Train iteration 51/164: Loss = 1.5260\n",
      "Epoch 20/50, Train iteration 52/164: Loss = 1.5491\n",
      "Epoch 20/50, Train iteration 53/164: Loss = 1.5306\n",
      "Epoch 20/50, Train iteration 54/164: Loss = 1.5320\n",
      "Epoch 20/50, Train iteration 55/164: Loss = 1.4856\n",
      "Epoch 20/50, Train iteration 56/164: Loss = 1.6149\n",
      "Epoch 20/50, Train iteration 57/164: Loss = 1.5459\n",
      "Epoch 20/50, Train iteration 58/164: Loss = 1.5456\n",
      "Epoch 20/50, Train iteration 59/164: Loss = 1.5349\n",
      "Epoch 20/50, Train iteration 60/164: Loss = 1.5543\n",
      "Epoch 20/50, Train iteration 61/164: Loss = 1.5329\n",
      "Epoch 20/50, Train iteration 62/164: Loss = 1.5117\n",
      "Epoch 20/50, Train iteration 63/164: Loss = 1.5759\n",
      "Epoch 20/50, Train iteration 64/164: Loss = 1.5148\n",
      "Epoch 20/50, Train iteration 65/164: Loss = 1.4873\n",
      "Epoch 20/50, Train iteration 66/164: Loss = 1.4405\n",
      "Epoch 20/50, Train iteration 67/164: Loss = 1.5265\n",
      "Epoch 20/50, Train iteration 68/164: Loss = 1.4926\n",
      "Epoch 20/50, Train iteration 69/164: Loss = 1.5717\n",
      "Epoch 20/50, Train iteration 70/164: Loss = 1.5344\n",
      "Epoch 20/50, Train iteration 71/164: Loss = 1.5369\n",
      "Epoch 20/50, Train iteration 72/164: Loss = 1.5826\n",
      "Epoch 20/50, Train iteration 73/164: Loss = 1.6279\n",
      "Epoch 20/50, Train iteration 74/164: Loss = 1.5051\n",
      "Epoch 20/50, Train iteration 75/164: Loss = 1.4870\n",
      "Epoch 20/50, Train iteration 76/164: Loss = 1.5413\n",
      "Epoch 20/50, Train iteration 77/164: Loss = 1.5507\n",
      "Epoch 20/50, Train iteration 78/164: Loss = 1.5786\n",
      "Epoch 20/50, Train iteration 79/164: Loss = 1.5992\n",
      "Epoch 20/50, Train iteration 80/164: Loss = 1.5797\n",
      "Epoch 20/50, Train iteration 81/164: Loss = 1.5395\n",
      "Epoch 20/50, Train iteration 82/164: Loss = 1.5290\n",
      "Epoch 20/50, Train iteration 83/164: Loss = 1.5901\n",
      "Epoch 20/50, Train iteration 84/164: Loss = 1.4889\n",
      "Epoch 20/50, Train iteration 85/164: Loss = 1.5949\n",
      "Epoch 20/50, Train iteration 86/164: Loss = 1.4034\n",
      "Epoch 20/50, Train iteration 87/164: Loss = 1.5753\n",
      "Epoch 20/50, Train iteration 88/164: Loss = 1.5764\n",
      "Epoch 20/50, Train iteration 89/164: Loss = 1.5462\n",
      "Epoch 20/50, Train iteration 90/164: Loss = 1.4655\n",
      "Epoch 20/50, Train iteration 91/164: Loss = 1.5500\n",
      "Epoch 20/50, Train iteration 92/164: Loss = 1.5494\n",
      "Epoch 20/50, Train iteration 93/164: Loss = 1.5190\n",
      "Epoch 20/50, Train iteration 94/164: Loss = 1.5589\n",
      "Epoch 20/50, Train iteration 95/164: Loss = 1.4948\n",
      "Epoch 20/50, Train iteration 96/164: Loss = 1.5852\n",
      "Epoch 20/50, Train iteration 97/164: Loss = 1.5366\n",
      "Epoch 20/50, Train iteration 98/164: Loss = 1.5579\n",
      "Epoch 20/50, Train iteration 99/164: Loss = 1.5109\n",
      "Epoch 20/50, Train iteration 100/164: Loss = 1.5098\n",
      "Epoch 20/50, Train iteration 101/164: Loss = 1.5385\n",
      "Epoch 20/50, Train iteration 102/164: Loss = 1.5780\n",
      "Epoch 20/50, Train iteration 103/164: Loss = 1.6131\n",
      "Epoch 20/50, Train iteration 104/164: Loss = 1.5919\n",
      "Epoch 20/50, Train iteration 105/164: Loss = 1.5191\n",
      "Epoch 20/50, Train iteration 106/164: Loss = 1.6005\n",
      "Epoch 20/50, Train iteration 107/164: Loss = 1.5242\n",
      "Epoch 20/50, Train iteration 108/164: Loss = 1.5596\n",
      "Epoch 20/50, Train iteration 109/164: Loss = 1.5421\n",
      "Epoch 20/50, Train iteration 110/164: Loss = 1.5430\n",
      "Epoch 20/50, Train iteration 111/164: Loss = 1.5415\n",
      "Epoch 20/50, Train iteration 112/164: Loss = 1.5968\n",
      "Epoch 20/50, Train iteration 113/164: Loss = 1.4961\n",
      "Epoch 20/50, Train iteration 114/164: Loss = 1.4781\n",
      "Epoch 20/50, Train iteration 115/164: Loss = 1.4631\n",
      "Epoch 20/50, Train iteration 116/164: Loss = 1.5570\n",
      "Epoch 20/50, Train iteration 117/164: Loss = 1.5132\n",
      "Epoch 20/50, Train iteration 118/164: Loss = 1.5632\n",
      "Epoch 20/50, Train iteration 119/164: Loss = 1.5819\n",
      "Epoch 20/50, Train iteration 120/164: Loss = 1.5401\n",
      "Epoch 20/50, Train iteration 121/164: Loss = 1.5457\n",
      "Epoch 20/50, Train iteration 122/164: Loss = 1.5094\n",
      "Epoch 20/50, Train iteration 123/164: Loss = 1.5062\n",
      "Epoch 20/50, Train iteration 124/164: Loss = 1.5537\n",
      "Epoch 20/50, Train iteration 125/164: Loss = 1.4440\n",
      "Epoch 20/50, Train iteration 126/164: Loss = 1.4659\n",
      "Epoch 20/50, Train iteration 127/164: Loss = 1.5556\n",
      "Epoch 20/50, Train iteration 128/164: Loss = 1.5303\n",
      "Epoch 20/50, Train iteration 129/164: Loss = 1.4859\n",
      "Epoch 20/50, Train iteration 130/164: Loss = 1.5612\n",
      "Epoch 20/50, Train iteration 131/164: Loss = 1.5690\n",
      "Epoch 20/50, Train iteration 132/164: Loss = 1.5037\n",
      "Epoch 20/50, Train iteration 133/164: Loss = 1.5586\n",
      "Epoch 20/50, Train iteration 134/164: Loss = 1.5768\n",
      "Epoch 20/50, Train iteration 135/164: Loss = 1.5377\n",
      "Epoch 20/50, Train iteration 136/164: Loss = 1.5791\n",
      "Epoch 20/50, Train iteration 137/164: Loss = 1.5290\n",
      "Epoch 20/50, Train iteration 138/164: Loss = 1.5496\n",
      "Epoch 20/50, Train iteration 139/164: Loss = 1.6110\n",
      "Epoch 20/50, Train iteration 140/164: Loss = 1.4875\n",
      "Epoch 20/50, Train iteration 141/164: Loss = 1.5726\n",
      "Epoch 20/50, Train iteration 142/164: Loss = 1.5252\n",
      "Epoch 20/50, Train iteration 143/164: Loss = 1.4872\n",
      "Epoch 20/50, Train iteration 144/164: Loss = 1.5698\n",
      "Epoch 20/50, Train iteration 145/164: Loss = 1.5455\n",
      "Epoch 20/50, Train iteration 146/164: Loss = 1.5915\n",
      "Epoch 20/50, Train iteration 147/164: Loss = 1.5054\n",
      "Epoch 20/50, Train iteration 148/164: Loss = 1.5240\n",
      "Epoch 20/50, Train iteration 149/164: Loss = 1.5032\n",
      "Epoch 20/50, Train iteration 150/164: Loss = 1.5299\n",
      "Epoch 20/50, Train iteration 151/164: Loss = 1.5297\n",
      "Epoch 20/50, Train iteration 152/164: Loss = 1.4782\n",
      "Epoch 20/50, Train iteration 153/164: Loss = 1.5188\n",
      "Epoch 20/50, Train iteration 154/164: Loss = 1.5318\n",
      "Epoch 20/50, Train iteration 155/164: Loss = 1.5422\n",
      "Epoch 20/50, Train iteration 156/164: Loss = 1.5195\n",
      "Epoch 20/50, Train iteration 157/164: Loss = 1.5711\n",
      "Epoch 20/50, Train iteration 158/164: Loss = 1.6031\n",
      "Epoch 20/50, Train iteration 159/164: Loss = 1.5723\n",
      "Epoch 20/50, Train iteration 160/164: Loss = 1.5843\n",
      "Epoch 20/50, Train iteration 161/164: Loss = 1.5543\n",
      "Epoch 20/50, Train iteration 162/164: Loss = 1.5139\n",
      "Epoch 20/50, Train iteration 163/164: Loss = 1.5517\n",
      "Epoch 20/50, Train iteration 164/164: Loss = 1.3463\n",
      "Epoch 20/50, Val iteration 1/27: Loss = 1.6118\n",
      "Epoch 20/50, Val iteration 2/27: Loss = 1.6208\n",
      "Epoch 20/50, Val iteration 3/27: Loss = 1.5923\n",
      "Epoch 20/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 20/50, Val iteration 5/27: Loss = 1.6137\n",
      "Epoch 20/50, Val iteration 6/27: Loss = 1.5806\n",
      "Epoch 20/50, Val iteration 7/27: Loss = 1.5564\n",
      "Epoch 20/50, Val iteration 8/27: Loss = 1.6110\n",
      "Epoch 20/50, Val iteration 9/27: Loss = 1.5855\n",
      "Epoch 20/50, Val iteration 10/27: Loss = 1.5783\n",
      "Epoch 20/50, Val iteration 11/27: Loss = 1.5990\n",
      "Epoch 20/50, Val iteration 12/27: Loss = 1.5663\n",
      "Epoch 20/50, Val iteration 13/27: Loss = 1.5730\n",
      "Epoch 20/50, Val iteration 14/27: Loss = 1.5479\n",
      "Epoch 20/50, Val iteration 15/27: Loss = 1.5901\n",
      "Epoch 20/50, Val iteration 16/27: Loss = 1.5814\n",
      "Epoch 20/50, Val iteration 17/27: Loss = 1.5931\n",
      "Epoch 20/50, Val iteration 18/27: Loss = 1.5572\n",
      "Epoch 20/50, Val iteration 19/27: Loss = 1.5770\n",
      "Epoch 20/50, Val iteration 20/27: Loss = 1.5961\n",
      "Epoch 20/50, Val iteration 21/27: Loss = 1.5869\n",
      "Epoch 20/50, Val iteration 22/27: Loss = 1.6019\n",
      "Epoch 20/50, Val iteration 23/27: Loss = 1.4890\n",
      "Epoch 20/50, Val iteration 24/27: Loss = 1.5591\n",
      "Epoch 20/50, Val iteration 25/27: Loss = 1.5841\n",
      "Epoch 20/50, Val iteration 26/27: Loss = 1.5953\n",
      "Epoch 20/50, Val iteration 27/27: Loss = 1.6013\n",
      "Epoch 20/50: Train Loss = 1.5405, Val Loss = 1.5831\n",
      "Current learning rate: 2.7e-06\n",
      "Epoch 21/50, Train iteration 1/164: Loss = 1.5458\n",
      "Epoch 21/50, Train iteration 2/164: Loss = 1.5894\n",
      "Epoch 21/50, Train iteration 3/164: Loss = 1.5826\n",
      "Epoch 21/50, Train iteration 4/164: Loss = 1.5469\n",
      "Epoch 21/50, Train iteration 5/164: Loss = 1.5842\n",
      "Epoch 21/50, Train iteration 6/164: Loss = 1.6038\n",
      "Epoch 21/50, Train iteration 7/164: Loss = 1.5982\n",
      "Epoch 21/50, Train iteration 8/164: Loss = 1.4756\n",
      "Epoch 21/50, Train iteration 9/164: Loss = 1.6083\n",
      "Epoch 21/50, Train iteration 10/164: Loss = 1.5841\n",
      "Epoch 21/50, Train iteration 11/164: Loss = 1.5658\n",
      "Epoch 21/50, Train iteration 12/164: Loss = 1.4775\n",
      "Epoch 21/50, Train iteration 13/164: Loss = 1.5173\n",
      "Epoch 21/50, Train iteration 14/164: Loss = 1.5536\n",
      "Epoch 21/50, Train iteration 15/164: Loss = 1.5106\n",
      "Epoch 21/50, Train iteration 16/164: Loss = 1.5443\n",
      "Epoch 21/50, Train iteration 17/164: Loss = 1.5697\n",
      "Epoch 21/50, Train iteration 18/164: Loss = 1.5130\n",
      "Epoch 21/50, Train iteration 19/164: Loss = 1.5275\n",
      "Epoch 21/50, Train iteration 20/164: Loss = 1.5403\n",
      "Epoch 21/50, Train iteration 21/164: Loss = 1.5963\n",
      "Epoch 21/50, Train iteration 22/164: Loss = 1.5776\n",
      "Epoch 21/50, Train iteration 23/164: Loss = 1.5363\n",
      "Epoch 21/50, Train iteration 24/164: Loss = 1.5885\n",
      "Epoch 21/50, Train iteration 25/164: Loss = 1.5805\n",
      "Epoch 21/50, Train iteration 26/164: Loss = 1.5442\n",
      "Epoch 21/50, Train iteration 27/164: Loss = 1.5006\n",
      "Epoch 21/50, Train iteration 28/164: Loss = 1.5208\n",
      "Epoch 21/50, Train iteration 29/164: Loss = 1.4971\n",
      "Epoch 21/50, Train iteration 30/164: Loss = 1.5688\n",
      "Epoch 21/50, Train iteration 31/164: Loss = 1.4796\n",
      "Epoch 21/50, Train iteration 32/164: Loss = 1.5039\n",
      "Epoch 21/50, Train iteration 33/164: Loss = 1.5707\n",
      "Epoch 21/50, Train iteration 34/164: Loss = 1.4950\n",
      "Epoch 21/50, Train iteration 35/164: Loss = 1.5339\n",
      "Epoch 21/50, Train iteration 36/164: Loss = 1.5271\n",
      "Epoch 21/50, Train iteration 37/164: Loss = 1.5803\n",
      "Epoch 21/50, Train iteration 38/164: Loss = 1.5328\n",
      "Epoch 21/50, Train iteration 39/164: Loss = 1.5329\n",
      "Epoch 21/50, Train iteration 40/164: Loss = 1.5005\n",
      "Epoch 21/50, Train iteration 41/164: Loss = 1.4600\n",
      "Epoch 21/50, Train iteration 42/164: Loss = 1.5366\n",
      "Epoch 21/50, Train iteration 43/164: Loss = 1.5283\n",
      "Epoch 21/50, Train iteration 44/164: Loss = 1.4789\n",
      "Epoch 21/50, Train iteration 45/164: Loss = 1.5489\n",
      "Epoch 21/50, Train iteration 46/164: Loss = 1.5394\n",
      "Epoch 21/50, Train iteration 47/164: Loss = 1.5495\n",
      "Epoch 21/50, Train iteration 48/164: Loss = 1.5359\n",
      "Epoch 21/50, Train iteration 49/164: Loss = 1.5382\n",
      "Epoch 21/50, Train iteration 50/164: Loss = 1.5608\n",
      "Epoch 21/50, Train iteration 51/164: Loss = 1.5153\n",
      "Epoch 21/50, Train iteration 52/164: Loss = 1.5076\n",
      "Epoch 21/50, Train iteration 53/164: Loss = 1.5608\n",
      "Epoch 21/50, Train iteration 54/164: Loss = 1.5782\n",
      "Epoch 21/50, Train iteration 55/164: Loss = 1.5061\n",
      "Epoch 21/50, Train iteration 56/164: Loss = 1.5566\n",
      "Epoch 21/50, Train iteration 57/164: Loss = 1.5295\n",
      "Epoch 21/50, Train iteration 58/164: Loss = 1.5558\n",
      "Epoch 21/50, Train iteration 59/164: Loss = 1.5745\n",
      "Epoch 21/50, Train iteration 60/164: Loss = 1.5230\n",
      "Epoch 21/50, Train iteration 61/164: Loss = 1.5033\n",
      "Epoch 21/50, Train iteration 62/164: Loss = 1.5179\n",
      "Epoch 21/50, Train iteration 63/164: Loss = 1.5746\n",
      "Epoch 21/50, Train iteration 64/164: Loss = 1.5108\n",
      "Epoch 21/50, Train iteration 65/164: Loss = 1.5202\n",
      "Epoch 21/50, Train iteration 66/164: Loss = 1.4300\n",
      "Epoch 21/50, Train iteration 67/164: Loss = 1.4929\n",
      "Epoch 21/50, Train iteration 68/164: Loss = 1.5544\n",
      "Epoch 21/50, Train iteration 69/164: Loss = 1.6174\n",
      "Epoch 21/50, Train iteration 70/164: Loss = 1.5462\n",
      "Epoch 21/50, Train iteration 71/164: Loss = 1.5286\n",
      "Epoch 21/50, Train iteration 72/164: Loss = 1.5546\n",
      "Epoch 21/50, Train iteration 73/164: Loss = 1.5700\n",
      "Epoch 21/50, Train iteration 74/164: Loss = 1.5456\n",
      "Epoch 21/50, Train iteration 75/164: Loss = 1.4653\n",
      "Epoch 21/50, Train iteration 76/164: Loss = 1.5113\n",
      "Epoch 21/50, Train iteration 77/164: Loss = 1.5798\n",
      "Epoch 21/50, Train iteration 78/164: Loss = 1.5244\n",
      "Epoch 21/50, Train iteration 79/164: Loss = 1.6176\n",
      "Epoch 21/50, Train iteration 80/164: Loss = 1.5535\n",
      "Epoch 21/50, Train iteration 81/164: Loss = 1.4965\n",
      "Epoch 21/50, Train iteration 82/164: Loss = 1.5386\n",
      "Epoch 21/50, Train iteration 83/164: Loss = 1.5915\n",
      "Epoch 21/50, Train iteration 84/164: Loss = 1.5018\n",
      "Epoch 21/50, Train iteration 85/164: Loss = 1.5621\n",
      "Epoch 21/50, Train iteration 86/164: Loss = 1.3699\n",
      "Epoch 21/50, Train iteration 87/164: Loss = 1.5573\n",
      "Epoch 21/50, Train iteration 88/164: Loss = 1.5858\n",
      "Epoch 21/50, Train iteration 89/164: Loss = 1.5665\n",
      "Epoch 21/50, Train iteration 90/164: Loss = 1.5352\n",
      "Epoch 21/50, Train iteration 91/164: Loss = 1.5968\n",
      "Epoch 21/50, Train iteration 92/164: Loss = 1.5064\n",
      "Epoch 21/50, Train iteration 93/164: Loss = 1.5209\n",
      "Epoch 21/50, Train iteration 94/164: Loss = 1.5656\n",
      "Epoch 21/50, Train iteration 95/164: Loss = 1.4979\n",
      "Epoch 21/50, Train iteration 96/164: Loss = 1.5575\n",
      "Epoch 21/50, Train iteration 97/164: Loss = 1.5534\n",
      "Epoch 21/50, Train iteration 98/164: Loss = 1.5414\n",
      "Epoch 21/50, Train iteration 99/164: Loss = 1.5417\n",
      "Epoch 21/50, Train iteration 100/164: Loss = 1.4944\n",
      "Epoch 21/50, Train iteration 101/164: Loss = 1.5280\n",
      "Epoch 21/50, Train iteration 102/164: Loss = 1.5204\n",
      "Epoch 21/50, Train iteration 103/164: Loss = 1.5579\n",
      "Epoch 21/50, Train iteration 104/164: Loss = 1.5830\n",
      "Epoch 21/50, Train iteration 105/164: Loss = 1.5571\n",
      "Epoch 21/50, Train iteration 106/164: Loss = 1.5800\n",
      "Epoch 21/50, Train iteration 107/164: Loss = 1.5172\n",
      "Epoch 21/50, Train iteration 108/164: Loss = 1.5507\n",
      "Epoch 21/50, Train iteration 109/164: Loss = 1.5397\n",
      "Epoch 21/50, Train iteration 110/164: Loss = 1.5485\n",
      "Epoch 21/50, Train iteration 111/164: Loss = 1.5421\n",
      "Epoch 21/50, Train iteration 112/164: Loss = 1.6063\n",
      "Epoch 21/50, Train iteration 113/164: Loss = 1.4835\n",
      "Epoch 21/50, Train iteration 114/164: Loss = 1.4452\n",
      "Epoch 21/50, Train iteration 115/164: Loss = 1.5094\n",
      "Epoch 21/50, Train iteration 116/164: Loss = 1.4835\n",
      "Epoch 21/50, Train iteration 117/164: Loss = 1.5293\n",
      "Epoch 21/50, Train iteration 118/164: Loss = 1.5559\n",
      "Epoch 21/50, Train iteration 119/164: Loss = 1.5216\n",
      "Epoch 21/50, Train iteration 120/164: Loss = 1.5577\n",
      "Epoch 21/50, Train iteration 121/164: Loss = 1.5746\n",
      "Epoch 21/50, Train iteration 122/164: Loss = 1.4639\n",
      "Epoch 21/50, Train iteration 123/164: Loss = 1.5108\n",
      "Epoch 21/50, Train iteration 124/164: Loss = 1.5790\n",
      "Epoch 21/50, Train iteration 125/164: Loss = 1.5224\n",
      "Epoch 21/50, Train iteration 126/164: Loss = 1.4970\n",
      "Epoch 21/50, Train iteration 127/164: Loss = 1.5392\n",
      "Epoch 21/50, Train iteration 128/164: Loss = 1.4985\n",
      "Epoch 21/50, Train iteration 129/164: Loss = 1.5364\n",
      "Epoch 21/50, Train iteration 130/164: Loss = 1.5962\n",
      "Epoch 21/50, Train iteration 131/164: Loss = 1.5445\n",
      "Epoch 21/50, Train iteration 132/164: Loss = 1.4622\n",
      "Epoch 21/50, Train iteration 133/164: Loss = 1.5824\n",
      "Epoch 21/50, Train iteration 134/164: Loss = 1.4993\n",
      "Epoch 21/50, Train iteration 135/164: Loss = 1.5514\n",
      "Epoch 21/50, Train iteration 136/164: Loss = 1.5661\n",
      "Epoch 21/50, Train iteration 137/164: Loss = 1.5182\n",
      "Epoch 21/50, Train iteration 138/164: Loss = 1.5674\n",
      "Epoch 21/50, Train iteration 139/164: Loss = 1.5952\n",
      "Epoch 21/50, Train iteration 140/164: Loss = 1.5580\n",
      "Epoch 21/50, Train iteration 141/164: Loss = 1.5325\n",
      "Epoch 21/50, Train iteration 142/164: Loss = 1.5672\n",
      "Epoch 21/50, Train iteration 143/164: Loss = 1.5042\n",
      "Epoch 21/50, Train iteration 144/164: Loss = 1.5767\n",
      "Epoch 21/50, Train iteration 145/164: Loss = 1.5275\n",
      "Epoch 21/50, Train iteration 146/164: Loss = 1.5139\n",
      "Epoch 21/50, Train iteration 147/164: Loss = 1.5390\n",
      "Epoch 21/50, Train iteration 148/164: Loss = 1.5289\n",
      "Epoch 21/50, Train iteration 149/164: Loss = 1.5447\n",
      "Epoch 21/50, Train iteration 150/164: Loss = 1.5733\n",
      "Epoch 21/50, Train iteration 151/164: Loss = 1.5847\n",
      "Epoch 21/50, Train iteration 152/164: Loss = 1.5218\n",
      "Epoch 21/50, Train iteration 153/164: Loss = 1.5401\n",
      "Epoch 21/50, Train iteration 154/164: Loss = 1.5147\n",
      "Epoch 21/50, Train iteration 155/164: Loss = 1.5466\n",
      "Epoch 21/50, Train iteration 156/164: Loss = 1.5226\n",
      "Epoch 21/50, Train iteration 157/164: Loss = 1.5752\n",
      "Epoch 21/50, Train iteration 158/164: Loss = 1.5632\n",
      "Epoch 21/50, Train iteration 159/164: Loss = 1.5493\n",
      "Epoch 21/50, Train iteration 160/164: Loss = 1.5375\n",
      "Epoch 21/50, Train iteration 161/164: Loss = 1.6003\n",
      "Epoch 21/50, Train iteration 162/164: Loss = 1.5735\n",
      "Epoch 21/50, Train iteration 163/164: Loss = 1.5265\n",
      "Epoch 21/50, Train iteration 164/164: Loss = 0.9613\n",
      "Epoch 21/50, Val iteration 1/27: Loss = 1.6125\n",
      "Epoch 21/50, Val iteration 2/27: Loss = 1.6207\n",
      "Epoch 21/50, Val iteration 3/27: Loss = 1.5916\n",
      "Epoch 21/50, Val iteration 4/27: Loss = 1.5954\n",
      "Epoch 21/50, Val iteration 5/27: Loss = 1.6144\n",
      "Epoch 21/50, Val iteration 6/27: Loss = 1.5809\n",
      "Epoch 21/50, Val iteration 7/27: Loss = 1.5556\n",
      "Epoch 21/50, Val iteration 8/27: Loss = 1.6125\n",
      "Epoch 21/50, Val iteration 9/27: Loss = 1.5861\n",
      "Epoch 21/50, Val iteration 10/27: Loss = 1.5784\n",
      "Epoch 21/50, Val iteration 11/27: Loss = 1.5990\n",
      "Epoch 21/50, Val iteration 12/27: Loss = 1.5658\n",
      "Epoch 21/50, Val iteration 13/27: Loss = 1.5721\n",
      "Epoch 21/50, Val iteration 14/27: Loss = 1.5460\n",
      "Epoch 21/50, Val iteration 15/27: Loss = 1.5902\n",
      "Epoch 21/50, Val iteration 16/27: Loss = 1.5808\n",
      "Epoch 21/50, Val iteration 17/27: Loss = 1.5939\n",
      "Epoch 21/50, Val iteration 18/27: Loss = 1.5573\n",
      "Epoch 21/50, Val iteration 19/27: Loss = 1.5776\n",
      "Epoch 21/50, Val iteration 20/27: Loss = 1.5969\n",
      "Epoch 21/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 21/50, Val iteration 22/27: Loss = 1.6032\n",
      "Epoch 21/50, Val iteration 23/27: Loss = 1.4872\n",
      "Epoch 21/50, Val iteration 24/27: Loss = 1.5585\n",
      "Epoch 21/50, Val iteration 25/27: Loss = 1.5850\n",
      "Epoch 21/50, Val iteration 26/27: Loss = 1.5946\n",
      "Epoch 21/50, Val iteration 27/27: Loss = 1.6036\n",
      "Epoch 21/50: Train Loss = 1.5359, Val Loss = 1.5832\n",
      "Current learning rate: 2.7e-06\n",
      "Epoch 22/50, Train iteration 1/164: Loss = 1.5709\n",
      "Epoch 22/50, Train iteration 2/164: Loss = 1.5450\n",
      "Epoch 22/50, Train iteration 3/164: Loss = 1.5780\n",
      "Epoch 22/50, Train iteration 4/164: Loss = 1.5212\n",
      "Epoch 22/50, Train iteration 5/164: Loss = 1.5531\n",
      "Epoch 22/50, Train iteration 6/164: Loss = 1.6187\n",
      "Epoch 22/50, Train iteration 7/164: Loss = 1.6173\n",
      "Epoch 22/50, Train iteration 8/164: Loss = 1.4790\n",
      "Epoch 22/50, Train iteration 9/164: Loss = 1.5743\n",
      "Epoch 22/50, Train iteration 10/164: Loss = 1.5730\n",
      "Epoch 22/50, Train iteration 11/164: Loss = 1.5854\n",
      "Epoch 22/50, Train iteration 12/164: Loss = 1.5541\n",
      "Epoch 22/50, Train iteration 13/164: Loss = 1.4407\n",
      "Epoch 22/50, Train iteration 14/164: Loss = 1.5903\n",
      "Epoch 22/50, Train iteration 15/164: Loss = 1.5692\n",
      "Epoch 22/50, Train iteration 16/164: Loss = 1.5820\n",
      "Epoch 22/50, Train iteration 17/164: Loss = 1.5190\n",
      "Epoch 22/50, Train iteration 18/164: Loss = 1.4983\n",
      "Epoch 22/50, Train iteration 19/164: Loss = 1.5841\n",
      "Epoch 22/50, Train iteration 20/164: Loss = 1.5632\n",
      "Epoch 22/50, Train iteration 21/164: Loss = 1.5457\n",
      "Epoch 22/50, Train iteration 22/164: Loss = 1.5858\n",
      "Epoch 22/50, Train iteration 23/164: Loss = 1.5665\n",
      "Epoch 22/50, Train iteration 24/164: Loss = 1.5520\n",
      "Epoch 22/50, Train iteration 25/164: Loss = 1.6018\n",
      "Epoch 22/50, Train iteration 26/164: Loss = 1.5913\n",
      "Epoch 22/50, Train iteration 27/164: Loss = 1.5806\n",
      "Epoch 22/50, Train iteration 28/164: Loss = 1.5569\n",
      "Epoch 22/50, Train iteration 29/164: Loss = 1.5037\n",
      "Epoch 22/50, Train iteration 30/164: Loss = 1.6276\n",
      "Epoch 22/50, Train iteration 31/164: Loss = 1.5095\n",
      "Epoch 22/50, Train iteration 32/164: Loss = 1.5244\n",
      "Epoch 22/50, Train iteration 33/164: Loss = 1.5862\n",
      "Epoch 22/50, Train iteration 34/164: Loss = 1.4940\n",
      "Epoch 22/50, Train iteration 35/164: Loss = 1.5792\n",
      "Epoch 22/50, Train iteration 36/164: Loss = 1.5281\n",
      "Epoch 22/50, Train iteration 37/164: Loss = 1.5888\n",
      "Epoch 22/50, Train iteration 38/164: Loss = 1.5049\n",
      "Epoch 22/50, Train iteration 39/164: Loss = 1.5789\n",
      "Epoch 22/50, Train iteration 40/164: Loss = 1.4958\n",
      "Epoch 22/50, Train iteration 41/164: Loss = 1.4794\n",
      "Epoch 22/50, Train iteration 42/164: Loss = 1.5033\n",
      "Epoch 22/50, Train iteration 43/164: Loss = 1.5154\n",
      "Epoch 22/50, Train iteration 44/164: Loss = 1.5523\n",
      "Epoch 22/50, Train iteration 45/164: Loss = 1.5602\n",
      "Epoch 22/50, Train iteration 46/164: Loss = 1.5657\n",
      "Epoch 22/50, Train iteration 47/164: Loss = 1.5588\n",
      "Epoch 22/50, Train iteration 48/164: Loss = 1.5027\n",
      "Epoch 22/50, Train iteration 49/164: Loss = 1.4831\n",
      "Epoch 22/50, Train iteration 50/164: Loss = 1.5522\n",
      "Epoch 22/50, Train iteration 51/164: Loss = 1.4912\n",
      "Epoch 22/50, Train iteration 52/164: Loss = 1.4975\n",
      "Epoch 22/50, Train iteration 53/164: Loss = 1.5709\n",
      "Epoch 22/50, Train iteration 54/164: Loss = 1.5465\n",
      "Epoch 22/50, Train iteration 55/164: Loss = 1.5259\n",
      "Epoch 22/50, Train iteration 56/164: Loss = 1.5571\n",
      "Epoch 22/50, Train iteration 57/164: Loss = 1.6053\n",
      "Epoch 22/50, Train iteration 58/164: Loss = 1.5546\n",
      "Epoch 22/50, Train iteration 59/164: Loss = 1.5458\n",
      "Epoch 22/50, Train iteration 60/164: Loss = 1.5321\n",
      "Epoch 22/50, Train iteration 61/164: Loss = 1.5055\n",
      "Epoch 22/50, Train iteration 62/164: Loss = 1.5539\n",
      "Epoch 22/50, Train iteration 63/164: Loss = 1.5885\n",
      "Epoch 22/50, Train iteration 64/164: Loss = 1.5104\n",
      "Epoch 22/50, Train iteration 65/164: Loss = 1.5247\n",
      "Epoch 22/50, Train iteration 66/164: Loss = 1.4630\n",
      "Epoch 22/50, Train iteration 67/164: Loss = 1.5282\n",
      "Epoch 22/50, Train iteration 68/164: Loss = 1.5534\n",
      "Epoch 22/50, Train iteration 69/164: Loss = 1.5579\n",
      "Epoch 22/50, Train iteration 70/164: Loss = 1.5123\n",
      "Epoch 22/50, Train iteration 71/164: Loss = 1.5819\n",
      "Epoch 22/50, Train iteration 72/164: Loss = 1.5656\n",
      "Epoch 22/50, Train iteration 73/164: Loss = 1.5887\n",
      "Epoch 22/50, Train iteration 74/164: Loss = 1.4998\n",
      "Epoch 22/50, Train iteration 75/164: Loss = 1.5013\n",
      "Epoch 22/50, Train iteration 76/164: Loss = 1.5577\n",
      "Epoch 22/50, Train iteration 77/164: Loss = 1.6044\n",
      "Epoch 22/50, Train iteration 78/164: Loss = 1.5527\n",
      "Epoch 22/50, Train iteration 79/164: Loss = 1.5326\n",
      "Epoch 22/50, Train iteration 80/164: Loss = 1.5327\n",
      "Epoch 22/50, Train iteration 81/164: Loss = 1.5121\n",
      "Epoch 22/50, Train iteration 82/164: Loss = 1.5800\n",
      "Epoch 22/50, Train iteration 83/164: Loss = 1.6056\n",
      "Epoch 22/50, Train iteration 84/164: Loss = 1.5407\n",
      "Epoch 22/50, Train iteration 85/164: Loss = 1.6088\n",
      "Epoch 22/50, Train iteration 86/164: Loss = 1.4426\n",
      "Epoch 22/50, Train iteration 87/164: Loss = 1.5414\n",
      "Epoch 22/50, Train iteration 88/164: Loss = 1.5494\n",
      "Epoch 22/50, Train iteration 89/164: Loss = 1.5547\n",
      "Epoch 22/50, Train iteration 90/164: Loss = 1.5150\n",
      "Epoch 22/50, Train iteration 91/164: Loss = 1.5444\n",
      "Epoch 22/50, Train iteration 92/164: Loss = 1.5390\n",
      "Epoch 22/50, Train iteration 93/164: Loss = 1.5325\n",
      "Epoch 22/50, Train iteration 94/164: Loss = 1.5815\n",
      "Epoch 22/50, Train iteration 95/164: Loss = 1.4926\n",
      "Epoch 22/50, Train iteration 96/164: Loss = 1.5482\n",
      "Epoch 22/50, Train iteration 97/164: Loss = 1.5300\n",
      "Epoch 22/50, Train iteration 98/164: Loss = 1.5850\n",
      "Epoch 22/50, Train iteration 99/164: Loss = 1.5442\n",
      "Epoch 22/50, Train iteration 100/164: Loss = 1.4850\n",
      "Epoch 22/50, Train iteration 101/164: Loss = 1.4719\n",
      "Epoch 22/50, Train iteration 102/164: Loss = 1.5184\n",
      "Epoch 22/50, Train iteration 103/164: Loss = 1.5807\n",
      "Epoch 22/50, Train iteration 104/164: Loss = 1.5078\n",
      "Epoch 22/50, Train iteration 105/164: Loss = 1.5551\n",
      "Epoch 22/50, Train iteration 106/164: Loss = 1.5768\n",
      "Epoch 22/50, Train iteration 107/164: Loss = 1.5559\n",
      "Epoch 22/50, Train iteration 108/164: Loss = 1.5208\n",
      "Epoch 22/50, Train iteration 109/164: Loss = 1.5591\n",
      "Epoch 22/50, Train iteration 110/164: Loss = 1.5162\n",
      "Epoch 22/50, Train iteration 111/164: Loss = 1.5277\n",
      "Epoch 22/50, Train iteration 112/164: Loss = 1.5821\n",
      "Epoch 22/50, Train iteration 113/164: Loss = 1.5354\n",
      "Epoch 22/50, Train iteration 114/164: Loss = 1.4956\n",
      "Epoch 22/50, Train iteration 115/164: Loss = 1.5827\n",
      "Epoch 22/50, Train iteration 116/164: Loss = 1.4842\n",
      "Epoch 22/50, Train iteration 117/164: Loss = 1.5332\n",
      "Epoch 22/50, Train iteration 118/164: Loss = 1.5921\n",
      "Epoch 22/50, Train iteration 119/164: Loss = 1.5474\n",
      "Epoch 22/50, Train iteration 120/164: Loss = 1.5474\n",
      "Epoch 22/50, Train iteration 121/164: Loss = 1.5925\n",
      "Epoch 22/50, Train iteration 122/164: Loss = 1.4064\n",
      "Epoch 22/50, Train iteration 123/164: Loss = 1.4813\n",
      "Epoch 22/50, Train iteration 124/164: Loss = 1.5848\n",
      "Epoch 22/50, Train iteration 125/164: Loss = 1.4839\n",
      "Epoch 22/50, Train iteration 126/164: Loss = 1.5192\n",
      "Epoch 22/50, Train iteration 127/164: Loss = 1.5494\n",
      "Epoch 22/50, Train iteration 128/164: Loss = 1.4859\n",
      "Epoch 22/50, Train iteration 129/164: Loss = 1.4955\n",
      "Epoch 22/50, Train iteration 130/164: Loss = 1.5626\n",
      "Epoch 22/50, Train iteration 131/164: Loss = 1.5895\n",
      "Epoch 22/50, Train iteration 132/164: Loss = 1.4970\n",
      "Epoch 22/50, Train iteration 133/164: Loss = 1.5502\n",
      "Epoch 22/50, Train iteration 134/164: Loss = 1.5279\n",
      "Epoch 22/50, Train iteration 135/164: Loss = 1.5388\n",
      "Epoch 22/50, Train iteration 136/164: Loss = 1.4884\n",
      "Epoch 22/50, Train iteration 137/164: Loss = 1.5344\n",
      "Epoch 22/50, Train iteration 138/164: Loss = 1.5260\n",
      "Epoch 22/50, Train iteration 139/164: Loss = 1.5702\n",
      "Epoch 22/50, Train iteration 140/164: Loss = 1.5432\n",
      "Epoch 22/50, Train iteration 141/164: Loss = 1.5421\n",
      "Epoch 22/50, Train iteration 142/164: Loss = 1.6024\n",
      "Epoch 22/50, Train iteration 143/164: Loss = 1.5090\n",
      "Epoch 22/50, Train iteration 144/164: Loss = 1.5604\n",
      "Epoch 22/50, Train iteration 145/164: Loss = 1.4687\n",
      "Epoch 22/50, Train iteration 146/164: Loss = 1.4982\n",
      "Epoch 22/50, Train iteration 147/164: Loss = 1.5461\n",
      "Epoch 22/50, Train iteration 148/164: Loss = 1.4844\n",
      "Epoch 22/50, Train iteration 149/164: Loss = 1.5518\n",
      "Epoch 22/50, Train iteration 150/164: Loss = 1.6051\n",
      "Epoch 22/50, Train iteration 151/164: Loss = 1.5151\n",
      "Epoch 22/50, Train iteration 152/164: Loss = 1.5208\n",
      "Epoch 22/50, Train iteration 153/164: Loss = 1.5510\n",
      "Epoch 22/50, Train iteration 154/164: Loss = 1.5366\n",
      "Epoch 22/50, Train iteration 155/164: Loss = 1.5580\n",
      "Epoch 22/50, Train iteration 156/164: Loss = 1.5340\n",
      "Epoch 22/50, Train iteration 157/164: Loss = 1.4769\n",
      "Epoch 22/50, Train iteration 158/164: Loss = 1.5397\n",
      "Epoch 22/50, Train iteration 159/164: Loss = 1.5814\n",
      "Epoch 22/50, Train iteration 160/164: Loss = 1.5527\n",
      "Epoch 22/50, Train iteration 161/164: Loss = 1.5711\n",
      "Epoch 22/50, Train iteration 162/164: Loss = 1.5588\n",
      "Epoch 22/50, Train iteration 163/164: Loss = 1.5206\n",
      "Epoch 22/50, Train iteration 164/164: Loss = 1.4502\n",
      "Epoch 22/50, Val iteration 1/27: Loss = 1.6135\n",
      "Epoch 22/50, Val iteration 2/27: Loss = 1.6210\n",
      "Epoch 22/50, Val iteration 3/27: Loss = 1.5912\n",
      "Epoch 22/50, Val iteration 4/27: Loss = 1.5954\n",
      "Epoch 22/50, Val iteration 5/27: Loss = 1.6150\n",
      "Epoch 22/50, Val iteration 6/27: Loss = 1.5814\n",
      "Epoch 22/50, Val iteration 7/27: Loss = 1.5550\n",
      "Epoch 22/50, Val iteration 8/27: Loss = 1.6137\n",
      "Epoch 22/50, Val iteration 9/27: Loss = 1.5864\n",
      "Epoch 22/50, Val iteration 10/27: Loss = 1.5781\n",
      "Epoch 22/50, Val iteration 11/27: Loss = 1.5998\n",
      "Epoch 22/50, Val iteration 12/27: Loss = 1.5653\n",
      "Epoch 22/50, Val iteration 13/27: Loss = 1.5710\n",
      "Epoch 22/50, Val iteration 14/27: Loss = 1.5441\n",
      "Epoch 22/50, Val iteration 15/27: Loss = 1.5900\n",
      "Epoch 22/50, Val iteration 16/27: Loss = 1.5802\n",
      "Epoch 22/50, Val iteration 17/27: Loss = 1.5946\n",
      "Epoch 22/50, Val iteration 18/27: Loss = 1.5567\n",
      "Epoch 22/50, Val iteration 19/27: Loss = 1.5774\n",
      "Epoch 22/50, Val iteration 20/27: Loss = 1.5974\n",
      "Epoch 22/50, Val iteration 21/27: Loss = 1.5870\n",
      "Epoch 22/50, Val iteration 22/27: Loss = 1.6042\n",
      "Epoch 22/50, Val iteration 23/27: Loss = 1.4856\n",
      "Epoch 22/50, Val iteration 24/27: Loss = 1.5584\n",
      "Epoch 22/50, Val iteration 25/27: Loss = 1.5858\n",
      "Epoch 22/50, Val iteration 26/27: Loss = 1.5934\n",
      "Epoch 22/50, Val iteration 27/27: Loss = 1.6054\n",
      "Epoch 22/50: Train Loss = 1.5410, Val Loss = 1.5832\n",
      "Current learning rate: 2.7e-06\n",
      "Epoch 23/50, Train iteration 1/164: Loss = 1.5650\n",
      "Epoch 23/50, Train iteration 2/164: Loss = 1.5389\n",
      "Epoch 23/50, Train iteration 3/164: Loss = 1.5833\n",
      "Epoch 23/50, Train iteration 4/164: Loss = 1.5418\n",
      "Epoch 23/50, Train iteration 5/164: Loss = 1.5626\n",
      "Epoch 23/50, Train iteration 6/164: Loss = 1.5927\n",
      "Epoch 23/50, Train iteration 7/164: Loss = 1.6381\n",
      "Epoch 23/50, Train iteration 8/164: Loss = 1.4571\n",
      "Epoch 23/50, Train iteration 9/164: Loss = 1.5580\n",
      "Epoch 23/50, Train iteration 10/164: Loss = 1.5971\n",
      "Epoch 23/50, Train iteration 11/164: Loss = 1.5712\n",
      "Epoch 23/50, Train iteration 12/164: Loss = 1.5010\n",
      "Epoch 23/50, Train iteration 13/164: Loss = 1.5005\n",
      "Epoch 23/50, Train iteration 14/164: Loss = 1.6086\n",
      "Epoch 23/50, Train iteration 15/164: Loss = 1.5565\n",
      "Epoch 23/50, Train iteration 16/164: Loss = 1.5489\n",
      "Epoch 23/50, Train iteration 17/164: Loss = 1.5559\n",
      "Epoch 23/50, Train iteration 18/164: Loss = 1.5169\n",
      "Epoch 23/50, Train iteration 19/164: Loss = 1.5062\n",
      "Epoch 23/50, Train iteration 20/164: Loss = 1.5380\n",
      "Epoch 23/50, Train iteration 21/164: Loss = 1.5437\n",
      "Epoch 23/50, Train iteration 22/164: Loss = 1.5596\n",
      "Epoch 23/50, Train iteration 23/164: Loss = 1.4989\n",
      "Epoch 23/50, Train iteration 24/164: Loss = 1.5471\n",
      "Epoch 23/50, Train iteration 25/164: Loss = 1.5791\n",
      "Epoch 23/50, Train iteration 26/164: Loss = 1.5706\n",
      "Epoch 23/50, Train iteration 27/164: Loss = 1.5506\n",
      "Epoch 23/50, Train iteration 28/164: Loss = 1.5734\n",
      "Epoch 23/50, Train iteration 29/164: Loss = 1.5040\n",
      "Epoch 23/50, Train iteration 30/164: Loss = 1.5886\n",
      "Epoch 23/50, Train iteration 31/164: Loss = 1.4705\n",
      "Epoch 23/50, Train iteration 32/164: Loss = 1.5459\n",
      "Epoch 23/50, Train iteration 33/164: Loss = 1.5911\n",
      "Epoch 23/50, Train iteration 34/164: Loss = 1.4770\n",
      "Epoch 23/50, Train iteration 35/164: Loss = 1.5387\n",
      "Epoch 23/50, Train iteration 36/164: Loss = 1.5037\n",
      "Epoch 23/50, Train iteration 37/164: Loss = 1.5397\n",
      "Epoch 23/50, Train iteration 38/164: Loss = 1.5116\n",
      "Epoch 23/50, Train iteration 39/164: Loss = 1.5737\n",
      "Epoch 23/50, Train iteration 40/164: Loss = 1.4934\n",
      "Epoch 23/50, Train iteration 41/164: Loss = 1.4370\n",
      "Epoch 23/50, Train iteration 42/164: Loss = 1.5318\n",
      "Epoch 23/50, Train iteration 43/164: Loss = 1.5180\n",
      "Epoch 23/50, Train iteration 44/164: Loss = 1.5426\n",
      "Epoch 23/50, Train iteration 45/164: Loss = 1.5169\n",
      "Epoch 23/50, Train iteration 46/164: Loss = 1.6001\n",
      "Epoch 23/50, Train iteration 47/164: Loss = 1.5443\n",
      "Epoch 23/50, Train iteration 48/164: Loss = 1.5127\n",
      "Epoch 23/50, Train iteration 49/164: Loss = 1.4843\n",
      "Epoch 23/50, Train iteration 50/164: Loss = 1.6069\n",
      "Epoch 23/50, Train iteration 51/164: Loss = 1.4536\n",
      "Epoch 23/50, Train iteration 52/164: Loss = 1.5185\n",
      "Epoch 23/50, Train iteration 53/164: Loss = 1.5351\n",
      "Epoch 23/50, Train iteration 54/164: Loss = 1.5269\n",
      "Epoch 23/50, Train iteration 55/164: Loss = 1.5737\n",
      "Epoch 23/50, Train iteration 56/164: Loss = 1.5821\n",
      "Epoch 23/50, Train iteration 57/164: Loss = 1.5084\n",
      "Epoch 23/50, Train iteration 58/164: Loss = 1.5621\n",
      "Epoch 23/50, Train iteration 59/164: Loss = 1.5457\n",
      "Epoch 23/50, Train iteration 60/164: Loss = 1.5203\n",
      "Epoch 23/50, Train iteration 61/164: Loss = 1.4918\n",
      "Epoch 23/50, Train iteration 62/164: Loss = 1.5546\n",
      "Epoch 23/50, Train iteration 63/164: Loss = 1.6010\n",
      "Epoch 23/50, Train iteration 64/164: Loss = 1.4971\n",
      "Epoch 23/50, Train iteration 65/164: Loss = 1.5176\n",
      "Epoch 23/50, Train iteration 66/164: Loss = 1.4928\n",
      "Epoch 23/50, Train iteration 67/164: Loss = 1.5231\n",
      "Epoch 23/50, Train iteration 68/164: Loss = 1.4950\n",
      "Epoch 23/50, Train iteration 69/164: Loss = 1.5119\n",
      "Epoch 23/50, Train iteration 70/164: Loss = 1.5767\n",
      "Epoch 23/50, Train iteration 71/164: Loss = 1.5838\n",
      "Epoch 23/50, Train iteration 72/164: Loss = 1.5817\n",
      "Epoch 23/50, Train iteration 73/164: Loss = 1.5640\n",
      "Epoch 23/50, Train iteration 74/164: Loss = 1.4842\n",
      "Epoch 23/50, Train iteration 75/164: Loss = 1.4741\n",
      "Epoch 23/50, Train iteration 76/164: Loss = 1.5507\n",
      "Epoch 23/50, Train iteration 77/164: Loss = 1.5413\n",
      "Epoch 23/50, Train iteration 78/164: Loss = 1.5444\n",
      "Epoch 23/50, Train iteration 79/164: Loss = 1.5853\n",
      "Epoch 23/50, Train iteration 80/164: Loss = 1.5962\n",
      "Epoch 23/50, Train iteration 81/164: Loss = 1.5164\n",
      "Epoch 23/50, Train iteration 82/164: Loss = 1.5233\n",
      "Epoch 23/50, Train iteration 83/164: Loss = 1.5455\n",
      "Epoch 23/50, Train iteration 84/164: Loss = 1.5165\n",
      "Epoch 23/50, Train iteration 85/164: Loss = 1.5767\n",
      "Epoch 23/50, Train iteration 86/164: Loss = 1.4482\n",
      "Epoch 23/50, Train iteration 87/164: Loss = 1.5174\n",
      "Epoch 23/50, Train iteration 88/164: Loss = 1.6153\n",
      "Epoch 23/50, Train iteration 89/164: Loss = 1.5481\n",
      "Epoch 23/50, Train iteration 90/164: Loss = 1.4478\n",
      "Epoch 23/50, Train iteration 91/164: Loss = 1.5210\n",
      "Epoch 23/50, Train iteration 92/164: Loss = 1.5473\n",
      "Epoch 23/50, Train iteration 93/164: Loss = 1.5601\n",
      "Epoch 23/50, Train iteration 94/164: Loss = 1.6090\n",
      "Epoch 23/50, Train iteration 95/164: Loss = 1.5499\n",
      "Epoch 23/50, Train iteration 96/164: Loss = 1.5913\n",
      "Epoch 23/50, Train iteration 97/164: Loss = 1.5642\n",
      "Epoch 23/50, Train iteration 98/164: Loss = 1.5376\n",
      "Epoch 23/50, Train iteration 99/164: Loss = 1.4558\n",
      "Epoch 23/50, Train iteration 100/164: Loss = 1.5369\n",
      "Epoch 23/50, Train iteration 101/164: Loss = 1.5168\n",
      "Epoch 23/50, Train iteration 102/164: Loss = 1.5320\n",
      "Epoch 23/50, Train iteration 103/164: Loss = 1.6097\n",
      "Epoch 23/50, Train iteration 104/164: Loss = 1.5992\n",
      "Epoch 23/50, Train iteration 105/164: Loss = 1.5404\n",
      "Epoch 23/50, Train iteration 106/164: Loss = 1.5602\n",
      "Epoch 23/50, Train iteration 107/164: Loss = 1.5588\n",
      "Epoch 23/50, Train iteration 108/164: Loss = 1.5291\n",
      "Epoch 23/50, Train iteration 109/164: Loss = 1.5675\n",
      "Epoch 23/50, Train iteration 110/164: Loss = 1.5222\n",
      "Epoch 23/50, Train iteration 111/164: Loss = 1.5615\n",
      "Epoch 23/50, Train iteration 112/164: Loss = 1.5302\n",
      "Epoch 23/50, Train iteration 113/164: Loss = 1.4806\n",
      "Epoch 23/50, Train iteration 114/164: Loss = 1.4591\n",
      "Epoch 23/50, Train iteration 115/164: Loss = 1.5616\n",
      "Epoch 23/50, Train iteration 116/164: Loss = 1.5272\n",
      "Epoch 23/50, Train iteration 117/164: Loss = 1.4984\n",
      "Epoch 23/50, Train iteration 118/164: Loss = 1.5513\n",
      "Epoch 23/50, Train iteration 119/164: Loss = 1.4844\n",
      "Epoch 23/50, Train iteration 120/164: Loss = 1.5234\n",
      "Epoch 23/50, Train iteration 121/164: Loss = 1.5547\n",
      "Epoch 23/50, Train iteration 122/164: Loss = 1.4361\n",
      "Epoch 23/50, Train iteration 123/164: Loss = 1.5018\n",
      "Epoch 23/50, Train iteration 124/164: Loss = 1.4853\n",
      "Epoch 23/50, Train iteration 125/164: Loss = 1.4910\n",
      "Epoch 23/50, Train iteration 126/164: Loss = 1.4934\n",
      "Epoch 23/50, Train iteration 127/164: Loss = 1.5386\n",
      "Epoch 23/50, Train iteration 128/164: Loss = 1.5304\n",
      "Epoch 23/50, Train iteration 129/164: Loss = 1.5818\n",
      "Epoch 23/50, Train iteration 130/164: Loss = 1.5398\n",
      "Epoch 23/50, Train iteration 131/164: Loss = 1.5179\n",
      "Epoch 23/50, Train iteration 132/164: Loss = 1.4838\n",
      "Epoch 23/50, Train iteration 133/164: Loss = 1.5929\n",
      "Epoch 23/50, Train iteration 134/164: Loss = 1.4873\n",
      "Epoch 23/50, Train iteration 135/164: Loss = 1.5164\n",
      "Epoch 23/50, Train iteration 136/164: Loss = 1.5455\n",
      "Epoch 23/50, Train iteration 137/164: Loss = 1.5059\n",
      "Epoch 23/50, Train iteration 138/164: Loss = 1.5379\n",
      "Epoch 23/50, Train iteration 139/164: Loss = 1.5618\n",
      "Epoch 23/50, Train iteration 140/164: Loss = 1.5561\n",
      "Epoch 23/50, Train iteration 141/164: Loss = 1.5318\n",
      "Epoch 23/50, Train iteration 142/164: Loss = 1.5746\n",
      "Epoch 23/50, Train iteration 143/164: Loss = 1.5190\n",
      "Epoch 23/50, Train iteration 144/164: Loss = 1.6308\n",
      "Epoch 23/50, Train iteration 145/164: Loss = 1.4719\n",
      "Epoch 23/50, Train iteration 146/164: Loss = 1.5082\n",
      "Epoch 23/50, Train iteration 147/164: Loss = 1.5407\n",
      "Epoch 23/50, Train iteration 148/164: Loss = 1.5145\n",
      "Epoch 23/50, Train iteration 149/164: Loss = 1.5589\n",
      "Epoch 23/50, Train iteration 150/164: Loss = 1.5012\n",
      "Epoch 23/50, Train iteration 151/164: Loss = 1.5535\n",
      "Epoch 23/50, Train iteration 152/164: Loss = 1.5218\n",
      "Epoch 23/50, Train iteration 153/164: Loss = 1.5366\n",
      "Epoch 23/50, Train iteration 154/164: Loss = 1.5134\n",
      "Epoch 23/50, Train iteration 155/164: Loss = 1.5534\n",
      "Epoch 23/50, Train iteration 156/164: Loss = 1.5105\n",
      "Epoch 23/50, Train iteration 157/164: Loss = 1.6067\n",
      "Epoch 23/50, Train iteration 158/164: Loss = 1.5392\n",
      "Epoch 23/50, Train iteration 159/164: Loss = 1.5703\n",
      "Epoch 23/50, Train iteration 160/164: Loss = 1.5279\n",
      "Epoch 23/50, Train iteration 161/164: Loss = 1.5738\n",
      "Epoch 23/50, Train iteration 162/164: Loss = 1.5995\n",
      "Epoch 23/50, Train iteration 163/164: Loss = 1.5582\n",
      "Epoch 23/50, Train iteration 164/164: Loss = 1.4131\n",
      "Epoch 23/50, Val iteration 1/27: Loss = 1.6145\n",
      "Epoch 23/50, Val iteration 2/27: Loss = 1.6214\n",
      "Epoch 23/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 23/50, Val iteration 4/27: Loss = 1.5956\n",
      "Epoch 23/50, Val iteration 5/27: Loss = 1.6163\n",
      "Epoch 23/50, Val iteration 6/27: Loss = 1.5821\n",
      "Epoch 23/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 23/50, Val iteration 8/27: Loss = 1.6147\n",
      "Epoch 23/50, Val iteration 9/27: Loss = 1.5872\n",
      "Epoch 23/50, Val iteration 10/27: Loss = 1.5775\n",
      "Epoch 23/50, Val iteration 11/27: Loss = 1.6003\n",
      "Epoch 23/50, Val iteration 12/27: Loss = 1.5650\n",
      "Epoch 23/50, Val iteration 13/27: Loss = 1.5705\n",
      "Epoch 23/50, Val iteration 14/27: Loss = 1.5435\n",
      "Epoch 23/50, Val iteration 15/27: Loss = 1.5902\n",
      "Epoch 23/50, Val iteration 16/27: Loss = 1.5801\n",
      "Epoch 23/50, Val iteration 17/27: Loss = 1.5951\n",
      "Epoch 23/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 23/50, Val iteration 19/27: Loss = 1.5775\n",
      "Epoch 23/50, Val iteration 20/27: Loss = 1.5976\n",
      "Epoch 23/50, Val iteration 21/27: Loss = 1.5871\n",
      "Epoch 23/50, Val iteration 22/27: Loss = 1.6058\n",
      "Epoch 23/50, Val iteration 23/27: Loss = 1.4841\n",
      "Epoch 23/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 23/50, Val iteration 25/27: Loss = 1.5868\n",
      "Epoch 23/50, Val iteration 26/27: Loss = 1.5927\n",
      "Epoch 23/50, Val iteration 27/27: Loss = 1.6064\n",
      "Epoch 23/50: Train Loss = 1.5367, Val Loss = 1.5834\n",
      "Current learning rate: 8.1e-07\n",
      "Epoch 24/50, Train iteration 1/164: Loss = 1.5527\n",
      "Epoch 24/50, Train iteration 2/164: Loss = 1.5164\n",
      "Epoch 24/50, Train iteration 3/164: Loss = 1.5250\n",
      "Epoch 24/50, Train iteration 4/164: Loss = 1.4969\n",
      "Epoch 24/50, Train iteration 5/164: Loss = 1.5955\n",
      "Epoch 24/50, Train iteration 6/164: Loss = 1.5615\n",
      "Epoch 24/50, Train iteration 7/164: Loss = 1.5949\n",
      "Epoch 24/50, Train iteration 8/164: Loss = 1.4878\n",
      "Epoch 24/50, Train iteration 9/164: Loss = 1.5678\n",
      "Epoch 24/50, Train iteration 10/164: Loss = 1.5879\n",
      "Epoch 24/50, Train iteration 11/164: Loss = 1.5765\n",
      "Epoch 24/50, Train iteration 12/164: Loss = 1.5473\n",
      "Epoch 24/50, Train iteration 13/164: Loss = 1.4715\n",
      "Epoch 24/50, Train iteration 14/164: Loss = 1.5932\n",
      "Epoch 24/50, Train iteration 15/164: Loss = 1.5724\n",
      "Epoch 24/50, Train iteration 16/164: Loss = 1.5874\n",
      "Epoch 24/50, Train iteration 17/164: Loss = 1.5791\n",
      "Epoch 24/50, Train iteration 18/164: Loss = 1.5044\n",
      "Epoch 24/50, Train iteration 19/164: Loss = 1.5127\n",
      "Epoch 24/50, Train iteration 20/164: Loss = 1.5337\n",
      "Epoch 24/50, Train iteration 21/164: Loss = 1.5996\n",
      "Epoch 24/50, Train iteration 22/164: Loss = 1.5045\n",
      "Epoch 24/50, Train iteration 23/164: Loss = 1.5254\n",
      "Epoch 24/50, Train iteration 24/164: Loss = 1.5925\n",
      "Epoch 24/50, Train iteration 25/164: Loss = 1.6099\n",
      "Epoch 24/50, Train iteration 26/164: Loss = 1.5298\n",
      "Epoch 24/50, Train iteration 27/164: Loss = 1.5537\n",
      "Epoch 24/50, Train iteration 28/164: Loss = 1.5771\n",
      "Epoch 24/50, Train iteration 29/164: Loss = 1.4965\n",
      "Epoch 24/50, Train iteration 30/164: Loss = 1.5822\n",
      "Epoch 24/50, Train iteration 31/164: Loss = 1.4714\n",
      "Epoch 24/50, Train iteration 32/164: Loss = 1.5043\n",
      "Epoch 24/50, Train iteration 33/164: Loss = 1.5940\n",
      "Epoch 24/50, Train iteration 34/164: Loss = 1.5317\n",
      "Epoch 24/50, Train iteration 35/164: Loss = 1.5553\n",
      "Epoch 24/50, Train iteration 36/164: Loss = 1.5098\n",
      "Epoch 24/50, Train iteration 37/164: Loss = 1.5968\n",
      "Epoch 24/50, Train iteration 38/164: Loss = 1.5208\n",
      "Epoch 24/50, Train iteration 39/164: Loss = 1.5382\n",
      "Epoch 24/50, Train iteration 40/164: Loss = 1.4901\n",
      "Epoch 24/50, Train iteration 41/164: Loss = 1.4729\n",
      "Epoch 24/50, Train iteration 42/164: Loss = 1.5541\n",
      "Epoch 24/50, Train iteration 43/164: Loss = 1.5605\n",
      "Epoch 24/50, Train iteration 44/164: Loss = 1.5135\n",
      "Epoch 24/50, Train iteration 45/164: Loss = 1.5616\n",
      "Epoch 24/50, Train iteration 46/164: Loss = 1.5431\n",
      "Epoch 24/50, Train iteration 47/164: Loss = 1.5434\n",
      "Epoch 24/50, Train iteration 48/164: Loss = 1.5495\n",
      "Epoch 24/50, Train iteration 49/164: Loss = 1.5030\n",
      "Epoch 24/50, Train iteration 50/164: Loss = 1.6012\n",
      "Epoch 24/50, Train iteration 51/164: Loss = 1.4798\n",
      "Epoch 24/50, Train iteration 52/164: Loss = 1.5051\n",
      "Epoch 24/50, Train iteration 53/164: Loss = 1.5221\n",
      "Epoch 24/50, Train iteration 54/164: Loss = 1.5795\n",
      "Epoch 24/50, Train iteration 55/164: Loss = 1.5022\n",
      "Epoch 24/50, Train iteration 56/164: Loss = 1.5842\n",
      "Epoch 24/50, Train iteration 57/164: Loss = 1.5924\n",
      "Epoch 24/50, Train iteration 58/164: Loss = 1.5979\n",
      "Epoch 24/50, Train iteration 59/164: Loss = 1.5149\n",
      "Epoch 24/50, Train iteration 60/164: Loss = 1.4950\n",
      "Epoch 24/50, Train iteration 61/164: Loss = 1.5522\n",
      "Epoch 24/50, Train iteration 62/164: Loss = 1.5274\n",
      "Epoch 24/50, Train iteration 63/164: Loss = 1.5496\n",
      "Epoch 24/50, Train iteration 64/164: Loss = 1.4742\n",
      "Epoch 24/50, Train iteration 65/164: Loss = 1.4960\n",
      "Epoch 24/50, Train iteration 66/164: Loss = 1.4683\n",
      "Epoch 24/50, Train iteration 67/164: Loss = 1.5086\n",
      "Epoch 24/50, Train iteration 68/164: Loss = 1.5355\n",
      "Epoch 24/50, Train iteration 69/164: Loss = 1.5452\n",
      "Epoch 24/50, Train iteration 70/164: Loss = 1.5153\n",
      "Epoch 24/50, Train iteration 71/164: Loss = 1.5241\n",
      "Epoch 24/50, Train iteration 72/164: Loss = 1.5669\n",
      "Epoch 24/50, Train iteration 73/164: Loss = 1.5853\n",
      "Epoch 24/50, Train iteration 74/164: Loss = 1.5388\n",
      "Epoch 24/50, Train iteration 75/164: Loss = 1.4564\n",
      "Epoch 24/50, Train iteration 76/164: Loss = 1.5411\n",
      "Epoch 24/50, Train iteration 77/164: Loss = 1.5481\n",
      "Epoch 24/50, Train iteration 78/164: Loss = 1.5082\n",
      "Epoch 24/50, Train iteration 79/164: Loss = 1.5723\n",
      "Epoch 24/50, Train iteration 80/164: Loss = 1.5738\n",
      "Epoch 24/50, Train iteration 81/164: Loss = 1.5306\n",
      "Epoch 24/50, Train iteration 82/164: Loss = 1.5456\n",
      "Epoch 24/50, Train iteration 83/164: Loss = 1.5632\n",
      "Epoch 24/50, Train iteration 84/164: Loss = 1.5096\n",
      "Epoch 24/50, Train iteration 85/164: Loss = 1.6053\n",
      "Epoch 24/50, Train iteration 86/164: Loss = 1.4203\n",
      "Epoch 24/50, Train iteration 87/164: Loss = 1.5678\n",
      "Epoch 24/50, Train iteration 88/164: Loss = 1.6082\n",
      "Epoch 24/50, Train iteration 89/164: Loss = 1.5640\n",
      "Epoch 24/50, Train iteration 90/164: Loss = 1.4912\n",
      "Epoch 24/50, Train iteration 91/164: Loss = 1.5749\n",
      "Epoch 24/50, Train iteration 92/164: Loss = 1.5409\n",
      "Epoch 24/50, Train iteration 93/164: Loss = 1.5359\n",
      "Epoch 24/50, Train iteration 94/164: Loss = 1.5482\n",
      "Epoch 24/50, Train iteration 95/164: Loss = 1.5243\n",
      "Epoch 24/50, Train iteration 96/164: Loss = 1.5435\n",
      "Epoch 24/50, Train iteration 97/164: Loss = 1.5500\n",
      "Epoch 24/50, Train iteration 98/164: Loss = 1.5178\n",
      "Epoch 24/50, Train iteration 99/164: Loss = 1.4667\n",
      "Epoch 24/50, Train iteration 100/164: Loss = 1.4710\n",
      "Epoch 24/50, Train iteration 101/164: Loss = 1.4701\n",
      "Epoch 24/50, Train iteration 102/164: Loss = 1.5176\n",
      "Epoch 24/50, Train iteration 103/164: Loss = 1.5782\n",
      "Epoch 24/50, Train iteration 104/164: Loss = 1.5659\n",
      "Epoch 24/50, Train iteration 105/164: Loss = 1.5559\n",
      "Epoch 24/50, Train iteration 106/164: Loss = 1.5591\n",
      "Epoch 24/50, Train iteration 107/164: Loss = 1.5410\n",
      "Epoch 24/50, Train iteration 108/164: Loss = 1.5312\n",
      "Epoch 24/50, Train iteration 109/164: Loss = 1.5683\n",
      "Epoch 24/50, Train iteration 110/164: Loss = 1.5733\n",
      "Epoch 24/50, Train iteration 111/164: Loss = 1.5775\n",
      "Epoch 24/50, Train iteration 112/164: Loss = 1.5700\n",
      "Epoch 24/50, Train iteration 113/164: Loss = 1.4776\n",
      "Epoch 24/50, Train iteration 114/164: Loss = 1.4834\n",
      "Epoch 24/50, Train iteration 115/164: Loss = 1.5645\n",
      "Epoch 24/50, Train iteration 116/164: Loss = 1.5213\n",
      "Epoch 24/50, Train iteration 117/164: Loss = 1.5018\n",
      "Epoch 24/50, Train iteration 118/164: Loss = 1.5653\n",
      "Epoch 24/50, Train iteration 119/164: Loss = 1.5248\n",
      "Epoch 24/50, Train iteration 120/164: Loss = 1.4950\n",
      "Epoch 24/50, Train iteration 121/164: Loss = 1.5757\n",
      "Epoch 24/50, Train iteration 122/164: Loss = 1.4683\n",
      "Epoch 24/50, Train iteration 123/164: Loss = 1.4580\n",
      "Epoch 24/50, Train iteration 124/164: Loss = 1.5337\n",
      "Epoch 24/50, Train iteration 125/164: Loss = 1.4858\n",
      "Epoch 24/50, Train iteration 126/164: Loss = 1.5006\n",
      "Epoch 24/50, Train iteration 127/164: Loss = 1.5560\n",
      "Epoch 24/50, Train iteration 128/164: Loss = 1.5074\n",
      "Epoch 24/50, Train iteration 129/164: Loss = 1.5534\n",
      "Epoch 24/50, Train iteration 130/164: Loss = 1.5822\n",
      "Epoch 24/50, Train iteration 131/164: Loss = 1.5285\n",
      "Epoch 24/50, Train iteration 132/164: Loss = 1.5002\n",
      "Epoch 24/50, Train iteration 133/164: Loss = 1.5909\n",
      "Epoch 24/50, Train iteration 134/164: Loss = 1.5320\n",
      "Epoch 24/50, Train iteration 135/164: Loss = 1.5494\n",
      "Epoch 24/50, Train iteration 136/164: Loss = 1.5600\n",
      "Epoch 24/50, Train iteration 137/164: Loss = 1.4939\n",
      "Epoch 24/50, Train iteration 138/164: Loss = 1.5333\n",
      "Epoch 24/50, Train iteration 139/164: Loss = 1.5716\n",
      "Epoch 24/50, Train iteration 140/164: Loss = 1.5423\n",
      "Epoch 24/50, Train iteration 141/164: Loss = 1.5743\n",
      "Epoch 24/50, Train iteration 142/164: Loss = 1.5649\n",
      "Epoch 24/50, Train iteration 143/164: Loss = 1.5608\n",
      "Epoch 24/50, Train iteration 144/164: Loss = 1.5995\n",
      "Epoch 24/50, Train iteration 145/164: Loss = 1.5070\n",
      "Epoch 24/50, Train iteration 146/164: Loss = 1.4880\n",
      "Epoch 24/50, Train iteration 147/164: Loss = 1.5024\n",
      "Epoch 24/50, Train iteration 148/164: Loss = 1.5176\n",
      "Epoch 24/50, Train iteration 149/164: Loss = 1.5191\n",
      "Epoch 24/50, Train iteration 150/164: Loss = 1.5736\n",
      "Epoch 24/50, Train iteration 151/164: Loss = 1.5379\n",
      "Epoch 24/50, Train iteration 152/164: Loss = 1.4825\n",
      "Epoch 24/50, Train iteration 153/164: Loss = 1.5744\n",
      "Epoch 24/50, Train iteration 154/164: Loss = 1.5261\n",
      "Epoch 24/50, Train iteration 155/164: Loss = 1.5673\n",
      "Epoch 24/50, Train iteration 156/164: Loss = 1.4779\n",
      "Epoch 24/50, Train iteration 157/164: Loss = 1.6018\n",
      "Epoch 24/50, Train iteration 158/164: Loss = 1.5776\n",
      "Epoch 24/50, Train iteration 159/164: Loss = 1.5768\n",
      "Epoch 24/50, Train iteration 160/164: Loss = 1.5669\n",
      "Epoch 24/50, Train iteration 161/164: Loss = 1.5776\n",
      "Epoch 24/50, Train iteration 162/164: Loss = 1.5154\n",
      "Epoch 24/50, Train iteration 163/164: Loss = 1.5090\n",
      "Epoch 24/50, Train iteration 164/164: Loss = 1.4078\n",
      "Epoch 24/50, Val iteration 1/27: Loss = 1.6142\n",
      "Epoch 24/50, Val iteration 2/27: Loss = 1.6213\n",
      "Epoch 24/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 24/50, Val iteration 4/27: Loss = 1.5956\n",
      "Epoch 24/50, Val iteration 5/27: Loss = 1.6162\n",
      "Epoch 24/50, Val iteration 6/27: Loss = 1.5819\n",
      "Epoch 24/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 24/50, Val iteration 8/27: Loss = 1.6146\n",
      "Epoch 24/50, Val iteration 9/27: Loss = 1.5873\n",
      "Epoch 24/50, Val iteration 10/27: Loss = 1.5776\n",
      "Epoch 24/50, Val iteration 11/27: Loss = 1.6005\n",
      "Epoch 24/50, Val iteration 12/27: Loss = 1.5651\n",
      "Epoch 24/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 24/50, Val iteration 14/27: Loss = 1.5435\n",
      "Epoch 24/50, Val iteration 15/27: Loss = 1.5900\n",
      "Epoch 24/50, Val iteration 16/27: Loss = 1.5801\n",
      "Epoch 24/50, Val iteration 17/27: Loss = 1.5951\n",
      "Epoch 24/50, Val iteration 18/27: Loss = 1.5560\n",
      "Epoch 24/50, Val iteration 19/27: Loss = 1.5773\n",
      "Epoch 24/50, Val iteration 20/27: Loss = 1.5976\n",
      "Epoch 24/50, Val iteration 21/27: Loss = 1.5870\n",
      "Epoch 24/50, Val iteration 22/27: Loss = 1.6057\n",
      "Epoch 24/50, Val iteration 23/27: Loss = 1.4842\n",
      "Epoch 24/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 24/50, Val iteration 25/27: Loss = 1.5868\n",
      "Epoch 24/50, Val iteration 26/27: Loss = 1.5926\n",
      "Epoch 24/50, Val iteration 27/27: Loss = 1.6061\n",
      "Epoch 24/50: Train Loss = 1.5376, Val Loss = 1.5834\n",
      "Current learning rate: 8.1e-07\n",
      "Epoch 25/50, Train iteration 1/164: Loss = 1.5390\n",
      "Epoch 25/50, Train iteration 2/164: Loss = 1.5443\n",
      "Epoch 25/50, Train iteration 3/164: Loss = 1.5637\n",
      "Epoch 25/50, Train iteration 4/164: Loss = 1.5177\n",
      "Epoch 25/50, Train iteration 5/164: Loss = 1.5165\n",
      "Epoch 25/50, Train iteration 6/164: Loss = 1.6020\n",
      "Epoch 25/50, Train iteration 7/164: Loss = 1.5921\n",
      "Epoch 25/50, Train iteration 8/164: Loss = 1.5355\n",
      "Epoch 25/50, Train iteration 9/164: Loss = 1.6179\n",
      "Epoch 25/50, Train iteration 10/164: Loss = 1.6200\n",
      "Epoch 25/50, Train iteration 11/164: Loss = 1.5736\n",
      "Epoch 25/50, Train iteration 12/164: Loss = 1.5229\n",
      "Epoch 25/50, Train iteration 13/164: Loss = 1.5056\n",
      "Epoch 25/50, Train iteration 14/164: Loss = 1.5488\n",
      "Epoch 25/50, Train iteration 15/164: Loss = 1.5886\n",
      "Epoch 25/50, Train iteration 16/164: Loss = 1.5445\n",
      "Epoch 25/50, Train iteration 17/164: Loss = 1.5163\n",
      "Epoch 25/50, Train iteration 18/164: Loss = 1.5957\n",
      "Epoch 25/50, Train iteration 19/164: Loss = 1.5597\n",
      "Epoch 25/50, Train iteration 20/164: Loss = 1.5001\n",
      "Epoch 25/50, Train iteration 21/164: Loss = 1.5654\n",
      "Epoch 25/50, Train iteration 22/164: Loss = 1.6404\n",
      "Epoch 25/50, Train iteration 23/164: Loss = 1.5420\n",
      "Epoch 25/50, Train iteration 24/164: Loss = 1.5690\n",
      "Epoch 25/50, Train iteration 25/164: Loss = 1.5979\n",
      "Epoch 25/50, Train iteration 26/164: Loss = 1.5480\n",
      "Epoch 25/50, Train iteration 27/164: Loss = 1.5721\n",
      "Epoch 25/50, Train iteration 28/164: Loss = 1.5695\n",
      "Epoch 25/50, Train iteration 29/164: Loss = 1.5149\n",
      "Epoch 25/50, Train iteration 30/164: Loss = 1.5864\n",
      "Epoch 25/50, Train iteration 31/164: Loss = 1.4432\n",
      "Epoch 25/50, Train iteration 32/164: Loss = 1.5553\n",
      "Epoch 25/50, Train iteration 33/164: Loss = 1.5587\n",
      "Epoch 25/50, Train iteration 34/164: Loss = 1.5008\n",
      "Epoch 25/50, Train iteration 35/164: Loss = 1.5413\n",
      "Epoch 25/50, Train iteration 36/164: Loss = 1.5096\n",
      "Epoch 25/50, Train iteration 37/164: Loss = 1.5619\n",
      "Epoch 25/50, Train iteration 38/164: Loss = 1.5422\n",
      "Epoch 25/50, Train iteration 39/164: Loss = 1.5289\n",
      "Epoch 25/50, Train iteration 40/164: Loss = 1.5088\n",
      "Epoch 25/50, Train iteration 41/164: Loss = 1.5036\n",
      "Epoch 25/50, Train iteration 42/164: Loss = 1.5718\n",
      "Epoch 25/50, Train iteration 43/164: Loss = 1.5474\n",
      "Epoch 25/50, Train iteration 44/164: Loss = 1.5133\n",
      "Epoch 25/50, Train iteration 45/164: Loss = 1.5401\n",
      "Epoch 25/50, Train iteration 46/164: Loss = 1.5281\n",
      "Epoch 25/50, Train iteration 47/164: Loss = 1.5700\n",
      "Epoch 25/50, Train iteration 48/164: Loss = 1.5536\n",
      "Epoch 25/50, Train iteration 49/164: Loss = 1.4921\n",
      "Epoch 25/50, Train iteration 50/164: Loss = 1.5754\n",
      "Epoch 25/50, Train iteration 51/164: Loss = 1.4277\n",
      "Epoch 25/50, Train iteration 52/164: Loss = 1.5260\n",
      "Epoch 25/50, Train iteration 53/164: Loss = 1.6077\n",
      "Epoch 25/50, Train iteration 54/164: Loss = 1.5740\n",
      "Epoch 25/50, Train iteration 55/164: Loss = 1.4854\n",
      "Epoch 25/50, Train iteration 56/164: Loss = 1.5627\n",
      "Epoch 25/50, Train iteration 57/164: Loss = 1.5059\n",
      "Epoch 25/50, Train iteration 58/164: Loss = 1.5793\n",
      "Epoch 25/50, Train iteration 59/164: Loss = 1.5555\n",
      "Epoch 25/50, Train iteration 60/164: Loss = 1.5140\n",
      "Epoch 25/50, Train iteration 61/164: Loss = 1.5155\n",
      "Epoch 25/50, Train iteration 62/164: Loss = 1.4754\n",
      "Epoch 25/50, Train iteration 63/164: Loss = 1.5867\n",
      "Epoch 25/50, Train iteration 64/164: Loss = 1.5372\n",
      "Epoch 25/50, Train iteration 65/164: Loss = 1.5385\n",
      "Epoch 25/50, Train iteration 66/164: Loss = 1.4769\n",
      "Epoch 25/50, Train iteration 67/164: Loss = 1.4595\n",
      "Epoch 25/50, Train iteration 68/164: Loss = 1.5063\n",
      "Epoch 25/50, Train iteration 69/164: Loss = 1.5306\n",
      "Epoch 25/50, Train iteration 70/164: Loss = 1.5837\n",
      "Epoch 25/50, Train iteration 71/164: Loss = 1.5610\n",
      "Epoch 25/50, Train iteration 72/164: Loss = 1.5918\n",
      "Epoch 25/50, Train iteration 73/164: Loss = 1.5326\n",
      "Epoch 25/50, Train iteration 74/164: Loss = 1.5512\n",
      "Epoch 25/50, Train iteration 75/164: Loss = 1.5256\n",
      "Epoch 25/50, Train iteration 76/164: Loss = 1.5354\n",
      "Epoch 25/50, Train iteration 77/164: Loss = 1.5715\n",
      "Epoch 25/50, Train iteration 78/164: Loss = 1.4646\n",
      "Epoch 25/50, Train iteration 79/164: Loss = 1.5475\n",
      "Epoch 25/50, Train iteration 80/164: Loss = 1.5585\n",
      "Epoch 25/50, Train iteration 81/164: Loss = 1.5293\n",
      "Epoch 25/50, Train iteration 82/164: Loss = 1.5923\n",
      "Epoch 25/50, Train iteration 83/164: Loss = 1.5182\n",
      "Epoch 25/50, Train iteration 84/164: Loss = 1.5131\n",
      "Epoch 25/50, Train iteration 85/164: Loss = 1.5874\n",
      "Epoch 25/50, Train iteration 86/164: Loss = 1.4371\n",
      "Epoch 25/50, Train iteration 87/164: Loss = 1.5326\n",
      "Epoch 25/50, Train iteration 88/164: Loss = 1.5964\n",
      "Epoch 25/50, Train iteration 89/164: Loss = 1.5471\n",
      "Epoch 25/50, Train iteration 90/164: Loss = 1.4792\n",
      "Epoch 25/50, Train iteration 91/164: Loss = 1.5758\n",
      "Epoch 25/50, Train iteration 92/164: Loss = 1.5674\n",
      "Epoch 25/50, Train iteration 93/164: Loss = 1.5840\n",
      "Epoch 25/50, Train iteration 94/164: Loss = 1.5923\n",
      "Epoch 25/50, Train iteration 95/164: Loss = 1.5180\n",
      "Epoch 25/50, Train iteration 96/164: Loss = 1.5845\n",
      "Epoch 25/50, Train iteration 97/164: Loss = 1.5904\n",
      "Epoch 25/50, Train iteration 98/164: Loss = 1.5267\n",
      "Epoch 25/50, Train iteration 99/164: Loss = 1.4716\n",
      "Epoch 25/50, Train iteration 100/164: Loss = 1.4960\n",
      "Epoch 25/50, Train iteration 101/164: Loss = 1.4641\n",
      "Epoch 25/50, Train iteration 102/164: Loss = 1.5472\n",
      "Epoch 25/50, Train iteration 103/164: Loss = 1.6371\n",
      "Epoch 25/50, Train iteration 104/164: Loss = 1.5756\n",
      "Epoch 25/50, Train iteration 105/164: Loss = 1.5626\n",
      "Epoch 25/50, Train iteration 106/164: Loss = 1.5548\n",
      "Epoch 25/50, Train iteration 107/164: Loss = 1.5536\n",
      "Epoch 25/50, Train iteration 108/164: Loss = 1.5724\n",
      "Epoch 25/50, Train iteration 109/164: Loss = 1.5548\n",
      "Epoch 25/50, Train iteration 110/164: Loss = 1.5498\n",
      "Epoch 25/50, Train iteration 111/164: Loss = 1.5279\n",
      "Epoch 25/50, Train iteration 112/164: Loss = 1.5323\n",
      "Epoch 25/50, Train iteration 113/164: Loss = 1.5143\n",
      "Epoch 25/50, Train iteration 114/164: Loss = 1.4202\n",
      "Epoch 25/50, Train iteration 115/164: Loss = 1.5538\n",
      "Epoch 25/50, Train iteration 116/164: Loss = 1.4926\n",
      "Epoch 25/50, Train iteration 117/164: Loss = 1.4792\n",
      "Epoch 25/50, Train iteration 118/164: Loss = 1.5070\n",
      "Epoch 25/50, Train iteration 119/164: Loss = 1.5280\n",
      "Epoch 25/50, Train iteration 120/164: Loss = 1.5291\n",
      "Epoch 25/50, Train iteration 121/164: Loss = 1.5687\n",
      "Epoch 25/50, Train iteration 122/164: Loss = 1.4552\n",
      "Epoch 25/50, Train iteration 123/164: Loss = 1.5122\n",
      "Epoch 25/50, Train iteration 124/164: Loss = 1.5691\n",
      "Epoch 25/50, Train iteration 125/164: Loss = 1.5173\n",
      "Epoch 25/50, Train iteration 126/164: Loss = 1.5222\n",
      "Epoch 25/50, Train iteration 127/164: Loss = 1.5818\n",
      "Epoch 25/50, Train iteration 128/164: Loss = 1.4721\n",
      "Epoch 25/50, Train iteration 129/164: Loss = 1.4862\n",
      "Epoch 25/50, Train iteration 130/164: Loss = 1.5558\n",
      "Epoch 25/50, Train iteration 131/164: Loss = 1.5921\n",
      "Epoch 25/50, Train iteration 132/164: Loss = 1.4764\n",
      "Epoch 25/50, Train iteration 133/164: Loss = 1.5526\n",
      "Epoch 25/50, Train iteration 134/164: Loss = 1.5591\n",
      "Epoch 25/50, Train iteration 135/164: Loss = 1.5530\n",
      "Epoch 25/50, Train iteration 136/164: Loss = 1.5309\n",
      "Epoch 25/50, Train iteration 137/164: Loss = 1.4927\n",
      "Epoch 25/50, Train iteration 138/164: Loss = 1.5270\n",
      "Epoch 25/50, Train iteration 139/164: Loss = 1.5826\n",
      "Epoch 25/50, Train iteration 140/164: Loss = 1.5478\n",
      "Epoch 25/50, Train iteration 141/164: Loss = 1.5530\n",
      "Epoch 25/50, Train iteration 142/164: Loss = 1.5760\n",
      "Epoch 25/50, Train iteration 143/164: Loss = 1.4805\n",
      "Epoch 25/50, Train iteration 144/164: Loss = 1.5436\n",
      "Epoch 25/50, Train iteration 145/164: Loss = 1.4924\n",
      "Epoch 25/50, Train iteration 146/164: Loss = 1.4578\n",
      "Epoch 25/50, Train iteration 147/164: Loss = 1.5291\n",
      "Epoch 25/50, Train iteration 148/164: Loss = 1.5444\n",
      "Epoch 25/50, Train iteration 149/164: Loss = 1.5386\n",
      "Epoch 25/50, Train iteration 150/164: Loss = 1.5329\n",
      "Epoch 25/50, Train iteration 151/164: Loss = 1.6018\n",
      "Epoch 25/50, Train iteration 152/164: Loss = 1.5363\n",
      "Epoch 25/50, Train iteration 153/164: Loss = 1.5422\n",
      "Epoch 25/50, Train iteration 154/164: Loss = 1.5344\n",
      "Epoch 25/50, Train iteration 155/164: Loss = 1.5004\n",
      "Epoch 25/50, Train iteration 156/164: Loss = 1.5068\n",
      "Epoch 25/50, Train iteration 157/164: Loss = 1.6026\n",
      "Epoch 25/50, Train iteration 158/164: Loss = 1.6035\n",
      "Epoch 25/50, Train iteration 159/164: Loss = 1.5941\n",
      "Epoch 25/50, Train iteration 160/164: Loss = 1.5892\n",
      "Epoch 25/50, Train iteration 161/164: Loss = 1.6561\n",
      "Epoch 25/50, Train iteration 162/164: Loss = 1.5319\n",
      "Epoch 25/50, Train iteration 163/164: Loss = 1.5858\n",
      "Epoch 25/50, Train iteration 164/164: Loss = 1.4363\n",
      "Epoch 25/50, Val iteration 1/27: Loss = 1.6137\n",
      "Epoch 25/50, Val iteration 2/27: Loss = 1.6210\n",
      "Epoch 25/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 25/50, Val iteration 4/27: Loss = 1.5954\n",
      "Epoch 25/50, Val iteration 5/27: Loss = 1.6159\n",
      "Epoch 25/50, Val iteration 6/27: Loss = 1.5818\n",
      "Epoch 25/50, Val iteration 7/27: Loss = 1.5546\n",
      "Epoch 25/50, Val iteration 8/27: Loss = 1.6143\n",
      "Epoch 25/50, Val iteration 9/27: Loss = 1.5873\n",
      "Epoch 25/50, Val iteration 10/27: Loss = 1.5777\n",
      "Epoch 25/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 25/50, Val iteration 12/27: Loss = 1.5650\n",
      "Epoch 25/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 25/50, Val iteration 14/27: Loss = 1.5439\n",
      "Epoch 25/50, Val iteration 15/27: Loss = 1.5899\n",
      "Epoch 25/50, Val iteration 16/27: Loss = 1.5802\n",
      "Epoch 25/50, Val iteration 17/27: Loss = 1.5947\n",
      "Epoch 25/50, Val iteration 18/27: Loss = 1.5561\n",
      "Epoch 25/50, Val iteration 19/27: Loss = 1.5773\n",
      "Epoch 25/50, Val iteration 20/27: Loss = 1.5974\n",
      "Epoch 25/50, Val iteration 21/27: Loss = 1.5870\n",
      "Epoch 25/50, Val iteration 22/27: Loss = 1.6051\n",
      "Epoch 25/50, Val iteration 23/27: Loss = 1.4844\n",
      "Epoch 25/50, Val iteration 24/27: Loss = 1.5584\n",
      "Epoch 25/50, Val iteration 25/27: Loss = 1.5864\n",
      "Epoch 25/50, Val iteration 26/27: Loss = 1.5928\n",
      "Epoch 25/50, Val iteration 27/27: Loss = 1.6057\n",
      "Epoch 25/50: Train Loss = 1.5406, Val Loss = 1.5833\n",
      "Current learning rate: 8.1e-07\n",
      "Epoch 26/50, Train iteration 1/164: Loss = 1.5419\n",
      "Epoch 26/50, Train iteration 2/164: Loss = 1.5119\n",
      "Epoch 26/50, Train iteration 3/164: Loss = 1.5967\n",
      "Epoch 26/50, Train iteration 4/164: Loss = 1.5454\n",
      "Epoch 26/50, Train iteration 5/164: Loss = 1.5949\n",
      "Epoch 26/50, Train iteration 6/164: Loss = 1.5958\n",
      "Epoch 26/50, Train iteration 7/164: Loss = 1.5837\n",
      "Epoch 26/50, Train iteration 8/164: Loss = 1.4942\n",
      "Epoch 26/50, Train iteration 9/164: Loss = 1.6294\n",
      "Epoch 26/50, Train iteration 10/164: Loss = 1.6125\n",
      "Epoch 26/50, Train iteration 11/164: Loss = 1.5767\n",
      "Epoch 26/50, Train iteration 12/164: Loss = 1.5813\n",
      "Epoch 26/50, Train iteration 13/164: Loss = 1.5005\n",
      "Epoch 26/50, Train iteration 14/164: Loss = 1.5922\n",
      "Epoch 26/50, Train iteration 15/164: Loss = 1.5511\n",
      "Epoch 26/50, Train iteration 16/164: Loss = 1.5409\n",
      "Epoch 26/50, Train iteration 17/164: Loss = 1.5529\n",
      "Epoch 26/50, Train iteration 18/164: Loss = 1.5659\n",
      "Epoch 26/50, Train iteration 19/164: Loss = 1.5500\n",
      "Epoch 26/50, Train iteration 20/164: Loss = 1.5815\n",
      "Epoch 26/50, Train iteration 21/164: Loss = 1.5371\n",
      "Epoch 26/50, Train iteration 22/164: Loss = 1.5732\n",
      "Epoch 26/50, Train iteration 23/164: Loss = 1.5766\n",
      "Epoch 26/50, Train iteration 24/164: Loss = 1.6184\n",
      "Epoch 26/50, Train iteration 25/164: Loss = 1.6147\n",
      "Epoch 26/50, Train iteration 26/164: Loss = 1.6033\n",
      "Epoch 26/50, Train iteration 27/164: Loss = 1.5349\n",
      "Epoch 26/50, Train iteration 28/164: Loss = 1.5580\n",
      "Epoch 26/50, Train iteration 29/164: Loss = 1.5104\n",
      "Epoch 26/50, Train iteration 30/164: Loss = 1.5557\n",
      "Epoch 26/50, Train iteration 31/164: Loss = 1.4748\n",
      "Epoch 26/50, Train iteration 32/164: Loss = 1.5026\n",
      "Epoch 26/50, Train iteration 33/164: Loss = 1.5252\n",
      "Epoch 26/50, Train iteration 34/164: Loss = 1.5083\n",
      "Epoch 26/50, Train iteration 35/164: Loss = 1.5582\n",
      "Epoch 26/50, Train iteration 36/164: Loss = 1.5365\n",
      "Epoch 26/50, Train iteration 37/164: Loss = 1.5810\n",
      "Epoch 26/50, Train iteration 38/164: Loss = 1.4980\n",
      "Epoch 26/50, Train iteration 39/164: Loss = 1.5778\n",
      "Epoch 26/50, Train iteration 40/164: Loss = 1.4708\n",
      "Epoch 26/50, Train iteration 41/164: Loss = 1.4993\n",
      "Epoch 26/50, Train iteration 42/164: Loss = 1.5507\n",
      "Epoch 26/50, Train iteration 43/164: Loss = 1.5792\n",
      "Epoch 26/50, Train iteration 44/164: Loss = 1.4975\n",
      "Epoch 26/50, Train iteration 45/164: Loss = 1.5378\n",
      "Epoch 26/50, Train iteration 46/164: Loss = 1.5702\n",
      "Epoch 26/50, Train iteration 47/164: Loss = 1.5902\n",
      "Epoch 26/50, Train iteration 48/164: Loss = 1.5297\n",
      "Epoch 26/50, Train iteration 49/164: Loss = 1.5326\n",
      "Epoch 26/50, Train iteration 50/164: Loss = 1.5296\n",
      "Epoch 26/50, Train iteration 51/164: Loss = 1.4716\n",
      "Epoch 26/50, Train iteration 52/164: Loss = 1.5200\n",
      "Epoch 26/50, Train iteration 53/164: Loss = 1.5560\n",
      "Epoch 26/50, Train iteration 54/164: Loss = 1.5388\n",
      "Epoch 26/50, Train iteration 55/164: Loss = 1.5515\n",
      "Epoch 26/50, Train iteration 56/164: Loss = 1.5871\n",
      "Epoch 26/50, Train iteration 57/164: Loss = 1.5485\n",
      "Epoch 26/50, Train iteration 58/164: Loss = 1.5793\n",
      "Epoch 26/50, Train iteration 59/164: Loss = 1.5344\n",
      "Epoch 26/50, Train iteration 60/164: Loss = 1.5564\n",
      "Epoch 26/50, Train iteration 61/164: Loss = 1.5324\n",
      "Epoch 26/50, Train iteration 62/164: Loss = 1.4899\n",
      "Epoch 26/50, Train iteration 63/164: Loss = 1.5590\n",
      "Epoch 26/50, Train iteration 64/164: Loss = 1.5487\n",
      "Epoch 26/50, Train iteration 65/164: Loss = 1.5671\n",
      "Epoch 26/50, Train iteration 66/164: Loss = 1.4494\n",
      "Epoch 26/50, Train iteration 67/164: Loss = 1.5012\n",
      "Epoch 26/50, Train iteration 68/164: Loss = 1.5212\n",
      "Epoch 26/50, Train iteration 69/164: Loss = 1.5686\n",
      "Epoch 26/50, Train iteration 70/164: Loss = 1.5324\n",
      "Epoch 26/50, Train iteration 71/164: Loss = 1.5733\n",
      "Epoch 26/50, Train iteration 72/164: Loss = 1.5262\n",
      "Epoch 26/50, Train iteration 73/164: Loss = 1.5437\n",
      "Epoch 26/50, Train iteration 74/164: Loss = 1.5368\n",
      "Epoch 26/50, Train iteration 75/164: Loss = 1.5480\n",
      "Epoch 26/50, Train iteration 76/164: Loss = 1.5979\n",
      "Epoch 26/50, Train iteration 77/164: Loss = 1.5913\n",
      "Epoch 26/50, Train iteration 78/164: Loss = 1.5453\n",
      "Epoch 26/50, Train iteration 79/164: Loss = 1.5509\n",
      "Epoch 26/50, Train iteration 80/164: Loss = 1.5674\n",
      "Epoch 26/50, Train iteration 81/164: Loss = 1.4870\n",
      "Epoch 26/50, Train iteration 82/164: Loss = 1.5114\n",
      "Epoch 26/50, Train iteration 83/164: Loss = 1.5750\n",
      "Epoch 26/50, Train iteration 84/164: Loss = 1.4884\n",
      "Epoch 26/50, Train iteration 85/164: Loss = 1.5960\n",
      "Epoch 26/50, Train iteration 86/164: Loss = 1.4513\n",
      "Epoch 26/50, Train iteration 87/164: Loss = 1.4943\n",
      "Epoch 26/50, Train iteration 88/164: Loss = 1.6123\n",
      "Epoch 26/50, Train iteration 89/164: Loss = 1.5489\n",
      "Epoch 26/50, Train iteration 90/164: Loss = 1.4953\n",
      "Epoch 26/50, Train iteration 91/164: Loss = 1.6120\n",
      "Epoch 26/50, Train iteration 92/164: Loss = 1.5272\n",
      "Epoch 26/50, Train iteration 93/164: Loss = 1.5085\n",
      "Epoch 26/50, Train iteration 94/164: Loss = 1.6216\n",
      "Epoch 26/50, Train iteration 95/164: Loss = 1.5227\n",
      "Epoch 26/50, Train iteration 96/164: Loss = 1.5079\n",
      "Epoch 26/50, Train iteration 97/164: Loss = 1.5616\n",
      "Epoch 26/50, Train iteration 98/164: Loss = 1.5506\n",
      "Epoch 26/50, Train iteration 99/164: Loss = 1.5242\n",
      "Epoch 26/50, Train iteration 100/164: Loss = 1.4659\n",
      "Epoch 26/50, Train iteration 101/164: Loss = 1.5125\n",
      "Epoch 26/50, Train iteration 102/164: Loss = 1.5626\n",
      "Epoch 26/50, Train iteration 103/164: Loss = 1.6212\n",
      "Epoch 26/50, Train iteration 104/164: Loss = 1.5742\n",
      "Epoch 26/50, Train iteration 105/164: Loss = 1.5751\n",
      "Epoch 26/50, Train iteration 106/164: Loss = 1.6251\n",
      "Epoch 26/50, Train iteration 107/164: Loss = 1.5442\n",
      "Epoch 26/50, Train iteration 108/164: Loss = 1.5195\n",
      "Epoch 26/50, Train iteration 109/164: Loss = 1.5496\n",
      "Epoch 26/50, Train iteration 110/164: Loss = 1.5333\n",
      "Epoch 26/50, Train iteration 111/164: Loss = 1.5833\n",
      "Epoch 26/50, Train iteration 112/164: Loss = 1.5436\n",
      "Epoch 26/50, Train iteration 113/164: Loss = 1.4971\n",
      "Epoch 26/50, Train iteration 114/164: Loss = 1.4186\n",
      "Epoch 26/50, Train iteration 115/164: Loss = 1.5330\n",
      "Epoch 26/50, Train iteration 116/164: Loss = 1.4522\n",
      "Epoch 26/50, Train iteration 117/164: Loss = 1.5038\n",
      "Epoch 26/50, Train iteration 118/164: Loss = 1.5504\n",
      "Epoch 26/50, Train iteration 119/164: Loss = 1.5529\n",
      "Epoch 26/50, Train iteration 120/164: Loss = 1.5505\n",
      "Epoch 26/50, Train iteration 121/164: Loss = 1.5188\n",
      "Epoch 26/50, Train iteration 122/164: Loss = 1.4686\n",
      "Epoch 26/50, Train iteration 123/164: Loss = 1.5179\n",
      "Epoch 26/50, Train iteration 124/164: Loss = 1.5239\n",
      "Epoch 26/50, Train iteration 125/164: Loss = 1.5033\n",
      "Epoch 26/50, Train iteration 126/164: Loss = 1.4822\n",
      "Epoch 26/50, Train iteration 127/164: Loss = 1.5846\n",
      "Epoch 26/50, Train iteration 128/164: Loss = 1.4581\n",
      "Epoch 26/50, Train iteration 129/164: Loss = 1.5099\n",
      "Epoch 26/50, Train iteration 130/164: Loss = 1.5215\n",
      "Epoch 26/50, Train iteration 131/164: Loss = 1.5441\n",
      "Epoch 26/50, Train iteration 132/164: Loss = 1.4693\n",
      "Epoch 26/50, Train iteration 133/164: Loss = 1.5402\n",
      "Epoch 26/50, Train iteration 134/164: Loss = 1.5010\n",
      "Epoch 26/50, Train iteration 135/164: Loss = 1.5519\n",
      "Epoch 26/50, Train iteration 136/164: Loss = 1.5752\n",
      "Epoch 26/50, Train iteration 137/164: Loss = 1.5106\n",
      "Epoch 26/50, Train iteration 138/164: Loss = 1.5378\n",
      "Epoch 26/50, Train iteration 139/164: Loss = 1.6169\n",
      "Epoch 26/50, Train iteration 140/164: Loss = 1.5171\n",
      "Epoch 26/50, Train iteration 141/164: Loss = 1.5717\n",
      "Epoch 26/50, Train iteration 142/164: Loss = 1.5387\n",
      "Epoch 26/50, Train iteration 143/164: Loss = 1.5247\n",
      "Epoch 26/50, Train iteration 144/164: Loss = 1.6403\n",
      "Epoch 26/50, Train iteration 145/164: Loss = 1.4820\n",
      "Epoch 26/50, Train iteration 146/164: Loss = 1.5452\n",
      "Epoch 26/50, Train iteration 147/164: Loss = 1.5527\n",
      "Epoch 26/50, Train iteration 148/164: Loss = 1.4921\n",
      "Epoch 26/50, Train iteration 149/164: Loss = 1.5448\n",
      "Epoch 26/50, Train iteration 150/164: Loss = 1.5942\n",
      "Epoch 26/50, Train iteration 151/164: Loss = 1.5551\n",
      "Epoch 26/50, Train iteration 152/164: Loss = 1.5006\n",
      "Epoch 26/50, Train iteration 153/164: Loss = 1.5713\n",
      "Epoch 26/50, Train iteration 154/164: Loss = 1.5227\n",
      "Epoch 26/50, Train iteration 155/164: Loss = 1.5232\n",
      "Epoch 26/50, Train iteration 156/164: Loss = 1.5283\n",
      "Epoch 26/50, Train iteration 157/164: Loss = 1.6008\n",
      "Epoch 26/50, Train iteration 158/164: Loss = 1.6059\n",
      "Epoch 26/50, Train iteration 159/164: Loss = 1.5580\n",
      "Epoch 26/50, Train iteration 160/164: Loss = 1.5414\n",
      "Epoch 26/50, Train iteration 161/164: Loss = 1.5818\n",
      "Epoch 26/50, Train iteration 162/164: Loss = 1.5492\n",
      "Epoch 26/50, Train iteration 163/164: Loss = 1.5450\n",
      "Epoch 26/50, Train iteration 164/164: Loss = 1.4106\n",
      "Epoch 26/50, Val iteration 1/27: Loss = 1.6128\n",
      "Epoch 26/50, Val iteration 2/27: Loss = 1.6207\n",
      "Epoch 26/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 26/50, Val iteration 4/27: Loss = 1.5951\n",
      "Epoch 26/50, Val iteration 5/27: Loss = 1.6152\n",
      "Epoch 26/50, Val iteration 6/27: Loss = 1.5814\n",
      "Epoch 26/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 26/50, Val iteration 8/27: Loss = 1.6139\n",
      "Epoch 26/50, Val iteration 9/27: Loss = 1.5870\n",
      "Epoch 26/50, Val iteration 10/27: Loss = 1.5777\n",
      "Epoch 26/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 26/50, Val iteration 12/27: Loss = 1.5651\n",
      "Epoch 26/50, Val iteration 13/27: Loss = 1.5707\n",
      "Epoch 26/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 26/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 26/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 26/50, Val iteration 17/27: Loss = 1.5943\n",
      "Epoch 26/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 26/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 26/50, Val iteration 20/27: Loss = 1.5973\n",
      "Epoch 26/50, Val iteration 21/27: Loss = 1.5869\n",
      "Epoch 26/50, Val iteration 22/27: Loss = 1.6042\n",
      "Epoch 26/50, Val iteration 23/27: Loss = 1.4849\n",
      "Epoch 26/50, Val iteration 24/27: Loss = 1.5582\n",
      "Epoch 26/50, Val iteration 25/27: Loss = 1.5857\n",
      "Epoch 26/50, Val iteration 26/27: Loss = 1.5932\n",
      "Epoch 26/50, Val iteration 27/27: Loss = 1.6054\n",
      "Epoch 26/50: Train Loss = 1.5422, Val Loss = 1.5831\n",
      "Current learning rate: 2.43e-07\n",
      "Epoch 27/50, Train iteration 1/164: Loss = 1.5382\n",
      "Epoch 27/50, Train iteration 2/164: Loss = 1.5330\n",
      "Epoch 27/50, Train iteration 3/164: Loss = 1.5660\n",
      "Epoch 27/50, Train iteration 4/164: Loss = 1.5783\n",
      "Epoch 27/50, Train iteration 5/164: Loss = 1.5487\n",
      "Epoch 27/50, Train iteration 6/164: Loss = 1.5749\n",
      "Epoch 27/50, Train iteration 7/164: Loss = 1.6336\n",
      "Epoch 27/50, Train iteration 8/164: Loss = 1.5313\n",
      "Epoch 27/50, Train iteration 9/164: Loss = 1.5796\n",
      "Epoch 27/50, Train iteration 10/164: Loss = 1.6086\n",
      "Epoch 27/50, Train iteration 11/164: Loss = 1.5892\n",
      "Epoch 27/50, Train iteration 12/164: Loss = 1.5665\n",
      "Epoch 27/50, Train iteration 13/164: Loss = 1.4658\n",
      "Epoch 27/50, Train iteration 14/164: Loss = 1.5559\n",
      "Epoch 27/50, Train iteration 15/164: Loss = 1.5771\n",
      "Epoch 27/50, Train iteration 16/164: Loss = 1.5344\n",
      "Epoch 27/50, Train iteration 17/164: Loss = 1.5726\n",
      "Epoch 27/50, Train iteration 18/164: Loss = 1.4878\n",
      "Epoch 27/50, Train iteration 19/164: Loss = 1.5318\n",
      "Epoch 27/50, Train iteration 20/164: Loss = 1.5481\n",
      "Epoch 27/50, Train iteration 21/164: Loss = 1.5829\n",
      "Epoch 27/50, Train iteration 22/164: Loss = 1.5912\n",
      "Epoch 27/50, Train iteration 23/164: Loss = 1.5929\n",
      "Epoch 27/50, Train iteration 24/164: Loss = 1.5783\n",
      "Epoch 27/50, Train iteration 25/164: Loss = 1.5601\n",
      "Epoch 27/50, Train iteration 26/164: Loss = 1.5901\n",
      "Epoch 27/50, Train iteration 27/164: Loss = 1.5594\n",
      "Epoch 27/50, Train iteration 28/164: Loss = 1.5699\n",
      "Epoch 27/50, Train iteration 29/164: Loss = 1.5592\n",
      "Epoch 27/50, Train iteration 30/164: Loss = 1.5671\n",
      "Epoch 27/50, Train iteration 31/164: Loss = 1.4911\n",
      "Epoch 27/50, Train iteration 32/164: Loss = 1.5467\n",
      "Epoch 27/50, Train iteration 33/164: Loss = 1.5660\n",
      "Epoch 27/50, Train iteration 34/164: Loss = 1.4661\n",
      "Epoch 27/50, Train iteration 35/164: Loss = 1.5322\n",
      "Epoch 27/50, Train iteration 36/164: Loss = 1.5623\n",
      "Epoch 27/50, Train iteration 37/164: Loss = 1.5606\n",
      "Epoch 27/50, Train iteration 38/164: Loss = 1.5705\n",
      "Epoch 27/50, Train iteration 39/164: Loss = 1.5572\n",
      "Epoch 27/50, Train iteration 40/164: Loss = 1.4755\n",
      "Epoch 27/50, Train iteration 41/164: Loss = 1.4397\n",
      "Epoch 27/50, Train iteration 42/164: Loss = 1.5413\n",
      "Epoch 27/50, Train iteration 43/164: Loss = 1.5033\n",
      "Epoch 27/50, Train iteration 44/164: Loss = 1.5149\n",
      "Epoch 27/50, Train iteration 45/164: Loss = 1.5537\n",
      "Epoch 27/50, Train iteration 46/164: Loss = 1.5702\n",
      "Epoch 27/50, Train iteration 47/164: Loss = 1.5762\n",
      "Epoch 27/50, Train iteration 48/164: Loss = 1.5565\n",
      "Epoch 27/50, Train iteration 49/164: Loss = 1.5317\n",
      "Epoch 27/50, Train iteration 50/164: Loss = 1.5760\n",
      "Epoch 27/50, Train iteration 51/164: Loss = 1.4721\n",
      "Epoch 27/50, Train iteration 52/164: Loss = 1.5112\n",
      "Epoch 27/50, Train iteration 53/164: Loss = 1.5650\n",
      "Epoch 27/50, Train iteration 54/164: Loss = 1.5705\n",
      "Epoch 27/50, Train iteration 55/164: Loss = 1.4866\n",
      "Epoch 27/50, Train iteration 56/164: Loss = 1.5515\n",
      "Epoch 27/50, Train iteration 57/164: Loss = 1.5518\n",
      "Epoch 27/50, Train iteration 58/164: Loss = 1.5486\n",
      "Epoch 27/50, Train iteration 59/164: Loss = 1.5655\n",
      "Epoch 27/50, Train iteration 60/164: Loss = 1.5262\n",
      "Epoch 27/50, Train iteration 61/164: Loss = 1.5201\n",
      "Epoch 27/50, Train iteration 62/164: Loss = 1.5035\n",
      "Epoch 27/50, Train iteration 63/164: Loss = 1.5979\n",
      "Epoch 27/50, Train iteration 64/164: Loss = 1.5455\n",
      "Epoch 27/50, Train iteration 65/164: Loss = 1.4633\n",
      "Epoch 27/50, Train iteration 66/164: Loss = 1.4751\n",
      "Epoch 27/50, Train iteration 67/164: Loss = 1.4866\n",
      "Epoch 27/50, Train iteration 68/164: Loss = 1.5264\n",
      "Epoch 27/50, Train iteration 69/164: Loss = 1.5218\n",
      "Epoch 27/50, Train iteration 70/164: Loss = 1.5339\n",
      "Epoch 27/50, Train iteration 71/164: Loss = 1.5378\n",
      "Epoch 27/50, Train iteration 72/164: Loss = 1.6261\n",
      "Epoch 27/50, Train iteration 73/164: Loss = 1.6219\n",
      "Epoch 27/50, Train iteration 74/164: Loss = 1.5308\n",
      "Epoch 27/50, Train iteration 75/164: Loss = 1.4809\n",
      "Epoch 27/50, Train iteration 76/164: Loss = 1.5675\n",
      "Epoch 27/50, Train iteration 77/164: Loss = 1.6052\n",
      "Epoch 27/50, Train iteration 78/164: Loss = 1.5562\n",
      "Epoch 27/50, Train iteration 79/164: Loss = 1.5329\n",
      "Epoch 27/50, Train iteration 80/164: Loss = 1.5705\n",
      "Epoch 27/50, Train iteration 81/164: Loss = 1.5565\n",
      "Epoch 27/50, Train iteration 82/164: Loss = 1.5192\n",
      "Epoch 27/50, Train iteration 83/164: Loss = 1.5409\n",
      "Epoch 27/50, Train iteration 84/164: Loss = 1.4622\n",
      "Epoch 27/50, Train iteration 85/164: Loss = 1.6287\n",
      "Epoch 27/50, Train iteration 86/164: Loss = 1.4399\n",
      "Epoch 27/50, Train iteration 87/164: Loss = 1.5835\n",
      "Epoch 27/50, Train iteration 88/164: Loss = 1.5954\n",
      "Epoch 27/50, Train iteration 89/164: Loss = 1.5682\n",
      "Epoch 27/50, Train iteration 90/164: Loss = 1.5050\n",
      "Epoch 27/50, Train iteration 91/164: Loss = 1.5795\n",
      "Epoch 27/50, Train iteration 92/164: Loss = 1.5942\n",
      "Epoch 27/50, Train iteration 93/164: Loss = 1.5303\n",
      "Epoch 27/50, Train iteration 94/164: Loss = 1.5993\n",
      "Epoch 27/50, Train iteration 95/164: Loss = 1.4583\n",
      "Epoch 27/50, Train iteration 96/164: Loss = 1.5650\n",
      "Epoch 27/50, Train iteration 97/164: Loss = 1.5416\n",
      "Epoch 27/50, Train iteration 98/164: Loss = 1.5071\n",
      "Epoch 27/50, Train iteration 99/164: Loss = 1.4502\n",
      "Epoch 27/50, Train iteration 100/164: Loss = 1.5427\n",
      "Epoch 27/50, Train iteration 101/164: Loss = 1.5143\n",
      "Epoch 27/50, Train iteration 102/164: Loss = 1.5580\n",
      "Epoch 27/50, Train iteration 103/164: Loss = 1.5654\n",
      "Epoch 27/50, Train iteration 104/164: Loss = 1.5790\n",
      "Epoch 27/50, Train iteration 105/164: Loss = 1.5720\n",
      "Epoch 27/50, Train iteration 106/164: Loss = 1.5733\n",
      "Epoch 27/50, Train iteration 107/164: Loss = 1.5093\n",
      "Epoch 27/50, Train iteration 108/164: Loss = 1.4950\n",
      "Epoch 27/50, Train iteration 109/164: Loss = 1.5520\n",
      "Epoch 27/50, Train iteration 110/164: Loss = 1.5381\n",
      "Epoch 27/50, Train iteration 111/164: Loss = 1.5614\n",
      "Epoch 27/50, Train iteration 112/164: Loss = 1.5889\n",
      "Epoch 27/50, Train iteration 113/164: Loss = 1.5274\n",
      "Epoch 27/50, Train iteration 114/164: Loss = 1.4664\n",
      "Epoch 27/50, Train iteration 115/164: Loss = 1.5502\n",
      "Epoch 27/50, Train iteration 116/164: Loss = 1.5020\n",
      "Epoch 27/50, Train iteration 117/164: Loss = 1.5054\n",
      "Epoch 27/50, Train iteration 118/164: Loss = 1.5605\n",
      "Epoch 27/50, Train iteration 119/164: Loss = 1.5425\n",
      "Epoch 27/50, Train iteration 120/164: Loss = 1.5909\n",
      "Epoch 27/50, Train iteration 121/164: Loss = 1.5150\n",
      "Epoch 27/50, Train iteration 122/164: Loss = 1.4919\n",
      "Epoch 27/50, Train iteration 123/164: Loss = 1.4851\n",
      "Epoch 27/50, Train iteration 124/164: Loss = 1.4807\n",
      "Epoch 27/50, Train iteration 125/164: Loss = 1.5218\n",
      "Epoch 27/50, Train iteration 126/164: Loss = 1.5017\n",
      "Epoch 27/50, Train iteration 127/164: Loss = 1.5408\n",
      "Epoch 27/50, Train iteration 128/164: Loss = 1.4734\n",
      "Epoch 27/50, Train iteration 129/164: Loss = 1.5340\n",
      "Epoch 27/50, Train iteration 130/164: Loss = 1.6041\n",
      "Epoch 27/50, Train iteration 131/164: Loss = 1.5802\n",
      "Epoch 27/50, Train iteration 132/164: Loss = 1.4422\n",
      "Epoch 27/50, Train iteration 133/164: Loss = 1.5518\n",
      "Epoch 27/50, Train iteration 134/164: Loss = 1.5307\n",
      "Epoch 27/50, Train iteration 135/164: Loss = 1.5240\n",
      "Epoch 27/50, Train iteration 136/164: Loss = 1.5616\n",
      "Epoch 27/50, Train iteration 137/164: Loss = 1.5050\n",
      "Epoch 27/50, Train iteration 138/164: Loss = 1.5193\n",
      "Epoch 27/50, Train iteration 139/164: Loss = 1.5647\n",
      "Epoch 27/50, Train iteration 140/164: Loss = 1.4901\n",
      "Epoch 27/50, Train iteration 141/164: Loss = 1.5616\n",
      "Epoch 27/50, Train iteration 142/164: Loss = 1.5786\n",
      "Epoch 27/50, Train iteration 143/164: Loss = 1.4844\n",
      "Epoch 27/50, Train iteration 144/164: Loss = 1.5789\n",
      "Epoch 27/50, Train iteration 145/164: Loss = 1.4826\n",
      "Epoch 27/50, Train iteration 146/164: Loss = 1.5144\n",
      "Epoch 27/50, Train iteration 147/164: Loss = 1.4940\n",
      "Epoch 27/50, Train iteration 148/164: Loss = 1.4688\n",
      "Epoch 27/50, Train iteration 149/164: Loss = 1.5208\n",
      "Epoch 27/50, Train iteration 150/164: Loss = 1.5541\n",
      "Epoch 27/50, Train iteration 151/164: Loss = 1.5671\n",
      "Epoch 27/50, Train iteration 152/164: Loss = 1.4597\n",
      "Epoch 27/50, Train iteration 153/164: Loss = 1.5526\n",
      "Epoch 27/50, Train iteration 154/164: Loss = 1.5257\n",
      "Epoch 27/50, Train iteration 155/164: Loss = 1.5314\n",
      "Epoch 27/50, Train iteration 156/164: Loss = 1.5028\n",
      "Epoch 27/50, Train iteration 157/164: Loss = 1.5349\n",
      "Epoch 27/50, Train iteration 158/164: Loss = 1.6042\n",
      "Epoch 27/50, Train iteration 159/164: Loss = 1.5459\n",
      "Epoch 27/50, Train iteration 160/164: Loss = 1.5334\n",
      "Epoch 27/50, Train iteration 161/164: Loss = 1.5772\n",
      "Epoch 27/50, Train iteration 162/164: Loss = 1.5675\n",
      "Epoch 27/50, Train iteration 163/164: Loss = 1.5045\n",
      "Epoch 27/50, Train iteration 164/164: Loss = 1.4127\n",
      "Epoch 27/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 27/50, Val iteration 2/27: Loss = 1.6206\n",
      "Epoch 27/50, Val iteration 3/27: Loss = 1.5916\n",
      "Epoch 27/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 27/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 27/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 27/50, Val iteration 7/27: Loss = 1.5548\n",
      "Epoch 27/50, Val iteration 8/27: Loss = 1.6137\n",
      "Epoch 27/50, Val iteration 9/27: Loss = 1.5870\n",
      "Epoch 27/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 27/50, Val iteration 11/27: Loss = 1.6001\n",
      "Epoch 27/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 27/50, Val iteration 13/27: Loss = 1.5708\n",
      "Epoch 27/50, Val iteration 14/27: Loss = 1.5445\n",
      "Epoch 27/50, Val iteration 15/27: Loss = 1.5896\n",
      "Epoch 27/50, Val iteration 16/27: Loss = 1.5805\n",
      "Epoch 27/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 27/50, Val iteration 18/27: Loss = 1.5563\n",
      "Epoch 27/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 27/50, Val iteration 20/27: Loss = 1.5973\n",
      "Epoch 27/50, Val iteration 21/27: Loss = 1.5869\n",
      "Epoch 27/50, Val iteration 22/27: Loss = 1.6040\n",
      "Epoch 27/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 27/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 27/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 27/50, Val iteration 26/27: Loss = 1.5934\n",
      "Epoch 27/50, Val iteration 27/27: Loss = 1.6051\n",
      "Epoch 27/50: Train Loss = 1.5391, Val Loss = 1.5831\n",
      "Current learning rate: 2.43e-07\n",
      "Epoch 28/50, Train iteration 1/164: Loss = 1.5306\n",
      "Epoch 28/50, Train iteration 2/164: Loss = 1.5329\n",
      "Epoch 28/50, Train iteration 3/164: Loss = 1.5811\n",
      "Epoch 28/50, Train iteration 4/164: Loss = 1.5737\n",
      "Epoch 28/50, Train iteration 5/164: Loss = 1.5645\n",
      "Epoch 28/50, Train iteration 6/164: Loss = 1.5735\n",
      "Epoch 28/50, Train iteration 7/164: Loss = 1.5639\n",
      "Epoch 28/50, Train iteration 8/164: Loss = 1.4945\n",
      "Epoch 28/50, Train iteration 9/164: Loss = 1.6078\n",
      "Epoch 28/50, Train iteration 10/164: Loss = 1.5793\n",
      "Epoch 28/50, Train iteration 11/164: Loss = 1.5758\n",
      "Epoch 28/50, Train iteration 12/164: Loss = 1.5746\n",
      "Epoch 28/50, Train iteration 13/164: Loss = 1.4886\n",
      "Epoch 28/50, Train iteration 14/164: Loss = 1.5388\n",
      "Epoch 28/50, Train iteration 15/164: Loss = 1.5396\n",
      "Epoch 28/50, Train iteration 16/164: Loss = 1.5583\n",
      "Epoch 28/50, Train iteration 17/164: Loss = 1.5286\n",
      "Epoch 28/50, Train iteration 18/164: Loss = 1.5486\n",
      "Epoch 28/50, Train iteration 19/164: Loss = 1.5053\n",
      "Epoch 28/50, Train iteration 20/164: Loss = 1.5183\n",
      "Epoch 28/50, Train iteration 21/164: Loss = 1.5349\n",
      "Epoch 28/50, Train iteration 22/164: Loss = 1.5822\n",
      "Epoch 28/50, Train iteration 23/164: Loss = 1.5369\n",
      "Epoch 28/50, Train iteration 24/164: Loss = 1.5711\n",
      "Epoch 28/50, Train iteration 25/164: Loss = 1.5967\n",
      "Epoch 28/50, Train iteration 26/164: Loss = 1.5010\n",
      "Epoch 28/50, Train iteration 27/164: Loss = 1.5672\n",
      "Epoch 28/50, Train iteration 28/164: Loss = 1.5442\n",
      "Epoch 28/50, Train iteration 29/164: Loss = 1.5473\n",
      "Epoch 28/50, Train iteration 30/164: Loss = 1.5833\n",
      "Epoch 28/50, Train iteration 31/164: Loss = 1.4775\n",
      "Epoch 28/50, Train iteration 32/164: Loss = 1.5091\n",
      "Epoch 28/50, Train iteration 33/164: Loss = 1.6008\n",
      "Epoch 28/50, Train iteration 34/164: Loss = 1.4943\n",
      "Epoch 28/50, Train iteration 35/164: Loss = 1.5208\n",
      "Epoch 28/50, Train iteration 36/164: Loss = 1.5255\n",
      "Epoch 28/50, Train iteration 37/164: Loss = 1.5290\n",
      "Epoch 28/50, Train iteration 38/164: Loss = 1.5426\n",
      "Epoch 28/50, Train iteration 39/164: Loss = 1.5267\n",
      "Epoch 28/50, Train iteration 40/164: Loss = 1.5114\n",
      "Epoch 28/50, Train iteration 41/164: Loss = 1.5294\n",
      "Epoch 28/50, Train iteration 42/164: Loss = 1.5308\n",
      "Epoch 28/50, Train iteration 43/164: Loss = 1.5300\n",
      "Epoch 28/50, Train iteration 44/164: Loss = 1.4973\n",
      "Epoch 28/50, Train iteration 45/164: Loss = 1.5152\n",
      "Epoch 28/50, Train iteration 46/164: Loss = 1.5413\n",
      "Epoch 28/50, Train iteration 47/164: Loss = 1.5871\n",
      "Epoch 28/50, Train iteration 48/164: Loss = 1.5488\n",
      "Epoch 28/50, Train iteration 49/164: Loss = 1.5095\n",
      "Epoch 28/50, Train iteration 50/164: Loss = 1.6073\n",
      "Epoch 28/50, Train iteration 51/164: Loss = 1.5176\n",
      "Epoch 28/50, Train iteration 52/164: Loss = 1.4955\n",
      "Epoch 28/50, Train iteration 53/164: Loss = 1.4969\n",
      "Epoch 28/50, Train iteration 54/164: Loss = 1.5349\n",
      "Epoch 28/50, Train iteration 55/164: Loss = 1.4907\n",
      "Epoch 28/50, Train iteration 56/164: Loss = 1.5388\n",
      "Epoch 28/50, Train iteration 57/164: Loss = 1.5725\n",
      "Epoch 28/50, Train iteration 58/164: Loss = 1.5385\n",
      "Epoch 28/50, Train iteration 59/164: Loss = 1.5771\n",
      "Epoch 28/50, Train iteration 60/164: Loss = 1.5000\n",
      "Epoch 28/50, Train iteration 61/164: Loss = 1.4585\n",
      "Epoch 28/50, Train iteration 62/164: Loss = 1.4852\n",
      "Epoch 28/50, Train iteration 63/164: Loss = 1.5902\n",
      "Epoch 28/50, Train iteration 64/164: Loss = 1.5147\n",
      "Epoch 28/50, Train iteration 65/164: Loss = 1.4573\n",
      "Epoch 28/50, Train iteration 66/164: Loss = 1.4647\n",
      "Epoch 28/50, Train iteration 67/164: Loss = 1.5201\n",
      "Epoch 28/50, Train iteration 68/164: Loss = 1.4592\n",
      "Epoch 28/50, Train iteration 69/164: Loss = 1.5531\n",
      "Epoch 28/50, Train iteration 70/164: Loss = 1.5481\n",
      "Epoch 28/50, Train iteration 71/164: Loss = 1.5330\n",
      "Epoch 28/50, Train iteration 72/164: Loss = 1.5615\n",
      "Epoch 28/50, Train iteration 73/164: Loss = 1.5958\n",
      "Epoch 28/50, Train iteration 74/164: Loss = 1.4968\n",
      "Epoch 28/50, Train iteration 75/164: Loss = 1.5038\n",
      "Epoch 28/50, Train iteration 76/164: Loss = 1.5386\n",
      "Epoch 28/50, Train iteration 77/164: Loss = 1.5642\n",
      "Epoch 28/50, Train iteration 78/164: Loss = 1.5175\n",
      "Epoch 28/50, Train iteration 79/164: Loss = 1.5340\n",
      "Epoch 28/50, Train iteration 80/164: Loss = 1.5681\n",
      "Epoch 28/50, Train iteration 81/164: Loss = 1.5248\n",
      "Epoch 28/50, Train iteration 82/164: Loss = 1.5256\n",
      "Epoch 28/50, Train iteration 83/164: Loss = 1.5431\n",
      "Epoch 28/50, Train iteration 84/164: Loss = 1.5012\n",
      "Epoch 28/50, Train iteration 85/164: Loss = 1.5698\n",
      "Epoch 28/50, Train iteration 86/164: Loss = 1.4661\n",
      "Epoch 28/50, Train iteration 87/164: Loss = 1.5551\n",
      "Epoch 28/50, Train iteration 88/164: Loss = 1.5480\n",
      "Epoch 28/50, Train iteration 89/164: Loss = 1.5627\n",
      "Epoch 28/50, Train iteration 90/164: Loss = 1.5116\n",
      "Epoch 28/50, Train iteration 91/164: Loss = 1.5892\n",
      "Epoch 28/50, Train iteration 92/164: Loss = 1.5740\n",
      "Epoch 28/50, Train iteration 93/164: Loss = 1.5120\n",
      "Epoch 28/50, Train iteration 94/164: Loss = 1.6074\n",
      "Epoch 28/50, Train iteration 95/164: Loss = 1.4747\n",
      "Epoch 28/50, Train iteration 96/164: Loss = 1.6005\n",
      "Epoch 28/50, Train iteration 97/164: Loss = 1.6054\n",
      "Epoch 28/50, Train iteration 98/164: Loss = 1.5433\n",
      "Epoch 28/50, Train iteration 99/164: Loss = 1.4455\n",
      "Epoch 28/50, Train iteration 100/164: Loss = 1.5536\n",
      "Epoch 28/50, Train iteration 101/164: Loss = 1.5072\n",
      "Epoch 28/50, Train iteration 102/164: Loss = 1.5385\n",
      "Epoch 28/50, Train iteration 103/164: Loss = 1.5822\n",
      "Epoch 28/50, Train iteration 104/164: Loss = 1.5503\n",
      "Epoch 28/50, Train iteration 105/164: Loss = 1.5613\n",
      "Epoch 28/50, Train iteration 106/164: Loss = 1.5281\n",
      "Epoch 28/50, Train iteration 107/164: Loss = 1.5537\n",
      "Epoch 28/50, Train iteration 108/164: Loss = 1.5288\n",
      "Epoch 28/50, Train iteration 109/164: Loss = 1.5228\n",
      "Epoch 28/50, Train iteration 110/164: Loss = 1.5346\n",
      "Epoch 28/50, Train iteration 111/164: Loss = 1.5830\n",
      "Epoch 28/50, Train iteration 112/164: Loss = 1.5212\n",
      "Epoch 28/50, Train iteration 113/164: Loss = 1.5258\n",
      "Epoch 28/50, Train iteration 114/164: Loss = 1.4711\n",
      "Epoch 28/50, Train iteration 115/164: Loss = 1.4776\n",
      "Epoch 28/50, Train iteration 116/164: Loss = 1.4475\n",
      "Epoch 28/50, Train iteration 117/164: Loss = 1.4663\n",
      "Epoch 28/50, Train iteration 118/164: Loss = 1.5548\n",
      "Epoch 28/50, Train iteration 119/164: Loss = 1.5595\n",
      "Epoch 28/50, Train iteration 120/164: Loss = 1.5600\n",
      "Epoch 28/50, Train iteration 121/164: Loss = 1.5494\n",
      "Epoch 28/50, Train iteration 122/164: Loss = 1.4515\n",
      "Epoch 28/50, Train iteration 123/164: Loss = 1.5198\n",
      "Epoch 28/50, Train iteration 124/164: Loss = 1.5753\n",
      "Epoch 28/50, Train iteration 125/164: Loss = 1.4697\n",
      "Epoch 28/50, Train iteration 126/164: Loss = 1.4796\n",
      "Epoch 28/50, Train iteration 127/164: Loss = 1.6069\n",
      "Epoch 28/50, Train iteration 128/164: Loss = 1.4625\n",
      "Epoch 28/50, Train iteration 129/164: Loss = 1.5196\n",
      "Epoch 28/50, Train iteration 130/164: Loss = 1.5260\n",
      "Epoch 28/50, Train iteration 131/164: Loss = 1.5646\n",
      "Epoch 28/50, Train iteration 132/164: Loss = 1.5275\n",
      "Epoch 28/50, Train iteration 133/164: Loss = 1.5999\n",
      "Epoch 28/50, Train iteration 134/164: Loss = 1.4968\n",
      "Epoch 28/50, Train iteration 135/164: Loss = 1.5316\n",
      "Epoch 28/50, Train iteration 136/164: Loss = 1.5510\n",
      "Epoch 28/50, Train iteration 137/164: Loss = 1.5134\n",
      "Epoch 28/50, Train iteration 138/164: Loss = 1.5377\n",
      "Epoch 28/50, Train iteration 139/164: Loss = 1.6135\n",
      "Epoch 28/50, Train iteration 140/164: Loss = 1.5539\n",
      "Epoch 28/50, Train iteration 141/164: Loss = 1.4881\n",
      "Epoch 28/50, Train iteration 142/164: Loss = 1.5919\n",
      "Epoch 28/50, Train iteration 143/164: Loss = 1.5303\n",
      "Epoch 28/50, Train iteration 144/164: Loss = 1.5747\n",
      "Epoch 28/50, Train iteration 145/164: Loss = 1.5118\n",
      "Epoch 28/50, Train iteration 146/164: Loss = 1.4882\n",
      "Epoch 28/50, Train iteration 147/164: Loss = 1.4992\n",
      "Epoch 28/50, Train iteration 148/164: Loss = 1.5015\n",
      "Epoch 28/50, Train iteration 149/164: Loss = 1.5597\n",
      "Epoch 28/50, Train iteration 150/164: Loss = 1.5775\n",
      "Epoch 28/50, Train iteration 151/164: Loss = 1.5339\n",
      "Epoch 28/50, Train iteration 152/164: Loss = 1.5068\n",
      "Epoch 28/50, Train iteration 153/164: Loss = 1.5887\n",
      "Epoch 28/50, Train iteration 154/164: Loss = 1.4683\n",
      "Epoch 28/50, Train iteration 155/164: Loss = 1.5723\n",
      "Epoch 28/50, Train iteration 156/164: Loss = 1.5308\n",
      "Epoch 28/50, Train iteration 157/164: Loss = 1.5366\n",
      "Epoch 28/50, Train iteration 158/164: Loss = 1.5711\n",
      "Epoch 28/50, Train iteration 159/164: Loss = 1.5545\n",
      "Epoch 28/50, Train iteration 160/164: Loss = 1.5417\n",
      "Epoch 28/50, Train iteration 161/164: Loss = 1.6084\n",
      "Epoch 28/50, Train iteration 162/164: Loss = 1.5611\n",
      "Epoch 28/50, Train iteration 163/164: Loss = 1.5438\n",
      "Epoch 28/50, Train iteration 164/164: Loss = 1.2067\n",
      "Epoch 28/50, Val iteration 1/27: Loss = 1.6129\n",
      "Epoch 28/50, Val iteration 2/27: Loss = 1.6207\n",
      "Epoch 28/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 28/50, Val iteration 4/27: Loss = 1.5951\n",
      "Epoch 28/50, Val iteration 5/27: Loss = 1.6153\n",
      "Epoch 28/50, Val iteration 6/27: Loss = 1.5814\n",
      "Epoch 28/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 28/50, Val iteration 8/27: Loss = 1.6140\n",
      "Epoch 28/50, Val iteration 9/27: Loss = 1.5870\n",
      "Epoch 28/50, Val iteration 10/27: Loss = 1.5777\n",
      "Epoch 28/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 28/50, Val iteration 12/27: Loss = 1.5651\n",
      "Epoch 28/50, Val iteration 13/27: Loss = 1.5705\n",
      "Epoch 28/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 28/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 28/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 28/50, Val iteration 17/27: Loss = 1.5944\n",
      "Epoch 28/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 28/50, Val iteration 19/27: Loss = 1.5770\n",
      "Epoch 28/50, Val iteration 20/27: Loss = 1.5973\n",
      "Epoch 28/50, Val iteration 21/27: Loss = 1.5869\n",
      "Epoch 28/50, Val iteration 22/27: Loss = 1.6044\n",
      "Epoch 28/50, Val iteration 23/27: Loss = 1.4849\n",
      "Epoch 28/50, Val iteration 24/27: Loss = 1.5582\n",
      "Epoch 28/50, Val iteration 25/27: Loss = 1.5857\n",
      "Epoch 28/50, Val iteration 26/27: Loss = 1.5932\n",
      "Epoch 28/50, Val iteration 27/27: Loss = 1.6055\n",
      "Epoch 28/50: Train Loss = 1.5341, Val Loss = 1.5831\n",
      "Current learning rate: 2.43e-07\n",
      "Epoch 29/50, Train iteration 1/164: Loss = 1.5366\n",
      "Epoch 29/50, Train iteration 2/164: Loss = 1.5529\n",
      "Epoch 29/50, Train iteration 3/164: Loss = 1.5350\n",
      "Epoch 29/50, Train iteration 4/164: Loss = 1.5671\n",
      "Epoch 29/50, Train iteration 5/164: Loss = 1.5719\n",
      "Epoch 29/50, Train iteration 6/164: Loss = 1.6074\n",
      "Epoch 29/50, Train iteration 7/164: Loss = 1.5944\n",
      "Epoch 29/50, Train iteration 8/164: Loss = 1.4911\n",
      "Epoch 29/50, Train iteration 9/164: Loss = 1.6171\n",
      "Epoch 29/50, Train iteration 10/164: Loss = 1.6072\n",
      "Epoch 29/50, Train iteration 11/164: Loss = 1.5969\n",
      "Epoch 29/50, Train iteration 12/164: Loss = 1.5263\n",
      "Epoch 29/50, Train iteration 13/164: Loss = 1.4584\n",
      "Epoch 29/50, Train iteration 14/164: Loss = 1.5890\n",
      "Epoch 29/50, Train iteration 15/164: Loss = 1.5534\n",
      "Epoch 29/50, Train iteration 16/164: Loss = 1.5451\n",
      "Epoch 29/50, Train iteration 17/164: Loss = 1.5546\n",
      "Epoch 29/50, Train iteration 18/164: Loss = 1.6037\n",
      "Epoch 29/50, Train iteration 19/164: Loss = 1.5242\n",
      "Epoch 29/50, Train iteration 20/164: Loss = 1.5999\n",
      "Epoch 29/50, Train iteration 21/164: Loss = 1.5921\n",
      "Epoch 29/50, Train iteration 22/164: Loss = 1.5967\n",
      "Epoch 29/50, Train iteration 23/164: Loss = 1.5455\n",
      "Epoch 29/50, Train iteration 24/164: Loss = 1.5243\n",
      "Epoch 29/50, Train iteration 25/164: Loss = 1.6128\n",
      "Epoch 29/50, Train iteration 26/164: Loss = 1.5513\n",
      "Epoch 29/50, Train iteration 27/164: Loss = 1.5473\n",
      "Epoch 29/50, Train iteration 28/164: Loss = 1.5531\n",
      "Epoch 29/50, Train iteration 29/164: Loss = 1.5387\n",
      "Epoch 29/50, Train iteration 30/164: Loss = 1.5550\n",
      "Epoch 29/50, Train iteration 31/164: Loss = 1.4782\n",
      "Epoch 29/50, Train iteration 32/164: Loss = 1.5048\n",
      "Epoch 29/50, Train iteration 33/164: Loss = 1.5947\n",
      "Epoch 29/50, Train iteration 34/164: Loss = 1.5084\n",
      "Epoch 29/50, Train iteration 35/164: Loss = 1.5397\n",
      "Epoch 29/50, Train iteration 36/164: Loss = 1.4928\n",
      "Epoch 29/50, Train iteration 37/164: Loss = 1.5359\n",
      "Epoch 29/50, Train iteration 38/164: Loss = 1.4850\n",
      "Epoch 29/50, Train iteration 39/164: Loss = 1.5757\n",
      "Epoch 29/50, Train iteration 40/164: Loss = 1.5396\n",
      "Epoch 29/50, Train iteration 41/164: Loss = 1.4760\n",
      "Epoch 29/50, Train iteration 42/164: Loss = 1.5563\n",
      "Epoch 29/50, Train iteration 43/164: Loss = 1.5527\n",
      "Epoch 29/50, Train iteration 44/164: Loss = 1.5327\n",
      "Epoch 29/50, Train iteration 45/164: Loss = 1.5382\n",
      "Epoch 29/50, Train iteration 46/164: Loss = 1.5396\n",
      "Epoch 29/50, Train iteration 47/164: Loss = 1.5569\n",
      "Epoch 29/50, Train iteration 48/164: Loss = 1.5677\n",
      "Epoch 29/50, Train iteration 49/164: Loss = 1.5218\n",
      "Epoch 29/50, Train iteration 50/164: Loss = 1.5684\n",
      "Epoch 29/50, Train iteration 51/164: Loss = 1.4917\n",
      "Epoch 29/50, Train iteration 52/164: Loss = 1.5486\n",
      "Epoch 29/50, Train iteration 53/164: Loss = 1.5471\n",
      "Epoch 29/50, Train iteration 54/164: Loss = 1.5204\n",
      "Epoch 29/50, Train iteration 55/164: Loss = 1.5756\n",
      "Epoch 29/50, Train iteration 56/164: Loss = 1.5564\n",
      "Epoch 29/50, Train iteration 57/164: Loss = 1.5157\n",
      "Epoch 29/50, Train iteration 58/164: Loss = 1.6010\n",
      "Epoch 29/50, Train iteration 59/164: Loss = 1.5199\n",
      "Epoch 29/50, Train iteration 60/164: Loss = 1.5352\n",
      "Epoch 29/50, Train iteration 61/164: Loss = 1.4871\n",
      "Epoch 29/50, Train iteration 62/164: Loss = 1.4834\n",
      "Epoch 29/50, Train iteration 63/164: Loss = 1.6256\n",
      "Epoch 29/50, Train iteration 64/164: Loss = 1.5186\n",
      "Epoch 29/50, Train iteration 65/164: Loss = 1.5072\n",
      "Epoch 29/50, Train iteration 66/164: Loss = 1.4324\n",
      "Epoch 29/50, Train iteration 67/164: Loss = 1.4816\n",
      "Epoch 29/50, Train iteration 68/164: Loss = 1.5114\n",
      "Epoch 29/50, Train iteration 69/164: Loss = 1.5300\n",
      "Epoch 29/50, Train iteration 70/164: Loss = 1.5945\n",
      "Epoch 29/50, Train iteration 71/164: Loss = 1.5874\n",
      "Epoch 29/50, Train iteration 72/164: Loss = 1.5331\n",
      "Epoch 29/50, Train iteration 73/164: Loss = 1.6017\n",
      "Epoch 29/50, Train iteration 74/164: Loss = 1.5711\n",
      "Epoch 29/50, Train iteration 75/164: Loss = 1.4633\n",
      "Epoch 29/50, Train iteration 76/164: Loss = 1.5782\n",
      "Epoch 29/50, Train iteration 77/164: Loss = 1.6404\n",
      "Epoch 29/50, Train iteration 78/164: Loss = 1.5333\n",
      "Epoch 29/50, Train iteration 79/164: Loss = 1.5254\n",
      "Epoch 29/50, Train iteration 80/164: Loss = 1.5422\n",
      "Epoch 29/50, Train iteration 81/164: Loss = 1.5268\n",
      "Epoch 29/50, Train iteration 82/164: Loss = 1.4986\n",
      "Epoch 29/50, Train iteration 83/164: Loss = 1.5739\n",
      "Epoch 29/50, Train iteration 84/164: Loss = 1.5254\n",
      "Epoch 29/50, Train iteration 85/164: Loss = 1.5924\n",
      "Epoch 29/50, Train iteration 86/164: Loss = 1.4370\n",
      "Epoch 29/50, Train iteration 87/164: Loss = 1.5268\n",
      "Epoch 29/50, Train iteration 88/164: Loss = 1.5866\n",
      "Epoch 29/50, Train iteration 89/164: Loss = 1.5459\n",
      "Epoch 29/50, Train iteration 90/164: Loss = 1.4972\n",
      "Epoch 29/50, Train iteration 91/164: Loss = 1.5610\n",
      "Epoch 29/50, Train iteration 92/164: Loss = 1.5741\n",
      "Epoch 29/50, Train iteration 93/164: Loss = 1.5789\n",
      "Epoch 29/50, Train iteration 94/164: Loss = 1.5237\n",
      "Epoch 29/50, Train iteration 95/164: Loss = 1.4995\n",
      "Epoch 29/50, Train iteration 96/164: Loss = 1.6198\n",
      "Epoch 29/50, Train iteration 97/164: Loss = 1.5575\n",
      "Epoch 29/50, Train iteration 98/164: Loss = 1.5810\n",
      "Epoch 29/50, Train iteration 99/164: Loss = 1.4994\n",
      "Epoch 29/50, Train iteration 100/164: Loss = 1.5325\n",
      "Epoch 29/50, Train iteration 101/164: Loss = 1.4959\n",
      "Epoch 29/50, Train iteration 102/164: Loss = 1.5774\n",
      "Epoch 29/50, Train iteration 103/164: Loss = 1.6003\n",
      "Epoch 29/50, Train iteration 104/164: Loss = 1.5177\n",
      "Epoch 29/50, Train iteration 105/164: Loss = 1.5486\n",
      "Epoch 29/50, Train iteration 106/164: Loss = 1.5284\n",
      "Epoch 29/50, Train iteration 107/164: Loss = 1.6051\n",
      "Epoch 29/50, Train iteration 108/164: Loss = 1.5367\n",
      "Epoch 29/50, Train iteration 109/164: Loss = 1.5475\n",
      "Epoch 29/50, Train iteration 110/164: Loss = 1.4814\n",
      "Epoch 29/50, Train iteration 111/164: Loss = 1.6000\n",
      "Epoch 29/50, Train iteration 112/164: Loss = 1.6040\n",
      "Epoch 29/50, Train iteration 113/164: Loss = 1.5429\n",
      "Epoch 29/50, Train iteration 114/164: Loss = 1.4517\n",
      "Epoch 29/50, Train iteration 115/164: Loss = 1.5150\n",
      "Epoch 29/50, Train iteration 116/164: Loss = 1.5181\n",
      "Epoch 29/50, Train iteration 117/164: Loss = 1.4761\n",
      "Epoch 29/50, Train iteration 118/164: Loss = 1.5629\n",
      "Epoch 29/50, Train iteration 119/164: Loss = 1.5396\n",
      "Epoch 29/50, Train iteration 120/164: Loss = 1.5209\n",
      "Epoch 29/50, Train iteration 121/164: Loss = 1.5320\n",
      "Epoch 29/50, Train iteration 122/164: Loss = 1.4399\n",
      "Epoch 29/50, Train iteration 123/164: Loss = 1.4909\n",
      "Epoch 29/50, Train iteration 124/164: Loss = 1.5268\n",
      "Epoch 29/50, Train iteration 125/164: Loss = 1.4547\n",
      "Epoch 29/50, Train iteration 126/164: Loss = 1.5281\n",
      "Epoch 29/50, Train iteration 127/164: Loss = 1.6040\n",
      "Epoch 29/50, Train iteration 128/164: Loss = 1.4833\n",
      "Epoch 29/50, Train iteration 129/164: Loss = 1.4647\n",
      "Epoch 29/50, Train iteration 130/164: Loss = 1.5527\n",
      "Epoch 29/50, Train iteration 131/164: Loss = 1.5744\n",
      "Epoch 29/50, Train iteration 132/164: Loss = 1.5223\n",
      "Epoch 29/50, Train iteration 133/164: Loss = 1.5781\n",
      "Epoch 29/50, Train iteration 134/164: Loss = 1.4746\n",
      "Epoch 29/50, Train iteration 135/164: Loss = 1.5631\n",
      "Epoch 29/50, Train iteration 136/164: Loss = 1.5684\n",
      "Epoch 29/50, Train iteration 137/164: Loss = 1.5248\n",
      "Epoch 29/50, Train iteration 138/164: Loss = 1.5376\n",
      "Epoch 29/50, Train iteration 139/164: Loss = 1.6222\n",
      "Epoch 29/50, Train iteration 140/164: Loss = 1.5422\n",
      "Epoch 29/50, Train iteration 141/164: Loss = 1.4713\n",
      "Epoch 29/50, Train iteration 142/164: Loss = 1.5748\n",
      "Epoch 29/50, Train iteration 143/164: Loss = 1.4413\n",
      "Epoch 29/50, Train iteration 144/164: Loss = 1.5993\n",
      "Epoch 29/50, Train iteration 145/164: Loss = 1.5025\n",
      "Epoch 29/50, Train iteration 146/164: Loss = 1.4956\n",
      "Epoch 29/50, Train iteration 147/164: Loss = 1.5376\n",
      "Epoch 29/50, Train iteration 148/164: Loss = 1.4907\n",
      "Epoch 29/50, Train iteration 149/164: Loss = 1.5215\n",
      "Epoch 29/50, Train iteration 150/164: Loss = 1.5735\n",
      "Epoch 29/50, Train iteration 151/164: Loss = 1.6070\n",
      "Epoch 29/50, Train iteration 152/164: Loss = 1.4817\n",
      "Epoch 29/50, Train iteration 153/164: Loss = 1.5631\n",
      "Epoch 29/50, Train iteration 154/164: Loss = 1.4758\n",
      "Epoch 29/50, Train iteration 155/164: Loss = 1.5323\n",
      "Epoch 29/50, Train iteration 156/164: Loss = 1.5190\n",
      "Epoch 29/50, Train iteration 157/164: Loss = 1.5145\n",
      "Epoch 29/50, Train iteration 158/164: Loss = 1.5949\n",
      "Epoch 29/50, Train iteration 159/164: Loss = 1.5655\n",
      "Epoch 29/50, Train iteration 160/164: Loss = 1.5515\n",
      "Epoch 29/50, Train iteration 161/164: Loss = 1.6270\n",
      "Epoch 29/50, Train iteration 162/164: Loss = 1.5435\n",
      "Epoch 29/50, Train iteration 163/164: Loss = 1.5087\n",
      "Epoch 29/50, Train iteration 164/164: Loss = 1.4120\n",
      "Epoch 29/50, Val iteration 1/27: Loss = 1.6128\n",
      "Epoch 29/50, Val iteration 2/27: Loss = 1.6206\n",
      "Epoch 29/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 29/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 29/50, Val iteration 5/27: Loss = 1.6152\n",
      "Epoch 29/50, Val iteration 6/27: Loss = 1.5813\n",
      "Epoch 29/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 29/50, Val iteration 8/27: Loss = 1.6139\n",
      "Epoch 29/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 29/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 29/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 29/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 29/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 29/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 29/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 29/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 29/50, Val iteration 17/27: Loss = 1.5943\n",
      "Epoch 29/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 29/50, Val iteration 19/27: Loss = 1.5770\n",
      "Epoch 29/50, Val iteration 20/27: Loss = 1.5973\n",
      "Epoch 29/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 29/50, Val iteration 22/27: Loss = 1.6042\n",
      "Epoch 29/50, Val iteration 23/27: Loss = 1.4851\n",
      "Epoch 29/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 29/50, Val iteration 25/27: Loss = 1.5856\n",
      "Epoch 29/50, Val iteration 26/27: Loss = 1.5932\n",
      "Epoch 29/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 29/50: Train Loss = 1.5401, Val Loss = 1.5831\n",
      "Current learning rate: 7.29e-08\n",
      "Epoch 30/50, Train iteration 1/164: Loss = 1.5240\n",
      "Epoch 30/50, Train iteration 2/164: Loss = 1.5522\n",
      "Epoch 30/50, Train iteration 3/164: Loss = 1.5344\n",
      "Epoch 30/50, Train iteration 4/164: Loss = 1.5492\n",
      "Epoch 30/50, Train iteration 5/164: Loss = 1.5680\n",
      "Epoch 30/50, Train iteration 6/164: Loss = 1.6242\n",
      "Epoch 30/50, Train iteration 7/164: Loss = 1.6102\n",
      "Epoch 30/50, Train iteration 8/164: Loss = 1.4751\n",
      "Epoch 30/50, Train iteration 9/164: Loss = 1.5521\n",
      "Epoch 30/50, Train iteration 10/164: Loss = 1.5940\n",
      "Epoch 30/50, Train iteration 11/164: Loss = 1.5646\n",
      "Epoch 30/50, Train iteration 12/164: Loss = 1.5672\n",
      "Epoch 30/50, Train iteration 13/164: Loss = 1.4797\n",
      "Epoch 30/50, Train iteration 14/164: Loss = 1.5797\n",
      "Epoch 30/50, Train iteration 15/164: Loss = 1.5392\n",
      "Epoch 30/50, Train iteration 16/164: Loss = 1.5387\n",
      "Epoch 30/50, Train iteration 17/164: Loss = 1.5724\n",
      "Epoch 30/50, Train iteration 18/164: Loss = 1.5448\n",
      "Epoch 30/50, Train iteration 19/164: Loss = 1.5283\n",
      "Epoch 30/50, Train iteration 20/164: Loss = 1.5170\n",
      "Epoch 30/50, Train iteration 21/164: Loss = 1.5655\n",
      "Epoch 30/50, Train iteration 22/164: Loss = 1.5696\n",
      "Epoch 30/50, Train iteration 23/164: Loss = 1.5254\n",
      "Epoch 30/50, Train iteration 24/164: Loss = 1.5851\n",
      "Epoch 30/50, Train iteration 25/164: Loss = 1.5974\n",
      "Epoch 30/50, Train iteration 26/164: Loss = 1.5411\n",
      "Epoch 30/50, Train iteration 27/164: Loss = 1.5600\n",
      "Epoch 30/50, Train iteration 28/164: Loss = 1.5235\n",
      "Epoch 30/50, Train iteration 29/164: Loss = 1.5405\n",
      "Epoch 30/50, Train iteration 30/164: Loss = 1.6026\n",
      "Epoch 30/50, Train iteration 31/164: Loss = 1.4896\n",
      "Epoch 30/50, Train iteration 32/164: Loss = 1.5248\n",
      "Epoch 30/50, Train iteration 33/164: Loss = 1.5712\n",
      "Epoch 30/50, Train iteration 34/164: Loss = 1.5230\n",
      "Epoch 30/50, Train iteration 35/164: Loss = 1.5328\n",
      "Epoch 30/50, Train iteration 36/164: Loss = 1.5430\n",
      "Epoch 30/50, Train iteration 37/164: Loss = 1.5379\n",
      "Epoch 30/50, Train iteration 38/164: Loss = 1.5182\n",
      "Epoch 30/50, Train iteration 39/164: Loss = 1.5282\n",
      "Epoch 30/50, Train iteration 40/164: Loss = 1.4918\n",
      "Epoch 30/50, Train iteration 41/164: Loss = 1.4919\n",
      "Epoch 30/50, Train iteration 42/164: Loss = 1.6009\n",
      "Epoch 30/50, Train iteration 43/164: Loss = 1.5215\n",
      "Epoch 30/50, Train iteration 44/164: Loss = 1.5095\n",
      "Epoch 30/50, Train iteration 45/164: Loss = 1.5554\n",
      "Epoch 30/50, Train iteration 46/164: Loss = 1.5660\n",
      "Epoch 30/50, Train iteration 47/164: Loss = 1.5408\n",
      "Epoch 30/50, Train iteration 48/164: Loss = 1.4869\n",
      "Epoch 30/50, Train iteration 49/164: Loss = 1.5207\n",
      "Epoch 30/50, Train iteration 50/164: Loss = 1.5936\n",
      "Epoch 30/50, Train iteration 51/164: Loss = 1.5147\n",
      "Epoch 30/50, Train iteration 52/164: Loss = 1.5069\n",
      "Epoch 30/50, Train iteration 53/164: Loss = 1.5820\n",
      "Epoch 30/50, Train iteration 54/164: Loss = 1.5224\n",
      "Epoch 30/50, Train iteration 55/164: Loss = 1.4706\n",
      "Epoch 30/50, Train iteration 56/164: Loss = 1.6055\n",
      "Epoch 30/50, Train iteration 57/164: Loss = 1.5589\n",
      "Epoch 30/50, Train iteration 58/164: Loss = 1.5517\n",
      "Epoch 30/50, Train iteration 59/164: Loss = 1.5454\n",
      "Epoch 30/50, Train iteration 60/164: Loss = 1.4689\n",
      "Epoch 30/50, Train iteration 61/164: Loss = 1.5075\n",
      "Epoch 30/50, Train iteration 62/164: Loss = 1.4874\n",
      "Epoch 30/50, Train iteration 63/164: Loss = 1.5903\n",
      "Epoch 30/50, Train iteration 64/164: Loss = 1.5011\n",
      "Epoch 30/50, Train iteration 65/164: Loss = 1.5063\n",
      "Epoch 30/50, Train iteration 66/164: Loss = 1.4735\n",
      "Epoch 30/50, Train iteration 67/164: Loss = 1.5134\n",
      "Epoch 30/50, Train iteration 68/164: Loss = 1.4907\n",
      "Epoch 30/50, Train iteration 69/164: Loss = 1.5819\n",
      "Epoch 30/50, Train iteration 70/164: Loss = 1.5019\n",
      "Epoch 30/50, Train iteration 71/164: Loss = 1.5856\n",
      "Epoch 30/50, Train iteration 72/164: Loss = 1.6105\n",
      "Epoch 30/50, Train iteration 73/164: Loss = 1.5562\n",
      "Epoch 30/50, Train iteration 74/164: Loss = 1.5137\n",
      "Epoch 30/50, Train iteration 75/164: Loss = 1.4908\n",
      "Epoch 30/50, Train iteration 76/164: Loss = 1.5256\n",
      "Epoch 30/50, Train iteration 77/164: Loss = 1.5828\n",
      "Epoch 30/50, Train iteration 78/164: Loss = 1.5593\n",
      "Epoch 30/50, Train iteration 79/164: Loss = 1.5585\n",
      "Epoch 30/50, Train iteration 80/164: Loss = 1.5618\n",
      "Epoch 30/50, Train iteration 81/164: Loss = 1.5245\n",
      "Epoch 30/50, Train iteration 82/164: Loss = 1.5125\n",
      "Epoch 30/50, Train iteration 83/164: Loss = 1.5843\n",
      "Epoch 30/50, Train iteration 84/164: Loss = 1.5131\n",
      "Epoch 30/50, Train iteration 85/164: Loss = 1.5955\n",
      "Epoch 30/50, Train iteration 86/164: Loss = 1.4600\n",
      "Epoch 30/50, Train iteration 87/164: Loss = 1.4969\n",
      "Epoch 30/50, Train iteration 88/164: Loss = 1.6368\n",
      "Epoch 30/50, Train iteration 89/164: Loss = 1.5095\n",
      "Epoch 30/50, Train iteration 90/164: Loss = 1.5173\n",
      "Epoch 30/50, Train iteration 91/164: Loss = 1.5876\n",
      "Epoch 30/50, Train iteration 92/164: Loss = 1.5433\n",
      "Epoch 30/50, Train iteration 93/164: Loss = 1.5590\n",
      "Epoch 30/50, Train iteration 94/164: Loss = 1.6096\n",
      "Epoch 30/50, Train iteration 95/164: Loss = 1.4663\n",
      "Epoch 30/50, Train iteration 96/164: Loss = 1.6087\n",
      "Epoch 30/50, Train iteration 97/164: Loss = 1.5332\n",
      "Epoch 30/50, Train iteration 98/164: Loss = 1.5765\n",
      "Epoch 30/50, Train iteration 99/164: Loss = 1.5329\n",
      "Epoch 30/50, Train iteration 100/164: Loss = 1.4613\n",
      "Epoch 30/50, Train iteration 101/164: Loss = 1.4715\n",
      "Epoch 30/50, Train iteration 102/164: Loss = 1.5305\n",
      "Epoch 30/50, Train iteration 103/164: Loss = 1.5599\n",
      "Epoch 30/50, Train iteration 104/164: Loss = 1.5734\n",
      "Epoch 30/50, Train iteration 105/164: Loss = 1.5321\n",
      "Epoch 30/50, Train iteration 106/164: Loss = 1.5495\n",
      "Epoch 30/50, Train iteration 107/164: Loss = 1.5482\n",
      "Epoch 30/50, Train iteration 108/164: Loss = 1.5158\n",
      "Epoch 30/50, Train iteration 109/164: Loss = 1.5701\n",
      "Epoch 30/50, Train iteration 110/164: Loss = 1.5310\n",
      "Epoch 30/50, Train iteration 111/164: Loss = 1.5362\n",
      "Epoch 30/50, Train iteration 112/164: Loss = 1.5743\n",
      "Epoch 30/50, Train iteration 113/164: Loss = 1.5009\n",
      "Epoch 30/50, Train iteration 114/164: Loss = 1.5044\n",
      "Epoch 30/50, Train iteration 115/164: Loss = 1.5759\n",
      "Epoch 30/50, Train iteration 116/164: Loss = 1.5253\n",
      "Epoch 30/50, Train iteration 117/164: Loss = 1.4789\n",
      "Epoch 30/50, Train iteration 118/164: Loss = 1.5418\n",
      "Epoch 30/50, Train iteration 119/164: Loss = 1.4783\n",
      "Epoch 30/50, Train iteration 120/164: Loss = 1.4920\n",
      "Epoch 30/50, Train iteration 121/164: Loss = 1.5580\n",
      "Epoch 30/50, Train iteration 122/164: Loss = 1.4516\n",
      "Epoch 30/50, Train iteration 123/164: Loss = 1.5134\n",
      "Epoch 30/50, Train iteration 124/164: Loss = 1.5330\n",
      "Epoch 30/50, Train iteration 125/164: Loss = 1.5014\n",
      "Epoch 30/50, Train iteration 126/164: Loss = 1.5135\n",
      "Epoch 30/50, Train iteration 127/164: Loss = 1.6112\n",
      "Epoch 30/50, Train iteration 128/164: Loss = 1.4464\n",
      "Epoch 30/50, Train iteration 129/164: Loss = 1.5232\n",
      "Epoch 30/50, Train iteration 130/164: Loss = 1.5556\n",
      "Epoch 30/50, Train iteration 131/164: Loss = 1.6075\n",
      "Epoch 30/50, Train iteration 132/164: Loss = 1.5443\n",
      "Epoch 30/50, Train iteration 133/164: Loss = 1.5017\n",
      "Epoch 30/50, Train iteration 134/164: Loss = 1.4612\n",
      "Epoch 30/50, Train iteration 135/164: Loss = 1.5696\n",
      "Epoch 30/50, Train iteration 136/164: Loss = 1.5723\n",
      "Epoch 30/50, Train iteration 137/164: Loss = 1.5318\n",
      "Epoch 30/50, Train iteration 138/164: Loss = 1.5777\n",
      "Epoch 30/50, Train iteration 139/164: Loss = 1.5773\n",
      "Epoch 30/50, Train iteration 140/164: Loss = 1.5254\n",
      "Epoch 30/50, Train iteration 141/164: Loss = 1.5150\n",
      "Epoch 30/50, Train iteration 142/164: Loss = 1.6126\n",
      "Epoch 30/50, Train iteration 143/164: Loss = 1.4787\n",
      "Epoch 30/50, Train iteration 144/164: Loss = 1.5823\n",
      "Epoch 30/50, Train iteration 145/164: Loss = 1.5057\n",
      "Epoch 30/50, Train iteration 146/164: Loss = 1.4770\n",
      "Epoch 30/50, Train iteration 147/164: Loss = 1.5608\n",
      "Epoch 30/50, Train iteration 148/164: Loss = 1.5067\n",
      "Epoch 30/50, Train iteration 149/164: Loss = 1.5292\n",
      "Epoch 30/50, Train iteration 150/164: Loss = 1.5124\n",
      "Epoch 30/50, Train iteration 151/164: Loss = 1.5656\n",
      "Epoch 30/50, Train iteration 152/164: Loss = 1.5412\n",
      "Epoch 30/50, Train iteration 153/164: Loss = 1.5581\n",
      "Epoch 30/50, Train iteration 154/164: Loss = 1.5473\n",
      "Epoch 30/50, Train iteration 155/164: Loss = 1.5087\n",
      "Epoch 30/50, Train iteration 156/164: Loss = 1.5554\n",
      "Epoch 30/50, Train iteration 157/164: Loss = 1.5493\n",
      "Epoch 30/50, Train iteration 158/164: Loss = 1.6067\n",
      "Epoch 30/50, Train iteration 159/164: Loss = 1.5290\n",
      "Epoch 30/50, Train iteration 160/164: Loss = 1.5562\n",
      "Epoch 30/50, Train iteration 161/164: Loss = 1.6210\n",
      "Epoch 30/50, Train iteration 162/164: Loss = 1.6256\n",
      "Epoch 30/50, Train iteration 163/164: Loss = 1.6032\n",
      "Epoch 30/50, Train iteration 164/164: Loss = 1.3436\n",
      "Epoch 30/50, Val iteration 1/27: Loss = 1.6128\n",
      "Epoch 30/50, Val iteration 2/27: Loss = 1.6206\n",
      "Epoch 30/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 30/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 30/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 30/50, Val iteration 6/27: Loss = 1.5813\n",
      "Epoch 30/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 30/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 30/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 30/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 30/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 30/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 30/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 30/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 30/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 30/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 30/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 30/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 30/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 30/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 30/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 30/50, Val iteration 22/27: Loss = 1.6042\n",
      "Epoch 30/50, Val iteration 23/27: Loss = 1.4851\n",
      "Epoch 30/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 30/50, Val iteration 25/27: Loss = 1.5856\n",
      "Epoch 30/50, Val iteration 26/27: Loss = 1.5932\n",
      "Epoch 30/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 30/50: Train Loss = 1.5389, Val Loss = 1.5831\n",
      "Current learning rate: 7.29e-08\n",
      "Epoch 31/50, Train iteration 1/164: Loss = 1.5555\n",
      "Epoch 31/50, Train iteration 2/164: Loss = 1.5453\n",
      "Epoch 31/50, Train iteration 3/164: Loss = 1.5828\n",
      "Epoch 31/50, Train iteration 4/164: Loss = 1.5841\n",
      "Epoch 31/50, Train iteration 5/164: Loss = 1.6069\n",
      "Epoch 31/50, Train iteration 6/164: Loss = 1.6379\n",
      "Epoch 31/50, Train iteration 7/164: Loss = 1.5800\n",
      "Epoch 31/50, Train iteration 8/164: Loss = 1.5009\n",
      "Epoch 31/50, Train iteration 9/164: Loss = 1.5895\n",
      "Epoch 31/50, Train iteration 10/164: Loss = 1.5930\n",
      "Epoch 31/50, Train iteration 11/164: Loss = 1.5563\n",
      "Epoch 31/50, Train iteration 12/164: Loss = 1.5057\n",
      "Epoch 31/50, Train iteration 13/164: Loss = 1.4853\n",
      "Epoch 31/50, Train iteration 14/164: Loss = 1.5430\n",
      "Epoch 31/50, Train iteration 15/164: Loss = 1.5581\n",
      "Epoch 31/50, Train iteration 16/164: Loss = 1.6077\n",
      "Epoch 31/50, Train iteration 17/164: Loss = 1.5338\n",
      "Epoch 31/50, Train iteration 18/164: Loss = 1.5607\n",
      "Epoch 31/50, Train iteration 19/164: Loss = 1.5150\n",
      "Epoch 31/50, Train iteration 20/164: Loss = 1.5287\n",
      "Epoch 31/50, Train iteration 21/164: Loss = 1.5193\n",
      "Epoch 31/50, Train iteration 22/164: Loss = 1.5733\n",
      "Epoch 31/50, Train iteration 23/164: Loss = 1.5476\n",
      "Epoch 31/50, Train iteration 24/164: Loss = 1.5750\n",
      "Epoch 31/50, Train iteration 25/164: Loss = 1.5630\n",
      "Epoch 31/50, Train iteration 26/164: Loss = 1.5513\n",
      "Epoch 31/50, Train iteration 27/164: Loss = 1.5334\n",
      "Epoch 31/50, Train iteration 28/164: Loss = 1.5339\n",
      "Epoch 31/50, Train iteration 29/164: Loss = 1.5229\n",
      "Epoch 31/50, Train iteration 30/164: Loss = 1.5796\n",
      "Epoch 31/50, Train iteration 31/164: Loss = 1.4634\n",
      "Epoch 31/50, Train iteration 32/164: Loss = 1.5290\n",
      "Epoch 31/50, Train iteration 33/164: Loss = 1.5901\n",
      "Epoch 31/50, Train iteration 34/164: Loss = 1.5138\n",
      "Epoch 31/50, Train iteration 35/164: Loss = 1.5302\n",
      "Epoch 31/50, Train iteration 36/164: Loss = 1.5278\n",
      "Epoch 31/50, Train iteration 37/164: Loss = 1.5479\n",
      "Epoch 31/50, Train iteration 38/164: Loss = 1.5090\n",
      "Epoch 31/50, Train iteration 39/164: Loss = 1.5423\n",
      "Epoch 31/50, Train iteration 40/164: Loss = 1.5040\n",
      "Epoch 31/50, Train iteration 41/164: Loss = 1.5198\n",
      "Epoch 31/50, Train iteration 42/164: Loss = 1.4953\n",
      "Epoch 31/50, Train iteration 43/164: Loss = 1.5448\n",
      "Epoch 31/50, Train iteration 44/164: Loss = 1.5017\n",
      "Epoch 31/50, Train iteration 45/164: Loss = 1.4824\n",
      "Epoch 31/50, Train iteration 46/164: Loss = 1.5266\n",
      "Epoch 31/50, Train iteration 47/164: Loss = 1.5407\n",
      "Epoch 31/50, Train iteration 48/164: Loss = 1.5231\n",
      "Epoch 31/50, Train iteration 49/164: Loss = 1.5133\n",
      "Epoch 31/50, Train iteration 50/164: Loss = 1.6230\n",
      "Epoch 31/50, Train iteration 51/164: Loss = 1.4771\n",
      "Epoch 31/50, Train iteration 52/164: Loss = 1.4906\n",
      "Epoch 31/50, Train iteration 53/164: Loss = 1.5265\n",
      "Epoch 31/50, Train iteration 54/164: Loss = 1.5553\n",
      "Epoch 31/50, Train iteration 55/164: Loss = 1.4731\n",
      "Epoch 31/50, Train iteration 56/164: Loss = 1.5718\n",
      "Epoch 31/50, Train iteration 57/164: Loss = 1.5148\n",
      "Epoch 31/50, Train iteration 58/164: Loss = 1.6504\n",
      "Epoch 31/50, Train iteration 59/164: Loss = 1.5439\n",
      "Epoch 31/50, Train iteration 60/164: Loss = 1.5195\n",
      "Epoch 31/50, Train iteration 61/164: Loss = 1.5337\n",
      "Epoch 31/50, Train iteration 62/164: Loss = 1.4912\n",
      "Epoch 31/50, Train iteration 63/164: Loss = 1.5905\n",
      "Epoch 31/50, Train iteration 64/164: Loss = 1.5261\n",
      "Epoch 31/50, Train iteration 65/164: Loss = 1.5227\n",
      "Epoch 31/50, Train iteration 66/164: Loss = 1.4662\n",
      "Epoch 31/50, Train iteration 67/164: Loss = 1.4793\n",
      "Epoch 31/50, Train iteration 68/164: Loss = 1.5345\n",
      "Epoch 31/50, Train iteration 69/164: Loss = 1.5584\n",
      "Epoch 31/50, Train iteration 70/164: Loss = 1.5862\n",
      "Epoch 31/50, Train iteration 71/164: Loss = 1.5619\n",
      "Epoch 31/50, Train iteration 72/164: Loss = 1.5698\n",
      "Epoch 31/50, Train iteration 73/164: Loss = 1.5806\n",
      "Epoch 31/50, Train iteration 74/164: Loss = 1.5495\n",
      "Epoch 31/50, Train iteration 75/164: Loss = 1.4663\n",
      "Epoch 31/50, Train iteration 76/164: Loss = 1.5272\n",
      "Epoch 31/50, Train iteration 77/164: Loss = 1.5755\n",
      "Epoch 31/50, Train iteration 78/164: Loss = 1.5420\n",
      "Epoch 31/50, Train iteration 79/164: Loss = 1.5511\n",
      "Epoch 31/50, Train iteration 80/164: Loss = 1.5697\n",
      "Epoch 31/50, Train iteration 81/164: Loss = 1.4912\n",
      "Epoch 31/50, Train iteration 82/164: Loss = 1.5900\n",
      "Epoch 31/50, Train iteration 83/164: Loss = 1.5461\n",
      "Epoch 31/50, Train iteration 84/164: Loss = 1.4930\n",
      "Epoch 31/50, Train iteration 85/164: Loss = 1.6476\n",
      "Epoch 31/50, Train iteration 86/164: Loss = 1.4251\n",
      "Epoch 31/50, Train iteration 87/164: Loss = 1.5736\n",
      "Epoch 31/50, Train iteration 88/164: Loss = 1.6151\n",
      "Epoch 31/50, Train iteration 89/164: Loss = 1.5514\n",
      "Epoch 31/50, Train iteration 90/164: Loss = 1.5049\n",
      "Epoch 31/50, Train iteration 91/164: Loss = 1.5914\n",
      "Epoch 31/50, Train iteration 92/164: Loss = 1.4760\n",
      "Epoch 31/50, Train iteration 93/164: Loss = 1.5273\n",
      "Epoch 31/50, Train iteration 94/164: Loss = 1.5649\n",
      "Epoch 31/50, Train iteration 95/164: Loss = 1.5324\n",
      "Epoch 31/50, Train iteration 96/164: Loss = 1.5030\n",
      "Epoch 31/50, Train iteration 97/164: Loss = 1.5185\n",
      "Epoch 31/50, Train iteration 98/164: Loss = 1.5172\n",
      "Epoch 31/50, Train iteration 99/164: Loss = 1.4979\n",
      "Epoch 31/50, Train iteration 100/164: Loss = 1.4581\n",
      "Epoch 31/50, Train iteration 101/164: Loss = 1.4959\n",
      "Epoch 31/50, Train iteration 102/164: Loss = 1.5173\n",
      "Epoch 31/50, Train iteration 103/164: Loss = 1.5242\n",
      "Epoch 31/50, Train iteration 104/164: Loss = 1.5250\n",
      "Epoch 31/50, Train iteration 105/164: Loss = 1.5317\n",
      "Epoch 31/50, Train iteration 106/164: Loss = 1.5284\n",
      "Epoch 31/50, Train iteration 107/164: Loss = 1.4881\n",
      "Epoch 31/50, Train iteration 108/164: Loss = 1.5274\n",
      "Epoch 31/50, Train iteration 109/164: Loss = 1.5908\n",
      "Epoch 31/50, Train iteration 110/164: Loss = 1.5178\n",
      "Epoch 31/50, Train iteration 111/164: Loss = 1.5713\n",
      "Epoch 31/50, Train iteration 112/164: Loss = 1.5703\n",
      "Epoch 31/50, Train iteration 113/164: Loss = 1.5176\n",
      "Epoch 31/50, Train iteration 114/164: Loss = 1.4432\n",
      "Epoch 31/50, Train iteration 115/164: Loss = 1.5730\n",
      "Epoch 31/50, Train iteration 116/164: Loss = 1.4983\n",
      "Epoch 31/50, Train iteration 117/164: Loss = 1.5064\n",
      "Epoch 31/50, Train iteration 118/164: Loss = 1.5936\n",
      "Epoch 31/50, Train iteration 119/164: Loss = 1.5207\n",
      "Epoch 31/50, Train iteration 120/164: Loss = 1.5342\n",
      "Epoch 31/50, Train iteration 121/164: Loss = 1.5491\n",
      "Epoch 31/50, Train iteration 122/164: Loss = 1.4247\n",
      "Epoch 31/50, Train iteration 123/164: Loss = 1.5210\n",
      "Epoch 31/50, Train iteration 124/164: Loss = 1.5225\n",
      "Epoch 31/50, Train iteration 125/164: Loss = 1.5191\n",
      "Epoch 31/50, Train iteration 126/164: Loss = 1.4934\n",
      "Epoch 31/50, Train iteration 127/164: Loss = 1.5768\n",
      "Epoch 31/50, Train iteration 128/164: Loss = 1.4697\n",
      "Epoch 31/50, Train iteration 129/164: Loss = 1.5539\n",
      "Epoch 31/50, Train iteration 130/164: Loss = 1.5753\n",
      "Epoch 31/50, Train iteration 131/164: Loss = 1.5803\n",
      "Epoch 31/50, Train iteration 132/164: Loss = 1.4841\n",
      "Epoch 31/50, Train iteration 133/164: Loss = 1.5270\n",
      "Epoch 31/50, Train iteration 134/164: Loss = 1.5266\n",
      "Epoch 31/50, Train iteration 135/164: Loss = 1.5769\n",
      "Epoch 31/50, Train iteration 136/164: Loss = 1.5166\n",
      "Epoch 31/50, Train iteration 137/164: Loss = 1.5045\n",
      "Epoch 31/50, Train iteration 138/164: Loss = 1.5661\n",
      "Epoch 31/50, Train iteration 139/164: Loss = 1.6328\n",
      "Epoch 31/50, Train iteration 140/164: Loss = 1.4976\n",
      "Epoch 31/50, Train iteration 141/164: Loss = 1.5452\n",
      "Epoch 31/50, Train iteration 142/164: Loss = 1.5654\n",
      "Epoch 31/50, Train iteration 143/164: Loss = 1.5215\n",
      "Epoch 31/50, Train iteration 144/164: Loss = 1.5973\n",
      "Epoch 31/50, Train iteration 145/164: Loss = 1.5053\n",
      "Epoch 31/50, Train iteration 146/164: Loss = 1.5354\n",
      "Epoch 31/50, Train iteration 147/164: Loss = 1.5080\n",
      "Epoch 31/50, Train iteration 148/164: Loss = 1.4949\n",
      "Epoch 31/50, Train iteration 149/164: Loss = 1.4860\n",
      "Epoch 31/50, Train iteration 150/164: Loss = 1.5873\n",
      "Epoch 31/50, Train iteration 151/164: Loss = 1.5673\n",
      "Epoch 31/50, Train iteration 152/164: Loss = 1.4920\n",
      "Epoch 31/50, Train iteration 153/164: Loss = 1.5658\n",
      "Epoch 31/50, Train iteration 154/164: Loss = 1.5156\n",
      "Epoch 31/50, Train iteration 155/164: Loss = 1.5264\n",
      "Epoch 31/50, Train iteration 156/164: Loss = 1.5246\n",
      "Epoch 31/50, Train iteration 157/164: Loss = 1.5860\n",
      "Epoch 31/50, Train iteration 158/164: Loss = 1.5418\n",
      "Epoch 31/50, Train iteration 159/164: Loss = 1.5558\n",
      "Epoch 31/50, Train iteration 160/164: Loss = 1.5768\n",
      "Epoch 31/50, Train iteration 161/164: Loss = 1.6328\n",
      "Epoch 31/50, Train iteration 162/164: Loss = 1.5491\n",
      "Epoch 31/50, Train iteration 163/164: Loss = 1.5707\n",
      "Epoch 31/50, Train iteration 164/164: Loss = 1.3609\n",
      "Epoch 31/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 31/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 31/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 31/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 31/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 31/50, Val iteration 6/27: Loss = 1.5813\n",
      "Epoch 31/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 31/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 31/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 31/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 31/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 31/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 31/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 31/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 31/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 31/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 31/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 31/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 31/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 31/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 31/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 31/50, Val iteration 22/27: Loss = 1.6042\n",
      "Epoch 31/50, Val iteration 23/27: Loss = 1.4851\n",
      "Epoch 31/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 31/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 31/50, Val iteration 26/27: Loss = 1.5932\n",
      "Epoch 31/50, Val iteration 27/27: Loss = 1.6054\n",
      "Epoch 31/50: Train Loss = 1.5368, Val Loss = 1.5831\n",
      "Current learning rate: 7.29e-08\n",
      "Epoch 32/50, Train iteration 1/164: Loss = 1.5132\n",
      "Epoch 32/50, Train iteration 2/164: Loss = 1.5330\n",
      "Epoch 32/50, Train iteration 3/164: Loss = 1.5714\n",
      "Epoch 32/50, Train iteration 4/164: Loss = 1.5240\n",
      "Epoch 32/50, Train iteration 5/164: Loss = 1.5652\n",
      "Epoch 32/50, Train iteration 6/164: Loss = 1.6065\n",
      "Epoch 32/50, Train iteration 7/164: Loss = 1.5492\n",
      "Epoch 32/50, Train iteration 8/164: Loss = 1.4634\n",
      "Epoch 32/50, Train iteration 9/164: Loss = 1.6218\n",
      "Epoch 32/50, Train iteration 10/164: Loss = 1.5729\n",
      "Epoch 32/50, Train iteration 11/164: Loss = 1.5719\n",
      "Epoch 32/50, Train iteration 12/164: Loss = 1.5347\n",
      "Epoch 32/50, Train iteration 13/164: Loss = 1.4258\n",
      "Epoch 32/50, Train iteration 14/164: Loss = 1.5282\n",
      "Epoch 32/50, Train iteration 15/164: Loss = 1.5450\n",
      "Epoch 32/50, Train iteration 16/164: Loss = 1.5441\n",
      "Epoch 32/50, Train iteration 17/164: Loss = 1.5395\n",
      "Epoch 32/50, Train iteration 18/164: Loss = 1.5310\n",
      "Epoch 32/50, Train iteration 19/164: Loss = 1.4963\n",
      "Epoch 32/50, Train iteration 20/164: Loss = 1.5374\n",
      "Epoch 32/50, Train iteration 21/164: Loss = 1.5666\n",
      "Epoch 32/50, Train iteration 22/164: Loss = 1.6007\n",
      "Epoch 32/50, Train iteration 23/164: Loss = 1.5080\n",
      "Epoch 32/50, Train iteration 24/164: Loss = 1.5941\n",
      "Epoch 32/50, Train iteration 25/164: Loss = 1.5526\n",
      "Epoch 32/50, Train iteration 26/164: Loss = 1.5902\n",
      "Epoch 32/50, Train iteration 27/164: Loss = 1.5264\n",
      "Epoch 32/50, Train iteration 28/164: Loss = 1.5941\n",
      "Epoch 32/50, Train iteration 29/164: Loss = 1.5127\n",
      "Epoch 32/50, Train iteration 30/164: Loss = 1.5385\n",
      "Epoch 32/50, Train iteration 31/164: Loss = 1.5424\n",
      "Epoch 32/50, Train iteration 32/164: Loss = 1.5294\n",
      "Epoch 32/50, Train iteration 33/164: Loss = 1.5565\n",
      "Epoch 32/50, Train iteration 34/164: Loss = 1.5363\n",
      "Epoch 32/50, Train iteration 35/164: Loss = 1.5709\n",
      "Epoch 32/50, Train iteration 36/164: Loss = 1.5019\n",
      "Epoch 32/50, Train iteration 37/164: Loss = 1.5493\n",
      "Epoch 32/50, Train iteration 38/164: Loss = 1.5733\n",
      "Epoch 32/50, Train iteration 39/164: Loss = 1.5325\n",
      "Epoch 32/50, Train iteration 40/164: Loss = 1.4752\n",
      "Epoch 32/50, Train iteration 41/164: Loss = 1.4776\n",
      "Epoch 32/50, Train iteration 42/164: Loss = 1.5894\n",
      "Epoch 32/50, Train iteration 43/164: Loss = 1.5410\n",
      "Epoch 32/50, Train iteration 44/164: Loss = 1.5231\n",
      "Epoch 32/50, Train iteration 45/164: Loss = 1.5734\n",
      "Epoch 32/50, Train iteration 46/164: Loss = 1.5813\n",
      "Epoch 32/50, Train iteration 47/164: Loss = 1.5339\n",
      "Epoch 32/50, Train iteration 48/164: Loss = 1.5163\n",
      "Epoch 32/50, Train iteration 49/164: Loss = 1.5071\n",
      "Epoch 32/50, Train iteration 50/164: Loss = 1.5924\n",
      "Epoch 32/50, Train iteration 51/164: Loss = 1.4829\n",
      "Epoch 32/50, Train iteration 52/164: Loss = 1.5096\n",
      "Epoch 32/50, Train iteration 53/164: Loss = 1.5220\n",
      "Epoch 32/50, Train iteration 54/164: Loss = 1.5630\n",
      "Epoch 32/50, Train iteration 55/164: Loss = 1.4744\n",
      "Epoch 32/50, Train iteration 56/164: Loss = 1.5754\n",
      "Epoch 32/50, Train iteration 57/164: Loss = 1.5875\n",
      "Epoch 32/50, Train iteration 58/164: Loss = 1.5577\n",
      "Epoch 32/50, Train iteration 59/164: Loss = 1.5344\n",
      "Epoch 32/50, Train iteration 60/164: Loss = 1.4488\n",
      "Epoch 32/50, Train iteration 61/164: Loss = 1.4956\n",
      "Epoch 32/50, Train iteration 62/164: Loss = 1.5134\n",
      "Epoch 32/50, Train iteration 63/164: Loss = 1.5703\n",
      "Epoch 32/50, Train iteration 64/164: Loss = 1.5175\n",
      "Epoch 32/50, Train iteration 65/164: Loss = 1.5339\n",
      "Epoch 32/50, Train iteration 66/164: Loss = 1.4810\n",
      "Epoch 32/50, Train iteration 67/164: Loss = 1.5339\n",
      "Epoch 32/50, Train iteration 68/164: Loss = 1.5329\n",
      "Epoch 32/50, Train iteration 69/164: Loss = 1.5183\n",
      "Epoch 32/50, Train iteration 70/164: Loss = 1.5656\n",
      "Epoch 32/50, Train iteration 71/164: Loss = 1.5989\n",
      "Epoch 32/50, Train iteration 72/164: Loss = 1.5652\n",
      "Epoch 32/50, Train iteration 73/164: Loss = 1.5795\n",
      "Epoch 32/50, Train iteration 74/164: Loss = 1.5347\n",
      "Epoch 32/50, Train iteration 75/164: Loss = 1.4988\n",
      "Epoch 32/50, Train iteration 76/164: Loss = 1.5436\n",
      "Epoch 32/50, Train iteration 77/164: Loss = 1.5397\n",
      "Epoch 32/50, Train iteration 78/164: Loss = 1.5522\n",
      "Epoch 32/50, Train iteration 79/164: Loss = 1.5430\n",
      "Epoch 32/50, Train iteration 80/164: Loss = 1.5403\n",
      "Epoch 32/50, Train iteration 81/164: Loss = 1.5136\n",
      "Epoch 32/50, Train iteration 82/164: Loss = 1.5523\n",
      "Epoch 32/50, Train iteration 83/164: Loss = 1.5424\n",
      "Epoch 32/50, Train iteration 84/164: Loss = 1.5000\n",
      "Epoch 32/50, Train iteration 85/164: Loss = 1.5941\n",
      "Epoch 32/50, Train iteration 86/164: Loss = 1.4466\n",
      "Epoch 32/50, Train iteration 87/164: Loss = 1.5551\n",
      "Epoch 32/50, Train iteration 88/164: Loss = 1.5755\n",
      "Epoch 32/50, Train iteration 89/164: Loss = 1.5431\n",
      "Epoch 32/50, Train iteration 90/164: Loss = 1.5452\n",
      "Epoch 32/50, Train iteration 91/164: Loss = 1.5763\n",
      "Epoch 32/50, Train iteration 92/164: Loss = 1.5637\n",
      "Epoch 32/50, Train iteration 93/164: Loss = 1.5189\n",
      "Epoch 32/50, Train iteration 94/164: Loss = 1.5678\n",
      "Epoch 32/50, Train iteration 95/164: Loss = 1.5338\n",
      "Epoch 32/50, Train iteration 96/164: Loss = 1.6054\n",
      "Epoch 32/50, Train iteration 97/164: Loss = 1.5601\n",
      "Epoch 32/50, Train iteration 98/164: Loss = 1.5935\n",
      "Epoch 32/50, Train iteration 99/164: Loss = 1.4576\n",
      "Epoch 32/50, Train iteration 100/164: Loss = 1.5298\n",
      "Epoch 32/50, Train iteration 101/164: Loss = 1.4973\n",
      "Epoch 32/50, Train iteration 102/164: Loss = 1.5480\n",
      "Epoch 32/50, Train iteration 103/164: Loss = 1.5488\n",
      "Epoch 32/50, Train iteration 104/164: Loss = 1.5611\n",
      "Epoch 32/50, Train iteration 105/164: Loss = 1.5680\n",
      "Epoch 32/50, Train iteration 106/164: Loss = 1.5666\n",
      "Epoch 32/50, Train iteration 107/164: Loss = 1.4825\n",
      "Epoch 32/50, Train iteration 108/164: Loss = 1.5418\n",
      "Epoch 32/50, Train iteration 109/164: Loss = 1.5544\n",
      "Epoch 32/50, Train iteration 110/164: Loss = 1.5543\n",
      "Epoch 32/50, Train iteration 111/164: Loss = 1.5587\n",
      "Epoch 32/50, Train iteration 112/164: Loss = 1.6080\n",
      "Epoch 32/50, Train iteration 113/164: Loss = 1.5054\n",
      "Epoch 32/50, Train iteration 114/164: Loss = 1.4662\n",
      "Epoch 32/50, Train iteration 115/164: Loss = 1.5354\n",
      "Epoch 32/50, Train iteration 116/164: Loss = 1.5148\n",
      "Epoch 32/50, Train iteration 117/164: Loss = 1.4899\n",
      "Epoch 32/50, Train iteration 118/164: Loss = 1.5331\n",
      "Epoch 32/50, Train iteration 119/164: Loss = 1.5882\n",
      "Epoch 32/50, Train iteration 120/164: Loss = 1.5230\n",
      "Epoch 32/50, Train iteration 121/164: Loss = 1.5652\n",
      "Epoch 32/50, Train iteration 122/164: Loss = 1.4401\n",
      "Epoch 32/50, Train iteration 123/164: Loss = 1.4834\n",
      "Epoch 32/50, Train iteration 124/164: Loss = 1.5180\n",
      "Epoch 32/50, Train iteration 125/164: Loss = 1.5300\n",
      "Epoch 32/50, Train iteration 126/164: Loss = 1.5063\n",
      "Epoch 32/50, Train iteration 127/164: Loss = 1.5885\n",
      "Epoch 32/50, Train iteration 128/164: Loss = 1.4980\n",
      "Epoch 32/50, Train iteration 129/164: Loss = 1.5571\n",
      "Epoch 32/50, Train iteration 130/164: Loss = 1.5499\n",
      "Epoch 32/50, Train iteration 131/164: Loss = 1.5955\n",
      "Epoch 32/50, Train iteration 132/164: Loss = 1.4662\n",
      "Epoch 32/50, Train iteration 133/164: Loss = 1.5549\n",
      "Epoch 32/50, Train iteration 134/164: Loss = 1.5473\n",
      "Epoch 32/50, Train iteration 135/164: Loss = 1.5295\n",
      "Epoch 32/50, Train iteration 136/164: Loss = 1.5408\n",
      "Epoch 32/50, Train iteration 137/164: Loss = 1.4996\n",
      "Epoch 32/50, Train iteration 138/164: Loss = 1.5660\n",
      "Epoch 32/50, Train iteration 139/164: Loss = 1.5579\n",
      "Epoch 32/50, Train iteration 140/164: Loss = 1.4757\n",
      "Epoch 32/50, Train iteration 141/164: Loss = 1.5063\n",
      "Epoch 32/50, Train iteration 142/164: Loss = 1.5832\n",
      "Epoch 32/50, Train iteration 143/164: Loss = 1.4937\n",
      "Epoch 32/50, Train iteration 144/164: Loss = 1.5414\n",
      "Epoch 32/50, Train iteration 145/164: Loss = 1.5099\n",
      "Epoch 32/50, Train iteration 146/164: Loss = 1.5130\n",
      "Epoch 32/50, Train iteration 147/164: Loss = 1.5191\n",
      "Epoch 32/50, Train iteration 148/164: Loss = 1.5411\n",
      "Epoch 32/50, Train iteration 149/164: Loss = 1.5945\n",
      "Epoch 32/50, Train iteration 150/164: Loss = 1.5425\n",
      "Epoch 32/50, Train iteration 151/164: Loss = 1.5966\n",
      "Epoch 32/50, Train iteration 152/164: Loss = 1.5214\n",
      "Epoch 32/50, Train iteration 153/164: Loss = 1.5073\n",
      "Epoch 32/50, Train iteration 154/164: Loss = 1.5309\n",
      "Epoch 32/50, Train iteration 155/164: Loss = 1.5292\n",
      "Epoch 32/50, Train iteration 156/164: Loss = 1.5198\n",
      "Epoch 32/50, Train iteration 157/164: Loss = 1.5800\n",
      "Epoch 32/50, Train iteration 158/164: Loss = 1.5814\n",
      "Epoch 32/50, Train iteration 159/164: Loss = 1.5906\n",
      "Epoch 32/50, Train iteration 160/164: Loss = 1.5391\n",
      "Epoch 32/50, Train iteration 161/164: Loss = 1.6151\n",
      "Epoch 32/50, Train iteration 162/164: Loss = 1.5300\n",
      "Epoch 32/50, Train iteration 163/164: Loss = 1.5210\n",
      "Epoch 32/50, Train iteration 164/164: Loss = 1.3829\n",
      "Epoch 32/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 32/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 32/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 32/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 32/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 32/50, Val iteration 6/27: Loss = 1.5813\n",
      "Epoch 32/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 32/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 32/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 32/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 32/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 32/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 32/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 32/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 32/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 32/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 32/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 32/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 32/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 32/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 32/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 32/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 32/50, Val iteration 23/27: Loss = 1.4851\n",
      "Epoch 32/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 32/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 32/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 32/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 32/50: Train Loss = 1.5381, Val Loss = 1.5831\n",
      "Current learning rate: 2.187e-08\n",
      "Epoch 33/50, Train iteration 1/164: Loss = 1.5419\n",
      "Epoch 33/50, Train iteration 2/164: Loss = 1.5063\n",
      "Epoch 33/50, Train iteration 3/164: Loss = 1.5557\n",
      "Epoch 33/50, Train iteration 4/164: Loss = 1.5189\n",
      "Epoch 33/50, Train iteration 5/164: Loss = 1.6003\n",
      "Epoch 33/50, Train iteration 6/164: Loss = 1.6309\n",
      "Epoch 33/50, Train iteration 7/164: Loss = 1.6196\n",
      "Epoch 33/50, Train iteration 8/164: Loss = 1.4798\n",
      "Epoch 33/50, Train iteration 9/164: Loss = 1.5871\n",
      "Epoch 33/50, Train iteration 10/164: Loss = 1.5806\n",
      "Epoch 33/50, Train iteration 11/164: Loss = 1.5711\n",
      "Epoch 33/50, Train iteration 12/164: Loss = 1.5532\n",
      "Epoch 33/50, Train iteration 13/164: Loss = 1.4685\n",
      "Epoch 33/50, Train iteration 14/164: Loss = 1.5492\n",
      "Epoch 33/50, Train iteration 15/164: Loss = 1.5809\n",
      "Epoch 33/50, Train iteration 16/164: Loss = 1.5449\n",
      "Epoch 33/50, Train iteration 17/164: Loss = 1.5415\n",
      "Epoch 33/50, Train iteration 18/164: Loss = 1.5007\n",
      "Epoch 33/50, Train iteration 19/164: Loss = 1.5029\n",
      "Epoch 33/50, Train iteration 20/164: Loss = 1.4821\n",
      "Epoch 33/50, Train iteration 21/164: Loss = 1.5812\n",
      "Epoch 33/50, Train iteration 22/164: Loss = 1.5584\n",
      "Epoch 33/50, Train iteration 23/164: Loss = 1.5754\n",
      "Epoch 33/50, Train iteration 24/164: Loss = 1.5770\n",
      "Epoch 33/50, Train iteration 25/164: Loss = 1.5791\n",
      "Epoch 33/50, Train iteration 26/164: Loss = 1.5543\n",
      "Epoch 33/50, Train iteration 27/164: Loss = 1.5493\n",
      "Epoch 33/50, Train iteration 28/164: Loss = 1.5467\n",
      "Epoch 33/50, Train iteration 29/164: Loss = 1.5341\n",
      "Epoch 33/50, Train iteration 30/164: Loss = 1.5163\n",
      "Epoch 33/50, Train iteration 31/164: Loss = 1.4583\n",
      "Epoch 33/50, Train iteration 32/164: Loss = 1.5008\n",
      "Epoch 33/50, Train iteration 33/164: Loss = 1.5866\n",
      "Epoch 33/50, Train iteration 34/164: Loss = 1.4715\n",
      "Epoch 33/50, Train iteration 35/164: Loss = 1.5310\n",
      "Epoch 33/50, Train iteration 36/164: Loss = 1.5083\n",
      "Epoch 33/50, Train iteration 37/164: Loss = 1.5826\n",
      "Epoch 33/50, Train iteration 38/164: Loss = 1.5175\n",
      "Epoch 33/50, Train iteration 39/164: Loss = 1.5234\n",
      "Epoch 33/50, Train iteration 40/164: Loss = 1.4670\n",
      "Epoch 33/50, Train iteration 41/164: Loss = 1.4925\n",
      "Epoch 33/50, Train iteration 42/164: Loss = 1.5623\n",
      "Epoch 33/50, Train iteration 43/164: Loss = 1.5308\n",
      "Epoch 33/50, Train iteration 44/164: Loss = 1.4779\n",
      "Epoch 33/50, Train iteration 45/164: Loss = 1.5289\n",
      "Epoch 33/50, Train iteration 46/164: Loss = 1.5314\n",
      "Epoch 33/50, Train iteration 47/164: Loss = 1.5924\n",
      "Epoch 33/50, Train iteration 48/164: Loss = 1.5857\n",
      "Epoch 33/50, Train iteration 49/164: Loss = 1.5483\n",
      "Epoch 33/50, Train iteration 50/164: Loss = 1.6120\n",
      "Epoch 33/50, Train iteration 51/164: Loss = 1.5342\n",
      "Epoch 33/50, Train iteration 52/164: Loss = 1.4919\n",
      "Epoch 33/50, Train iteration 53/164: Loss = 1.5477\n",
      "Epoch 33/50, Train iteration 54/164: Loss = 1.5350\n",
      "Epoch 33/50, Train iteration 55/164: Loss = 1.4974\n",
      "Epoch 33/50, Train iteration 56/164: Loss = 1.6012\n",
      "Epoch 33/50, Train iteration 57/164: Loss = 1.5406\n",
      "Epoch 33/50, Train iteration 58/164: Loss = 1.5762\n",
      "Epoch 33/50, Train iteration 59/164: Loss = 1.5409\n",
      "Epoch 33/50, Train iteration 60/164: Loss = 1.5555\n",
      "Epoch 33/50, Train iteration 61/164: Loss = 1.4743\n",
      "Epoch 33/50, Train iteration 62/164: Loss = 1.5325\n",
      "Epoch 33/50, Train iteration 63/164: Loss = 1.6246\n",
      "Epoch 33/50, Train iteration 64/164: Loss = 1.5396\n",
      "Epoch 33/50, Train iteration 65/164: Loss = 1.4450\n",
      "Epoch 33/50, Train iteration 66/164: Loss = 1.4980\n",
      "Epoch 33/50, Train iteration 67/164: Loss = 1.4704\n",
      "Epoch 33/50, Train iteration 68/164: Loss = 1.5758\n",
      "Epoch 33/50, Train iteration 69/164: Loss = 1.6124\n",
      "Epoch 33/50, Train iteration 70/164: Loss = 1.5766\n",
      "Epoch 33/50, Train iteration 71/164: Loss = 1.5543\n",
      "Epoch 33/50, Train iteration 72/164: Loss = 1.5797\n",
      "Epoch 33/50, Train iteration 73/164: Loss = 1.5845\n",
      "Epoch 33/50, Train iteration 74/164: Loss = 1.4614\n",
      "Epoch 33/50, Train iteration 75/164: Loss = 1.4777\n",
      "Epoch 33/50, Train iteration 76/164: Loss = 1.5219\n",
      "Epoch 33/50, Train iteration 77/164: Loss = 1.5379\n",
      "Epoch 33/50, Train iteration 78/164: Loss = 1.5328\n",
      "Epoch 33/50, Train iteration 79/164: Loss = 1.5723\n",
      "Epoch 33/50, Train iteration 80/164: Loss = 1.5462\n",
      "Epoch 33/50, Train iteration 81/164: Loss = 1.5294\n",
      "Epoch 33/50, Train iteration 82/164: Loss = 1.5273\n",
      "Epoch 33/50, Train iteration 83/164: Loss = 1.5287\n",
      "Epoch 33/50, Train iteration 84/164: Loss = 1.4745\n",
      "Epoch 33/50, Train iteration 85/164: Loss = 1.5831\n",
      "Epoch 33/50, Train iteration 86/164: Loss = 1.4294\n",
      "Epoch 33/50, Train iteration 87/164: Loss = 1.5594\n",
      "Epoch 33/50, Train iteration 88/164: Loss = 1.6136\n",
      "Epoch 33/50, Train iteration 89/164: Loss = 1.5794\n",
      "Epoch 33/50, Train iteration 90/164: Loss = 1.5210\n",
      "Epoch 33/50, Train iteration 91/164: Loss = 1.6138\n",
      "Epoch 33/50, Train iteration 92/164: Loss = 1.5381\n",
      "Epoch 33/50, Train iteration 93/164: Loss = 1.5364\n",
      "Epoch 33/50, Train iteration 94/164: Loss = 1.6139\n",
      "Epoch 33/50, Train iteration 95/164: Loss = 1.4931\n",
      "Epoch 33/50, Train iteration 96/164: Loss = 1.6122\n",
      "Epoch 33/50, Train iteration 97/164: Loss = 1.5467\n",
      "Epoch 33/50, Train iteration 98/164: Loss = 1.5767\n",
      "Epoch 33/50, Train iteration 99/164: Loss = 1.5085\n",
      "Epoch 33/50, Train iteration 100/164: Loss = 1.4974\n",
      "Epoch 33/50, Train iteration 101/164: Loss = 1.5165\n",
      "Epoch 33/50, Train iteration 102/164: Loss = 1.5589\n",
      "Epoch 33/50, Train iteration 103/164: Loss = 1.5562\n",
      "Epoch 33/50, Train iteration 104/164: Loss = 1.5971\n",
      "Epoch 33/50, Train iteration 105/164: Loss = 1.5549\n",
      "Epoch 33/50, Train iteration 106/164: Loss = 1.5965\n",
      "Epoch 33/50, Train iteration 107/164: Loss = 1.5440\n",
      "Epoch 33/50, Train iteration 108/164: Loss = 1.4848\n",
      "Epoch 33/50, Train iteration 109/164: Loss = 1.5756\n",
      "Epoch 33/50, Train iteration 110/164: Loss = 1.5636\n",
      "Epoch 33/50, Train iteration 111/164: Loss = 1.5444\n",
      "Epoch 33/50, Train iteration 112/164: Loss = 1.5450\n",
      "Epoch 33/50, Train iteration 113/164: Loss = 1.5220\n",
      "Epoch 33/50, Train iteration 114/164: Loss = 1.4818\n",
      "Epoch 33/50, Train iteration 115/164: Loss = 1.5238\n",
      "Epoch 33/50, Train iteration 116/164: Loss = 1.5107\n",
      "Epoch 33/50, Train iteration 117/164: Loss = 1.4578\n",
      "Epoch 33/50, Train iteration 118/164: Loss = 1.5481\n",
      "Epoch 33/50, Train iteration 119/164: Loss = 1.5365\n",
      "Epoch 33/50, Train iteration 120/164: Loss = 1.5459\n",
      "Epoch 33/50, Train iteration 121/164: Loss = 1.5224\n",
      "Epoch 33/50, Train iteration 122/164: Loss = 1.4572\n",
      "Epoch 33/50, Train iteration 123/164: Loss = 1.5103\n",
      "Epoch 33/50, Train iteration 124/164: Loss = 1.5439\n",
      "Epoch 33/50, Train iteration 125/164: Loss = 1.4729\n",
      "Epoch 33/50, Train iteration 126/164: Loss = 1.5351\n",
      "Epoch 33/50, Train iteration 127/164: Loss = 1.5689\n",
      "Epoch 33/50, Train iteration 128/164: Loss = 1.4646\n",
      "Epoch 33/50, Train iteration 129/164: Loss = 1.5398\n",
      "Epoch 33/50, Train iteration 130/164: Loss = 1.5682\n",
      "Epoch 33/50, Train iteration 131/164: Loss = 1.5509\n",
      "Epoch 33/50, Train iteration 132/164: Loss = 1.4545\n",
      "Epoch 33/50, Train iteration 133/164: Loss = 1.5659\n",
      "Epoch 33/50, Train iteration 134/164: Loss = 1.4896\n",
      "Epoch 33/50, Train iteration 135/164: Loss = 1.5418\n",
      "Epoch 33/50, Train iteration 136/164: Loss = 1.5295\n",
      "Epoch 33/50, Train iteration 137/164: Loss = 1.4866\n",
      "Epoch 33/50, Train iteration 138/164: Loss = 1.5663\n",
      "Epoch 33/50, Train iteration 139/164: Loss = 1.5911\n",
      "Epoch 33/50, Train iteration 140/164: Loss = 1.5567\n",
      "Epoch 33/50, Train iteration 141/164: Loss = 1.5270\n",
      "Epoch 33/50, Train iteration 142/164: Loss = 1.6075\n",
      "Epoch 33/50, Train iteration 143/164: Loss = 1.5027\n",
      "Epoch 33/50, Train iteration 144/164: Loss = 1.5938\n",
      "Epoch 33/50, Train iteration 145/164: Loss = 1.5204\n",
      "Epoch 33/50, Train iteration 146/164: Loss = 1.4919\n",
      "Epoch 33/50, Train iteration 147/164: Loss = 1.4946\n",
      "Epoch 33/50, Train iteration 148/164: Loss = 1.5278\n",
      "Epoch 33/50, Train iteration 149/164: Loss = 1.5410\n",
      "Epoch 33/50, Train iteration 150/164: Loss = 1.5816\n",
      "Epoch 33/50, Train iteration 151/164: Loss = 1.5274\n",
      "Epoch 33/50, Train iteration 152/164: Loss = 1.5503\n",
      "Epoch 33/50, Train iteration 153/164: Loss = 1.5758\n",
      "Epoch 33/50, Train iteration 154/164: Loss = 1.4868\n",
      "Epoch 33/50, Train iteration 155/164: Loss = 1.5084\n",
      "Epoch 33/50, Train iteration 156/164: Loss = 1.4857\n",
      "Epoch 33/50, Train iteration 157/164: Loss = 1.5848\n",
      "Epoch 33/50, Train iteration 158/164: Loss = 1.5878\n",
      "Epoch 33/50, Train iteration 159/164: Loss = 1.6034\n",
      "Epoch 33/50, Train iteration 160/164: Loss = 1.5765\n",
      "Epoch 33/50, Train iteration 161/164: Loss = 1.6224\n",
      "Epoch 33/50, Train iteration 162/164: Loss = 1.5576\n",
      "Epoch 33/50, Train iteration 163/164: Loss = 1.5740\n",
      "Epoch 33/50, Train iteration 164/164: Loss = 1.4326\n",
      "Epoch 33/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 33/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 33/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 33/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 33/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 33/50, Val iteration 6/27: Loss = 1.5813\n",
      "Epoch 33/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 33/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 33/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 33/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 33/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 33/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 33/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 33/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 33/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 33/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 33/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 33/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 33/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 33/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 33/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 33/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 33/50, Val iteration 23/27: Loss = 1.4851\n",
      "Epoch 33/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 33/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 33/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 33/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 33/50: Train Loss = 1.5394, Val Loss = 1.5831\n",
      "Current learning rate: 2.187e-08\n",
      "Epoch 34/50, Train iteration 1/164: Loss = 1.5192\n",
      "Epoch 34/50, Train iteration 2/164: Loss = 1.5529\n",
      "Epoch 34/50, Train iteration 3/164: Loss = 1.5256\n",
      "Epoch 34/50, Train iteration 4/164: Loss = 1.5878\n",
      "Epoch 34/50, Train iteration 5/164: Loss = 1.5899\n",
      "Epoch 34/50, Train iteration 6/164: Loss = 1.6470\n",
      "Epoch 34/50, Train iteration 7/164: Loss = 1.6040\n",
      "Epoch 34/50, Train iteration 8/164: Loss = 1.4528\n",
      "Epoch 34/50, Train iteration 9/164: Loss = 1.5964\n",
      "Epoch 34/50, Train iteration 10/164: Loss = 1.6245\n",
      "Epoch 34/50, Train iteration 11/164: Loss = 1.5644\n",
      "Epoch 34/50, Train iteration 12/164: Loss = 1.5447\n",
      "Epoch 34/50, Train iteration 13/164: Loss = 1.4762\n",
      "Epoch 34/50, Train iteration 14/164: Loss = 1.5367\n",
      "Epoch 34/50, Train iteration 15/164: Loss = 1.5874\n",
      "Epoch 34/50, Train iteration 16/164: Loss = 1.5379\n",
      "Epoch 34/50, Train iteration 17/164: Loss = 1.5285\n",
      "Epoch 34/50, Train iteration 18/164: Loss = 1.5319\n",
      "Epoch 34/50, Train iteration 19/164: Loss = 1.4859\n",
      "Epoch 34/50, Train iteration 20/164: Loss = 1.5266\n",
      "Epoch 34/50, Train iteration 21/164: Loss = 1.5172\n",
      "Epoch 34/50, Train iteration 22/164: Loss = 1.5369\n",
      "Epoch 34/50, Train iteration 23/164: Loss = 1.5813\n",
      "Epoch 34/50, Train iteration 24/164: Loss = 1.6010\n",
      "Epoch 34/50, Train iteration 25/164: Loss = 1.5833\n",
      "Epoch 34/50, Train iteration 26/164: Loss = 1.5936\n",
      "Epoch 34/50, Train iteration 27/164: Loss = 1.5608\n",
      "Epoch 34/50, Train iteration 28/164: Loss = 1.5113\n",
      "Epoch 34/50, Train iteration 29/164: Loss = 1.5489\n",
      "Epoch 34/50, Train iteration 30/164: Loss = 1.5727\n",
      "Epoch 34/50, Train iteration 31/164: Loss = 1.5298\n",
      "Epoch 34/50, Train iteration 32/164: Loss = 1.5626\n",
      "Epoch 34/50, Train iteration 33/164: Loss = 1.6034\n",
      "Epoch 34/50, Train iteration 34/164: Loss = 1.5313\n",
      "Epoch 34/50, Train iteration 35/164: Loss = 1.5745\n",
      "Epoch 34/50, Train iteration 36/164: Loss = 1.5285\n",
      "Epoch 34/50, Train iteration 37/164: Loss = 1.5595\n",
      "Epoch 34/50, Train iteration 38/164: Loss = 1.5269\n",
      "Epoch 34/50, Train iteration 39/164: Loss = 1.5159\n",
      "Epoch 34/50, Train iteration 40/164: Loss = 1.4933\n",
      "Epoch 34/50, Train iteration 41/164: Loss = 1.4412\n",
      "Epoch 34/50, Train iteration 42/164: Loss = 1.5413\n",
      "Epoch 34/50, Train iteration 43/164: Loss = 1.5665\n",
      "Epoch 34/50, Train iteration 44/164: Loss = 1.5087\n",
      "Epoch 34/50, Train iteration 45/164: Loss = 1.5205\n",
      "Epoch 34/50, Train iteration 46/164: Loss = 1.5601\n",
      "Epoch 34/50, Train iteration 47/164: Loss = 1.5446\n",
      "Epoch 34/50, Train iteration 48/164: Loss = 1.5178\n",
      "Epoch 34/50, Train iteration 49/164: Loss = 1.5544\n",
      "Epoch 34/50, Train iteration 50/164: Loss = 1.5934\n",
      "Epoch 34/50, Train iteration 51/164: Loss = 1.4732\n",
      "Epoch 34/50, Train iteration 52/164: Loss = 1.5046\n",
      "Epoch 34/50, Train iteration 53/164: Loss = 1.4952\n",
      "Epoch 34/50, Train iteration 54/164: Loss = 1.5436\n",
      "Epoch 34/50, Train iteration 55/164: Loss = 1.4810\n",
      "Epoch 34/50, Train iteration 56/164: Loss = 1.5344\n",
      "Epoch 34/50, Train iteration 57/164: Loss = 1.5008\n",
      "Epoch 34/50, Train iteration 58/164: Loss = 1.6094\n",
      "Epoch 34/50, Train iteration 59/164: Loss = 1.5280\n",
      "Epoch 34/50, Train iteration 60/164: Loss = 1.5275\n",
      "Epoch 34/50, Train iteration 61/164: Loss = 1.4923\n",
      "Epoch 34/50, Train iteration 62/164: Loss = 1.5173\n",
      "Epoch 34/50, Train iteration 63/164: Loss = 1.5767\n",
      "Epoch 34/50, Train iteration 64/164: Loss = 1.5529\n",
      "Epoch 34/50, Train iteration 65/164: Loss = 1.5121\n",
      "Epoch 34/50, Train iteration 66/164: Loss = 1.4782\n",
      "Epoch 34/50, Train iteration 67/164: Loss = 1.5141\n",
      "Epoch 34/50, Train iteration 68/164: Loss = 1.5147\n",
      "Epoch 34/50, Train iteration 69/164: Loss = 1.6059\n",
      "Epoch 34/50, Train iteration 70/164: Loss = 1.5696\n",
      "Epoch 34/50, Train iteration 71/164: Loss = 1.5538\n",
      "Epoch 34/50, Train iteration 72/164: Loss = 1.4803\n",
      "Epoch 34/50, Train iteration 73/164: Loss = 1.5677\n",
      "Epoch 34/50, Train iteration 74/164: Loss = 1.5169\n",
      "Epoch 34/50, Train iteration 75/164: Loss = 1.4828\n",
      "Epoch 34/50, Train iteration 76/164: Loss = 1.5422\n",
      "Epoch 34/50, Train iteration 77/164: Loss = 1.5745\n",
      "Epoch 34/50, Train iteration 78/164: Loss = 1.5630\n",
      "Epoch 34/50, Train iteration 79/164: Loss = 1.5844\n",
      "Epoch 34/50, Train iteration 80/164: Loss = 1.5364\n",
      "Epoch 34/50, Train iteration 81/164: Loss = 1.5082\n",
      "Epoch 34/50, Train iteration 82/164: Loss = 1.5415\n",
      "Epoch 34/50, Train iteration 83/164: Loss = 1.5727\n",
      "Epoch 34/50, Train iteration 84/164: Loss = 1.5250\n",
      "Epoch 34/50, Train iteration 85/164: Loss = 1.5897\n",
      "Epoch 34/50, Train iteration 86/164: Loss = 1.4421\n",
      "Epoch 34/50, Train iteration 87/164: Loss = 1.5590\n",
      "Epoch 34/50, Train iteration 88/164: Loss = 1.5917\n",
      "Epoch 34/50, Train iteration 89/164: Loss = 1.5367\n",
      "Epoch 34/50, Train iteration 90/164: Loss = 1.5176\n",
      "Epoch 34/50, Train iteration 91/164: Loss = 1.5898\n",
      "Epoch 34/50, Train iteration 92/164: Loss = 1.5089\n",
      "Epoch 34/50, Train iteration 93/164: Loss = 1.5130\n",
      "Epoch 34/50, Train iteration 94/164: Loss = 1.5440\n",
      "Epoch 34/50, Train iteration 95/164: Loss = 1.4975\n",
      "Epoch 34/50, Train iteration 96/164: Loss = 1.5581\n",
      "Epoch 34/50, Train iteration 97/164: Loss = 1.5370\n",
      "Epoch 34/50, Train iteration 98/164: Loss = 1.5321\n",
      "Epoch 34/50, Train iteration 99/164: Loss = 1.4670\n",
      "Epoch 34/50, Train iteration 100/164: Loss = 1.5265\n",
      "Epoch 34/50, Train iteration 101/164: Loss = 1.5072\n",
      "Epoch 34/50, Train iteration 102/164: Loss = 1.5612\n",
      "Epoch 34/50, Train iteration 103/164: Loss = 1.5203\n",
      "Epoch 34/50, Train iteration 104/164: Loss = 1.5736\n",
      "Epoch 34/50, Train iteration 105/164: Loss = 1.5329\n",
      "Epoch 34/50, Train iteration 106/164: Loss = 1.5664\n",
      "Epoch 34/50, Train iteration 107/164: Loss = 1.5502\n",
      "Epoch 34/50, Train iteration 108/164: Loss = 1.5236\n",
      "Epoch 34/50, Train iteration 109/164: Loss = 1.5694\n",
      "Epoch 34/50, Train iteration 110/164: Loss = 1.5547\n",
      "Epoch 34/50, Train iteration 111/164: Loss = 1.5758\n",
      "Epoch 34/50, Train iteration 112/164: Loss = 1.5400\n",
      "Epoch 34/50, Train iteration 113/164: Loss = 1.5134\n",
      "Epoch 34/50, Train iteration 114/164: Loss = 1.4545\n",
      "Epoch 34/50, Train iteration 115/164: Loss = 1.5161\n",
      "Epoch 34/50, Train iteration 116/164: Loss = 1.5380\n",
      "Epoch 34/50, Train iteration 117/164: Loss = 1.5816\n",
      "Epoch 34/50, Train iteration 118/164: Loss = 1.5493\n",
      "Epoch 34/50, Train iteration 119/164: Loss = 1.5023\n",
      "Epoch 34/50, Train iteration 120/164: Loss = 1.5467\n",
      "Epoch 34/50, Train iteration 121/164: Loss = 1.5101\n",
      "Epoch 34/50, Train iteration 122/164: Loss = 1.4491\n",
      "Epoch 34/50, Train iteration 123/164: Loss = 1.5302\n",
      "Epoch 34/50, Train iteration 124/164: Loss = 1.4850\n",
      "Epoch 34/50, Train iteration 125/164: Loss = 1.5066\n",
      "Epoch 34/50, Train iteration 126/164: Loss = 1.5419\n",
      "Epoch 34/50, Train iteration 127/164: Loss = 1.5826\n",
      "Epoch 34/50, Train iteration 128/164: Loss = 1.4595\n",
      "Epoch 34/50, Train iteration 129/164: Loss = 1.5487\n",
      "Epoch 34/50, Train iteration 130/164: Loss = 1.5719\n",
      "Epoch 34/50, Train iteration 131/164: Loss = 1.5492\n",
      "Epoch 34/50, Train iteration 132/164: Loss = 1.5210\n",
      "Epoch 34/50, Train iteration 133/164: Loss = 1.5507\n",
      "Epoch 34/50, Train iteration 134/164: Loss = 1.5445\n",
      "Epoch 34/50, Train iteration 135/164: Loss = 1.5532\n",
      "Epoch 34/50, Train iteration 136/164: Loss = 1.5683\n",
      "Epoch 34/50, Train iteration 137/164: Loss = 1.5050\n",
      "Epoch 34/50, Train iteration 138/164: Loss = 1.5274\n",
      "Epoch 34/50, Train iteration 139/164: Loss = 1.6381\n",
      "Epoch 34/50, Train iteration 140/164: Loss = 1.5239\n",
      "Epoch 34/50, Train iteration 141/164: Loss = 1.5568\n",
      "Epoch 34/50, Train iteration 142/164: Loss = 1.5367\n",
      "Epoch 34/50, Train iteration 143/164: Loss = 1.4571\n",
      "Epoch 34/50, Train iteration 144/164: Loss = 1.5808\n",
      "Epoch 34/50, Train iteration 145/164: Loss = 1.5380\n",
      "Epoch 34/50, Train iteration 146/164: Loss = 1.4614\n",
      "Epoch 34/50, Train iteration 147/164: Loss = 1.5289\n",
      "Epoch 34/50, Train iteration 148/164: Loss = 1.5333\n",
      "Epoch 34/50, Train iteration 149/164: Loss = 1.5365\n",
      "Epoch 34/50, Train iteration 150/164: Loss = 1.5711\n",
      "Epoch 34/50, Train iteration 151/164: Loss = 1.5660\n",
      "Epoch 34/50, Train iteration 152/164: Loss = 1.5115\n",
      "Epoch 34/50, Train iteration 153/164: Loss = 1.5656\n",
      "Epoch 34/50, Train iteration 154/164: Loss = 1.5141\n",
      "Epoch 34/50, Train iteration 155/164: Loss = 1.5387\n",
      "Epoch 34/50, Train iteration 156/164: Loss = 1.5203\n",
      "Epoch 34/50, Train iteration 157/164: Loss = 1.5909\n",
      "Epoch 34/50, Train iteration 158/164: Loss = 1.5909\n",
      "Epoch 34/50, Train iteration 159/164: Loss = 1.5380\n",
      "Epoch 34/50, Train iteration 160/164: Loss = 1.5540\n",
      "Epoch 34/50, Train iteration 161/164: Loss = 1.5850\n",
      "Epoch 34/50, Train iteration 162/164: Loss = 1.5977\n",
      "Epoch 34/50, Train iteration 163/164: Loss = 1.5689\n",
      "Epoch 34/50, Train iteration 164/164: Loss = 1.4309\n",
      "Epoch 34/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 34/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 34/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 34/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 34/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 34/50, Val iteration 6/27: Loss = 1.5813\n",
      "Epoch 34/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 34/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 34/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 34/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 34/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 34/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 34/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 34/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 34/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 34/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 34/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 34/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 34/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 34/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 34/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 34/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 34/50, Val iteration 23/27: Loss = 1.4851\n",
      "Epoch 34/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 34/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 34/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 34/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 34/50: Train Loss = 1.5391, Val Loss = 1.5831\n",
      "Current learning rate: 2.187e-08\n",
      "Epoch 35/50, Train iteration 1/164: Loss = 1.5407\n",
      "Epoch 35/50, Train iteration 2/164: Loss = 1.5404\n",
      "Epoch 35/50, Train iteration 3/164: Loss = 1.5846\n",
      "Epoch 35/50, Train iteration 4/164: Loss = 1.5428\n",
      "Epoch 35/50, Train iteration 5/164: Loss = 1.5451\n",
      "Epoch 35/50, Train iteration 6/164: Loss = 1.5968\n",
      "Epoch 35/50, Train iteration 7/164: Loss = 1.5965\n",
      "Epoch 35/50, Train iteration 8/164: Loss = 1.5395\n",
      "Epoch 35/50, Train iteration 9/164: Loss = 1.6036\n",
      "Epoch 35/50, Train iteration 10/164: Loss = 1.5955\n",
      "Epoch 35/50, Train iteration 11/164: Loss = 1.5754\n",
      "Epoch 35/50, Train iteration 12/164: Loss = 1.5194\n",
      "Epoch 35/50, Train iteration 13/164: Loss = 1.5100\n",
      "Epoch 35/50, Train iteration 14/164: Loss = 1.5293\n",
      "Epoch 35/50, Train iteration 15/164: Loss = 1.5469\n",
      "Epoch 35/50, Train iteration 16/164: Loss = 1.5767\n",
      "Epoch 35/50, Train iteration 17/164: Loss = 1.5603\n",
      "Epoch 35/50, Train iteration 18/164: Loss = 1.5266\n",
      "Epoch 35/50, Train iteration 19/164: Loss = 1.5607\n",
      "Epoch 35/50, Train iteration 20/164: Loss = 1.5222\n",
      "Epoch 35/50, Train iteration 21/164: Loss = 1.5532\n",
      "Epoch 35/50, Train iteration 22/164: Loss = 1.5695\n",
      "Epoch 35/50, Train iteration 23/164: Loss = 1.5907\n",
      "Epoch 35/50, Train iteration 24/164: Loss = 1.6150\n",
      "Epoch 35/50, Train iteration 25/164: Loss = 1.5924\n",
      "Epoch 35/50, Train iteration 26/164: Loss = 1.5551\n",
      "Epoch 35/50, Train iteration 27/164: Loss = 1.5221\n",
      "Epoch 35/50, Train iteration 28/164: Loss = 1.5829\n",
      "Epoch 35/50, Train iteration 29/164: Loss = 1.5369\n",
      "Epoch 35/50, Train iteration 30/164: Loss = 1.5515\n",
      "Epoch 35/50, Train iteration 31/164: Loss = 1.4986\n",
      "Epoch 35/50, Train iteration 32/164: Loss = 1.5117\n",
      "Epoch 35/50, Train iteration 33/164: Loss = 1.5687\n",
      "Epoch 35/50, Train iteration 34/164: Loss = 1.5008\n",
      "Epoch 35/50, Train iteration 35/164: Loss = 1.5230\n",
      "Epoch 35/50, Train iteration 36/164: Loss = 1.5069\n",
      "Epoch 35/50, Train iteration 37/164: Loss = 1.5702\n",
      "Epoch 35/50, Train iteration 38/164: Loss = 1.5655\n",
      "Epoch 35/50, Train iteration 39/164: Loss = 1.5387\n",
      "Epoch 35/50, Train iteration 40/164: Loss = 1.5223\n",
      "Epoch 35/50, Train iteration 41/164: Loss = 1.5142\n",
      "Epoch 35/50, Train iteration 42/164: Loss = 1.5271\n",
      "Epoch 35/50, Train iteration 43/164: Loss = 1.5626\n",
      "Epoch 35/50, Train iteration 44/164: Loss = 1.5072\n",
      "Epoch 35/50, Train iteration 45/164: Loss = 1.5735\n",
      "Epoch 35/50, Train iteration 46/164: Loss = 1.5646\n",
      "Epoch 35/50, Train iteration 47/164: Loss = 1.5630\n",
      "Epoch 35/50, Train iteration 48/164: Loss = 1.5221\n",
      "Epoch 35/50, Train iteration 49/164: Loss = 1.5248\n",
      "Epoch 35/50, Train iteration 50/164: Loss = 1.5765\n",
      "Epoch 35/50, Train iteration 51/164: Loss = 1.4870\n",
      "Epoch 35/50, Train iteration 52/164: Loss = 1.5130\n",
      "Epoch 35/50, Train iteration 53/164: Loss = 1.4953\n",
      "Epoch 35/50, Train iteration 54/164: Loss = 1.5672\n",
      "Epoch 35/50, Train iteration 55/164: Loss = 1.4871\n",
      "Epoch 35/50, Train iteration 56/164: Loss = 1.5610\n",
      "Epoch 35/50, Train iteration 57/164: Loss = 1.5779\n",
      "Epoch 35/50, Train iteration 58/164: Loss = 1.5728\n",
      "Epoch 35/50, Train iteration 59/164: Loss = 1.5803\n",
      "Epoch 35/50, Train iteration 60/164: Loss = 1.5413\n",
      "Epoch 35/50, Train iteration 61/164: Loss = 1.4817\n",
      "Epoch 35/50, Train iteration 62/164: Loss = 1.4741\n",
      "Epoch 35/50, Train iteration 63/164: Loss = 1.5945\n",
      "Epoch 35/50, Train iteration 64/164: Loss = 1.5495\n",
      "Epoch 35/50, Train iteration 65/164: Loss = 1.5122\n",
      "Epoch 35/50, Train iteration 66/164: Loss = 1.4507\n",
      "Epoch 35/50, Train iteration 67/164: Loss = 1.5350\n",
      "Epoch 35/50, Train iteration 68/164: Loss = 1.5312\n",
      "Epoch 35/50, Train iteration 69/164: Loss = 1.5579\n",
      "Epoch 35/50, Train iteration 70/164: Loss = 1.5361\n",
      "Epoch 35/50, Train iteration 71/164: Loss = 1.5678\n",
      "Epoch 35/50, Train iteration 72/164: Loss = 1.5755\n",
      "Epoch 35/50, Train iteration 73/164: Loss = 1.5819\n",
      "Epoch 35/50, Train iteration 74/164: Loss = 1.5609\n",
      "Epoch 35/50, Train iteration 75/164: Loss = 1.5041\n",
      "Epoch 35/50, Train iteration 76/164: Loss = 1.5533\n",
      "Epoch 35/50, Train iteration 77/164: Loss = 1.6036\n",
      "Epoch 35/50, Train iteration 78/164: Loss = 1.5500\n",
      "Epoch 35/50, Train iteration 79/164: Loss = 1.5699\n",
      "Epoch 35/50, Train iteration 80/164: Loss = 1.5932\n",
      "Epoch 35/50, Train iteration 81/164: Loss = 1.5677\n",
      "Epoch 35/50, Train iteration 82/164: Loss = 1.5201\n",
      "Epoch 35/50, Train iteration 83/164: Loss = 1.5813\n",
      "Epoch 35/50, Train iteration 84/164: Loss = 1.5121\n",
      "Epoch 35/50, Train iteration 85/164: Loss = 1.6278\n",
      "Epoch 35/50, Train iteration 86/164: Loss = 1.3988\n",
      "Epoch 35/50, Train iteration 87/164: Loss = 1.5171\n",
      "Epoch 35/50, Train iteration 88/164: Loss = 1.6175\n",
      "Epoch 35/50, Train iteration 89/164: Loss = 1.5809\n",
      "Epoch 35/50, Train iteration 90/164: Loss = 1.5119\n",
      "Epoch 35/50, Train iteration 91/164: Loss = 1.5856\n",
      "Epoch 35/50, Train iteration 92/164: Loss = 1.5325\n",
      "Epoch 35/50, Train iteration 93/164: Loss = 1.5868\n",
      "Epoch 35/50, Train iteration 94/164: Loss = 1.6310\n",
      "Epoch 35/50, Train iteration 95/164: Loss = 1.5379\n",
      "Epoch 35/50, Train iteration 96/164: Loss = 1.5727\n",
      "Epoch 35/50, Train iteration 97/164: Loss = 1.5373\n",
      "Epoch 35/50, Train iteration 98/164: Loss = 1.4942\n",
      "Epoch 35/50, Train iteration 99/164: Loss = 1.5294\n",
      "Epoch 35/50, Train iteration 100/164: Loss = 1.5377\n",
      "Epoch 35/50, Train iteration 101/164: Loss = 1.5728\n",
      "Epoch 35/50, Train iteration 102/164: Loss = 1.5926\n",
      "Epoch 35/50, Train iteration 103/164: Loss = 1.5405\n",
      "Epoch 35/50, Train iteration 104/164: Loss = 1.5461\n",
      "Epoch 35/50, Train iteration 105/164: Loss = 1.6202\n",
      "Epoch 35/50, Train iteration 106/164: Loss = 1.5686\n",
      "Epoch 35/50, Train iteration 107/164: Loss = 1.5421\n",
      "Epoch 35/50, Train iteration 108/164: Loss = 1.5440\n",
      "Epoch 35/50, Train iteration 109/164: Loss = 1.5698\n",
      "Epoch 35/50, Train iteration 110/164: Loss = 1.5212\n",
      "Epoch 35/50, Train iteration 111/164: Loss = 1.5833\n",
      "Epoch 35/50, Train iteration 112/164: Loss = 1.5187\n",
      "Epoch 35/50, Train iteration 113/164: Loss = 1.4978\n",
      "Epoch 35/50, Train iteration 114/164: Loss = 1.4270\n",
      "Epoch 35/50, Train iteration 115/164: Loss = 1.5150\n",
      "Epoch 35/50, Train iteration 116/164: Loss = 1.4913\n",
      "Epoch 35/50, Train iteration 117/164: Loss = 1.5287\n",
      "Epoch 35/50, Train iteration 118/164: Loss = 1.5852\n",
      "Epoch 35/50, Train iteration 119/164: Loss = 1.5387\n",
      "Epoch 35/50, Train iteration 120/164: Loss = 1.5273\n",
      "Epoch 35/50, Train iteration 121/164: Loss = 1.5556\n",
      "Epoch 35/50, Train iteration 122/164: Loss = 1.5095\n",
      "Epoch 35/50, Train iteration 123/164: Loss = 1.5108\n",
      "Epoch 35/50, Train iteration 124/164: Loss = 1.5231\n",
      "Epoch 35/50, Train iteration 125/164: Loss = 1.4723\n",
      "Epoch 35/50, Train iteration 126/164: Loss = 1.5078\n",
      "Epoch 35/50, Train iteration 127/164: Loss = 1.5558\n",
      "Epoch 35/50, Train iteration 128/164: Loss = 1.5052\n",
      "Epoch 35/50, Train iteration 129/164: Loss = 1.5002\n",
      "Epoch 35/50, Train iteration 130/164: Loss = 1.5860\n",
      "Epoch 35/50, Train iteration 131/164: Loss = 1.5395\n",
      "Epoch 35/50, Train iteration 132/164: Loss = 1.4648\n",
      "Epoch 35/50, Train iteration 133/164: Loss = 1.5539\n",
      "Epoch 35/50, Train iteration 134/164: Loss = 1.5036\n",
      "Epoch 35/50, Train iteration 135/164: Loss = 1.5454\n",
      "Epoch 35/50, Train iteration 136/164: Loss = 1.5288\n",
      "Epoch 35/50, Train iteration 137/164: Loss = 1.4894\n",
      "Epoch 35/50, Train iteration 138/164: Loss = 1.5493\n",
      "Epoch 35/50, Train iteration 139/164: Loss = 1.5953\n",
      "Epoch 35/50, Train iteration 140/164: Loss = 1.5434\n",
      "Epoch 35/50, Train iteration 141/164: Loss = 1.5593\n",
      "Epoch 35/50, Train iteration 142/164: Loss = 1.5969\n",
      "Epoch 35/50, Train iteration 143/164: Loss = 1.4964\n",
      "Epoch 35/50, Train iteration 144/164: Loss = 1.5796\n",
      "Epoch 35/50, Train iteration 145/164: Loss = 1.5205\n",
      "Epoch 35/50, Train iteration 146/164: Loss = 1.5428\n",
      "Epoch 35/50, Train iteration 147/164: Loss = 1.5182\n",
      "Epoch 35/50, Train iteration 148/164: Loss = 1.5066\n",
      "Epoch 35/50, Train iteration 149/164: Loss = 1.5431\n",
      "Epoch 35/50, Train iteration 150/164: Loss = 1.5544\n",
      "Epoch 35/50, Train iteration 151/164: Loss = 1.5732\n",
      "Epoch 35/50, Train iteration 152/164: Loss = 1.4714\n",
      "Epoch 35/50, Train iteration 153/164: Loss = 1.5110\n",
      "Epoch 35/50, Train iteration 154/164: Loss = 1.5388\n",
      "Epoch 35/50, Train iteration 155/164: Loss = 1.5931\n",
      "Epoch 35/50, Train iteration 156/164: Loss = 1.5023\n",
      "Epoch 35/50, Train iteration 157/164: Loss = 1.5730\n",
      "Epoch 35/50, Train iteration 158/164: Loss = 1.5839\n",
      "Epoch 35/50, Train iteration 159/164: Loss = 1.5391\n",
      "Epoch 35/50, Train iteration 160/164: Loss = 1.5668\n",
      "Epoch 35/50, Train iteration 161/164: Loss = 1.6366\n",
      "Epoch 35/50, Train iteration 162/164: Loss = 1.5713\n",
      "Epoch 35/50, Train iteration 163/164: Loss = 1.5502\n",
      "Epoch 35/50, Train iteration 164/164: Loss = 1.4237\n",
      "Epoch 35/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 35/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 35/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 35/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 35/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 35/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 35/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 35/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 35/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 35/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 35/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 35/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 35/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 35/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 35/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 35/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 35/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 35/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 35/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 35/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 35/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 35/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 35/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 35/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 35/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 35/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 35/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 35/50: Train Loss = 1.5439, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 36/50, Train iteration 1/164: Loss = 1.4980\n",
      "Epoch 36/50, Train iteration 2/164: Loss = 1.5161\n",
      "Epoch 36/50, Train iteration 3/164: Loss = 1.5954\n",
      "Epoch 36/50, Train iteration 4/164: Loss = 1.5706\n",
      "Epoch 36/50, Train iteration 5/164: Loss = 1.5625\n",
      "Epoch 36/50, Train iteration 6/164: Loss = 1.5717\n",
      "Epoch 36/50, Train iteration 7/164: Loss = 1.5708\n",
      "Epoch 36/50, Train iteration 8/164: Loss = 1.4852\n",
      "Epoch 36/50, Train iteration 9/164: Loss = 1.5884\n",
      "Epoch 36/50, Train iteration 10/164: Loss = 1.6087\n",
      "Epoch 36/50, Train iteration 11/164: Loss = 1.5331\n",
      "Epoch 36/50, Train iteration 12/164: Loss = 1.5192\n",
      "Epoch 36/50, Train iteration 13/164: Loss = 1.5182\n",
      "Epoch 36/50, Train iteration 14/164: Loss = 1.5686\n",
      "Epoch 36/50, Train iteration 15/164: Loss = 1.5359\n",
      "Epoch 36/50, Train iteration 16/164: Loss = 1.5332\n",
      "Epoch 36/50, Train iteration 17/164: Loss = 1.5135\n",
      "Epoch 36/50, Train iteration 18/164: Loss = 1.5515\n",
      "Epoch 36/50, Train iteration 19/164: Loss = 1.5280\n",
      "Epoch 36/50, Train iteration 20/164: Loss = 1.5457\n",
      "Epoch 36/50, Train iteration 21/164: Loss = 1.5547\n",
      "Epoch 36/50, Train iteration 22/164: Loss = 1.5864\n",
      "Epoch 36/50, Train iteration 23/164: Loss = 1.5612\n",
      "Epoch 36/50, Train iteration 24/164: Loss = 1.5630\n",
      "Epoch 36/50, Train iteration 25/164: Loss = 1.5653\n",
      "Epoch 36/50, Train iteration 26/164: Loss = 1.5571\n",
      "Epoch 36/50, Train iteration 27/164: Loss = 1.5460\n",
      "Epoch 36/50, Train iteration 28/164: Loss = 1.5665\n",
      "Epoch 36/50, Train iteration 29/164: Loss = 1.5212\n",
      "Epoch 36/50, Train iteration 30/164: Loss = 1.5849\n",
      "Epoch 36/50, Train iteration 31/164: Loss = 1.5061\n",
      "Epoch 36/50, Train iteration 32/164: Loss = 1.4820\n",
      "Epoch 36/50, Train iteration 33/164: Loss = 1.5839\n",
      "Epoch 36/50, Train iteration 34/164: Loss = 1.4430\n",
      "Epoch 36/50, Train iteration 35/164: Loss = 1.5355\n",
      "Epoch 36/50, Train iteration 36/164: Loss = 1.4870\n",
      "Epoch 36/50, Train iteration 37/164: Loss = 1.5170\n",
      "Epoch 36/50, Train iteration 38/164: Loss = 1.5564\n",
      "Epoch 36/50, Train iteration 39/164: Loss = 1.5243\n",
      "Epoch 36/50, Train iteration 40/164: Loss = 1.4760\n",
      "Epoch 36/50, Train iteration 41/164: Loss = 1.4815\n",
      "Epoch 36/50, Train iteration 42/164: Loss = 1.5300\n",
      "Epoch 36/50, Train iteration 43/164: Loss = 1.5370\n",
      "Epoch 36/50, Train iteration 44/164: Loss = 1.5062\n",
      "Epoch 36/50, Train iteration 45/164: Loss = 1.5517\n",
      "Epoch 36/50, Train iteration 46/164: Loss = 1.5162\n",
      "Epoch 36/50, Train iteration 47/164: Loss = 1.5987\n",
      "Epoch 36/50, Train iteration 48/164: Loss = 1.4766\n",
      "Epoch 36/50, Train iteration 49/164: Loss = 1.5011\n",
      "Epoch 36/50, Train iteration 50/164: Loss = 1.5719\n",
      "Epoch 36/50, Train iteration 51/164: Loss = 1.4563\n",
      "Epoch 36/50, Train iteration 52/164: Loss = 1.4878\n",
      "Epoch 36/50, Train iteration 53/164: Loss = 1.5504\n",
      "Epoch 36/50, Train iteration 54/164: Loss = 1.5346\n",
      "Epoch 36/50, Train iteration 55/164: Loss = 1.4937\n",
      "Epoch 36/50, Train iteration 56/164: Loss = 1.5382\n",
      "Epoch 36/50, Train iteration 57/164: Loss = 1.5692\n",
      "Epoch 36/50, Train iteration 58/164: Loss = 1.5916\n",
      "Epoch 36/50, Train iteration 59/164: Loss = 1.5063\n",
      "Epoch 36/50, Train iteration 60/164: Loss = 1.5644\n",
      "Epoch 36/50, Train iteration 61/164: Loss = 1.5112\n",
      "Epoch 36/50, Train iteration 62/164: Loss = 1.5373\n",
      "Epoch 36/50, Train iteration 63/164: Loss = 1.5843\n",
      "Epoch 36/50, Train iteration 64/164: Loss = 1.4579\n",
      "Epoch 36/50, Train iteration 65/164: Loss = 1.5321\n",
      "Epoch 36/50, Train iteration 66/164: Loss = 1.4905\n",
      "Epoch 36/50, Train iteration 67/164: Loss = 1.4806\n",
      "Epoch 36/50, Train iteration 68/164: Loss = 1.5022\n",
      "Epoch 36/50, Train iteration 69/164: Loss = 1.5256\n",
      "Epoch 36/50, Train iteration 70/164: Loss = 1.5618\n",
      "Epoch 36/50, Train iteration 71/164: Loss = 1.6050\n",
      "Epoch 36/50, Train iteration 72/164: Loss = 1.5893\n",
      "Epoch 36/50, Train iteration 73/164: Loss = 1.6106\n",
      "Epoch 36/50, Train iteration 74/164: Loss = 1.5245\n",
      "Epoch 36/50, Train iteration 75/164: Loss = 1.4876\n",
      "Epoch 36/50, Train iteration 76/164: Loss = 1.5373\n",
      "Epoch 36/50, Train iteration 77/164: Loss = 1.5659\n",
      "Epoch 36/50, Train iteration 78/164: Loss = 1.5328\n",
      "Epoch 36/50, Train iteration 79/164: Loss = 1.5563\n",
      "Epoch 36/50, Train iteration 80/164: Loss = 1.5476\n",
      "Epoch 36/50, Train iteration 81/164: Loss = 1.5614\n",
      "Epoch 36/50, Train iteration 82/164: Loss = 1.5394\n",
      "Epoch 36/50, Train iteration 83/164: Loss = 1.5235\n",
      "Epoch 36/50, Train iteration 84/164: Loss = 1.5072\n",
      "Epoch 36/50, Train iteration 85/164: Loss = 1.5771\n",
      "Epoch 36/50, Train iteration 86/164: Loss = 1.4380\n",
      "Epoch 36/50, Train iteration 87/164: Loss = 1.5174\n",
      "Epoch 36/50, Train iteration 88/164: Loss = 1.5867\n",
      "Epoch 36/50, Train iteration 89/164: Loss = 1.5305\n",
      "Epoch 36/50, Train iteration 90/164: Loss = 1.4869\n",
      "Epoch 36/50, Train iteration 91/164: Loss = 1.5859\n",
      "Epoch 36/50, Train iteration 92/164: Loss = 1.5464\n",
      "Epoch 36/50, Train iteration 93/164: Loss = 1.5283\n",
      "Epoch 36/50, Train iteration 94/164: Loss = 1.5764\n",
      "Epoch 36/50, Train iteration 95/164: Loss = 1.5069\n",
      "Epoch 36/50, Train iteration 96/164: Loss = 1.6026\n",
      "Epoch 36/50, Train iteration 97/164: Loss = 1.5236\n",
      "Epoch 36/50, Train iteration 98/164: Loss = 1.5704\n",
      "Epoch 36/50, Train iteration 99/164: Loss = 1.4578\n",
      "Epoch 36/50, Train iteration 100/164: Loss = 1.5082\n",
      "Epoch 36/50, Train iteration 101/164: Loss = 1.5470\n",
      "Epoch 36/50, Train iteration 102/164: Loss = 1.5645\n",
      "Epoch 36/50, Train iteration 103/164: Loss = 1.5453\n",
      "Epoch 36/50, Train iteration 104/164: Loss = 1.5970\n",
      "Epoch 36/50, Train iteration 105/164: Loss = 1.5342\n",
      "Epoch 36/50, Train iteration 106/164: Loss = 1.5414\n",
      "Epoch 36/50, Train iteration 107/164: Loss = 1.5619\n",
      "Epoch 36/50, Train iteration 108/164: Loss = 1.5551\n",
      "Epoch 36/50, Train iteration 109/164: Loss = 1.5417\n",
      "Epoch 36/50, Train iteration 110/164: Loss = 1.5429\n",
      "Epoch 36/50, Train iteration 111/164: Loss = 1.6075\n",
      "Epoch 36/50, Train iteration 112/164: Loss = 1.5614\n",
      "Epoch 36/50, Train iteration 113/164: Loss = 1.5215\n",
      "Epoch 36/50, Train iteration 114/164: Loss = 1.4104\n",
      "Epoch 36/50, Train iteration 115/164: Loss = 1.5906\n",
      "Epoch 36/50, Train iteration 116/164: Loss = 1.4689\n",
      "Epoch 36/50, Train iteration 117/164: Loss = 1.4748\n",
      "Epoch 36/50, Train iteration 118/164: Loss = 1.5505\n",
      "Epoch 36/50, Train iteration 119/164: Loss = 1.5642\n",
      "Epoch 36/50, Train iteration 120/164: Loss = 1.5197\n",
      "Epoch 36/50, Train iteration 121/164: Loss = 1.5416\n",
      "Epoch 36/50, Train iteration 122/164: Loss = 1.4598\n",
      "Epoch 36/50, Train iteration 123/164: Loss = 1.5155\n",
      "Epoch 36/50, Train iteration 124/164: Loss = 1.5164\n",
      "Epoch 36/50, Train iteration 125/164: Loss = 1.4974\n",
      "Epoch 36/50, Train iteration 126/164: Loss = 1.4522\n",
      "Epoch 36/50, Train iteration 127/164: Loss = 1.5505\n",
      "Epoch 36/50, Train iteration 128/164: Loss = 1.4910\n",
      "Epoch 36/50, Train iteration 129/164: Loss = 1.5286\n",
      "Epoch 36/50, Train iteration 130/164: Loss = 1.5899\n",
      "Epoch 36/50, Train iteration 131/164: Loss = 1.5711\n",
      "Epoch 36/50, Train iteration 132/164: Loss = 1.4933\n",
      "Epoch 36/50, Train iteration 133/164: Loss = 1.5060\n",
      "Epoch 36/50, Train iteration 134/164: Loss = 1.5122\n",
      "Epoch 36/50, Train iteration 135/164: Loss = 1.5109\n",
      "Epoch 36/50, Train iteration 136/164: Loss = 1.5302\n",
      "Epoch 36/50, Train iteration 137/164: Loss = 1.4762\n",
      "Epoch 36/50, Train iteration 138/164: Loss = 1.5724\n",
      "Epoch 36/50, Train iteration 139/164: Loss = 1.5802\n",
      "Epoch 36/50, Train iteration 140/164: Loss = 1.5111\n",
      "Epoch 36/50, Train iteration 141/164: Loss = 1.5161\n",
      "Epoch 36/50, Train iteration 142/164: Loss = 1.5829\n",
      "Epoch 36/50, Train iteration 143/164: Loss = 1.5024\n",
      "Epoch 36/50, Train iteration 144/164: Loss = 1.6146\n",
      "Epoch 36/50, Train iteration 145/164: Loss = 1.5195\n",
      "Epoch 36/50, Train iteration 146/164: Loss = 1.5187\n",
      "Epoch 36/50, Train iteration 147/164: Loss = 1.5427\n",
      "Epoch 36/50, Train iteration 148/164: Loss = 1.4936\n",
      "Epoch 36/50, Train iteration 149/164: Loss = 1.5849\n",
      "Epoch 36/50, Train iteration 150/164: Loss = 1.5293\n",
      "Epoch 36/50, Train iteration 151/164: Loss = 1.5634\n",
      "Epoch 36/50, Train iteration 152/164: Loss = 1.4929\n",
      "Epoch 36/50, Train iteration 153/164: Loss = 1.5361\n",
      "Epoch 36/50, Train iteration 154/164: Loss = 1.5482\n",
      "Epoch 36/50, Train iteration 155/164: Loss = 1.5249\n",
      "Epoch 36/50, Train iteration 156/164: Loss = 1.5267\n",
      "Epoch 36/50, Train iteration 157/164: Loss = 1.5929\n",
      "Epoch 36/50, Train iteration 158/164: Loss = 1.5832\n",
      "Epoch 36/50, Train iteration 159/164: Loss = 1.5660\n",
      "Epoch 36/50, Train iteration 160/164: Loss = 1.5490\n",
      "Epoch 36/50, Train iteration 161/164: Loss = 1.6027\n",
      "Epoch 36/50, Train iteration 162/164: Loss = 1.5401\n",
      "Epoch 36/50, Train iteration 163/164: Loss = 1.5571\n",
      "Epoch 36/50, Train iteration 164/164: Loss = 1.3429\n",
      "Epoch 36/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 36/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 36/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 36/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 36/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 36/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 36/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 36/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 36/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 36/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 36/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 36/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 36/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 36/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 36/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 36/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 36/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 36/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 36/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 36/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 36/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 36/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 36/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 36/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 36/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 36/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 36/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 36/50: Train Loss = 1.5350, Val Loss = 1.5831\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 37/50, Train iteration 1/164: Loss = 1.5670\n",
      "Epoch 37/50, Train iteration 2/164: Loss = 1.5253\n",
      "Epoch 37/50, Train iteration 3/164: Loss = 1.5528\n",
      "Epoch 37/50, Train iteration 4/164: Loss = 1.5355\n",
      "Epoch 37/50, Train iteration 5/164: Loss = 1.6081\n",
      "Epoch 37/50, Train iteration 6/164: Loss = 1.6159\n",
      "Epoch 37/50, Train iteration 7/164: Loss = 1.5720\n",
      "Epoch 37/50, Train iteration 8/164: Loss = 1.5047\n",
      "Epoch 37/50, Train iteration 9/164: Loss = 1.5782\n",
      "Epoch 37/50, Train iteration 10/164: Loss = 1.6436\n",
      "Epoch 37/50, Train iteration 11/164: Loss = 1.5552\n",
      "Epoch 37/50, Train iteration 12/164: Loss = 1.5369\n",
      "Epoch 37/50, Train iteration 13/164: Loss = 1.4781\n",
      "Epoch 37/50, Train iteration 14/164: Loss = 1.5723\n",
      "Epoch 37/50, Train iteration 15/164: Loss = 1.5535\n",
      "Epoch 37/50, Train iteration 16/164: Loss = 1.5894\n",
      "Epoch 37/50, Train iteration 17/164: Loss = 1.5479\n",
      "Epoch 37/50, Train iteration 18/164: Loss = 1.5033\n",
      "Epoch 37/50, Train iteration 19/164: Loss = 1.5282\n",
      "Epoch 37/50, Train iteration 20/164: Loss = 1.5494\n",
      "Epoch 37/50, Train iteration 21/164: Loss = 1.5695\n",
      "Epoch 37/50, Train iteration 22/164: Loss = 1.5076\n",
      "Epoch 37/50, Train iteration 23/164: Loss = 1.5823\n",
      "Epoch 37/50, Train iteration 24/164: Loss = 1.5485\n",
      "Epoch 37/50, Train iteration 25/164: Loss = 1.5811\n",
      "Epoch 37/50, Train iteration 26/164: Loss = 1.5549\n",
      "Epoch 37/50, Train iteration 27/164: Loss = 1.5458\n",
      "Epoch 37/50, Train iteration 28/164: Loss = 1.5749\n",
      "Epoch 37/50, Train iteration 29/164: Loss = 1.5700\n",
      "Epoch 37/50, Train iteration 30/164: Loss = 1.5737\n",
      "Epoch 37/50, Train iteration 31/164: Loss = 1.5186\n",
      "Epoch 37/50, Train iteration 32/164: Loss = 1.5204\n",
      "Epoch 37/50, Train iteration 33/164: Loss = 1.5605\n",
      "Epoch 37/50, Train iteration 34/164: Loss = 1.5174\n",
      "Epoch 37/50, Train iteration 35/164: Loss = 1.5389\n",
      "Epoch 37/50, Train iteration 36/164: Loss = 1.5079\n",
      "Epoch 37/50, Train iteration 37/164: Loss = 1.5616\n",
      "Epoch 37/50, Train iteration 38/164: Loss = 1.5311\n",
      "Epoch 37/50, Train iteration 39/164: Loss = 1.5135\n",
      "Epoch 37/50, Train iteration 40/164: Loss = 1.5057\n",
      "Epoch 37/50, Train iteration 41/164: Loss = 1.4863\n",
      "Epoch 37/50, Train iteration 42/164: Loss = 1.5183\n",
      "Epoch 37/50, Train iteration 43/164: Loss = 1.5532\n",
      "Epoch 37/50, Train iteration 44/164: Loss = 1.5350\n",
      "Epoch 37/50, Train iteration 45/164: Loss = 1.5194\n",
      "Epoch 37/50, Train iteration 46/164: Loss = 1.5546\n",
      "Epoch 37/50, Train iteration 47/164: Loss = 1.5604\n",
      "Epoch 37/50, Train iteration 48/164: Loss = 1.5324\n",
      "Epoch 37/50, Train iteration 49/164: Loss = 1.5224\n",
      "Epoch 37/50, Train iteration 50/164: Loss = 1.5647\n",
      "Epoch 37/50, Train iteration 51/164: Loss = 1.4983\n",
      "Epoch 37/50, Train iteration 52/164: Loss = 1.4919\n",
      "Epoch 37/50, Train iteration 53/164: Loss = 1.5377\n",
      "Epoch 37/50, Train iteration 54/164: Loss = 1.5839\n",
      "Epoch 37/50, Train iteration 55/164: Loss = 1.4578\n",
      "Epoch 37/50, Train iteration 56/164: Loss = 1.6203\n",
      "Epoch 37/50, Train iteration 57/164: Loss = 1.5435\n",
      "Epoch 37/50, Train iteration 58/164: Loss = 1.6229\n",
      "Epoch 37/50, Train iteration 59/164: Loss = 1.5238\n",
      "Epoch 37/50, Train iteration 60/164: Loss = 1.5065\n",
      "Epoch 37/50, Train iteration 61/164: Loss = 1.4919\n",
      "Epoch 37/50, Train iteration 62/164: Loss = 1.5320\n",
      "Epoch 37/50, Train iteration 63/164: Loss = 1.6070\n",
      "Epoch 37/50, Train iteration 64/164: Loss = 1.5647\n",
      "Epoch 37/50, Train iteration 65/164: Loss = 1.4983\n",
      "Epoch 37/50, Train iteration 66/164: Loss = 1.5209\n",
      "Epoch 37/50, Train iteration 67/164: Loss = 1.4443\n",
      "Epoch 37/50, Train iteration 68/164: Loss = 1.5623\n",
      "Epoch 37/50, Train iteration 69/164: Loss = 1.5606\n",
      "Epoch 37/50, Train iteration 70/164: Loss = 1.6058\n",
      "Epoch 37/50, Train iteration 71/164: Loss = 1.5403\n",
      "Epoch 37/50, Train iteration 72/164: Loss = 1.5262\n",
      "Epoch 37/50, Train iteration 73/164: Loss = 1.5667\n",
      "Epoch 37/50, Train iteration 74/164: Loss = 1.5078\n",
      "Epoch 37/50, Train iteration 75/164: Loss = 1.5243\n",
      "Epoch 37/50, Train iteration 76/164: Loss = 1.5066\n",
      "Epoch 37/50, Train iteration 77/164: Loss = 1.5793\n",
      "Epoch 37/50, Train iteration 78/164: Loss = 1.5778\n",
      "Epoch 37/50, Train iteration 79/164: Loss = 1.5528\n",
      "Epoch 37/50, Train iteration 80/164: Loss = 1.5584\n",
      "Epoch 37/50, Train iteration 81/164: Loss = 1.5471\n",
      "Epoch 37/50, Train iteration 82/164: Loss = 1.5474\n",
      "Epoch 37/50, Train iteration 83/164: Loss = 1.5667\n",
      "Epoch 37/50, Train iteration 84/164: Loss = 1.5034\n",
      "Epoch 37/50, Train iteration 85/164: Loss = 1.6219\n",
      "Epoch 37/50, Train iteration 86/164: Loss = 1.4181\n",
      "Epoch 37/50, Train iteration 87/164: Loss = 1.5685\n",
      "Epoch 37/50, Train iteration 88/164: Loss = 1.5517\n",
      "Epoch 37/50, Train iteration 89/164: Loss = 1.5641\n",
      "Epoch 37/50, Train iteration 90/164: Loss = 1.5301\n",
      "Epoch 37/50, Train iteration 91/164: Loss = 1.6076\n",
      "Epoch 37/50, Train iteration 92/164: Loss = 1.5419\n",
      "Epoch 37/50, Train iteration 93/164: Loss = 1.5214\n",
      "Epoch 37/50, Train iteration 94/164: Loss = 1.6092\n",
      "Epoch 37/50, Train iteration 95/164: Loss = 1.5099\n",
      "Epoch 37/50, Train iteration 96/164: Loss = 1.5427\n",
      "Epoch 37/50, Train iteration 97/164: Loss = 1.5336\n",
      "Epoch 37/50, Train iteration 98/164: Loss = 1.4964\n",
      "Epoch 37/50, Train iteration 99/164: Loss = 1.4673\n",
      "Epoch 37/50, Train iteration 100/164: Loss = 1.5337\n",
      "Epoch 37/50, Train iteration 101/164: Loss = 1.5168\n",
      "Epoch 37/50, Train iteration 102/164: Loss = 1.5504\n",
      "Epoch 37/50, Train iteration 103/164: Loss = 1.5399\n",
      "Epoch 37/50, Train iteration 104/164: Loss = 1.5487\n",
      "Epoch 37/50, Train iteration 105/164: Loss = 1.5331\n",
      "Epoch 37/50, Train iteration 106/164: Loss = 1.5570\n",
      "Epoch 37/50, Train iteration 107/164: Loss = 1.4923\n",
      "Epoch 37/50, Train iteration 108/164: Loss = 1.5703\n",
      "Epoch 37/50, Train iteration 109/164: Loss = 1.5800\n",
      "Epoch 37/50, Train iteration 110/164: Loss = 1.5419\n",
      "Epoch 37/50, Train iteration 111/164: Loss = 1.5893\n",
      "Epoch 37/50, Train iteration 112/164: Loss = 1.5541\n",
      "Epoch 37/50, Train iteration 113/164: Loss = 1.5247\n",
      "Epoch 37/50, Train iteration 114/164: Loss = 1.4749\n",
      "Epoch 37/50, Train iteration 115/164: Loss = 1.5200\n",
      "Epoch 37/50, Train iteration 116/164: Loss = 1.5063\n",
      "Epoch 37/50, Train iteration 117/164: Loss = 1.4661\n",
      "Epoch 37/50, Train iteration 118/164: Loss = 1.5662\n",
      "Epoch 37/50, Train iteration 119/164: Loss = 1.5651\n",
      "Epoch 37/50, Train iteration 120/164: Loss = 1.5210\n",
      "Epoch 37/50, Train iteration 121/164: Loss = 1.5507\n",
      "Epoch 37/50, Train iteration 122/164: Loss = 1.4523\n",
      "Epoch 37/50, Train iteration 123/164: Loss = 1.5199\n",
      "Epoch 37/50, Train iteration 124/164: Loss = 1.5555\n",
      "Epoch 37/50, Train iteration 125/164: Loss = 1.4829\n",
      "Epoch 37/50, Train iteration 126/164: Loss = 1.4578\n",
      "Epoch 37/50, Train iteration 127/164: Loss = 1.5763\n",
      "Epoch 37/50, Train iteration 128/164: Loss = 1.4880\n",
      "Epoch 37/50, Train iteration 129/164: Loss = 1.5111\n",
      "Epoch 37/50, Train iteration 130/164: Loss = 1.5630\n",
      "Epoch 37/50, Train iteration 131/164: Loss = 1.5426\n",
      "Epoch 37/50, Train iteration 132/164: Loss = 1.4785\n",
      "Epoch 37/50, Train iteration 133/164: Loss = 1.5483\n",
      "Epoch 37/50, Train iteration 134/164: Loss = 1.5049\n",
      "Epoch 37/50, Train iteration 135/164: Loss = 1.5313\n",
      "Epoch 37/50, Train iteration 136/164: Loss = 1.5696\n",
      "Epoch 37/50, Train iteration 137/164: Loss = 1.5408\n",
      "Epoch 37/50, Train iteration 138/164: Loss = 1.5173\n",
      "Epoch 37/50, Train iteration 139/164: Loss = 1.5384\n",
      "Epoch 37/50, Train iteration 140/164: Loss = 1.5575\n",
      "Epoch 37/50, Train iteration 141/164: Loss = 1.5229\n",
      "Epoch 37/50, Train iteration 142/164: Loss = 1.5702\n",
      "Epoch 37/50, Train iteration 143/164: Loss = 1.5070\n",
      "Epoch 37/50, Train iteration 144/164: Loss = 1.6184\n",
      "Epoch 37/50, Train iteration 145/164: Loss = 1.5735\n",
      "Epoch 37/50, Train iteration 146/164: Loss = 1.5280\n",
      "Epoch 37/50, Train iteration 147/164: Loss = 1.5188\n",
      "Epoch 37/50, Train iteration 148/164: Loss = 1.5611\n",
      "Epoch 37/50, Train iteration 149/164: Loss = 1.6092\n",
      "Epoch 37/50, Train iteration 150/164: Loss = 1.5035\n",
      "Epoch 37/50, Train iteration 151/164: Loss = 1.5714\n",
      "Epoch 37/50, Train iteration 152/164: Loss = 1.5536\n",
      "Epoch 37/50, Train iteration 153/164: Loss = 1.5864\n",
      "Epoch 37/50, Train iteration 154/164: Loss = 1.5724\n",
      "Epoch 37/50, Train iteration 155/164: Loss = 1.5101\n",
      "Epoch 37/50, Train iteration 156/164: Loss = 1.5075\n",
      "Epoch 37/50, Train iteration 157/164: Loss = 1.5582\n",
      "Epoch 37/50, Train iteration 158/164: Loss = 1.5749\n",
      "Epoch 37/50, Train iteration 159/164: Loss = 1.5803\n",
      "Epoch 37/50, Train iteration 160/164: Loss = 1.5541\n",
      "Epoch 37/50, Train iteration 161/164: Loss = 1.5909\n",
      "Epoch 37/50, Train iteration 162/164: Loss = 1.5599\n",
      "Epoch 37/50, Train iteration 163/164: Loss = 1.5525\n",
      "Epoch 37/50, Train iteration 164/164: Loss = 1.4188\n",
      "Epoch 37/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 37/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 37/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 37/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 37/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 37/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 37/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 37/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 37/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 37/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 37/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 37/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 37/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 37/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 37/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 37/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 37/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 37/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 37/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 37/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 37/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 37/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 37/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 37/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 37/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 37/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 37/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 37/50: Train Loss = 1.5412, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 38/50, Train iteration 1/164: Loss = 1.5354\n",
      "Epoch 38/50, Train iteration 2/164: Loss = 1.5300\n",
      "Epoch 38/50, Train iteration 3/164: Loss = 1.5814\n",
      "Epoch 38/50, Train iteration 4/164: Loss = 1.5111\n",
      "Epoch 38/50, Train iteration 5/164: Loss = 1.5824\n",
      "Epoch 38/50, Train iteration 6/164: Loss = 1.6302\n",
      "Epoch 38/50, Train iteration 7/164: Loss = 1.5981\n",
      "Epoch 38/50, Train iteration 8/164: Loss = 1.4468\n",
      "Epoch 38/50, Train iteration 9/164: Loss = 1.5737\n",
      "Epoch 38/50, Train iteration 10/164: Loss = 1.6252\n",
      "Epoch 38/50, Train iteration 11/164: Loss = 1.5549\n",
      "Epoch 38/50, Train iteration 12/164: Loss = 1.5463\n",
      "Epoch 38/50, Train iteration 13/164: Loss = 1.4812\n",
      "Epoch 38/50, Train iteration 14/164: Loss = 1.5677\n",
      "Epoch 38/50, Train iteration 15/164: Loss = 1.5542\n",
      "Epoch 38/50, Train iteration 16/164: Loss = 1.5426\n",
      "Epoch 38/50, Train iteration 17/164: Loss = 1.5347\n",
      "Epoch 38/50, Train iteration 18/164: Loss = 1.4844\n",
      "Epoch 38/50, Train iteration 19/164: Loss = 1.5260\n",
      "Epoch 38/50, Train iteration 20/164: Loss = 1.5594\n",
      "Epoch 38/50, Train iteration 21/164: Loss = 1.5642\n",
      "Epoch 38/50, Train iteration 22/164: Loss = 1.5996\n",
      "Epoch 38/50, Train iteration 23/164: Loss = 1.5891\n",
      "Epoch 38/50, Train iteration 24/164: Loss = 1.6118\n",
      "Epoch 38/50, Train iteration 25/164: Loss = 1.5672\n",
      "Epoch 38/50, Train iteration 26/164: Loss = 1.4973\n",
      "Epoch 38/50, Train iteration 27/164: Loss = 1.5662\n",
      "Epoch 38/50, Train iteration 28/164: Loss = 1.5656\n",
      "Epoch 38/50, Train iteration 29/164: Loss = 1.5421\n",
      "Epoch 38/50, Train iteration 30/164: Loss = 1.5506\n",
      "Epoch 38/50, Train iteration 31/164: Loss = 1.5123\n",
      "Epoch 38/50, Train iteration 32/164: Loss = 1.5006\n",
      "Epoch 38/50, Train iteration 33/164: Loss = 1.5357\n",
      "Epoch 38/50, Train iteration 34/164: Loss = 1.4687\n",
      "Epoch 38/50, Train iteration 35/164: Loss = 1.5280\n",
      "Epoch 38/50, Train iteration 36/164: Loss = 1.5237\n",
      "Epoch 38/50, Train iteration 37/164: Loss = 1.5588\n",
      "Epoch 38/50, Train iteration 38/164: Loss = 1.5219\n",
      "Epoch 38/50, Train iteration 39/164: Loss = 1.5885\n",
      "Epoch 38/50, Train iteration 40/164: Loss = 1.4544\n",
      "Epoch 38/50, Train iteration 41/164: Loss = 1.5044\n",
      "Epoch 38/50, Train iteration 42/164: Loss = 1.5521\n",
      "Epoch 38/50, Train iteration 43/164: Loss = 1.4990\n",
      "Epoch 38/50, Train iteration 44/164: Loss = 1.5273\n",
      "Epoch 38/50, Train iteration 45/164: Loss = 1.5155\n",
      "Epoch 38/50, Train iteration 46/164: Loss = 1.5747\n",
      "Epoch 38/50, Train iteration 47/164: Loss = 1.5860\n",
      "Epoch 38/50, Train iteration 48/164: Loss = 1.5500\n",
      "Epoch 38/50, Train iteration 49/164: Loss = 1.4998\n",
      "Epoch 38/50, Train iteration 50/164: Loss = 1.6387\n",
      "Epoch 38/50, Train iteration 51/164: Loss = 1.5182\n",
      "Epoch 38/50, Train iteration 52/164: Loss = 1.5299\n",
      "Epoch 38/50, Train iteration 53/164: Loss = 1.5386\n",
      "Epoch 38/50, Train iteration 54/164: Loss = 1.5385\n",
      "Epoch 38/50, Train iteration 55/164: Loss = 1.4706\n",
      "Epoch 38/50, Train iteration 56/164: Loss = 1.5602\n",
      "Epoch 38/50, Train iteration 57/164: Loss = 1.5387\n",
      "Epoch 38/50, Train iteration 58/164: Loss = 1.6163\n",
      "Epoch 38/50, Train iteration 59/164: Loss = 1.5355\n",
      "Epoch 38/50, Train iteration 60/164: Loss = 1.5511\n",
      "Epoch 38/50, Train iteration 61/164: Loss = 1.5006\n",
      "Epoch 38/50, Train iteration 62/164: Loss = 1.5671\n",
      "Epoch 38/50, Train iteration 63/164: Loss = 1.6078\n",
      "Epoch 38/50, Train iteration 64/164: Loss = 1.5182\n",
      "Epoch 38/50, Train iteration 65/164: Loss = 1.5172\n",
      "Epoch 38/50, Train iteration 66/164: Loss = 1.4967\n",
      "Epoch 38/50, Train iteration 67/164: Loss = 1.5303\n",
      "Epoch 38/50, Train iteration 68/164: Loss = 1.5275\n",
      "Epoch 38/50, Train iteration 69/164: Loss = 1.5467\n",
      "Epoch 38/50, Train iteration 70/164: Loss = 1.5690\n",
      "Epoch 38/50, Train iteration 71/164: Loss = 1.5611\n",
      "Epoch 38/50, Train iteration 72/164: Loss = 1.5815\n",
      "Epoch 38/50, Train iteration 73/164: Loss = 1.5414\n",
      "Epoch 38/50, Train iteration 74/164: Loss = 1.5171\n",
      "Epoch 38/50, Train iteration 75/164: Loss = 1.4825\n",
      "Epoch 38/50, Train iteration 76/164: Loss = 1.6240\n",
      "Epoch 38/50, Train iteration 77/164: Loss = 1.6077\n",
      "Epoch 38/50, Train iteration 78/164: Loss = 1.5566\n",
      "Epoch 38/50, Train iteration 79/164: Loss = 1.5297\n",
      "Epoch 38/50, Train iteration 80/164: Loss = 1.5754\n",
      "Epoch 38/50, Train iteration 81/164: Loss = 1.5233\n",
      "Epoch 38/50, Train iteration 82/164: Loss = 1.5764\n",
      "Epoch 38/50, Train iteration 83/164: Loss = 1.5132\n",
      "Epoch 38/50, Train iteration 84/164: Loss = 1.4914\n",
      "Epoch 38/50, Train iteration 85/164: Loss = 1.6022\n",
      "Epoch 38/50, Train iteration 86/164: Loss = 1.4065\n",
      "Epoch 38/50, Train iteration 87/164: Loss = 1.5596\n",
      "Epoch 38/50, Train iteration 88/164: Loss = 1.5819\n",
      "Epoch 38/50, Train iteration 89/164: Loss = 1.5286\n",
      "Epoch 38/50, Train iteration 90/164: Loss = 1.4632\n",
      "Epoch 38/50, Train iteration 91/164: Loss = 1.6359\n",
      "Epoch 38/50, Train iteration 92/164: Loss = 1.5125\n",
      "Epoch 38/50, Train iteration 93/164: Loss = 1.4987\n",
      "Epoch 38/50, Train iteration 94/164: Loss = 1.6091\n",
      "Epoch 38/50, Train iteration 95/164: Loss = 1.4744\n",
      "Epoch 38/50, Train iteration 96/164: Loss = 1.5416\n",
      "Epoch 38/50, Train iteration 97/164: Loss = 1.5196\n",
      "Epoch 38/50, Train iteration 98/164: Loss = 1.5294\n",
      "Epoch 38/50, Train iteration 99/164: Loss = 1.5371\n",
      "Epoch 38/50, Train iteration 100/164: Loss = 1.4733\n",
      "Epoch 38/50, Train iteration 101/164: Loss = 1.4857\n",
      "Epoch 38/50, Train iteration 102/164: Loss = 1.5411\n",
      "Epoch 38/50, Train iteration 103/164: Loss = 1.5788\n",
      "Epoch 38/50, Train iteration 104/164: Loss = 1.5666\n",
      "Epoch 38/50, Train iteration 105/164: Loss = 1.5726\n",
      "Epoch 38/50, Train iteration 106/164: Loss = 1.5625\n",
      "Epoch 38/50, Train iteration 107/164: Loss = 1.5454\n",
      "Epoch 38/50, Train iteration 108/164: Loss = 1.5255\n",
      "Epoch 38/50, Train iteration 109/164: Loss = 1.5243\n",
      "Epoch 38/50, Train iteration 110/164: Loss = 1.5744\n",
      "Epoch 38/50, Train iteration 111/164: Loss = 1.5476\n",
      "Epoch 38/50, Train iteration 112/164: Loss = 1.5898\n",
      "Epoch 38/50, Train iteration 113/164: Loss = 1.5294\n",
      "Epoch 38/50, Train iteration 114/164: Loss = 1.4313\n",
      "Epoch 38/50, Train iteration 115/164: Loss = 1.5169\n",
      "Epoch 38/50, Train iteration 116/164: Loss = 1.4997\n",
      "Epoch 38/50, Train iteration 117/164: Loss = 1.4571\n",
      "Epoch 38/50, Train iteration 118/164: Loss = 1.5693\n",
      "Epoch 38/50, Train iteration 119/164: Loss = 1.5774\n",
      "Epoch 38/50, Train iteration 120/164: Loss = 1.5367\n",
      "Epoch 38/50, Train iteration 121/164: Loss = 1.5454\n",
      "Epoch 38/50, Train iteration 122/164: Loss = 1.4814\n",
      "Epoch 38/50, Train iteration 123/164: Loss = 1.5123\n",
      "Epoch 38/50, Train iteration 124/164: Loss = 1.5245\n",
      "Epoch 38/50, Train iteration 125/164: Loss = 1.4429\n",
      "Epoch 38/50, Train iteration 126/164: Loss = 1.4743\n",
      "Epoch 38/50, Train iteration 127/164: Loss = 1.5803\n",
      "Epoch 38/50, Train iteration 128/164: Loss = 1.4670\n",
      "Epoch 38/50, Train iteration 129/164: Loss = 1.5352\n",
      "Epoch 38/50, Train iteration 130/164: Loss = 1.5407\n",
      "Epoch 38/50, Train iteration 131/164: Loss = 1.5414\n",
      "Epoch 38/50, Train iteration 132/164: Loss = 1.4664\n",
      "Epoch 38/50, Train iteration 133/164: Loss = 1.5473\n",
      "Epoch 38/50, Train iteration 134/164: Loss = 1.5160\n",
      "Epoch 38/50, Train iteration 135/164: Loss = 1.5447\n",
      "Epoch 38/50, Train iteration 136/164: Loss = 1.5559\n",
      "Epoch 38/50, Train iteration 137/164: Loss = 1.5251\n",
      "Epoch 38/50, Train iteration 138/164: Loss = 1.5464\n",
      "Epoch 38/50, Train iteration 139/164: Loss = 1.6218\n",
      "Epoch 38/50, Train iteration 140/164: Loss = 1.5742\n",
      "Epoch 38/50, Train iteration 141/164: Loss = 1.5286\n",
      "Epoch 38/50, Train iteration 142/164: Loss = 1.5846\n",
      "Epoch 38/50, Train iteration 143/164: Loss = 1.4889\n",
      "Epoch 38/50, Train iteration 144/164: Loss = 1.6013\n",
      "Epoch 38/50, Train iteration 145/164: Loss = 1.5264\n",
      "Epoch 38/50, Train iteration 146/164: Loss = 1.5440\n",
      "Epoch 38/50, Train iteration 147/164: Loss = 1.5595\n",
      "Epoch 38/50, Train iteration 148/164: Loss = 1.5165\n",
      "Epoch 38/50, Train iteration 149/164: Loss = 1.5731\n",
      "Epoch 38/50, Train iteration 150/164: Loss = 1.5837\n",
      "Epoch 38/50, Train iteration 151/164: Loss = 1.5779\n",
      "Epoch 38/50, Train iteration 152/164: Loss = 1.5295\n",
      "Epoch 38/50, Train iteration 153/164: Loss = 1.5515\n",
      "Epoch 38/50, Train iteration 154/164: Loss = 1.5464\n",
      "Epoch 38/50, Train iteration 155/164: Loss = 1.4976\n",
      "Epoch 38/50, Train iteration 156/164: Loss = 1.4942\n",
      "Epoch 38/50, Train iteration 157/164: Loss = 1.5273\n",
      "Epoch 38/50, Train iteration 158/164: Loss = 1.5685\n",
      "Epoch 38/50, Train iteration 159/164: Loss = 1.5437\n",
      "Epoch 38/50, Train iteration 160/164: Loss = 1.5321\n",
      "Epoch 38/50, Train iteration 161/164: Loss = 1.5760\n",
      "Epoch 38/50, Train iteration 162/164: Loss = 1.5882\n",
      "Epoch 38/50, Train iteration 163/164: Loss = 1.5057\n",
      "Epoch 38/50, Train iteration 164/164: Loss = 1.4019\n",
      "Epoch 38/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 38/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 38/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 38/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 38/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 38/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 38/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 38/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 38/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 38/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 38/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 38/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 38/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 38/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 38/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 38/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 38/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 38/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 38/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 38/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 38/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 38/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 38/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 38/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 38/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 38/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 38/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 38/50: Train Loss = 1.5391, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 39/50, Train iteration 1/164: Loss = 1.5211\n",
      "Epoch 39/50, Train iteration 2/164: Loss = 1.5455\n",
      "Epoch 39/50, Train iteration 3/164: Loss = 1.5421\n",
      "Epoch 39/50, Train iteration 4/164: Loss = 1.5450\n",
      "Epoch 39/50, Train iteration 5/164: Loss = 1.5679\n",
      "Epoch 39/50, Train iteration 6/164: Loss = 1.6053\n",
      "Epoch 39/50, Train iteration 7/164: Loss = 1.5734\n",
      "Epoch 39/50, Train iteration 8/164: Loss = 1.5157\n",
      "Epoch 39/50, Train iteration 9/164: Loss = 1.6146\n",
      "Epoch 39/50, Train iteration 10/164: Loss = 1.5793\n",
      "Epoch 39/50, Train iteration 11/164: Loss = 1.5970\n",
      "Epoch 39/50, Train iteration 12/164: Loss = 1.5616\n",
      "Epoch 39/50, Train iteration 13/164: Loss = 1.4967\n",
      "Epoch 39/50, Train iteration 14/164: Loss = 1.5734\n",
      "Epoch 39/50, Train iteration 15/164: Loss = 1.5292\n",
      "Epoch 39/50, Train iteration 16/164: Loss = 1.5676\n",
      "Epoch 39/50, Train iteration 17/164: Loss = 1.5649\n",
      "Epoch 39/50, Train iteration 18/164: Loss = 1.5132\n",
      "Epoch 39/50, Train iteration 19/164: Loss = 1.5239\n",
      "Epoch 39/50, Train iteration 20/164: Loss = 1.5528\n",
      "Epoch 39/50, Train iteration 21/164: Loss = 1.5758\n",
      "Epoch 39/50, Train iteration 22/164: Loss = 1.5423\n",
      "Epoch 39/50, Train iteration 23/164: Loss = 1.5591\n",
      "Epoch 39/50, Train iteration 24/164: Loss = 1.5218\n",
      "Epoch 39/50, Train iteration 25/164: Loss = 1.5806\n",
      "Epoch 39/50, Train iteration 26/164: Loss = 1.5165\n",
      "Epoch 39/50, Train iteration 27/164: Loss = 1.6045\n",
      "Epoch 39/50, Train iteration 28/164: Loss = 1.5296\n",
      "Epoch 39/50, Train iteration 29/164: Loss = 1.5294\n",
      "Epoch 39/50, Train iteration 30/164: Loss = 1.5710\n",
      "Epoch 39/50, Train iteration 31/164: Loss = 1.5358\n",
      "Epoch 39/50, Train iteration 32/164: Loss = 1.4872\n",
      "Epoch 39/50, Train iteration 33/164: Loss = 1.5674\n",
      "Epoch 39/50, Train iteration 34/164: Loss = 1.4766\n",
      "Epoch 39/50, Train iteration 35/164: Loss = 1.5086\n",
      "Epoch 39/50, Train iteration 36/164: Loss = 1.5072\n",
      "Epoch 39/50, Train iteration 37/164: Loss = 1.5562\n",
      "Epoch 39/50, Train iteration 38/164: Loss = 1.4820\n",
      "Epoch 39/50, Train iteration 39/164: Loss = 1.5215\n",
      "Epoch 39/50, Train iteration 40/164: Loss = 1.4556\n",
      "Epoch 39/50, Train iteration 41/164: Loss = 1.4965\n",
      "Epoch 39/50, Train iteration 42/164: Loss = 1.5630\n",
      "Epoch 39/50, Train iteration 43/164: Loss = 1.5479\n",
      "Epoch 39/50, Train iteration 44/164: Loss = 1.4897\n",
      "Epoch 39/50, Train iteration 45/164: Loss = 1.5651\n",
      "Epoch 39/50, Train iteration 46/164: Loss = 1.6048\n",
      "Epoch 39/50, Train iteration 47/164: Loss = 1.5565\n",
      "Epoch 39/50, Train iteration 48/164: Loss = 1.5042\n",
      "Epoch 39/50, Train iteration 49/164: Loss = 1.5543\n",
      "Epoch 39/50, Train iteration 50/164: Loss = 1.5349\n",
      "Epoch 39/50, Train iteration 51/164: Loss = 1.4995\n",
      "Epoch 39/50, Train iteration 52/164: Loss = 1.5639\n",
      "Epoch 39/50, Train iteration 53/164: Loss = 1.5800\n",
      "Epoch 39/50, Train iteration 54/164: Loss = 1.5969\n",
      "Epoch 39/50, Train iteration 55/164: Loss = 1.4855\n",
      "Epoch 39/50, Train iteration 56/164: Loss = 1.6195\n",
      "Epoch 39/50, Train iteration 57/164: Loss = 1.5349\n",
      "Epoch 39/50, Train iteration 58/164: Loss = 1.5589\n",
      "Epoch 39/50, Train iteration 59/164: Loss = 1.5098\n",
      "Epoch 39/50, Train iteration 60/164: Loss = 1.5209\n",
      "Epoch 39/50, Train iteration 61/164: Loss = 1.5553\n",
      "Epoch 39/50, Train iteration 62/164: Loss = 1.5441\n",
      "Epoch 39/50, Train iteration 63/164: Loss = 1.6125\n",
      "Epoch 39/50, Train iteration 64/164: Loss = 1.5282\n",
      "Epoch 39/50, Train iteration 65/164: Loss = 1.5281\n",
      "Epoch 39/50, Train iteration 66/164: Loss = 1.4559\n",
      "Epoch 39/50, Train iteration 67/164: Loss = 1.5006\n",
      "Epoch 39/50, Train iteration 68/164: Loss = 1.5390\n",
      "Epoch 39/50, Train iteration 69/164: Loss = 1.5423\n",
      "Epoch 39/50, Train iteration 70/164: Loss = 1.5712\n",
      "Epoch 39/50, Train iteration 71/164: Loss = 1.5839\n",
      "Epoch 39/50, Train iteration 72/164: Loss = 1.5505\n",
      "Epoch 39/50, Train iteration 73/164: Loss = 1.6017\n",
      "Epoch 39/50, Train iteration 74/164: Loss = 1.5352\n",
      "Epoch 39/50, Train iteration 75/164: Loss = 1.5012\n",
      "Epoch 39/50, Train iteration 76/164: Loss = 1.5395\n",
      "Epoch 39/50, Train iteration 77/164: Loss = 1.5456\n",
      "Epoch 39/50, Train iteration 78/164: Loss = 1.5391\n",
      "Epoch 39/50, Train iteration 79/164: Loss = 1.5153\n",
      "Epoch 39/50, Train iteration 80/164: Loss = 1.5223\n",
      "Epoch 39/50, Train iteration 81/164: Loss = 1.5139\n",
      "Epoch 39/50, Train iteration 82/164: Loss = 1.5522\n",
      "Epoch 39/50, Train iteration 83/164: Loss = 1.5431\n",
      "Epoch 39/50, Train iteration 84/164: Loss = 1.5150\n",
      "Epoch 39/50, Train iteration 85/164: Loss = 1.6098\n",
      "Epoch 39/50, Train iteration 86/164: Loss = 1.4466\n",
      "Epoch 39/50, Train iteration 87/164: Loss = 1.5308\n",
      "Epoch 39/50, Train iteration 88/164: Loss = 1.5664\n",
      "Epoch 39/50, Train iteration 89/164: Loss = 1.5170\n",
      "Epoch 39/50, Train iteration 90/164: Loss = 1.5091\n",
      "Epoch 39/50, Train iteration 91/164: Loss = 1.5898\n",
      "Epoch 39/50, Train iteration 92/164: Loss = 1.5474\n",
      "Epoch 39/50, Train iteration 93/164: Loss = 1.5667\n",
      "Epoch 39/50, Train iteration 94/164: Loss = 1.6166\n",
      "Epoch 39/50, Train iteration 95/164: Loss = 1.4793\n",
      "Epoch 39/50, Train iteration 96/164: Loss = 1.5736\n",
      "Epoch 39/50, Train iteration 97/164: Loss = 1.5448\n",
      "Epoch 39/50, Train iteration 98/164: Loss = 1.5419\n",
      "Epoch 39/50, Train iteration 99/164: Loss = 1.4841\n",
      "Epoch 39/50, Train iteration 100/164: Loss = 1.4993\n",
      "Epoch 39/50, Train iteration 101/164: Loss = 1.5030\n",
      "Epoch 39/50, Train iteration 102/164: Loss = 1.5556\n",
      "Epoch 39/50, Train iteration 103/164: Loss = 1.5914\n",
      "Epoch 39/50, Train iteration 104/164: Loss = 1.5408\n",
      "Epoch 39/50, Train iteration 105/164: Loss = 1.6227\n",
      "Epoch 39/50, Train iteration 106/164: Loss = 1.5927\n",
      "Epoch 39/50, Train iteration 107/164: Loss = 1.4982\n",
      "Epoch 39/50, Train iteration 108/164: Loss = 1.5112\n",
      "Epoch 39/50, Train iteration 109/164: Loss = 1.5493\n",
      "Epoch 39/50, Train iteration 110/164: Loss = 1.5543\n",
      "Epoch 39/50, Train iteration 111/164: Loss = 1.5702\n",
      "Epoch 39/50, Train iteration 112/164: Loss = 1.5230\n",
      "Epoch 39/50, Train iteration 113/164: Loss = 1.5223\n",
      "Epoch 39/50, Train iteration 114/164: Loss = 1.4857\n",
      "Epoch 39/50, Train iteration 115/164: Loss = 1.5055\n",
      "Epoch 39/50, Train iteration 116/164: Loss = 1.4864\n",
      "Epoch 39/50, Train iteration 117/164: Loss = 1.5218\n",
      "Epoch 39/50, Train iteration 118/164: Loss = 1.5770\n",
      "Epoch 39/50, Train iteration 119/164: Loss = 1.5256\n",
      "Epoch 39/50, Train iteration 120/164: Loss = 1.5293\n",
      "Epoch 39/50, Train iteration 121/164: Loss = 1.5608\n",
      "Epoch 39/50, Train iteration 122/164: Loss = 1.4425\n",
      "Epoch 39/50, Train iteration 123/164: Loss = 1.5123\n",
      "Epoch 39/50, Train iteration 124/164: Loss = 1.5276\n",
      "Epoch 39/50, Train iteration 125/164: Loss = 1.4770\n",
      "Epoch 39/50, Train iteration 126/164: Loss = 1.4544\n",
      "Epoch 39/50, Train iteration 127/164: Loss = 1.5651\n",
      "Epoch 39/50, Train iteration 128/164: Loss = 1.4997\n",
      "Epoch 39/50, Train iteration 129/164: Loss = 1.5318\n",
      "Epoch 39/50, Train iteration 130/164: Loss = 1.5570\n",
      "Epoch 39/50, Train iteration 131/164: Loss = 1.6004\n",
      "Epoch 39/50, Train iteration 132/164: Loss = 1.4669\n",
      "Epoch 39/50, Train iteration 133/164: Loss = 1.5738\n",
      "Epoch 39/50, Train iteration 134/164: Loss = 1.5192\n",
      "Epoch 39/50, Train iteration 135/164: Loss = 1.5116\n",
      "Epoch 39/50, Train iteration 136/164: Loss = 1.5458\n",
      "Epoch 39/50, Train iteration 137/164: Loss = 1.5520\n",
      "Epoch 39/50, Train iteration 138/164: Loss = 1.5512\n",
      "Epoch 39/50, Train iteration 139/164: Loss = 1.5828\n",
      "Epoch 39/50, Train iteration 140/164: Loss = 1.5389\n",
      "Epoch 39/50, Train iteration 141/164: Loss = 1.5282\n",
      "Epoch 39/50, Train iteration 142/164: Loss = 1.5584\n",
      "Epoch 39/50, Train iteration 143/164: Loss = 1.4728\n",
      "Epoch 39/50, Train iteration 144/164: Loss = 1.6193\n",
      "Epoch 39/50, Train iteration 145/164: Loss = 1.4778\n",
      "Epoch 39/50, Train iteration 146/164: Loss = 1.4917\n",
      "Epoch 39/50, Train iteration 147/164: Loss = 1.5656\n",
      "Epoch 39/50, Train iteration 148/164: Loss = 1.5033\n",
      "Epoch 39/50, Train iteration 149/164: Loss = 1.5314\n",
      "Epoch 39/50, Train iteration 150/164: Loss = 1.5606\n",
      "Epoch 39/50, Train iteration 151/164: Loss = 1.6088\n",
      "Epoch 39/50, Train iteration 152/164: Loss = 1.4994\n",
      "Epoch 39/50, Train iteration 153/164: Loss = 1.5374\n",
      "Epoch 39/50, Train iteration 154/164: Loss = 1.4990\n",
      "Epoch 39/50, Train iteration 155/164: Loss = 1.5933\n",
      "Epoch 39/50, Train iteration 156/164: Loss = 1.5436\n",
      "Epoch 39/50, Train iteration 157/164: Loss = 1.5346\n",
      "Epoch 39/50, Train iteration 158/164: Loss = 1.6131\n",
      "Epoch 39/50, Train iteration 159/164: Loss = 1.5439\n",
      "Epoch 39/50, Train iteration 160/164: Loss = 1.5844\n",
      "Epoch 39/50, Train iteration 161/164: Loss = 1.6077\n",
      "Epoch 39/50, Train iteration 162/164: Loss = 1.5462\n",
      "Epoch 39/50, Train iteration 163/164: Loss = 1.5656\n",
      "Epoch 39/50, Train iteration 164/164: Loss = 1.3740\n",
      "Epoch 39/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 39/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 39/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 39/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 39/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 39/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 39/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 39/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 39/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 39/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 39/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 39/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 39/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 39/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 39/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 39/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 39/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 39/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 39/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 39/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 39/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 39/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 39/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 39/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 39/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 39/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 39/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 39/50: Train Loss = 1.5394, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 40/50, Train iteration 1/164: Loss = 1.5244\n",
      "Epoch 40/50, Train iteration 2/164: Loss = 1.4918\n",
      "Epoch 40/50, Train iteration 3/164: Loss = 1.5864\n",
      "Epoch 40/50, Train iteration 4/164: Loss = 1.5026\n",
      "Epoch 40/50, Train iteration 5/164: Loss = 1.5446\n",
      "Epoch 40/50, Train iteration 6/164: Loss = 1.5795\n",
      "Epoch 40/50, Train iteration 7/164: Loss = 1.5491\n",
      "Epoch 40/50, Train iteration 8/164: Loss = 1.5162\n",
      "Epoch 40/50, Train iteration 9/164: Loss = 1.5781\n",
      "Epoch 40/50, Train iteration 10/164: Loss = 1.5873\n",
      "Epoch 40/50, Train iteration 11/164: Loss = 1.6147\n",
      "Epoch 40/50, Train iteration 12/164: Loss = 1.5215\n",
      "Epoch 40/50, Train iteration 13/164: Loss = 1.5038\n",
      "Epoch 40/50, Train iteration 14/164: Loss = 1.5701\n",
      "Epoch 40/50, Train iteration 15/164: Loss = 1.5582\n",
      "Epoch 40/50, Train iteration 16/164: Loss = 1.5864\n",
      "Epoch 40/50, Train iteration 17/164: Loss = 1.5544\n",
      "Epoch 40/50, Train iteration 18/164: Loss = 1.5632\n",
      "Epoch 40/50, Train iteration 19/164: Loss = 1.4905\n",
      "Epoch 40/50, Train iteration 20/164: Loss = 1.5128\n",
      "Epoch 40/50, Train iteration 21/164: Loss = 1.5462\n",
      "Epoch 40/50, Train iteration 22/164: Loss = 1.5881\n",
      "Epoch 40/50, Train iteration 23/164: Loss = 1.5669\n",
      "Epoch 40/50, Train iteration 24/164: Loss = 1.5779\n",
      "Epoch 40/50, Train iteration 25/164: Loss = 1.5791\n",
      "Epoch 40/50, Train iteration 26/164: Loss = 1.5426\n",
      "Epoch 40/50, Train iteration 27/164: Loss = 1.5317\n",
      "Epoch 40/50, Train iteration 28/164: Loss = 1.5331\n",
      "Epoch 40/50, Train iteration 29/164: Loss = 1.5378\n",
      "Epoch 40/50, Train iteration 30/164: Loss = 1.5690\n",
      "Epoch 40/50, Train iteration 31/164: Loss = 1.4748\n",
      "Epoch 40/50, Train iteration 32/164: Loss = 1.5039\n",
      "Epoch 40/50, Train iteration 33/164: Loss = 1.5652\n",
      "Epoch 40/50, Train iteration 34/164: Loss = 1.4456\n",
      "Epoch 40/50, Train iteration 35/164: Loss = 1.5523\n",
      "Epoch 40/50, Train iteration 36/164: Loss = 1.5053\n",
      "Epoch 40/50, Train iteration 37/164: Loss = 1.5856\n",
      "Epoch 40/50, Train iteration 38/164: Loss = 1.5571\n",
      "Epoch 40/50, Train iteration 39/164: Loss = 1.5530\n",
      "Epoch 40/50, Train iteration 40/164: Loss = 1.4737\n",
      "Epoch 40/50, Train iteration 41/164: Loss = 1.5059\n",
      "Epoch 40/50, Train iteration 42/164: Loss = 1.5939\n",
      "Epoch 40/50, Train iteration 43/164: Loss = 1.4757\n",
      "Epoch 40/50, Train iteration 44/164: Loss = 1.4933\n",
      "Epoch 40/50, Train iteration 45/164: Loss = 1.5129\n",
      "Epoch 40/50, Train iteration 46/164: Loss = 1.5683\n",
      "Epoch 40/50, Train iteration 47/164: Loss = 1.5664\n",
      "Epoch 40/50, Train iteration 48/164: Loss = 1.5455\n",
      "Epoch 40/50, Train iteration 49/164: Loss = 1.5473\n",
      "Epoch 40/50, Train iteration 50/164: Loss = 1.5997\n",
      "Epoch 40/50, Train iteration 51/164: Loss = 1.4927\n",
      "Epoch 40/50, Train iteration 52/164: Loss = 1.5280\n",
      "Epoch 40/50, Train iteration 53/164: Loss = 1.5549\n",
      "Epoch 40/50, Train iteration 54/164: Loss = 1.6214\n",
      "Epoch 40/50, Train iteration 55/164: Loss = 1.4829\n",
      "Epoch 40/50, Train iteration 56/164: Loss = 1.5635\n",
      "Epoch 40/50, Train iteration 57/164: Loss = 1.5700\n",
      "Epoch 40/50, Train iteration 58/164: Loss = 1.5713\n",
      "Epoch 40/50, Train iteration 59/164: Loss = 1.5055\n",
      "Epoch 40/50, Train iteration 60/164: Loss = 1.5254\n",
      "Epoch 40/50, Train iteration 61/164: Loss = 1.5177\n",
      "Epoch 40/50, Train iteration 62/164: Loss = 1.5210\n",
      "Epoch 40/50, Train iteration 63/164: Loss = 1.6065\n",
      "Epoch 40/50, Train iteration 64/164: Loss = 1.5362\n",
      "Epoch 40/50, Train iteration 65/164: Loss = 1.5908\n",
      "Epoch 40/50, Train iteration 66/164: Loss = 1.4878\n",
      "Epoch 40/50, Train iteration 67/164: Loss = 1.4824\n",
      "Epoch 40/50, Train iteration 68/164: Loss = 1.5399\n",
      "Epoch 40/50, Train iteration 69/164: Loss = 1.5791\n",
      "Epoch 40/50, Train iteration 70/164: Loss = 1.5549\n",
      "Epoch 40/50, Train iteration 71/164: Loss = 1.5562\n",
      "Epoch 40/50, Train iteration 72/164: Loss = 1.5982\n",
      "Epoch 40/50, Train iteration 73/164: Loss = 1.5400\n",
      "Epoch 40/50, Train iteration 74/164: Loss = 1.5684\n",
      "Epoch 40/50, Train iteration 75/164: Loss = 1.4997\n",
      "Epoch 40/50, Train iteration 76/164: Loss = 1.5474\n",
      "Epoch 40/50, Train iteration 77/164: Loss = 1.5543\n",
      "Epoch 40/50, Train iteration 78/164: Loss = 1.5199\n",
      "Epoch 40/50, Train iteration 79/164: Loss = 1.5246\n",
      "Epoch 40/50, Train iteration 80/164: Loss = 1.5442\n",
      "Epoch 40/50, Train iteration 81/164: Loss = 1.5074\n",
      "Epoch 40/50, Train iteration 82/164: Loss = 1.5438\n",
      "Epoch 40/50, Train iteration 83/164: Loss = 1.5379\n",
      "Epoch 40/50, Train iteration 84/164: Loss = 1.5082\n",
      "Epoch 40/50, Train iteration 85/164: Loss = 1.5610\n",
      "Epoch 40/50, Train iteration 86/164: Loss = 1.4145\n",
      "Epoch 40/50, Train iteration 87/164: Loss = 1.4939\n",
      "Epoch 40/50, Train iteration 88/164: Loss = 1.6254\n",
      "Epoch 40/50, Train iteration 89/164: Loss = 1.5690\n",
      "Epoch 40/50, Train iteration 90/164: Loss = 1.5261\n",
      "Epoch 40/50, Train iteration 91/164: Loss = 1.5956\n",
      "Epoch 40/50, Train iteration 92/164: Loss = 1.5364\n",
      "Epoch 40/50, Train iteration 93/164: Loss = 1.5069\n",
      "Epoch 40/50, Train iteration 94/164: Loss = 1.5872\n",
      "Epoch 40/50, Train iteration 95/164: Loss = 1.4936\n",
      "Epoch 40/50, Train iteration 96/164: Loss = 1.5587\n",
      "Epoch 40/50, Train iteration 97/164: Loss = 1.5469\n",
      "Epoch 40/50, Train iteration 98/164: Loss = 1.5976\n",
      "Epoch 40/50, Train iteration 99/164: Loss = 1.5389\n",
      "Epoch 40/50, Train iteration 100/164: Loss = 1.4766\n",
      "Epoch 40/50, Train iteration 101/164: Loss = 1.5263\n",
      "Epoch 40/50, Train iteration 102/164: Loss = 1.5493\n",
      "Epoch 40/50, Train iteration 103/164: Loss = 1.5320\n",
      "Epoch 40/50, Train iteration 104/164: Loss = 1.5807\n",
      "Epoch 40/50, Train iteration 105/164: Loss = 1.5431\n",
      "Epoch 40/50, Train iteration 106/164: Loss = 1.6081\n",
      "Epoch 40/50, Train iteration 107/164: Loss = 1.5374\n",
      "Epoch 40/50, Train iteration 108/164: Loss = 1.5686\n",
      "Epoch 40/50, Train iteration 109/164: Loss = 1.5357\n",
      "Epoch 40/50, Train iteration 110/164: Loss = 1.5568\n",
      "Epoch 40/50, Train iteration 111/164: Loss = 1.5713\n",
      "Epoch 40/50, Train iteration 112/164: Loss = 1.5192\n",
      "Epoch 40/50, Train iteration 113/164: Loss = 1.4692\n",
      "Epoch 40/50, Train iteration 114/164: Loss = 1.4523\n",
      "Epoch 40/50, Train iteration 115/164: Loss = 1.5607\n",
      "Epoch 40/50, Train iteration 116/164: Loss = 1.4540\n",
      "Epoch 40/50, Train iteration 117/164: Loss = 1.5230\n",
      "Epoch 40/50, Train iteration 118/164: Loss = 1.5672\n",
      "Epoch 40/50, Train iteration 119/164: Loss = 1.5104\n",
      "Epoch 40/50, Train iteration 120/164: Loss = 1.5018\n",
      "Epoch 40/50, Train iteration 121/164: Loss = 1.5559\n",
      "Epoch 40/50, Train iteration 122/164: Loss = 1.3997\n",
      "Epoch 40/50, Train iteration 123/164: Loss = 1.4991\n",
      "Epoch 40/50, Train iteration 124/164: Loss = 1.5419\n",
      "Epoch 40/50, Train iteration 125/164: Loss = 1.4734\n",
      "Epoch 40/50, Train iteration 126/164: Loss = 1.4879\n",
      "Epoch 40/50, Train iteration 127/164: Loss = 1.5961\n",
      "Epoch 40/50, Train iteration 128/164: Loss = 1.5269\n",
      "Epoch 40/50, Train iteration 129/164: Loss = 1.5557\n",
      "Epoch 40/50, Train iteration 130/164: Loss = 1.5788\n",
      "Epoch 40/50, Train iteration 131/164: Loss = 1.5946\n",
      "Epoch 40/50, Train iteration 132/164: Loss = 1.4922\n",
      "Epoch 40/50, Train iteration 133/164: Loss = 1.5344\n",
      "Epoch 40/50, Train iteration 134/164: Loss = 1.5476\n",
      "Epoch 40/50, Train iteration 135/164: Loss = 1.6008\n",
      "Epoch 40/50, Train iteration 136/164: Loss = 1.5772\n",
      "Epoch 40/50, Train iteration 137/164: Loss = 1.5050\n",
      "Epoch 40/50, Train iteration 138/164: Loss = 1.5215\n",
      "Epoch 40/50, Train iteration 139/164: Loss = 1.6328\n",
      "Epoch 40/50, Train iteration 140/164: Loss = 1.4925\n",
      "Epoch 40/50, Train iteration 141/164: Loss = 1.5490\n",
      "Epoch 40/50, Train iteration 142/164: Loss = 1.5564\n",
      "Epoch 40/50, Train iteration 143/164: Loss = 1.5204\n",
      "Epoch 40/50, Train iteration 144/164: Loss = 1.5947\n",
      "Epoch 40/50, Train iteration 145/164: Loss = 1.5177\n",
      "Epoch 40/50, Train iteration 146/164: Loss = 1.4995\n",
      "Epoch 40/50, Train iteration 147/164: Loss = 1.5155\n",
      "Epoch 40/50, Train iteration 148/164: Loss = 1.5260\n",
      "Epoch 40/50, Train iteration 149/164: Loss = 1.5800\n",
      "Epoch 40/50, Train iteration 150/164: Loss = 1.5935\n",
      "Epoch 40/50, Train iteration 151/164: Loss = 1.5696\n",
      "Epoch 40/50, Train iteration 152/164: Loss = 1.4787\n",
      "Epoch 40/50, Train iteration 153/164: Loss = 1.6090\n",
      "Epoch 40/50, Train iteration 154/164: Loss = 1.5487\n",
      "Epoch 40/50, Train iteration 155/164: Loss = 1.4898\n",
      "Epoch 40/50, Train iteration 156/164: Loss = 1.5269\n",
      "Epoch 40/50, Train iteration 157/164: Loss = 1.5560\n",
      "Epoch 40/50, Train iteration 158/164: Loss = 1.5753\n",
      "Epoch 40/50, Train iteration 159/164: Loss = 1.5646\n",
      "Epoch 40/50, Train iteration 160/164: Loss = 1.5814\n",
      "Epoch 40/50, Train iteration 161/164: Loss = 1.6019\n",
      "Epoch 40/50, Train iteration 162/164: Loss = 1.5692\n",
      "Epoch 40/50, Train iteration 163/164: Loss = 1.5040\n",
      "Epoch 40/50, Train iteration 164/164: Loss = 1.2014\n",
      "Epoch 40/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 40/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 40/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 40/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 40/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 40/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 40/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 40/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 40/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 40/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 40/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 40/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 40/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 40/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 40/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 40/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 40/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 40/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 40/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 40/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 40/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 40/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 40/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 40/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 40/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 40/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 40/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 40/50: Train Loss = 1.5387, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 41/50, Train iteration 1/164: Loss = 1.5343\n",
      "Epoch 41/50, Train iteration 2/164: Loss = 1.5602\n",
      "Epoch 41/50, Train iteration 3/164: Loss = 1.5457\n",
      "Epoch 41/50, Train iteration 4/164: Loss = 1.5347\n",
      "Epoch 41/50, Train iteration 5/164: Loss = 1.5798\n",
      "Epoch 41/50, Train iteration 6/164: Loss = 1.5922\n",
      "Epoch 41/50, Train iteration 7/164: Loss = 1.5869\n",
      "Epoch 41/50, Train iteration 8/164: Loss = 1.5043\n",
      "Epoch 41/50, Train iteration 9/164: Loss = 1.5610\n",
      "Epoch 41/50, Train iteration 10/164: Loss = 1.5695\n",
      "Epoch 41/50, Train iteration 11/164: Loss = 1.5439\n",
      "Epoch 41/50, Train iteration 12/164: Loss = 1.5301\n",
      "Epoch 41/50, Train iteration 13/164: Loss = 1.4961\n",
      "Epoch 41/50, Train iteration 14/164: Loss = 1.5418\n",
      "Epoch 41/50, Train iteration 15/164: Loss = 1.5481\n",
      "Epoch 41/50, Train iteration 16/164: Loss = 1.5781\n",
      "Epoch 41/50, Train iteration 17/164: Loss = 1.5369\n",
      "Epoch 41/50, Train iteration 18/164: Loss = 1.4715\n",
      "Epoch 41/50, Train iteration 19/164: Loss = 1.5116\n",
      "Epoch 41/50, Train iteration 20/164: Loss = 1.5631\n",
      "Epoch 41/50, Train iteration 21/164: Loss = 1.5947\n",
      "Epoch 41/50, Train iteration 22/164: Loss = 1.5646\n",
      "Epoch 41/50, Train iteration 23/164: Loss = 1.5285\n",
      "Epoch 41/50, Train iteration 24/164: Loss = 1.5856\n",
      "Epoch 41/50, Train iteration 25/164: Loss = 1.6093\n",
      "Epoch 41/50, Train iteration 26/164: Loss = 1.5949\n",
      "Epoch 41/50, Train iteration 27/164: Loss = 1.5423\n",
      "Epoch 41/50, Train iteration 28/164: Loss = 1.5540\n",
      "Epoch 41/50, Train iteration 29/164: Loss = 1.5636\n",
      "Epoch 41/50, Train iteration 30/164: Loss = 1.5997\n",
      "Epoch 41/50, Train iteration 31/164: Loss = 1.5312\n",
      "Epoch 41/50, Train iteration 32/164: Loss = 1.5556\n",
      "Epoch 41/50, Train iteration 33/164: Loss = 1.5635\n",
      "Epoch 41/50, Train iteration 34/164: Loss = 1.4741\n",
      "Epoch 41/50, Train iteration 35/164: Loss = 1.5390\n",
      "Epoch 41/50, Train iteration 36/164: Loss = 1.5496\n",
      "Epoch 41/50, Train iteration 37/164: Loss = 1.5823\n",
      "Epoch 41/50, Train iteration 38/164: Loss = 1.5059\n",
      "Epoch 41/50, Train iteration 39/164: Loss = 1.5593\n",
      "Epoch 41/50, Train iteration 40/164: Loss = 1.4804\n",
      "Epoch 41/50, Train iteration 41/164: Loss = 1.4481\n",
      "Epoch 41/50, Train iteration 42/164: Loss = 1.5472\n",
      "Epoch 41/50, Train iteration 43/164: Loss = 1.5591\n",
      "Epoch 41/50, Train iteration 44/164: Loss = 1.5531\n",
      "Epoch 41/50, Train iteration 45/164: Loss = 1.5517\n",
      "Epoch 41/50, Train iteration 46/164: Loss = 1.5533\n",
      "Epoch 41/50, Train iteration 47/164: Loss = 1.5467\n",
      "Epoch 41/50, Train iteration 48/164: Loss = 1.5593\n",
      "Epoch 41/50, Train iteration 49/164: Loss = 1.5469\n",
      "Epoch 41/50, Train iteration 50/164: Loss = 1.5535\n",
      "Epoch 41/50, Train iteration 51/164: Loss = 1.4912\n",
      "Epoch 41/50, Train iteration 52/164: Loss = 1.5238\n",
      "Epoch 41/50, Train iteration 53/164: Loss = 1.5694\n",
      "Epoch 41/50, Train iteration 54/164: Loss = 1.5442\n",
      "Epoch 41/50, Train iteration 55/164: Loss = 1.5296\n",
      "Epoch 41/50, Train iteration 56/164: Loss = 1.5719\n",
      "Epoch 41/50, Train iteration 57/164: Loss = 1.5400\n",
      "Epoch 41/50, Train iteration 58/164: Loss = 1.5774\n",
      "Epoch 41/50, Train iteration 59/164: Loss = 1.5344\n",
      "Epoch 41/50, Train iteration 60/164: Loss = 1.5674\n",
      "Epoch 41/50, Train iteration 61/164: Loss = 1.4933\n",
      "Epoch 41/50, Train iteration 62/164: Loss = 1.5200\n",
      "Epoch 41/50, Train iteration 63/164: Loss = 1.5937\n",
      "Epoch 41/50, Train iteration 64/164: Loss = 1.5334\n",
      "Epoch 41/50, Train iteration 65/164: Loss = 1.5522\n",
      "Epoch 41/50, Train iteration 66/164: Loss = 1.5098\n",
      "Epoch 41/50, Train iteration 67/164: Loss = 1.5123\n",
      "Epoch 41/50, Train iteration 68/164: Loss = 1.5307\n",
      "Epoch 41/50, Train iteration 69/164: Loss = 1.6005\n",
      "Epoch 41/50, Train iteration 70/164: Loss = 1.5563\n",
      "Epoch 41/50, Train iteration 71/164: Loss = 1.5449\n",
      "Epoch 41/50, Train iteration 72/164: Loss = 1.5530\n",
      "Epoch 41/50, Train iteration 73/164: Loss = 1.5813\n",
      "Epoch 41/50, Train iteration 74/164: Loss = 1.5373\n",
      "Epoch 41/50, Train iteration 75/164: Loss = 1.5053\n",
      "Epoch 41/50, Train iteration 76/164: Loss = 1.5372\n",
      "Epoch 41/50, Train iteration 77/164: Loss = 1.6001\n",
      "Epoch 41/50, Train iteration 78/164: Loss = 1.5257\n",
      "Epoch 41/50, Train iteration 79/164: Loss = 1.5373\n",
      "Epoch 41/50, Train iteration 80/164: Loss = 1.5936\n",
      "Epoch 41/50, Train iteration 81/164: Loss = 1.4997\n",
      "Epoch 41/50, Train iteration 82/164: Loss = 1.5443\n",
      "Epoch 41/50, Train iteration 83/164: Loss = 1.5527\n",
      "Epoch 41/50, Train iteration 84/164: Loss = 1.5014\n",
      "Epoch 41/50, Train iteration 85/164: Loss = 1.6038\n",
      "Epoch 41/50, Train iteration 86/164: Loss = 1.4022\n",
      "Epoch 41/50, Train iteration 87/164: Loss = 1.5371\n",
      "Epoch 41/50, Train iteration 88/164: Loss = 1.5873\n",
      "Epoch 41/50, Train iteration 89/164: Loss = 1.5565\n",
      "Epoch 41/50, Train iteration 90/164: Loss = 1.5191\n",
      "Epoch 41/50, Train iteration 91/164: Loss = 1.5507\n",
      "Epoch 41/50, Train iteration 92/164: Loss = 1.5514\n",
      "Epoch 41/50, Train iteration 93/164: Loss = 1.5294\n",
      "Epoch 41/50, Train iteration 94/164: Loss = 1.5944\n",
      "Epoch 41/50, Train iteration 95/164: Loss = 1.5075\n",
      "Epoch 41/50, Train iteration 96/164: Loss = 1.5655\n",
      "Epoch 41/50, Train iteration 97/164: Loss = 1.5285\n",
      "Epoch 41/50, Train iteration 98/164: Loss = 1.5465\n",
      "Epoch 41/50, Train iteration 99/164: Loss = 1.4638\n",
      "Epoch 41/50, Train iteration 100/164: Loss = 1.4958\n",
      "Epoch 41/50, Train iteration 101/164: Loss = 1.5325\n",
      "Epoch 41/50, Train iteration 102/164: Loss = 1.5478\n",
      "Epoch 41/50, Train iteration 103/164: Loss = 1.5779\n",
      "Epoch 41/50, Train iteration 104/164: Loss = 1.5715\n",
      "Epoch 41/50, Train iteration 105/164: Loss = 1.5645\n",
      "Epoch 41/50, Train iteration 106/164: Loss = 1.5653\n",
      "Epoch 41/50, Train iteration 107/164: Loss = 1.4552\n",
      "Epoch 41/50, Train iteration 108/164: Loss = 1.5748\n",
      "Epoch 41/50, Train iteration 109/164: Loss = 1.5851\n",
      "Epoch 41/50, Train iteration 110/164: Loss = 1.4996\n",
      "Epoch 41/50, Train iteration 111/164: Loss = 1.4796\n",
      "Epoch 41/50, Train iteration 112/164: Loss = 1.6025\n",
      "Epoch 41/50, Train iteration 113/164: Loss = 1.5001\n",
      "Epoch 41/50, Train iteration 114/164: Loss = 1.4293\n",
      "Epoch 41/50, Train iteration 115/164: Loss = 1.5126\n",
      "Epoch 41/50, Train iteration 116/164: Loss = 1.5045\n",
      "Epoch 41/50, Train iteration 117/164: Loss = 1.4804\n",
      "Epoch 41/50, Train iteration 118/164: Loss = 1.5501\n",
      "Epoch 41/50, Train iteration 119/164: Loss = 1.5232\n",
      "Epoch 41/50, Train iteration 120/164: Loss = 1.4813\n",
      "Epoch 41/50, Train iteration 121/164: Loss = 1.5698\n",
      "Epoch 41/50, Train iteration 122/164: Loss = 1.4241\n",
      "Epoch 41/50, Train iteration 123/164: Loss = 1.5090\n",
      "Epoch 41/50, Train iteration 124/164: Loss = 1.5348\n",
      "Epoch 41/50, Train iteration 125/164: Loss = 1.4912\n",
      "Epoch 41/50, Train iteration 126/164: Loss = 1.5065\n",
      "Epoch 41/50, Train iteration 127/164: Loss = 1.5880\n",
      "Epoch 41/50, Train iteration 128/164: Loss = 1.4703\n",
      "Epoch 41/50, Train iteration 129/164: Loss = 1.5839\n",
      "Epoch 41/50, Train iteration 130/164: Loss = 1.5468\n",
      "Epoch 41/50, Train iteration 131/164: Loss = 1.5456\n",
      "Epoch 41/50, Train iteration 132/164: Loss = 1.5176\n",
      "Epoch 41/50, Train iteration 133/164: Loss = 1.5247\n",
      "Epoch 41/50, Train iteration 134/164: Loss = 1.4848\n",
      "Epoch 41/50, Train iteration 135/164: Loss = 1.5164\n",
      "Epoch 41/50, Train iteration 136/164: Loss = 1.5480\n",
      "Epoch 41/50, Train iteration 137/164: Loss = 1.5283\n",
      "Epoch 41/50, Train iteration 138/164: Loss = 1.5425\n",
      "Epoch 41/50, Train iteration 139/164: Loss = 1.6019\n",
      "Epoch 41/50, Train iteration 140/164: Loss = 1.5683\n",
      "Epoch 41/50, Train iteration 141/164: Loss = 1.5403\n",
      "Epoch 41/50, Train iteration 142/164: Loss = 1.5607\n",
      "Epoch 41/50, Train iteration 143/164: Loss = 1.4877\n",
      "Epoch 41/50, Train iteration 144/164: Loss = 1.5870\n",
      "Epoch 41/50, Train iteration 145/164: Loss = 1.5010\n",
      "Epoch 41/50, Train iteration 146/164: Loss = 1.5205\n",
      "Epoch 41/50, Train iteration 147/164: Loss = 1.5162\n",
      "Epoch 41/50, Train iteration 148/164: Loss = 1.5019\n",
      "Epoch 41/50, Train iteration 149/164: Loss = 1.5247\n",
      "Epoch 41/50, Train iteration 150/164: Loss = 1.5604\n",
      "Epoch 41/50, Train iteration 151/164: Loss = 1.6112\n",
      "Epoch 41/50, Train iteration 152/164: Loss = 1.4925\n",
      "Epoch 41/50, Train iteration 153/164: Loss = 1.5479\n",
      "Epoch 41/50, Train iteration 154/164: Loss = 1.5006\n",
      "Epoch 41/50, Train iteration 155/164: Loss = 1.5968\n",
      "Epoch 41/50, Train iteration 156/164: Loss = 1.5046\n",
      "Epoch 41/50, Train iteration 157/164: Loss = 1.5918\n",
      "Epoch 41/50, Train iteration 158/164: Loss = 1.5983\n",
      "Epoch 41/50, Train iteration 159/164: Loss = 1.5514\n",
      "Epoch 41/50, Train iteration 160/164: Loss = 1.5783\n",
      "Epoch 41/50, Train iteration 161/164: Loss = 1.5981\n",
      "Epoch 41/50, Train iteration 162/164: Loss = 1.5224\n",
      "Epoch 41/50, Train iteration 163/164: Loss = 1.5314\n",
      "Epoch 41/50, Train iteration 164/164: Loss = 1.3974\n",
      "Epoch 41/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 41/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 41/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 41/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 41/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 41/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 41/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 41/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 41/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 41/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 41/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 41/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 41/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 41/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 41/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 41/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 41/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 41/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 41/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 41/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 41/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 41/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 41/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 41/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 41/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 41/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 41/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 41/50: Train Loss = 1.5394, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 42/50, Train iteration 1/164: Loss = 1.5062\n",
      "Epoch 42/50, Train iteration 2/164: Loss = 1.5635\n",
      "Epoch 42/50, Train iteration 3/164: Loss = 1.5588\n",
      "Epoch 42/50, Train iteration 4/164: Loss = 1.5246\n",
      "Epoch 42/50, Train iteration 5/164: Loss = 1.5663\n",
      "Epoch 42/50, Train iteration 6/164: Loss = 1.5877\n",
      "Epoch 42/50, Train iteration 7/164: Loss = 1.5493\n",
      "Epoch 42/50, Train iteration 8/164: Loss = 1.4953\n",
      "Epoch 42/50, Train iteration 9/164: Loss = 1.5917\n",
      "Epoch 42/50, Train iteration 10/164: Loss = 1.5927\n",
      "Epoch 42/50, Train iteration 11/164: Loss = 1.5329\n",
      "Epoch 42/50, Train iteration 12/164: Loss = 1.5529\n",
      "Epoch 42/50, Train iteration 13/164: Loss = 1.4833\n",
      "Epoch 42/50, Train iteration 14/164: Loss = 1.5692\n",
      "Epoch 42/50, Train iteration 15/164: Loss = 1.5952\n",
      "Epoch 42/50, Train iteration 16/164: Loss = 1.5388\n",
      "Epoch 42/50, Train iteration 17/164: Loss = 1.5345\n",
      "Epoch 42/50, Train iteration 18/164: Loss = 1.4733\n",
      "Epoch 42/50, Train iteration 19/164: Loss = 1.4816\n",
      "Epoch 42/50, Train iteration 20/164: Loss = 1.5547\n",
      "Epoch 42/50, Train iteration 21/164: Loss = 1.5600\n",
      "Epoch 42/50, Train iteration 22/164: Loss = 1.5455\n",
      "Epoch 42/50, Train iteration 23/164: Loss = 1.5576\n",
      "Epoch 42/50, Train iteration 24/164: Loss = 1.5359\n",
      "Epoch 42/50, Train iteration 25/164: Loss = 1.5441\n",
      "Epoch 42/50, Train iteration 26/164: Loss = 1.5330\n",
      "Epoch 42/50, Train iteration 27/164: Loss = 1.5518\n",
      "Epoch 42/50, Train iteration 28/164: Loss = 1.4980\n",
      "Epoch 42/50, Train iteration 29/164: Loss = 1.5359\n",
      "Epoch 42/50, Train iteration 30/164: Loss = 1.5657\n",
      "Epoch 42/50, Train iteration 31/164: Loss = 1.4607\n",
      "Epoch 42/50, Train iteration 32/164: Loss = 1.5007\n",
      "Epoch 42/50, Train iteration 33/164: Loss = 1.5770\n",
      "Epoch 42/50, Train iteration 34/164: Loss = 1.5031\n",
      "Epoch 42/50, Train iteration 35/164: Loss = 1.5549\n",
      "Epoch 42/50, Train iteration 36/164: Loss = 1.5474\n",
      "Epoch 42/50, Train iteration 37/164: Loss = 1.5359\n",
      "Epoch 42/50, Train iteration 38/164: Loss = 1.5690\n",
      "Epoch 42/50, Train iteration 39/164: Loss = 1.5645\n",
      "Epoch 42/50, Train iteration 40/164: Loss = 1.5147\n",
      "Epoch 42/50, Train iteration 41/164: Loss = 1.4990\n",
      "Epoch 42/50, Train iteration 42/164: Loss = 1.5229\n",
      "Epoch 42/50, Train iteration 43/164: Loss = 1.5073\n",
      "Epoch 42/50, Train iteration 44/164: Loss = 1.5035\n",
      "Epoch 42/50, Train iteration 45/164: Loss = 1.5564\n",
      "Epoch 42/50, Train iteration 46/164: Loss = 1.5331\n",
      "Epoch 42/50, Train iteration 47/164: Loss = 1.5666\n",
      "Epoch 42/50, Train iteration 48/164: Loss = 1.5869\n",
      "Epoch 42/50, Train iteration 49/164: Loss = 1.5103\n",
      "Epoch 42/50, Train iteration 50/164: Loss = 1.6280\n",
      "Epoch 42/50, Train iteration 51/164: Loss = 1.5412\n",
      "Epoch 42/50, Train iteration 52/164: Loss = 1.5393\n",
      "Epoch 42/50, Train iteration 53/164: Loss = 1.5087\n",
      "Epoch 42/50, Train iteration 54/164: Loss = 1.5416\n",
      "Epoch 42/50, Train iteration 55/164: Loss = 1.5069\n",
      "Epoch 42/50, Train iteration 56/164: Loss = 1.5633\n",
      "Epoch 42/50, Train iteration 57/164: Loss = 1.5629\n",
      "Epoch 42/50, Train iteration 58/164: Loss = 1.5840\n",
      "Epoch 42/50, Train iteration 59/164: Loss = 1.5272\n",
      "Epoch 42/50, Train iteration 60/164: Loss = 1.5372\n",
      "Epoch 42/50, Train iteration 61/164: Loss = 1.4532\n",
      "Epoch 42/50, Train iteration 62/164: Loss = 1.5261\n",
      "Epoch 42/50, Train iteration 63/164: Loss = 1.5863\n",
      "Epoch 42/50, Train iteration 64/164: Loss = 1.4703\n",
      "Epoch 42/50, Train iteration 65/164: Loss = 1.5224\n",
      "Epoch 42/50, Train iteration 66/164: Loss = 1.5225\n",
      "Epoch 42/50, Train iteration 67/164: Loss = 1.4933\n",
      "Epoch 42/50, Train iteration 68/164: Loss = 1.5408\n",
      "Epoch 42/50, Train iteration 69/164: Loss = 1.5569\n",
      "Epoch 42/50, Train iteration 70/164: Loss = 1.5662\n",
      "Epoch 42/50, Train iteration 71/164: Loss = 1.5276\n",
      "Epoch 42/50, Train iteration 72/164: Loss = 1.5847\n",
      "Epoch 42/50, Train iteration 73/164: Loss = 1.6225\n",
      "Epoch 42/50, Train iteration 74/164: Loss = 1.4866\n",
      "Epoch 42/50, Train iteration 75/164: Loss = 1.5262\n",
      "Epoch 42/50, Train iteration 76/164: Loss = 1.5647\n",
      "Epoch 42/50, Train iteration 77/164: Loss = 1.5813\n",
      "Epoch 42/50, Train iteration 78/164: Loss = 1.5601\n",
      "Epoch 42/50, Train iteration 79/164: Loss = 1.5259\n",
      "Epoch 42/50, Train iteration 80/164: Loss = 1.5150\n",
      "Epoch 42/50, Train iteration 81/164: Loss = 1.5418\n",
      "Epoch 42/50, Train iteration 82/164: Loss = 1.5547\n",
      "Epoch 42/50, Train iteration 83/164: Loss = 1.5424\n",
      "Epoch 42/50, Train iteration 84/164: Loss = 1.4935\n",
      "Epoch 42/50, Train iteration 85/164: Loss = 1.5784\n",
      "Epoch 42/50, Train iteration 86/164: Loss = 1.4286\n",
      "Epoch 42/50, Train iteration 87/164: Loss = 1.5672\n",
      "Epoch 42/50, Train iteration 88/164: Loss = 1.5634\n",
      "Epoch 42/50, Train iteration 89/164: Loss = 1.5388\n",
      "Epoch 42/50, Train iteration 90/164: Loss = 1.5094\n",
      "Epoch 42/50, Train iteration 91/164: Loss = 1.5844\n",
      "Epoch 42/50, Train iteration 92/164: Loss = 1.5037\n",
      "Epoch 42/50, Train iteration 93/164: Loss = 1.5397\n",
      "Epoch 42/50, Train iteration 94/164: Loss = 1.5495\n",
      "Epoch 42/50, Train iteration 95/164: Loss = 1.5338\n",
      "Epoch 42/50, Train iteration 96/164: Loss = 1.5416\n",
      "Epoch 42/50, Train iteration 97/164: Loss = 1.5697\n",
      "Epoch 42/50, Train iteration 98/164: Loss = 1.5282\n",
      "Epoch 42/50, Train iteration 99/164: Loss = 1.4519\n",
      "Epoch 42/50, Train iteration 100/164: Loss = 1.4741\n",
      "Epoch 42/50, Train iteration 101/164: Loss = 1.5568\n",
      "Epoch 42/50, Train iteration 102/164: Loss = 1.5180\n",
      "Epoch 42/50, Train iteration 103/164: Loss = 1.5398\n",
      "Epoch 42/50, Train iteration 104/164: Loss = 1.5878\n",
      "Epoch 42/50, Train iteration 105/164: Loss = 1.5937\n",
      "Epoch 42/50, Train iteration 106/164: Loss = 1.5911\n",
      "Epoch 42/50, Train iteration 107/164: Loss = 1.5541\n",
      "Epoch 42/50, Train iteration 108/164: Loss = 1.5026\n",
      "Epoch 42/50, Train iteration 109/164: Loss = 1.5780\n",
      "Epoch 42/50, Train iteration 110/164: Loss = 1.4939\n",
      "Epoch 42/50, Train iteration 111/164: Loss = 1.5927\n",
      "Epoch 42/50, Train iteration 112/164: Loss = 1.5446\n",
      "Epoch 42/50, Train iteration 113/164: Loss = 1.4820\n",
      "Epoch 42/50, Train iteration 114/164: Loss = 1.4497\n",
      "Epoch 42/50, Train iteration 115/164: Loss = 1.5688\n",
      "Epoch 42/50, Train iteration 116/164: Loss = 1.4980\n",
      "Epoch 42/50, Train iteration 117/164: Loss = 1.5377\n",
      "Epoch 42/50, Train iteration 118/164: Loss = 1.5832\n",
      "Epoch 42/50, Train iteration 119/164: Loss = 1.5877\n",
      "Epoch 42/50, Train iteration 120/164: Loss = 1.5085\n",
      "Epoch 42/50, Train iteration 121/164: Loss = 1.5948\n",
      "Epoch 42/50, Train iteration 122/164: Loss = 1.4849\n",
      "Epoch 42/50, Train iteration 123/164: Loss = 1.5316\n",
      "Epoch 42/50, Train iteration 124/164: Loss = 1.5648\n",
      "Epoch 42/50, Train iteration 125/164: Loss = 1.4722\n",
      "Epoch 42/50, Train iteration 126/164: Loss = 1.5245\n",
      "Epoch 42/50, Train iteration 127/164: Loss = 1.5542\n",
      "Epoch 42/50, Train iteration 128/164: Loss = 1.5198\n",
      "Epoch 42/50, Train iteration 129/164: Loss = 1.5075\n",
      "Epoch 42/50, Train iteration 130/164: Loss = 1.5634\n",
      "Epoch 42/50, Train iteration 131/164: Loss = 1.5970\n",
      "Epoch 42/50, Train iteration 132/164: Loss = 1.5283\n",
      "Epoch 42/50, Train iteration 133/164: Loss = 1.5532\n",
      "Epoch 42/50, Train iteration 134/164: Loss = 1.5271\n",
      "Epoch 42/50, Train iteration 135/164: Loss = 1.5114\n",
      "Epoch 42/50, Train iteration 136/164: Loss = 1.5696\n",
      "Epoch 42/50, Train iteration 137/164: Loss = 1.5250\n",
      "Epoch 42/50, Train iteration 138/164: Loss = 1.5453\n",
      "Epoch 42/50, Train iteration 139/164: Loss = 1.5752\n",
      "Epoch 42/50, Train iteration 140/164: Loss = 1.4910\n",
      "Epoch 42/50, Train iteration 141/164: Loss = 1.5281\n",
      "Epoch 42/50, Train iteration 142/164: Loss = 1.5321\n",
      "Epoch 42/50, Train iteration 143/164: Loss = 1.4947\n",
      "Epoch 42/50, Train iteration 144/164: Loss = 1.6013\n",
      "Epoch 42/50, Train iteration 145/164: Loss = 1.5212\n",
      "Epoch 42/50, Train iteration 146/164: Loss = 1.5270\n",
      "Epoch 42/50, Train iteration 147/164: Loss = 1.5559\n",
      "Epoch 42/50, Train iteration 148/164: Loss = 1.4918\n",
      "Epoch 42/50, Train iteration 149/164: Loss = 1.5330\n",
      "Epoch 42/50, Train iteration 150/164: Loss = 1.5556\n",
      "Epoch 42/50, Train iteration 151/164: Loss = 1.5634\n",
      "Epoch 42/50, Train iteration 152/164: Loss = 1.5214\n",
      "Epoch 42/50, Train iteration 153/164: Loss = 1.5738\n",
      "Epoch 42/50, Train iteration 154/164: Loss = 1.4879\n",
      "Epoch 42/50, Train iteration 155/164: Loss = 1.4961\n",
      "Epoch 42/50, Train iteration 156/164: Loss = 1.5231\n",
      "Epoch 42/50, Train iteration 157/164: Loss = 1.5540\n",
      "Epoch 42/50, Train iteration 158/164: Loss = 1.5501\n",
      "Epoch 42/50, Train iteration 159/164: Loss = 1.5710\n",
      "Epoch 42/50, Train iteration 160/164: Loss = 1.5853\n",
      "Epoch 42/50, Train iteration 161/164: Loss = 1.6459\n",
      "Epoch 42/50, Train iteration 162/164: Loss = 1.5306\n",
      "Epoch 42/50, Train iteration 163/164: Loss = 1.5338\n",
      "Epoch 42/50, Train iteration 164/164: Loss = 1.4548\n",
      "Epoch 42/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 42/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 42/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 42/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 42/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 42/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 42/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 42/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 42/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 42/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 42/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 42/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 42/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 42/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 42/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 42/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 42/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 42/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 42/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 42/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 42/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 42/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 42/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 42/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 42/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 42/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 42/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 42/50: Train Loss = 1.5384, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 43/50, Train iteration 1/164: Loss = 1.5397\n",
      "Epoch 43/50, Train iteration 2/164: Loss = 1.5405\n",
      "Epoch 43/50, Train iteration 3/164: Loss = 1.5138\n",
      "Epoch 43/50, Train iteration 4/164: Loss = 1.5338\n",
      "Epoch 43/50, Train iteration 5/164: Loss = 1.5966\n",
      "Epoch 43/50, Train iteration 6/164: Loss = 1.6191\n",
      "Epoch 43/50, Train iteration 7/164: Loss = 1.6013\n",
      "Epoch 43/50, Train iteration 8/164: Loss = 1.5105\n",
      "Epoch 43/50, Train iteration 9/164: Loss = 1.6182\n",
      "Epoch 43/50, Train iteration 10/164: Loss = 1.6205\n",
      "Epoch 43/50, Train iteration 11/164: Loss = 1.5584\n",
      "Epoch 43/50, Train iteration 12/164: Loss = 1.5283\n",
      "Epoch 43/50, Train iteration 13/164: Loss = 1.4927\n",
      "Epoch 43/50, Train iteration 14/164: Loss = 1.5968\n",
      "Epoch 43/50, Train iteration 15/164: Loss = 1.5369\n",
      "Epoch 43/50, Train iteration 16/164: Loss = 1.6058\n",
      "Epoch 43/50, Train iteration 17/164: Loss = 1.5311\n",
      "Epoch 43/50, Train iteration 18/164: Loss = 1.5486\n",
      "Epoch 43/50, Train iteration 19/164: Loss = 1.5396\n",
      "Epoch 43/50, Train iteration 20/164: Loss = 1.5037\n",
      "Epoch 43/50, Train iteration 21/164: Loss = 1.5792\n",
      "Epoch 43/50, Train iteration 22/164: Loss = 1.5631\n",
      "Epoch 43/50, Train iteration 23/164: Loss = 1.4807\n",
      "Epoch 43/50, Train iteration 24/164: Loss = 1.5656\n",
      "Epoch 43/50, Train iteration 25/164: Loss = 1.6086\n",
      "Epoch 43/50, Train iteration 26/164: Loss = 1.5560\n",
      "Epoch 43/50, Train iteration 27/164: Loss = 1.5449\n",
      "Epoch 43/50, Train iteration 28/164: Loss = 1.5550\n",
      "Epoch 43/50, Train iteration 29/164: Loss = 1.5029\n",
      "Epoch 43/50, Train iteration 30/164: Loss = 1.5744\n",
      "Epoch 43/50, Train iteration 31/164: Loss = 1.5201\n",
      "Epoch 43/50, Train iteration 32/164: Loss = 1.5233\n",
      "Epoch 43/50, Train iteration 33/164: Loss = 1.5861\n",
      "Epoch 43/50, Train iteration 34/164: Loss = 1.5066\n",
      "Epoch 43/50, Train iteration 35/164: Loss = 1.5400\n",
      "Epoch 43/50, Train iteration 36/164: Loss = 1.5507\n",
      "Epoch 43/50, Train iteration 37/164: Loss = 1.5690\n",
      "Epoch 43/50, Train iteration 38/164: Loss = 1.5180\n",
      "Epoch 43/50, Train iteration 39/164: Loss = 1.5918\n",
      "Epoch 43/50, Train iteration 40/164: Loss = 1.5026\n",
      "Epoch 43/50, Train iteration 41/164: Loss = 1.4763\n",
      "Epoch 43/50, Train iteration 42/164: Loss = 1.5213\n",
      "Epoch 43/50, Train iteration 43/164: Loss = 1.5275\n",
      "Epoch 43/50, Train iteration 44/164: Loss = 1.4901\n",
      "Epoch 43/50, Train iteration 45/164: Loss = 1.5412\n",
      "Epoch 43/50, Train iteration 46/164: Loss = 1.5733\n",
      "Epoch 43/50, Train iteration 47/164: Loss = 1.5523\n",
      "Epoch 43/50, Train iteration 48/164: Loss = 1.6011\n",
      "Epoch 43/50, Train iteration 49/164: Loss = 1.5247\n",
      "Epoch 43/50, Train iteration 50/164: Loss = 1.6643\n",
      "Epoch 43/50, Train iteration 51/164: Loss = 1.4733\n",
      "Epoch 43/50, Train iteration 52/164: Loss = 1.4915\n",
      "Epoch 43/50, Train iteration 53/164: Loss = 1.5726\n",
      "Epoch 43/50, Train iteration 54/164: Loss = 1.5374\n",
      "Epoch 43/50, Train iteration 55/164: Loss = 1.4478\n",
      "Epoch 43/50, Train iteration 56/164: Loss = 1.5913\n",
      "Epoch 43/50, Train iteration 57/164: Loss = 1.4922\n",
      "Epoch 43/50, Train iteration 58/164: Loss = 1.5880\n",
      "Epoch 43/50, Train iteration 59/164: Loss = 1.5396\n",
      "Epoch 43/50, Train iteration 60/164: Loss = 1.5256\n",
      "Epoch 43/50, Train iteration 61/164: Loss = 1.4759\n",
      "Epoch 43/50, Train iteration 62/164: Loss = 1.5152\n",
      "Epoch 43/50, Train iteration 63/164: Loss = 1.6143\n",
      "Epoch 43/50, Train iteration 64/164: Loss = 1.5232\n",
      "Epoch 43/50, Train iteration 65/164: Loss = 1.5570\n",
      "Epoch 43/50, Train iteration 66/164: Loss = 1.4746\n",
      "Epoch 43/50, Train iteration 67/164: Loss = 1.4917\n",
      "Epoch 43/50, Train iteration 68/164: Loss = 1.5411\n",
      "Epoch 43/50, Train iteration 69/164: Loss = 1.5399\n",
      "Epoch 43/50, Train iteration 70/164: Loss = 1.5402\n",
      "Epoch 43/50, Train iteration 71/164: Loss = 1.6253\n",
      "Epoch 43/50, Train iteration 72/164: Loss = 1.6240\n",
      "Epoch 43/50, Train iteration 73/164: Loss = 1.6093\n",
      "Epoch 43/50, Train iteration 74/164: Loss = 1.5673\n",
      "Epoch 43/50, Train iteration 75/164: Loss = 1.5178\n",
      "Epoch 43/50, Train iteration 76/164: Loss = 1.5555\n",
      "Epoch 43/50, Train iteration 77/164: Loss = 1.6071\n",
      "Epoch 43/50, Train iteration 78/164: Loss = 1.5383\n",
      "Epoch 43/50, Train iteration 79/164: Loss = 1.5377\n",
      "Epoch 43/50, Train iteration 80/164: Loss = 1.5697\n",
      "Epoch 43/50, Train iteration 81/164: Loss = 1.5082\n",
      "Epoch 43/50, Train iteration 82/164: Loss = 1.5614\n",
      "Epoch 43/50, Train iteration 83/164: Loss = 1.5645\n",
      "Epoch 43/50, Train iteration 84/164: Loss = 1.5149\n",
      "Epoch 43/50, Train iteration 85/164: Loss = 1.6071\n",
      "Epoch 43/50, Train iteration 86/164: Loss = 1.4476\n",
      "Epoch 43/50, Train iteration 87/164: Loss = 1.5584\n",
      "Epoch 43/50, Train iteration 88/164: Loss = 1.5706\n",
      "Epoch 43/50, Train iteration 89/164: Loss = 1.5565\n",
      "Epoch 43/50, Train iteration 90/164: Loss = 1.5185\n",
      "Epoch 43/50, Train iteration 91/164: Loss = 1.5653\n",
      "Epoch 43/50, Train iteration 92/164: Loss = 1.5427\n",
      "Epoch 43/50, Train iteration 93/164: Loss = 1.5223\n",
      "Epoch 43/50, Train iteration 94/164: Loss = 1.5799\n",
      "Epoch 43/50, Train iteration 95/164: Loss = 1.4584\n",
      "Epoch 43/50, Train iteration 96/164: Loss = 1.5788\n",
      "Epoch 43/50, Train iteration 97/164: Loss = 1.5381\n",
      "Epoch 43/50, Train iteration 98/164: Loss = 1.5392\n",
      "Epoch 43/50, Train iteration 99/164: Loss = 1.4804\n",
      "Epoch 43/50, Train iteration 100/164: Loss = 1.4686\n",
      "Epoch 43/50, Train iteration 101/164: Loss = 1.5110\n",
      "Epoch 43/50, Train iteration 102/164: Loss = 1.4921\n",
      "Epoch 43/50, Train iteration 103/164: Loss = 1.5482\n",
      "Epoch 43/50, Train iteration 104/164: Loss = 1.5690\n",
      "Epoch 43/50, Train iteration 105/164: Loss = 1.5663\n",
      "Epoch 43/50, Train iteration 106/164: Loss = 1.5870\n",
      "Epoch 43/50, Train iteration 107/164: Loss = 1.5530\n",
      "Epoch 43/50, Train iteration 108/164: Loss = 1.5198\n",
      "Epoch 43/50, Train iteration 109/164: Loss = 1.6019\n",
      "Epoch 43/50, Train iteration 110/164: Loss = 1.5974\n",
      "Epoch 43/50, Train iteration 111/164: Loss = 1.5500\n",
      "Epoch 43/50, Train iteration 112/164: Loss = 1.5770\n",
      "Epoch 43/50, Train iteration 113/164: Loss = 1.4935\n",
      "Epoch 43/50, Train iteration 114/164: Loss = 1.4147\n",
      "Epoch 43/50, Train iteration 115/164: Loss = 1.5555\n",
      "Epoch 43/50, Train iteration 116/164: Loss = 1.4871\n",
      "Epoch 43/50, Train iteration 117/164: Loss = 1.4980\n",
      "Epoch 43/50, Train iteration 118/164: Loss = 1.6026\n",
      "Epoch 43/50, Train iteration 119/164: Loss = 1.5946\n",
      "Epoch 43/50, Train iteration 120/164: Loss = 1.5132\n",
      "Epoch 43/50, Train iteration 121/164: Loss = 1.5205\n",
      "Epoch 43/50, Train iteration 122/164: Loss = 1.4377\n",
      "Epoch 43/50, Train iteration 123/164: Loss = 1.5594\n",
      "Epoch 43/50, Train iteration 124/164: Loss = 1.5361\n",
      "Epoch 43/50, Train iteration 125/164: Loss = 1.5124\n",
      "Epoch 43/50, Train iteration 126/164: Loss = 1.5262\n",
      "Epoch 43/50, Train iteration 127/164: Loss = 1.5451\n",
      "Epoch 43/50, Train iteration 128/164: Loss = 1.4991\n",
      "Epoch 43/50, Train iteration 129/164: Loss = 1.5085\n",
      "Epoch 43/50, Train iteration 130/164: Loss = 1.5768\n",
      "Epoch 43/50, Train iteration 131/164: Loss = 1.5029\n",
      "Epoch 43/50, Train iteration 132/164: Loss = 1.5207\n",
      "Epoch 43/50, Train iteration 133/164: Loss = 1.5533\n",
      "Epoch 43/50, Train iteration 134/164: Loss = 1.5059\n",
      "Epoch 43/50, Train iteration 135/164: Loss = 1.5332\n",
      "Epoch 43/50, Train iteration 136/164: Loss = 1.5505\n",
      "Epoch 43/50, Train iteration 137/164: Loss = 1.5468\n",
      "Epoch 43/50, Train iteration 138/164: Loss = 1.5608\n",
      "Epoch 43/50, Train iteration 139/164: Loss = 1.6460\n",
      "Epoch 43/50, Train iteration 140/164: Loss = 1.5395\n",
      "Epoch 43/50, Train iteration 141/164: Loss = 1.4339\n",
      "Epoch 43/50, Train iteration 142/164: Loss = 1.5958\n",
      "Epoch 43/50, Train iteration 143/164: Loss = 1.4898\n",
      "Epoch 43/50, Train iteration 144/164: Loss = 1.6051\n",
      "Epoch 43/50, Train iteration 145/164: Loss = 1.5645\n",
      "Epoch 43/50, Train iteration 146/164: Loss = 1.5177\n",
      "Epoch 43/50, Train iteration 147/164: Loss = 1.5422\n",
      "Epoch 43/50, Train iteration 148/164: Loss = 1.4960\n",
      "Epoch 43/50, Train iteration 149/164: Loss = 1.5381\n",
      "Epoch 43/50, Train iteration 150/164: Loss = 1.5514\n",
      "Epoch 43/50, Train iteration 151/164: Loss = 1.5537\n",
      "Epoch 43/50, Train iteration 152/164: Loss = 1.5054\n",
      "Epoch 43/50, Train iteration 153/164: Loss = 1.5601\n",
      "Epoch 43/50, Train iteration 154/164: Loss = 1.5164\n",
      "Epoch 43/50, Train iteration 155/164: Loss = 1.5275\n",
      "Epoch 43/50, Train iteration 156/164: Loss = 1.5099\n",
      "Epoch 43/50, Train iteration 157/164: Loss = 1.5746\n",
      "Epoch 43/50, Train iteration 158/164: Loss = 1.5764\n",
      "Epoch 43/50, Train iteration 159/164: Loss = 1.5576\n",
      "Epoch 43/50, Train iteration 160/164: Loss = 1.5293\n",
      "Epoch 43/50, Train iteration 161/164: Loss = 1.6030\n",
      "Epoch 43/50, Train iteration 162/164: Loss = 1.5710\n",
      "Epoch 43/50, Train iteration 163/164: Loss = 1.5362\n",
      "Epoch 43/50, Train iteration 164/164: Loss = 1.4932\n",
      "Epoch 43/50, Val iteration 1/27: Loss = 1.6127\n",
      "Epoch 43/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 43/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 43/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 43/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 43/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 43/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 43/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 43/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 43/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 43/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 43/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 43/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 43/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 43/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 43/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 43/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 43/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 43/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 43/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 43/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 43/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 43/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 43/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 43/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 43/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 43/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 43/50: Train Loss = 1.5425, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 44/50, Train iteration 1/164: Loss = 1.5333\n",
      "Epoch 44/50, Train iteration 2/164: Loss = 1.5279\n",
      "Epoch 44/50, Train iteration 3/164: Loss = 1.6032\n",
      "Epoch 44/50, Train iteration 4/164: Loss = 1.5284\n",
      "Epoch 44/50, Train iteration 5/164: Loss = 1.5958\n",
      "Epoch 44/50, Train iteration 6/164: Loss = 1.5910\n",
      "Epoch 44/50, Train iteration 7/164: Loss = 1.5869\n",
      "Epoch 44/50, Train iteration 8/164: Loss = 1.5388\n",
      "Epoch 44/50, Train iteration 9/164: Loss = 1.6051\n",
      "Epoch 44/50, Train iteration 10/164: Loss = 1.5653\n",
      "Epoch 44/50, Train iteration 11/164: Loss = 1.5914\n",
      "Epoch 44/50, Train iteration 12/164: Loss = 1.5618\n",
      "Epoch 44/50, Train iteration 13/164: Loss = 1.5479\n",
      "Epoch 44/50, Train iteration 14/164: Loss = 1.5894\n",
      "Epoch 44/50, Train iteration 15/164: Loss = 1.4902\n",
      "Epoch 44/50, Train iteration 16/164: Loss = 1.5351\n",
      "Epoch 44/50, Train iteration 17/164: Loss = 1.5098\n",
      "Epoch 44/50, Train iteration 18/164: Loss = 1.5538\n",
      "Epoch 44/50, Train iteration 19/164: Loss = 1.5421\n",
      "Epoch 44/50, Train iteration 20/164: Loss = 1.5002\n",
      "Epoch 44/50, Train iteration 21/164: Loss = 1.5407\n",
      "Epoch 44/50, Train iteration 22/164: Loss = 1.5648\n",
      "Epoch 44/50, Train iteration 23/164: Loss = 1.5996\n",
      "Epoch 44/50, Train iteration 24/164: Loss = 1.5444\n",
      "Epoch 44/50, Train iteration 25/164: Loss = 1.5983\n",
      "Epoch 44/50, Train iteration 26/164: Loss = 1.5520\n",
      "Epoch 44/50, Train iteration 27/164: Loss = 1.5507\n",
      "Epoch 44/50, Train iteration 28/164: Loss = 1.5507\n",
      "Epoch 44/50, Train iteration 29/164: Loss = 1.5071\n",
      "Epoch 44/50, Train iteration 30/164: Loss = 1.6027\n",
      "Epoch 44/50, Train iteration 31/164: Loss = 1.4638\n",
      "Epoch 44/50, Train iteration 32/164: Loss = 1.5085\n",
      "Epoch 44/50, Train iteration 33/164: Loss = 1.5892\n",
      "Epoch 44/50, Train iteration 34/164: Loss = 1.5061\n",
      "Epoch 44/50, Train iteration 35/164: Loss = 1.5527\n",
      "Epoch 44/50, Train iteration 36/164: Loss = 1.5204\n",
      "Epoch 44/50, Train iteration 37/164: Loss = 1.6003\n",
      "Epoch 44/50, Train iteration 38/164: Loss = 1.5652\n",
      "Epoch 44/50, Train iteration 39/164: Loss = 1.5615\n",
      "Epoch 44/50, Train iteration 40/164: Loss = 1.5197\n",
      "Epoch 44/50, Train iteration 41/164: Loss = 1.4869\n",
      "Epoch 44/50, Train iteration 42/164: Loss = 1.5512\n",
      "Epoch 44/50, Train iteration 43/164: Loss = 1.5376\n",
      "Epoch 44/50, Train iteration 44/164: Loss = 1.5461\n",
      "Epoch 44/50, Train iteration 45/164: Loss = 1.5640\n",
      "Epoch 44/50, Train iteration 46/164: Loss = 1.5819\n",
      "Epoch 44/50, Train iteration 47/164: Loss = 1.5788\n",
      "Epoch 44/50, Train iteration 48/164: Loss = 1.5141\n",
      "Epoch 44/50, Train iteration 49/164: Loss = 1.5258\n",
      "Epoch 44/50, Train iteration 50/164: Loss = 1.5590\n",
      "Epoch 44/50, Train iteration 51/164: Loss = 1.5012\n",
      "Epoch 44/50, Train iteration 52/164: Loss = 1.5051\n",
      "Epoch 44/50, Train iteration 53/164: Loss = 1.5263\n",
      "Epoch 44/50, Train iteration 54/164: Loss = 1.5662\n",
      "Epoch 44/50, Train iteration 55/164: Loss = 1.4766\n",
      "Epoch 44/50, Train iteration 56/164: Loss = 1.5734\n",
      "Epoch 44/50, Train iteration 57/164: Loss = 1.5840\n",
      "Epoch 44/50, Train iteration 58/164: Loss = 1.5258\n",
      "Epoch 44/50, Train iteration 59/164: Loss = 1.5537\n",
      "Epoch 44/50, Train iteration 60/164: Loss = 1.5284\n",
      "Epoch 44/50, Train iteration 61/164: Loss = 1.5357\n",
      "Epoch 44/50, Train iteration 62/164: Loss = 1.5392\n",
      "Epoch 44/50, Train iteration 63/164: Loss = 1.6084\n",
      "Epoch 44/50, Train iteration 64/164: Loss = 1.5506\n",
      "Epoch 44/50, Train iteration 65/164: Loss = 1.4958\n",
      "Epoch 44/50, Train iteration 66/164: Loss = 1.4601\n",
      "Epoch 44/50, Train iteration 67/164: Loss = 1.5134\n",
      "Epoch 44/50, Train iteration 68/164: Loss = 1.5562\n",
      "Epoch 44/50, Train iteration 69/164: Loss = 1.5363\n",
      "Epoch 44/50, Train iteration 70/164: Loss = 1.5532\n",
      "Epoch 44/50, Train iteration 71/164: Loss = 1.5008\n",
      "Epoch 44/50, Train iteration 72/164: Loss = 1.5787\n",
      "Epoch 44/50, Train iteration 73/164: Loss = 1.6109\n",
      "Epoch 44/50, Train iteration 74/164: Loss = 1.5585\n",
      "Epoch 44/50, Train iteration 75/164: Loss = 1.5275\n",
      "Epoch 44/50, Train iteration 76/164: Loss = 1.5641\n",
      "Epoch 44/50, Train iteration 77/164: Loss = 1.5694\n",
      "Epoch 44/50, Train iteration 78/164: Loss = 1.5281\n",
      "Epoch 44/50, Train iteration 79/164: Loss = 1.5604\n",
      "Epoch 44/50, Train iteration 80/164: Loss = 1.5504\n",
      "Epoch 44/50, Train iteration 81/164: Loss = 1.5428\n",
      "Epoch 44/50, Train iteration 82/164: Loss = 1.5746\n",
      "Epoch 44/50, Train iteration 83/164: Loss = 1.5621\n",
      "Epoch 44/50, Train iteration 84/164: Loss = 1.4672\n",
      "Epoch 44/50, Train iteration 85/164: Loss = 1.5599\n",
      "Epoch 44/50, Train iteration 86/164: Loss = 1.4081\n",
      "Epoch 44/50, Train iteration 87/164: Loss = 1.5944\n",
      "Epoch 44/50, Train iteration 88/164: Loss = 1.5822\n",
      "Epoch 44/50, Train iteration 89/164: Loss = 1.5244\n",
      "Epoch 44/50, Train iteration 90/164: Loss = 1.4888\n",
      "Epoch 44/50, Train iteration 91/164: Loss = 1.5967\n",
      "Epoch 44/50, Train iteration 92/164: Loss = 1.5191\n",
      "Epoch 44/50, Train iteration 93/164: Loss = 1.5553\n",
      "Epoch 44/50, Train iteration 94/164: Loss = 1.5580\n",
      "Epoch 44/50, Train iteration 95/164: Loss = 1.4629\n",
      "Epoch 44/50, Train iteration 96/164: Loss = 1.5414\n",
      "Epoch 44/50, Train iteration 97/164: Loss = 1.5789\n",
      "Epoch 44/50, Train iteration 98/164: Loss = 1.5820\n",
      "Epoch 44/50, Train iteration 99/164: Loss = 1.5029\n",
      "Epoch 44/50, Train iteration 100/164: Loss = 1.4841\n",
      "Epoch 44/50, Train iteration 101/164: Loss = 1.4900\n",
      "Epoch 44/50, Train iteration 102/164: Loss = 1.5406\n",
      "Epoch 44/50, Train iteration 103/164: Loss = 1.5460\n",
      "Epoch 44/50, Train iteration 104/164: Loss = 1.5682\n",
      "Epoch 44/50, Train iteration 105/164: Loss = 1.5673\n",
      "Epoch 44/50, Train iteration 106/164: Loss = 1.6270\n",
      "Epoch 44/50, Train iteration 107/164: Loss = 1.5252\n",
      "Epoch 44/50, Train iteration 108/164: Loss = 1.5153\n",
      "Epoch 44/50, Train iteration 109/164: Loss = 1.5565\n",
      "Epoch 44/50, Train iteration 110/164: Loss = 1.5126\n",
      "Epoch 44/50, Train iteration 111/164: Loss = 1.5334\n",
      "Epoch 44/50, Train iteration 112/164: Loss = 1.5462\n",
      "Epoch 44/50, Train iteration 113/164: Loss = 1.4697\n",
      "Epoch 44/50, Train iteration 114/164: Loss = 1.4683\n",
      "Epoch 44/50, Train iteration 115/164: Loss = 1.4898\n",
      "Epoch 44/50, Train iteration 116/164: Loss = 1.4908\n",
      "Epoch 44/50, Train iteration 117/164: Loss = 1.4879\n",
      "Epoch 44/50, Train iteration 118/164: Loss = 1.5592\n",
      "Epoch 44/50, Train iteration 119/164: Loss = 1.5662\n",
      "Epoch 44/50, Train iteration 120/164: Loss = 1.5468\n",
      "Epoch 44/50, Train iteration 121/164: Loss = 1.5250\n",
      "Epoch 44/50, Train iteration 122/164: Loss = 1.4356\n",
      "Epoch 44/50, Train iteration 123/164: Loss = 1.4906\n",
      "Epoch 44/50, Train iteration 124/164: Loss = 1.5322\n",
      "Epoch 44/50, Train iteration 125/164: Loss = 1.4760\n",
      "Epoch 44/50, Train iteration 126/164: Loss = 1.5020\n",
      "Epoch 44/50, Train iteration 127/164: Loss = 1.5898\n",
      "Epoch 44/50, Train iteration 128/164: Loss = 1.4820\n",
      "Epoch 44/50, Train iteration 129/164: Loss = 1.4975\n",
      "Epoch 44/50, Train iteration 130/164: Loss = 1.5496\n",
      "Epoch 44/50, Train iteration 131/164: Loss = 1.6014\n",
      "Epoch 44/50, Train iteration 132/164: Loss = 1.5091\n",
      "Epoch 44/50, Train iteration 133/164: Loss = 1.5517\n",
      "Epoch 44/50, Train iteration 134/164: Loss = 1.5320\n",
      "Epoch 44/50, Train iteration 135/164: Loss = 1.5570\n",
      "Epoch 44/50, Train iteration 136/164: Loss = 1.5487\n",
      "Epoch 44/50, Train iteration 137/164: Loss = 1.5354\n",
      "Epoch 44/50, Train iteration 138/164: Loss = 1.5552\n",
      "Epoch 44/50, Train iteration 139/164: Loss = 1.5735\n",
      "Epoch 44/50, Train iteration 140/164: Loss = 1.5074\n",
      "Epoch 44/50, Train iteration 141/164: Loss = 1.5338\n",
      "Epoch 44/50, Train iteration 142/164: Loss = 1.6066\n",
      "Epoch 44/50, Train iteration 143/164: Loss = 1.4491\n",
      "Epoch 44/50, Train iteration 144/164: Loss = 1.5819\n",
      "Epoch 44/50, Train iteration 145/164: Loss = 1.5718\n",
      "Epoch 44/50, Train iteration 146/164: Loss = 1.4791\n",
      "Epoch 44/50, Train iteration 147/164: Loss = 1.5460\n",
      "Epoch 44/50, Train iteration 148/164: Loss = 1.4758\n",
      "Epoch 44/50, Train iteration 149/164: Loss = 1.5550\n",
      "Epoch 44/50, Train iteration 150/164: Loss = 1.5720\n",
      "Epoch 44/50, Train iteration 151/164: Loss = 1.5498\n",
      "Epoch 44/50, Train iteration 152/164: Loss = 1.5155\n",
      "Epoch 44/50, Train iteration 153/164: Loss = 1.5695\n",
      "Epoch 44/50, Train iteration 154/164: Loss = 1.4935\n",
      "Epoch 44/50, Train iteration 155/164: Loss = 1.4982\n",
      "Epoch 44/50, Train iteration 156/164: Loss = 1.5394\n",
      "Epoch 44/50, Train iteration 157/164: Loss = 1.5364\n",
      "Epoch 44/50, Train iteration 158/164: Loss = 1.5517\n",
      "Epoch 44/50, Train iteration 159/164: Loss = 1.5648\n",
      "Epoch 44/50, Train iteration 160/164: Loss = 1.5765\n",
      "Epoch 44/50, Train iteration 161/164: Loss = 1.6247\n",
      "Epoch 44/50, Train iteration 162/164: Loss = 1.5200\n",
      "Epoch 44/50, Train iteration 163/164: Loss = 1.6055\n",
      "Epoch 44/50, Train iteration 164/164: Loss = 1.3641\n",
      "Epoch 44/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 44/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 44/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 44/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 44/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 44/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 44/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 44/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 44/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 44/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 44/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 44/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 44/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 44/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 44/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 44/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 44/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 44/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 44/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 44/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 44/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 44/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 44/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 44/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 44/50, Val iteration 25/27: Loss = 1.5855\n",
      "Epoch 44/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 44/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 44/50: Train Loss = 1.5397, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 45/50, Train iteration 1/164: Loss = 1.5622\n",
      "Epoch 45/50, Train iteration 2/164: Loss = 1.5497\n",
      "Epoch 45/50, Train iteration 3/164: Loss = 1.5681\n",
      "Epoch 45/50, Train iteration 4/164: Loss = 1.5805\n",
      "Epoch 45/50, Train iteration 5/164: Loss = 1.5555\n",
      "Epoch 45/50, Train iteration 6/164: Loss = 1.5899\n",
      "Epoch 45/50, Train iteration 7/164: Loss = 1.5844\n",
      "Epoch 45/50, Train iteration 8/164: Loss = 1.5084\n",
      "Epoch 45/50, Train iteration 9/164: Loss = 1.5466\n",
      "Epoch 45/50, Train iteration 10/164: Loss = 1.5799\n",
      "Epoch 45/50, Train iteration 11/164: Loss = 1.5471\n",
      "Epoch 45/50, Train iteration 12/164: Loss = 1.5235\n",
      "Epoch 45/50, Train iteration 13/164: Loss = 1.5004\n",
      "Epoch 45/50, Train iteration 14/164: Loss = 1.5683\n",
      "Epoch 45/50, Train iteration 15/164: Loss = 1.5396\n",
      "Epoch 45/50, Train iteration 16/164: Loss = 1.5778\n",
      "Epoch 45/50, Train iteration 17/164: Loss = 1.5335\n",
      "Epoch 45/50, Train iteration 18/164: Loss = 1.5022\n",
      "Epoch 45/50, Train iteration 19/164: Loss = 1.4926\n",
      "Epoch 45/50, Train iteration 20/164: Loss = 1.5351\n",
      "Epoch 45/50, Train iteration 21/164: Loss = 1.5925\n",
      "Epoch 45/50, Train iteration 22/164: Loss = 1.6028\n",
      "Epoch 45/50, Train iteration 23/164: Loss = 1.5379\n",
      "Epoch 45/50, Train iteration 24/164: Loss = 1.5848\n",
      "Epoch 45/50, Train iteration 25/164: Loss = 1.5602\n",
      "Epoch 45/50, Train iteration 26/164: Loss = 1.5634\n",
      "Epoch 45/50, Train iteration 27/164: Loss = 1.5226\n",
      "Epoch 45/50, Train iteration 28/164: Loss = 1.5339\n",
      "Epoch 45/50, Train iteration 29/164: Loss = 1.5303\n",
      "Epoch 45/50, Train iteration 30/164: Loss = 1.5811\n",
      "Epoch 45/50, Train iteration 31/164: Loss = 1.5153\n",
      "Epoch 45/50, Train iteration 32/164: Loss = 1.5234\n",
      "Epoch 45/50, Train iteration 33/164: Loss = 1.5735\n",
      "Epoch 45/50, Train iteration 34/164: Loss = 1.4579\n",
      "Epoch 45/50, Train iteration 35/164: Loss = 1.5628\n",
      "Epoch 45/50, Train iteration 36/164: Loss = 1.5285\n",
      "Epoch 45/50, Train iteration 37/164: Loss = 1.5664\n",
      "Epoch 45/50, Train iteration 38/164: Loss = 1.5064\n",
      "Epoch 45/50, Train iteration 39/164: Loss = 1.5523\n",
      "Epoch 45/50, Train iteration 40/164: Loss = 1.4650\n",
      "Epoch 45/50, Train iteration 41/164: Loss = 1.4971\n",
      "Epoch 45/50, Train iteration 42/164: Loss = 1.5408\n",
      "Epoch 45/50, Train iteration 43/164: Loss = 1.5797\n",
      "Epoch 45/50, Train iteration 44/164: Loss = 1.5658\n",
      "Epoch 45/50, Train iteration 45/164: Loss = 1.5507\n",
      "Epoch 45/50, Train iteration 46/164: Loss = 1.6252\n",
      "Epoch 45/50, Train iteration 47/164: Loss = 1.5544\n",
      "Epoch 45/50, Train iteration 48/164: Loss = 1.5016\n",
      "Epoch 45/50, Train iteration 49/164: Loss = 1.4857\n",
      "Epoch 45/50, Train iteration 50/164: Loss = 1.5865\n",
      "Epoch 45/50, Train iteration 51/164: Loss = 1.4616\n",
      "Epoch 45/50, Train iteration 52/164: Loss = 1.4932\n",
      "Epoch 45/50, Train iteration 53/164: Loss = 1.5409\n",
      "Epoch 45/50, Train iteration 54/164: Loss = 1.5399\n",
      "Epoch 45/50, Train iteration 55/164: Loss = 1.5136\n",
      "Epoch 45/50, Train iteration 56/164: Loss = 1.5423\n",
      "Epoch 45/50, Train iteration 57/164: Loss = 1.5416\n",
      "Epoch 45/50, Train iteration 58/164: Loss = 1.5491\n",
      "Epoch 45/50, Train iteration 59/164: Loss = 1.5728\n",
      "Epoch 45/50, Train iteration 60/164: Loss = 1.5248\n",
      "Epoch 45/50, Train iteration 61/164: Loss = 1.4913\n",
      "Epoch 45/50, Train iteration 62/164: Loss = 1.4805\n",
      "Epoch 45/50, Train iteration 63/164: Loss = 1.6396\n",
      "Epoch 45/50, Train iteration 64/164: Loss = 1.5248\n",
      "Epoch 45/50, Train iteration 65/164: Loss = 1.5158\n",
      "Epoch 45/50, Train iteration 66/164: Loss = 1.4675\n",
      "Epoch 45/50, Train iteration 67/164: Loss = 1.4896\n",
      "Epoch 45/50, Train iteration 68/164: Loss = 1.5281\n",
      "Epoch 45/50, Train iteration 69/164: Loss = 1.5422\n",
      "Epoch 45/50, Train iteration 70/164: Loss = 1.5507\n",
      "Epoch 45/50, Train iteration 71/164: Loss = 1.5879\n",
      "Epoch 45/50, Train iteration 72/164: Loss = 1.5610\n",
      "Epoch 45/50, Train iteration 73/164: Loss = 1.6315\n",
      "Epoch 45/50, Train iteration 74/164: Loss = 1.5320\n",
      "Epoch 45/50, Train iteration 75/164: Loss = 1.4643\n",
      "Epoch 45/50, Train iteration 76/164: Loss = 1.5661\n",
      "Epoch 45/50, Train iteration 77/164: Loss = 1.5995\n",
      "Epoch 45/50, Train iteration 78/164: Loss = 1.4947\n",
      "Epoch 45/50, Train iteration 79/164: Loss = 1.5837\n",
      "Epoch 45/50, Train iteration 80/164: Loss = 1.5682\n",
      "Epoch 45/50, Train iteration 81/164: Loss = 1.4868\n",
      "Epoch 45/50, Train iteration 82/164: Loss = 1.5158\n",
      "Epoch 45/50, Train iteration 83/164: Loss = 1.5321\n",
      "Epoch 45/50, Train iteration 84/164: Loss = 1.5298\n",
      "Epoch 45/50, Train iteration 85/164: Loss = 1.5976\n",
      "Epoch 45/50, Train iteration 86/164: Loss = 1.4205\n",
      "Epoch 45/50, Train iteration 87/164: Loss = 1.5492\n",
      "Epoch 45/50, Train iteration 88/164: Loss = 1.5864\n",
      "Epoch 45/50, Train iteration 89/164: Loss = 1.5532\n",
      "Epoch 45/50, Train iteration 90/164: Loss = 1.5238\n",
      "Epoch 45/50, Train iteration 91/164: Loss = 1.5397\n",
      "Epoch 45/50, Train iteration 92/164: Loss = 1.5252\n",
      "Epoch 45/50, Train iteration 93/164: Loss = 1.5241\n",
      "Epoch 45/50, Train iteration 94/164: Loss = 1.5864\n",
      "Epoch 45/50, Train iteration 95/164: Loss = 1.4672\n",
      "Epoch 45/50, Train iteration 96/164: Loss = 1.6063\n",
      "Epoch 45/50, Train iteration 97/164: Loss = 1.5466\n",
      "Epoch 45/50, Train iteration 98/164: Loss = 1.5383\n",
      "Epoch 45/50, Train iteration 99/164: Loss = 1.5069\n",
      "Epoch 45/50, Train iteration 100/164: Loss = 1.5050\n",
      "Epoch 45/50, Train iteration 101/164: Loss = 1.4999\n",
      "Epoch 45/50, Train iteration 102/164: Loss = 1.5403\n",
      "Epoch 45/50, Train iteration 103/164: Loss = 1.6010\n",
      "Epoch 45/50, Train iteration 104/164: Loss = 1.5615\n",
      "Epoch 45/50, Train iteration 105/164: Loss = 1.5468\n",
      "Epoch 45/50, Train iteration 106/164: Loss = 1.5254\n",
      "Epoch 45/50, Train iteration 107/164: Loss = 1.5310\n",
      "Epoch 45/50, Train iteration 108/164: Loss = 1.5313\n",
      "Epoch 45/50, Train iteration 109/164: Loss = 1.5665\n",
      "Epoch 45/50, Train iteration 110/164: Loss = 1.5305\n",
      "Epoch 45/50, Train iteration 111/164: Loss = 1.5913\n",
      "Epoch 45/50, Train iteration 112/164: Loss = 1.5684\n",
      "Epoch 45/50, Train iteration 113/164: Loss = 1.5531\n",
      "Epoch 45/50, Train iteration 114/164: Loss = 1.4663\n",
      "Epoch 45/50, Train iteration 115/164: Loss = 1.5548\n",
      "Epoch 45/50, Train iteration 116/164: Loss = 1.4987\n",
      "Epoch 45/50, Train iteration 117/164: Loss = 1.5317\n",
      "Epoch 45/50, Train iteration 118/164: Loss = 1.5845\n",
      "Epoch 45/50, Train iteration 119/164: Loss = 1.4941\n",
      "Epoch 45/50, Train iteration 120/164: Loss = 1.5235\n",
      "Epoch 45/50, Train iteration 121/164: Loss = 1.5611\n",
      "Epoch 45/50, Train iteration 122/164: Loss = 1.4710\n",
      "Epoch 45/50, Train iteration 123/164: Loss = 1.5268\n",
      "Epoch 45/50, Train iteration 124/164: Loss = 1.5467\n",
      "Epoch 45/50, Train iteration 125/164: Loss = 1.5190\n",
      "Epoch 45/50, Train iteration 126/164: Loss = 1.4973\n",
      "Epoch 45/50, Train iteration 127/164: Loss = 1.6020\n",
      "Epoch 45/50, Train iteration 128/164: Loss = 1.4685\n",
      "Epoch 45/50, Train iteration 129/164: Loss = 1.5765\n",
      "Epoch 45/50, Train iteration 130/164: Loss = 1.5348\n",
      "Epoch 45/50, Train iteration 131/164: Loss = 1.5416\n",
      "Epoch 45/50, Train iteration 132/164: Loss = 1.5337\n",
      "Epoch 45/50, Train iteration 133/164: Loss = 1.5958\n",
      "Epoch 45/50, Train iteration 134/164: Loss = 1.5248\n",
      "Epoch 45/50, Train iteration 135/164: Loss = 1.5667\n",
      "Epoch 45/50, Train iteration 136/164: Loss = 1.5561\n",
      "Epoch 45/50, Train iteration 137/164: Loss = 1.5313\n",
      "Epoch 45/50, Train iteration 138/164: Loss = 1.5286\n",
      "Epoch 45/50, Train iteration 139/164: Loss = 1.5497\n",
      "Epoch 45/50, Train iteration 140/164: Loss = 1.5685\n",
      "Epoch 45/50, Train iteration 141/164: Loss = 1.5358\n",
      "Epoch 45/50, Train iteration 142/164: Loss = 1.5647\n",
      "Epoch 45/50, Train iteration 143/164: Loss = 1.5383\n",
      "Epoch 45/50, Train iteration 144/164: Loss = 1.5631\n",
      "Epoch 45/50, Train iteration 145/164: Loss = 1.5074\n",
      "Epoch 45/50, Train iteration 146/164: Loss = 1.4821\n",
      "Epoch 45/50, Train iteration 147/164: Loss = 1.5117\n",
      "Epoch 45/50, Train iteration 148/164: Loss = 1.5407\n",
      "Epoch 45/50, Train iteration 149/164: Loss = 1.5841\n",
      "Epoch 45/50, Train iteration 150/164: Loss = 1.5946\n",
      "Epoch 45/50, Train iteration 151/164: Loss = 1.5428\n",
      "Epoch 45/50, Train iteration 152/164: Loss = 1.5086\n",
      "Epoch 45/50, Train iteration 153/164: Loss = 1.5346\n",
      "Epoch 45/50, Train iteration 154/164: Loss = 1.5449\n",
      "Epoch 45/50, Train iteration 155/164: Loss = 1.5454\n",
      "Epoch 45/50, Train iteration 156/164: Loss = 1.4958\n",
      "Epoch 45/50, Train iteration 157/164: Loss = 1.5874\n",
      "Epoch 45/50, Train iteration 158/164: Loss = 1.6048\n",
      "Epoch 45/50, Train iteration 159/164: Loss = 1.5821\n",
      "Epoch 45/50, Train iteration 160/164: Loss = 1.5494\n",
      "Epoch 45/50, Train iteration 161/164: Loss = 1.6216\n",
      "Epoch 45/50, Train iteration 162/164: Loss = 1.5254\n",
      "Epoch 45/50, Train iteration 163/164: Loss = 1.5404\n",
      "Epoch 45/50, Train iteration 164/164: Loss = 1.3962\n",
      "Epoch 45/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 45/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 45/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 45/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 45/50, Val iteration 5/27: Loss = 1.6151\n",
      "Epoch 45/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 45/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 45/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 45/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 45/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 45/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 45/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 45/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 45/50, Val iteration 14/27: Loss = 1.5443\n",
      "Epoch 45/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 45/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 45/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 45/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 45/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 45/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 45/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 45/50, Val iteration 22/27: Loss = 1.6041\n",
      "Epoch 45/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 45/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 45/50, Val iteration 25/27: Loss = 1.5854\n",
      "Epoch 45/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 45/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 45/50: Train Loss = 1.5405, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 46/50, Train iteration 1/164: Loss = 1.5530\n",
      "Epoch 46/50, Train iteration 2/164: Loss = 1.5360\n",
      "Epoch 46/50, Train iteration 3/164: Loss = 1.5327\n",
      "Epoch 46/50, Train iteration 4/164: Loss = 1.5492\n",
      "Epoch 46/50, Train iteration 5/164: Loss = 1.5949\n",
      "Epoch 46/50, Train iteration 6/164: Loss = 1.5949\n",
      "Epoch 46/50, Train iteration 7/164: Loss = 1.6038\n",
      "Epoch 46/50, Train iteration 8/164: Loss = 1.4802\n",
      "Epoch 46/50, Train iteration 9/164: Loss = 1.5696\n",
      "Epoch 46/50, Train iteration 10/164: Loss = 1.5703\n",
      "Epoch 46/50, Train iteration 11/164: Loss = 1.5613\n",
      "Epoch 46/50, Train iteration 12/164: Loss = 1.5158\n",
      "Epoch 46/50, Train iteration 13/164: Loss = 1.4741\n",
      "Epoch 46/50, Train iteration 14/164: Loss = 1.5353\n",
      "Epoch 46/50, Train iteration 15/164: Loss = 1.5614\n",
      "Epoch 46/50, Train iteration 16/164: Loss = 1.5239\n",
      "Epoch 46/50, Train iteration 17/164: Loss = 1.5298\n",
      "Epoch 46/50, Train iteration 18/164: Loss = 1.5468\n",
      "Epoch 46/50, Train iteration 19/164: Loss = 1.5672\n",
      "Epoch 46/50, Train iteration 20/164: Loss = 1.5356\n",
      "Epoch 46/50, Train iteration 21/164: Loss = 1.5392\n",
      "Epoch 46/50, Train iteration 22/164: Loss = 1.6069\n",
      "Epoch 46/50, Train iteration 23/164: Loss = 1.5805\n",
      "Epoch 46/50, Train iteration 24/164: Loss = 1.5912\n",
      "Epoch 46/50, Train iteration 25/164: Loss = 1.5907\n",
      "Epoch 46/50, Train iteration 26/164: Loss = 1.5663\n",
      "Epoch 46/50, Train iteration 27/164: Loss = 1.5338\n",
      "Epoch 46/50, Train iteration 28/164: Loss = 1.5243\n",
      "Epoch 46/50, Train iteration 29/164: Loss = 1.5163\n",
      "Epoch 46/50, Train iteration 30/164: Loss = 1.6085\n",
      "Epoch 46/50, Train iteration 31/164: Loss = 1.4940\n",
      "Epoch 46/50, Train iteration 32/164: Loss = 1.4900\n",
      "Epoch 46/50, Train iteration 33/164: Loss = 1.6109\n",
      "Epoch 46/50, Train iteration 34/164: Loss = 1.4777\n",
      "Epoch 46/50, Train iteration 35/164: Loss = 1.5557\n",
      "Epoch 46/50, Train iteration 36/164: Loss = 1.5108\n",
      "Epoch 46/50, Train iteration 37/164: Loss = 1.5739\n",
      "Epoch 46/50, Train iteration 38/164: Loss = 1.5416\n",
      "Epoch 46/50, Train iteration 39/164: Loss = 1.4919\n",
      "Epoch 46/50, Train iteration 40/164: Loss = 1.5092\n",
      "Epoch 46/50, Train iteration 41/164: Loss = 1.5161\n",
      "Epoch 46/50, Train iteration 42/164: Loss = 1.5981\n",
      "Epoch 46/50, Train iteration 43/164: Loss = 1.5356\n",
      "Epoch 46/50, Train iteration 44/164: Loss = 1.5579\n",
      "Epoch 46/50, Train iteration 45/164: Loss = 1.5667\n",
      "Epoch 46/50, Train iteration 46/164: Loss = 1.6158\n",
      "Epoch 46/50, Train iteration 47/164: Loss = 1.5304\n",
      "Epoch 46/50, Train iteration 48/164: Loss = 1.5340\n",
      "Epoch 46/50, Train iteration 49/164: Loss = 1.5172\n",
      "Epoch 46/50, Train iteration 50/164: Loss = 1.5666\n",
      "Epoch 46/50, Train iteration 51/164: Loss = 1.4737\n",
      "Epoch 46/50, Train iteration 52/164: Loss = 1.5295\n",
      "Epoch 46/50, Train iteration 53/164: Loss = 1.5893\n",
      "Epoch 46/50, Train iteration 54/164: Loss = 1.5724\n",
      "Epoch 46/50, Train iteration 55/164: Loss = 1.5020\n",
      "Epoch 46/50, Train iteration 56/164: Loss = 1.5335\n",
      "Epoch 46/50, Train iteration 57/164: Loss = 1.5573\n",
      "Epoch 46/50, Train iteration 58/164: Loss = 1.6165\n",
      "Epoch 46/50, Train iteration 59/164: Loss = 1.5768\n",
      "Epoch 46/50, Train iteration 60/164: Loss = 1.5316\n",
      "Epoch 46/50, Train iteration 61/164: Loss = 1.4695\n",
      "Epoch 46/50, Train iteration 62/164: Loss = 1.5504\n",
      "Epoch 46/50, Train iteration 63/164: Loss = 1.6012\n",
      "Epoch 46/50, Train iteration 64/164: Loss = 1.5114\n",
      "Epoch 46/50, Train iteration 65/164: Loss = 1.5523\n",
      "Epoch 46/50, Train iteration 66/164: Loss = 1.4594\n",
      "Epoch 46/50, Train iteration 67/164: Loss = 1.4997\n",
      "Epoch 46/50, Train iteration 68/164: Loss = 1.5879\n",
      "Epoch 46/50, Train iteration 69/164: Loss = 1.5443\n",
      "Epoch 46/50, Train iteration 70/164: Loss = 1.6290\n",
      "Epoch 46/50, Train iteration 71/164: Loss = 1.5721\n",
      "Epoch 46/50, Train iteration 72/164: Loss = 1.5963\n",
      "Epoch 46/50, Train iteration 73/164: Loss = 1.5587\n",
      "Epoch 46/50, Train iteration 74/164: Loss = 1.5238\n",
      "Epoch 46/50, Train iteration 75/164: Loss = 1.5102\n",
      "Epoch 46/50, Train iteration 76/164: Loss = 1.5596\n",
      "Epoch 46/50, Train iteration 77/164: Loss = 1.5783\n",
      "Epoch 46/50, Train iteration 78/164: Loss = 1.5485\n",
      "Epoch 46/50, Train iteration 79/164: Loss = 1.5112\n",
      "Epoch 46/50, Train iteration 80/164: Loss = 1.5776\n",
      "Epoch 46/50, Train iteration 81/164: Loss = 1.5781\n",
      "Epoch 46/50, Train iteration 82/164: Loss = 1.5121\n",
      "Epoch 46/50, Train iteration 83/164: Loss = 1.5622\n",
      "Epoch 46/50, Train iteration 84/164: Loss = 1.5102\n",
      "Epoch 46/50, Train iteration 85/164: Loss = 1.5886\n",
      "Epoch 46/50, Train iteration 86/164: Loss = 1.4614\n",
      "Epoch 46/50, Train iteration 87/164: Loss = 1.5631\n",
      "Epoch 46/50, Train iteration 88/164: Loss = 1.5863\n",
      "Epoch 46/50, Train iteration 89/164: Loss = 1.5237\n",
      "Epoch 46/50, Train iteration 90/164: Loss = 1.5120\n",
      "Epoch 46/50, Train iteration 91/164: Loss = 1.5978\n",
      "Epoch 46/50, Train iteration 92/164: Loss = 1.5898\n",
      "Epoch 46/50, Train iteration 93/164: Loss = 1.5408\n",
      "Epoch 46/50, Train iteration 94/164: Loss = 1.5793\n",
      "Epoch 46/50, Train iteration 95/164: Loss = 1.4806\n",
      "Epoch 46/50, Train iteration 96/164: Loss = 1.5456\n",
      "Epoch 46/50, Train iteration 97/164: Loss = 1.5358\n",
      "Epoch 46/50, Train iteration 98/164: Loss = 1.5421\n",
      "Epoch 46/50, Train iteration 99/164: Loss = 1.4529\n",
      "Epoch 46/50, Train iteration 100/164: Loss = 1.4914\n",
      "Epoch 46/50, Train iteration 101/164: Loss = 1.4777\n",
      "Epoch 46/50, Train iteration 102/164: Loss = 1.5369\n",
      "Epoch 46/50, Train iteration 103/164: Loss = 1.5379\n",
      "Epoch 46/50, Train iteration 104/164: Loss = 1.5783\n",
      "Epoch 46/50, Train iteration 105/164: Loss = 1.5427\n",
      "Epoch 46/50, Train iteration 106/164: Loss = 1.5731\n",
      "Epoch 46/50, Train iteration 107/164: Loss = 1.5325\n",
      "Epoch 46/50, Train iteration 108/164: Loss = 1.5142\n",
      "Epoch 46/50, Train iteration 109/164: Loss = 1.5758\n",
      "Epoch 46/50, Train iteration 110/164: Loss = 1.5287\n",
      "Epoch 46/50, Train iteration 111/164: Loss = 1.5397\n",
      "Epoch 46/50, Train iteration 112/164: Loss = 1.5853\n",
      "Epoch 46/50, Train iteration 113/164: Loss = 1.5408\n",
      "Epoch 46/50, Train iteration 114/164: Loss = 1.4478\n",
      "Epoch 46/50, Train iteration 115/164: Loss = 1.4930\n",
      "Epoch 46/50, Train iteration 116/164: Loss = 1.5540\n",
      "Epoch 46/50, Train iteration 117/164: Loss = 1.5254\n",
      "Epoch 46/50, Train iteration 118/164: Loss = 1.5357\n",
      "Epoch 46/50, Train iteration 119/164: Loss = 1.5330\n",
      "Epoch 46/50, Train iteration 120/164: Loss = 1.5595\n",
      "Epoch 46/50, Train iteration 121/164: Loss = 1.5747\n",
      "Epoch 46/50, Train iteration 122/164: Loss = 1.4983\n",
      "Epoch 46/50, Train iteration 123/164: Loss = 1.4620\n",
      "Epoch 46/50, Train iteration 124/164: Loss = 1.5276\n",
      "Epoch 46/50, Train iteration 125/164: Loss = 1.5240\n",
      "Epoch 46/50, Train iteration 126/164: Loss = 1.4961\n",
      "Epoch 46/50, Train iteration 127/164: Loss = 1.5951\n",
      "Epoch 46/50, Train iteration 128/164: Loss = 1.4596\n",
      "Epoch 46/50, Train iteration 129/164: Loss = 1.5487\n",
      "Epoch 46/50, Train iteration 130/164: Loss = 1.6001\n",
      "Epoch 46/50, Train iteration 131/164: Loss = 1.5285\n",
      "Epoch 46/50, Train iteration 132/164: Loss = 1.5223\n",
      "Epoch 46/50, Train iteration 133/164: Loss = 1.5834\n",
      "Epoch 46/50, Train iteration 134/164: Loss = 1.5015\n",
      "Epoch 46/50, Train iteration 135/164: Loss = 1.5534\n",
      "Epoch 46/50, Train iteration 136/164: Loss = 1.5715\n",
      "Epoch 46/50, Train iteration 137/164: Loss = 1.5491\n",
      "Epoch 46/50, Train iteration 138/164: Loss = 1.5695\n",
      "Epoch 46/50, Train iteration 139/164: Loss = 1.5995\n",
      "Epoch 46/50, Train iteration 140/164: Loss = 1.5526\n",
      "Epoch 46/50, Train iteration 141/164: Loss = 1.5923\n",
      "Epoch 46/50, Train iteration 142/164: Loss = 1.5728\n",
      "Epoch 46/50, Train iteration 143/164: Loss = 1.5304\n",
      "Epoch 46/50, Train iteration 144/164: Loss = 1.6093\n",
      "Epoch 46/50, Train iteration 145/164: Loss = 1.5313\n",
      "Epoch 46/50, Train iteration 146/164: Loss = 1.5244\n",
      "Epoch 46/50, Train iteration 147/164: Loss = 1.4893\n",
      "Epoch 46/50, Train iteration 148/164: Loss = 1.5008\n",
      "Epoch 46/50, Train iteration 149/164: Loss = 1.5314\n",
      "Epoch 46/50, Train iteration 150/164: Loss = 1.5705\n",
      "Epoch 46/50, Train iteration 151/164: Loss = 1.5671\n",
      "Epoch 46/50, Train iteration 152/164: Loss = 1.4819\n",
      "Epoch 46/50, Train iteration 153/164: Loss = 1.5491\n",
      "Epoch 46/50, Train iteration 154/164: Loss = 1.5345\n",
      "Epoch 46/50, Train iteration 155/164: Loss = 1.5432\n",
      "Epoch 46/50, Train iteration 156/164: Loss = 1.5189\n",
      "Epoch 46/50, Train iteration 157/164: Loss = 1.5789\n",
      "Epoch 46/50, Train iteration 158/164: Loss = 1.5851\n",
      "Epoch 46/50, Train iteration 159/164: Loss = 1.5825\n",
      "Epoch 46/50, Train iteration 160/164: Loss = 1.5462\n",
      "Epoch 46/50, Train iteration 161/164: Loss = 1.5848\n",
      "Epoch 46/50, Train iteration 162/164: Loss = 1.5603\n",
      "Epoch 46/50, Train iteration 163/164: Loss = 1.5117\n",
      "Epoch 46/50, Train iteration 164/164: Loss = 1.3798\n",
      "Epoch 46/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 46/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 46/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 46/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 46/50, Val iteration 5/27: Loss = 1.6150\n",
      "Epoch 46/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 46/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 46/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 46/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 46/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 46/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 46/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 46/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 46/50, Val iteration 14/27: Loss = 1.5444\n",
      "Epoch 46/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 46/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 46/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 46/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 46/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 46/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 46/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 46/50, Val iteration 22/27: Loss = 1.6040\n",
      "Epoch 46/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 46/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 46/50, Val iteration 25/27: Loss = 1.5854\n",
      "Epoch 46/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 46/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 46/50: Train Loss = 1.5431, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 47/50, Train iteration 1/164: Loss = 1.5206\n",
      "Epoch 47/50, Train iteration 2/164: Loss = 1.6092\n",
      "Epoch 47/50, Train iteration 3/164: Loss = 1.5502\n",
      "Epoch 47/50, Train iteration 4/164: Loss = 1.5627\n",
      "Epoch 47/50, Train iteration 5/164: Loss = 1.5495\n",
      "Epoch 47/50, Train iteration 6/164: Loss = 1.5608\n",
      "Epoch 47/50, Train iteration 7/164: Loss = 1.5964\n",
      "Epoch 47/50, Train iteration 8/164: Loss = 1.5038\n",
      "Epoch 47/50, Train iteration 9/164: Loss = 1.5377\n",
      "Epoch 47/50, Train iteration 10/164: Loss = 1.5720\n",
      "Epoch 47/50, Train iteration 11/164: Loss = 1.5831\n",
      "Epoch 47/50, Train iteration 12/164: Loss = 1.5543\n",
      "Epoch 47/50, Train iteration 13/164: Loss = 1.4598\n",
      "Epoch 47/50, Train iteration 14/164: Loss = 1.5969\n",
      "Epoch 47/50, Train iteration 15/164: Loss = 1.5571\n",
      "Epoch 47/50, Train iteration 16/164: Loss = 1.5595\n",
      "Epoch 47/50, Train iteration 17/164: Loss = 1.5550\n",
      "Epoch 47/50, Train iteration 18/164: Loss = 1.5220\n",
      "Epoch 47/50, Train iteration 19/164: Loss = 1.4982\n",
      "Epoch 47/50, Train iteration 20/164: Loss = 1.5441\n",
      "Epoch 47/50, Train iteration 21/164: Loss = 1.5180\n",
      "Epoch 47/50, Train iteration 22/164: Loss = 1.5788\n",
      "Epoch 47/50, Train iteration 23/164: Loss = 1.5208\n",
      "Epoch 47/50, Train iteration 24/164: Loss = 1.5762\n",
      "Epoch 47/50, Train iteration 25/164: Loss = 1.5916\n",
      "Epoch 47/50, Train iteration 26/164: Loss = 1.5445\n",
      "Epoch 47/50, Train iteration 27/164: Loss = 1.5525\n",
      "Epoch 47/50, Train iteration 28/164: Loss = 1.5386\n",
      "Epoch 47/50, Train iteration 29/164: Loss = 1.5466\n",
      "Epoch 47/50, Train iteration 30/164: Loss = 1.5470\n",
      "Epoch 47/50, Train iteration 31/164: Loss = 1.4542\n",
      "Epoch 47/50, Train iteration 32/164: Loss = 1.5047\n",
      "Epoch 47/50, Train iteration 33/164: Loss = 1.5991\n",
      "Epoch 47/50, Train iteration 34/164: Loss = 1.5263\n",
      "Epoch 47/50, Train iteration 35/164: Loss = 1.6156\n",
      "Epoch 47/50, Train iteration 36/164: Loss = 1.5240\n",
      "Epoch 47/50, Train iteration 37/164: Loss = 1.5220\n",
      "Epoch 47/50, Train iteration 38/164: Loss = 1.5524\n",
      "Epoch 47/50, Train iteration 39/164: Loss = 1.5250\n",
      "Epoch 47/50, Train iteration 40/164: Loss = 1.5152\n",
      "Epoch 47/50, Train iteration 41/164: Loss = 1.5039\n",
      "Epoch 47/50, Train iteration 42/164: Loss = 1.6059\n",
      "Epoch 47/50, Train iteration 43/164: Loss = 1.5085\n",
      "Epoch 47/50, Train iteration 44/164: Loss = 1.4837\n",
      "Epoch 47/50, Train iteration 45/164: Loss = 1.5374\n",
      "Epoch 47/50, Train iteration 46/164: Loss = 1.5532\n",
      "Epoch 47/50, Train iteration 47/164: Loss = 1.5619\n",
      "Epoch 47/50, Train iteration 48/164: Loss = 1.5354\n",
      "Epoch 47/50, Train iteration 49/164: Loss = 1.4898\n",
      "Epoch 47/50, Train iteration 50/164: Loss = 1.5832\n",
      "Epoch 47/50, Train iteration 51/164: Loss = 1.4756\n",
      "Epoch 47/50, Train iteration 52/164: Loss = 1.5172\n",
      "Epoch 47/50, Train iteration 53/164: Loss = 1.5685\n",
      "Epoch 47/50, Train iteration 54/164: Loss = 1.5270\n",
      "Epoch 47/50, Train iteration 55/164: Loss = 1.5252\n",
      "Epoch 47/50, Train iteration 56/164: Loss = 1.5620\n",
      "Epoch 47/50, Train iteration 57/164: Loss = 1.5340\n",
      "Epoch 47/50, Train iteration 58/164: Loss = 1.5981\n",
      "Epoch 47/50, Train iteration 59/164: Loss = 1.5740\n",
      "Epoch 47/50, Train iteration 60/164: Loss = 1.4748\n",
      "Epoch 47/50, Train iteration 61/164: Loss = 1.5137\n",
      "Epoch 47/50, Train iteration 62/164: Loss = 1.5173\n",
      "Epoch 47/50, Train iteration 63/164: Loss = 1.5898\n",
      "Epoch 47/50, Train iteration 64/164: Loss = 1.5824\n",
      "Epoch 47/50, Train iteration 65/164: Loss = 1.5468\n",
      "Epoch 47/50, Train iteration 66/164: Loss = 1.4390\n",
      "Epoch 47/50, Train iteration 67/164: Loss = 1.4818\n",
      "Epoch 47/50, Train iteration 68/164: Loss = 1.5350\n",
      "Epoch 47/50, Train iteration 69/164: Loss = 1.5218\n",
      "Epoch 47/50, Train iteration 70/164: Loss = 1.5148\n",
      "Epoch 47/50, Train iteration 71/164: Loss = 1.5819\n",
      "Epoch 47/50, Train iteration 72/164: Loss = 1.5706\n",
      "Epoch 47/50, Train iteration 73/164: Loss = 1.5998\n",
      "Epoch 47/50, Train iteration 74/164: Loss = 1.4993\n",
      "Epoch 47/50, Train iteration 75/164: Loss = 1.4973\n",
      "Epoch 47/50, Train iteration 76/164: Loss = 1.5993\n",
      "Epoch 47/50, Train iteration 77/164: Loss = 1.6254\n",
      "Epoch 47/50, Train iteration 78/164: Loss = 1.5357\n",
      "Epoch 47/50, Train iteration 79/164: Loss = 1.5632\n",
      "Epoch 47/50, Train iteration 80/164: Loss = 1.5116\n",
      "Epoch 47/50, Train iteration 81/164: Loss = 1.5429\n",
      "Epoch 47/50, Train iteration 82/164: Loss = 1.5347\n",
      "Epoch 47/50, Train iteration 83/164: Loss = 1.5801\n",
      "Epoch 47/50, Train iteration 84/164: Loss = 1.5499\n",
      "Epoch 47/50, Train iteration 85/164: Loss = 1.5952\n",
      "Epoch 47/50, Train iteration 86/164: Loss = 1.4728\n",
      "Epoch 47/50, Train iteration 87/164: Loss = 1.5484\n",
      "Epoch 47/50, Train iteration 88/164: Loss = 1.5594\n",
      "Epoch 47/50, Train iteration 89/164: Loss = 1.5710\n",
      "Epoch 47/50, Train iteration 90/164: Loss = 1.5522\n",
      "Epoch 47/50, Train iteration 91/164: Loss = 1.5932\n",
      "Epoch 47/50, Train iteration 92/164: Loss = 1.5507\n",
      "Epoch 47/50, Train iteration 93/164: Loss = 1.4599\n",
      "Epoch 47/50, Train iteration 94/164: Loss = 1.5600\n",
      "Epoch 47/50, Train iteration 95/164: Loss = 1.5298\n",
      "Epoch 47/50, Train iteration 96/164: Loss = 1.6030\n",
      "Epoch 47/50, Train iteration 97/164: Loss = 1.6267\n",
      "Epoch 47/50, Train iteration 98/164: Loss = 1.5267\n",
      "Epoch 47/50, Train iteration 99/164: Loss = 1.4969\n",
      "Epoch 47/50, Train iteration 100/164: Loss = 1.5000\n",
      "Epoch 47/50, Train iteration 101/164: Loss = 1.5513\n",
      "Epoch 47/50, Train iteration 102/164: Loss = 1.5310\n",
      "Epoch 47/50, Train iteration 103/164: Loss = 1.5616\n",
      "Epoch 47/50, Train iteration 104/164: Loss = 1.5296\n",
      "Epoch 47/50, Train iteration 105/164: Loss = 1.5351\n",
      "Epoch 47/50, Train iteration 106/164: Loss = 1.6275\n",
      "Epoch 47/50, Train iteration 107/164: Loss = 1.5394\n",
      "Epoch 47/50, Train iteration 108/164: Loss = 1.5425\n",
      "Epoch 47/50, Train iteration 109/164: Loss = 1.6010\n",
      "Epoch 47/50, Train iteration 110/164: Loss = 1.5012\n",
      "Epoch 47/50, Train iteration 111/164: Loss = 1.5914\n",
      "Epoch 47/50, Train iteration 112/164: Loss = 1.5525\n",
      "Epoch 47/50, Train iteration 113/164: Loss = 1.5026\n",
      "Epoch 47/50, Train iteration 114/164: Loss = 1.4738\n",
      "Epoch 47/50, Train iteration 115/164: Loss = 1.5310\n",
      "Epoch 47/50, Train iteration 116/164: Loss = 1.5391\n",
      "Epoch 47/50, Train iteration 117/164: Loss = 1.5289\n",
      "Epoch 47/50, Train iteration 118/164: Loss = 1.5728\n",
      "Epoch 47/50, Train iteration 119/164: Loss = 1.5100\n",
      "Epoch 47/50, Train iteration 120/164: Loss = 1.5027\n",
      "Epoch 47/50, Train iteration 121/164: Loss = 1.5842\n",
      "Epoch 47/50, Train iteration 122/164: Loss = 1.3955\n",
      "Epoch 47/50, Train iteration 123/164: Loss = 1.5350\n",
      "Epoch 47/50, Train iteration 124/164: Loss = 1.5364\n",
      "Epoch 47/50, Train iteration 125/164: Loss = 1.4862\n",
      "Epoch 47/50, Train iteration 126/164: Loss = 1.4902\n",
      "Epoch 47/50, Train iteration 127/164: Loss = 1.5833\n",
      "Epoch 47/50, Train iteration 128/164: Loss = 1.4955\n",
      "Epoch 47/50, Train iteration 129/164: Loss = 1.5136\n",
      "Epoch 47/50, Train iteration 130/164: Loss = 1.5753\n",
      "Epoch 47/50, Train iteration 131/164: Loss = 1.5286\n",
      "Epoch 47/50, Train iteration 132/164: Loss = 1.5507\n",
      "Epoch 47/50, Train iteration 133/164: Loss = 1.5352\n",
      "Epoch 47/50, Train iteration 134/164: Loss = 1.4974\n",
      "Epoch 47/50, Train iteration 135/164: Loss = 1.5763\n",
      "Epoch 47/50, Train iteration 136/164: Loss = 1.5391\n",
      "Epoch 47/50, Train iteration 137/164: Loss = 1.4853\n",
      "Epoch 47/50, Train iteration 138/164: Loss = 1.5464\n",
      "Epoch 47/50, Train iteration 139/164: Loss = 1.5704\n",
      "Epoch 47/50, Train iteration 140/164: Loss = 1.5315\n",
      "Epoch 47/50, Train iteration 141/164: Loss = 1.4831\n",
      "Epoch 47/50, Train iteration 142/164: Loss = 1.5822\n",
      "Epoch 47/50, Train iteration 143/164: Loss = 1.4805\n",
      "Epoch 47/50, Train iteration 144/164: Loss = 1.5835\n",
      "Epoch 47/50, Train iteration 145/164: Loss = 1.5482\n",
      "Epoch 47/50, Train iteration 146/164: Loss = 1.4723\n",
      "Epoch 47/50, Train iteration 147/164: Loss = 1.5077\n",
      "Epoch 47/50, Train iteration 148/164: Loss = 1.5245\n",
      "Epoch 47/50, Train iteration 149/164: Loss = 1.5893\n",
      "Epoch 47/50, Train iteration 150/164: Loss = 1.5381\n",
      "Epoch 47/50, Train iteration 151/164: Loss = 1.5503\n",
      "Epoch 47/50, Train iteration 152/164: Loss = 1.4599\n",
      "Epoch 47/50, Train iteration 153/164: Loss = 1.5876\n",
      "Epoch 47/50, Train iteration 154/164: Loss = 1.5277\n",
      "Epoch 47/50, Train iteration 155/164: Loss = 1.5313\n",
      "Epoch 47/50, Train iteration 156/164: Loss = 1.5022\n",
      "Epoch 47/50, Train iteration 157/164: Loss = 1.5693\n",
      "Epoch 47/50, Train iteration 158/164: Loss = 1.5761\n",
      "Epoch 47/50, Train iteration 159/164: Loss = 1.5897\n",
      "Epoch 47/50, Train iteration 160/164: Loss = 1.5722\n",
      "Epoch 47/50, Train iteration 161/164: Loss = 1.6041\n",
      "Epoch 47/50, Train iteration 162/164: Loss = 1.5275\n",
      "Epoch 47/50, Train iteration 163/164: Loss = 1.5449\n",
      "Epoch 47/50, Train iteration 164/164: Loss = 1.2225\n",
      "Epoch 47/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 47/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 47/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 47/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 47/50, Val iteration 5/27: Loss = 1.6150\n",
      "Epoch 47/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 47/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 47/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 47/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 47/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 47/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 47/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 47/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 47/50, Val iteration 14/27: Loss = 1.5444\n",
      "Epoch 47/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 47/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 47/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 47/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 47/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 47/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 47/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 47/50, Val iteration 22/27: Loss = 1.6040\n",
      "Epoch 47/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 47/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 47/50, Val iteration 25/27: Loss = 1.5854\n",
      "Epoch 47/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 47/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 47/50: Train Loss = 1.5390, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 48/50, Train iteration 1/164: Loss = 1.5629\n",
      "Epoch 48/50, Train iteration 2/164: Loss = 1.5473\n",
      "Epoch 48/50, Train iteration 3/164: Loss = 1.5826\n",
      "Epoch 48/50, Train iteration 4/164: Loss = 1.5650\n",
      "Epoch 48/50, Train iteration 5/164: Loss = 1.5482\n",
      "Epoch 48/50, Train iteration 6/164: Loss = 1.6081\n",
      "Epoch 48/50, Train iteration 7/164: Loss = 1.6026\n",
      "Epoch 48/50, Train iteration 8/164: Loss = 1.4644\n",
      "Epoch 48/50, Train iteration 9/164: Loss = 1.5950\n",
      "Epoch 48/50, Train iteration 10/164: Loss = 1.5870\n",
      "Epoch 48/50, Train iteration 11/164: Loss = 1.5790\n",
      "Epoch 48/50, Train iteration 12/164: Loss = 1.5282\n",
      "Epoch 48/50, Train iteration 13/164: Loss = 1.4692\n",
      "Epoch 48/50, Train iteration 14/164: Loss = 1.5897\n",
      "Epoch 48/50, Train iteration 15/164: Loss = 1.5346\n",
      "Epoch 48/50, Train iteration 16/164: Loss = 1.5923\n",
      "Epoch 48/50, Train iteration 17/164: Loss = 1.5397\n",
      "Epoch 48/50, Train iteration 18/164: Loss = 1.4821\n",
      "Epoch 48/50, Train iteration 19/164: Loss = 1.5005\n",
      "Epoch 48/50, Train iteration 20/164: Loss = 1.5551\n",
      "Epoch 48/50, Train iteration 21/164: Loss = 1.5562\n",
      "Epoch 48/50, Train iteration 22/164: Loss = 1.5603\n",
      "Epoch 48/50, Train iteration 23/164: Loss = 1.5011\n",
      "Epoch 48/50, Train iteration 24/164: Loss = 1.5748\n",
      "Epoch 48/50, Train iteration 25/164: Loss = 1.5596\n",
      "Epoch 48/50, Train iteration 26/164: Loss = 1.5890\n",
      "Epoch 48/50, Train iteration 27/164: Loss = 1.5358\n",
      "Epoch 48/50, Train iteration 28/164: Loss = 1.5312\n",
      "Epoch 48/50, Train iteration 29/164: Loss = 1.5354\n",
      "Epoch 48/50, Train iteration 30/164: Loss = 1.5602\n",
      "Epoch 48/50, Train iteration 31/164: Loss = 1.4864\n",
      "Epoch 48/50, Train iteration 32/164: Loss = 1.5453\n",
      "Epoch 48/50, Train iteration 33/164: Loss = 1.5936\n",
      "Epoch 48/50, Train iteration 34/164: Loss = 1.4671\n",
      "Epoch 48/50, Train iteration 35/164: Loss = 1.5901\n",
      "Epoch 48/50, Train iteration 36/164: Loss = 1.5308\n",
      "Epoch 48/50, Train iteration 37/164: Loss = 1.5502\n",
      "Epoch 48/50, Train iteration 38/164: Loss = 1.5341\n",
      "Epoch 48/50, Train iteration 39/164: Loss = 1.5814\n",
      "Epoch 48/50, Train iteration 40/164: Loss = 1.4976\n",
      "Epoch 48/50, Train iteration 41/164: Loss = 1.4454\n",
      "Epoch 48/50, Train iteration 42/164: Loss = 1.5711\n",
      "Epoch 48/50, Train iteration 43/164: Loss = 1.5845\n",
      "Epoch 48/50, Train iteration 44/164: Loss = 1.5656\n",
      "Epoch 48/50, Train iteration 45/164: Loss = 1.5588\n",
      "Epoch 48/50, Train iteration 46/164: Loss = 1.5390\n",
      "Epoch 48/50, Train iteration 47/164: Loss = 1.5074\n",
      "Epoch 48/50, Train iteration 48/164: Loss = 1.5165\n",
      "Epoch 48/50, Train iteration 49/164: Loss = 1.5136\n",
      "Epoch 48/50, Train iteration 50/164: Loss = 1.5542\n",
      "Epoch 48/50, Train iteration 51/164: Loss = 1.4435\n",
      "Epoch 48/50, Train iteration 52/164: Loss = 1.5044\n",
      "Epoch 48/50, Train iteration 53/164: Loss = 1.5383\n",
      "Epoch 48/50, Train iteration 54/164: Loss = 1.5474\n",
      "Epoch 48/50, Train iteration 55/164: Loss = 1.5001\n",
      "Epoch 48/50, Train iteration 56/164: Loss = 1.6087\n",
      "Epoch 48/50, Train iteration 57/164: Loss = 1.5469\n",
      "Epoch 48/50, Train iteration 58/164: Loss = 1.5792\n",
      "Epoch 48/50, Train iteration 59/164: Loss = 1.5391\n",
      "Epoch 48/50, Train iteration 60/164: Loss = 1.5135\n",
      "Epoch 48/50, Train iteration 61/164: Loss = 1.4861\n",
      "Epoch 48/50, Train iteration 62/164: Loss = 1.5168\n",
      "Epoch 48/50, Train iteration 63/164: Loss = 1.5911\n",
      "Epoch 48/50, Train iteration 64/164: Loss = 1.5243\n",
      "Epoch 48/50, Train iteration 65/164: Loss = 1.5246\n",
      "Epoch 48/50, Train iteration 66/164: Loss = 1.5159\n",
      "Epoch 48/50, Train iteration 67/164: Loss = 1.4798\n",
      "Epoch 48/50, Train iteration 68/164: Loss = 1.4694\n",
      "Epoch 48/50, Train iteration 69/164: Loss = 1.5939\n",
      "Epoch 48/50, Train iteration 70/164: Loss = 1.5280\n",
      "Epoch 48/50, Train iteration 71/164: Loss = 1.5818\n",
      "Epoch 48/50, Train iteration 72/164: Loss = 1.5719\n",
      "Epoch 48/50, Train iteration 73/164: Loss = 1.5486\n",
      "Epoch 48/50, Train iteration 74/164: Loss = 1.5383\n",
      "Epoch 48/50, Train iteration 75/164: Loss = 1.5386\n",
      "Epoch 48/50, Train iteration 76/164: Loss = 1.5599\n",
      "Epoch 48/50, Train iteration 77/164: Loss = 1.5889\n",
      "Epoch 48/50, Train iteration 78/164: Loss = 1.5047\n",
      "Epoch 48/50, Train iteration 79/164: Loss = 1.4969\n",
      "Epoch 48/50, Train iteration 80/164: Loss = 1.5547\n",
      "Epoch 48/50, Train iteration 81/164: Loss = 1.5084\n",
      "Epoch 48/50, Train iteration 82/164: Loss = 1.5600\n",
      "Epoch 48/50, Train iteration 83/164: Loss = 1.5660\n",
      "Epoch 48/50, Train iteration 84/164: Loss = 1.5017\n",
      "Epoch 48/50, Train iteration 85/164: Loss = 1.6062\n",
      "Epoch 48/50, Train iteration 86/164: Loss = 1.4429\n",
      "Epoch 48/50, Train iteration 87/164: Loss = 1.5416\n",
      "Epoch 48/50, Train iteration 88/164: Loss = 1.5991\n",
      "Epoch 48/50, Train iteration 89/164: Loss = 1.5063\n",
      "Epoch 48/50, Train iteration 90/164: Loss = 1.5176\n",
      "Epoch 48/50, Train iteration 91/164: Loss = 1.5149\n",
      "Epoch 48/50, Train iteration 92/164: Loss = 1.4906\n",
      "Epoch 48/50, Train iteration 93/164: Loss = 1.5513\n",
      "Epoch 48/50, Train iteration 94/164: Loss = 1.5920\n",
      "Epoch 48/50, Train iteration 95/164: Loss = 1.5029\n",
      "Epoch 48/50, Train iteration 96/164: Loss = 1.5780\n",
      "Epoch 48/50, Train iteration 97/164: Loss = 1.5473\n",
      "Epoch 48/50, Train iteration 98/164: Loss = 1.5224\n",
      "Epoch 48/50, Train iteration 99/164: Loss = 1.4549\n",
      "Epoch 48/50, Train iteration 100/164: Loss = 1.4944\n",
      "Epoch 48/50, Train iteration 101/164: Loss = 1.5123\n",
      "Epoch 48/50, Train iteration 102/164: Loss = 1.5049\n",
      "Epoch 48/50, Train iteration 103/164: Loss = 1.5683\n",
      "Epoch 48/50, Train iteration 104/164: Loss = 1.5574\n",
      "Epoch 48/50, Train iteration 105/164: Loss = 1.5933\n",
      "Epoch 48/50, Train iteration 106/164: Loss = 1.5344\n",
      "Epoch 48/50, Train iteration 107/164: Loss = 1.5021\n",
      "Epoch 48/50, Train iteration 108/164: Loss = 1.5645\n",
      "Epoch 48/50, Train iteration 109/164: Loss = 1.5244\n",
      "Epoch 48/50, Train iteration 110/164: Loss = 1.5411\n",
      "Epoch 48/50, Train iteration 111/164: Loss = 1.5991\n",
      "Epoch 48/50, Train iteration 112/164: Loss = 1.5274\n",
      "Epoch 48/50, Train iteration 113/164: Loss = 1.5506\n",
      "Epoch 48/50, Train iteration 114/164: Loss = 1.4944\n",
      "Epoch 48/50, Train iteration 115/164: Loss = 1.5357\n",
      "Epoch 48/50, Train iteration 116/164: Loss = 1.5000\n",
      "Epoch 48/50, Train iteration 117/164: Loss = 1.5296\n",
      "Epoch 48/50, Train iteration 118/164: Loss = 1.5638\n",
      "Epoch 48/50, Train iteration 119/164: Loss = 1.5821\n",
      "Epoch 48/50, Train iteration 120/164: Loss = 1.5002\n",
      "Epoch 48/50, Train iteration 121/164: Loss = 1.5485\n",
      "Epoch 48/50, Train iteration 122/164: Loss = 1.4865\n",
      "Epoch 48/50, Train iteration 123/164: Loss = 1.4988\n",
      "Epoch 48/50, Train iteration 124/164: Loss = 1.5351\n",
      "Epoch 48/50, Train iteration 125/164: Loss = 1.4861\n",
      "Epoch 48/50, Train iteration 126/164: Loss = 1.4957\n",
      "Epoch 48/50, Train iteration 127/164: Loss = 1.5908\n",
      "Epoch 48/50, Train iteration 128/164: Loss = 1.4984\n",
      "Epoch 48/50, Train iteration 129/164: Loss = 1.5335\n",
      "Epoch 48/50, Train iteration 130/164: Loss = 1.5891\n",
      "Epoch 48/50, Train iteration 131/164: Loss = 1.5296\n",
      "Epoch 48/50, Train iteration 132/164: Loss = 1.5178\n",
      "Epoch 48/50, Train iteration 133/164: Loss = 1.6002\n",
      "Epoch 48/50, Train iteration 134/164: Loss = 1.5433\n",
      "Epoch 48/50, Train iteration 135/164: Loss = 1.5206\n",
      "Epoch 48/50, Train iteration 136/164: Loss = 1.5748\n",
      "Epoch 48/50, Train iteration 137/164: Loss = 1.5690\n",
      "Epoch 48/50, Train iteration 138/164: Loss = 1.5335\n",
      "Epoch 48/50, Train iteration 139/164: Loss = 1.6310\n",
      "Epoch 48/50, Train iteration 140/164: Loss = 1.5378\n",
      "Epoch 48/50, Train iteration 141/164: Loss = 1.5248\n",
      "Epoch 48/50, Train iteration 142/164: Loss = 1.5316\n",
      "Epoch 48/50, Train iteration 143/164: Loss = 1.5207\n",
      "Epoch 48/50, Train iteration 144/164: Loss = 1.5864\n",
      "Epoch 48/50, Train iteration 145/164: Loss = 1.5195\n",
      "Epoch 48/50, Train iteration 146/164: Loss = 1.5495\n",
      "Epoch 48/50, Train iteration 147/164: Loss = 1.5332\n",
      "Epoch 48/50, Train iteration 148/164: Loss = 1.4926\n",
      "Epoch 48/50, Train iteration 149/164: Loss = 1.5648\n",
      "Epoch 48/50, Train iteration 150/164: Loss = 1.5555\n",
      "Epoch 48/50, Train iteration 151/164: Loss = 1.5489\n",
      "Epoch 48/50, Train iteration 152/164: Loss = 1.5217\n",
      "Epoch 48/50, Train iteration 153/164: Loss = 1.5611\n",
      "Epoch 48/50, Train iteration 154/164: Loss = 1.5548\n",
      "Epoch 48/50, Train iteration 155/164: Loss = 1.5635\n",
      "Epoch 48/50, Train iteration 156/164: Loss = 1.4896\n",
      "Epoch 48/50, Train iteration 157/164: Loss = 1.5867\n",
      "Epoch 48/50, Train iteration 158/164: Loss = 1.5647\n",
      "Epoch 48/50, Train iteration 159/164: Loss = 1.5751\n",
      "Epoch 48/50, Train iteration 160/164: Loss = 1.5331\n",
      "Epoch 48/50, Train iteration 161/164: Loss = 1.5699\n",
      "Epoch 48/50, Train iteration 162/164: Loss = 1.5337\n",
      "Epoch 48/50, Train iteration 163/164: Loss = 1.5124\n",
      "Epoch 48/50, Train iteration 164/164: Loss = 1.1628\n",
      "Epoch 48/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 48/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 48/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 48/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 48/50, Val iteration 5/27: Loss = 1.6150\n",
      "Epoch 48/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 48/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 48/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 48/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 48/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 48/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 48/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 48/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 48/50, Val iteration 14/27: Loss = 1.5444\n",
      "Epoch 48/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 48/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 48/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 48/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 48/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 48/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 48/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 48/50, Val iteration 22/27: Loss = 1.6040\n",
      "Epoch 48/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 48/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 48/50, Val iteration 25/27: Loss = 1.5854\n",
      "Epoch 48/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 48/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 48/50: Train Loss = 1.5376, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 49/50, Train iteration 1/164: Loss = 1.5325\n",
      "Epoch 49/50, Train iteration 2/164: Loss = 1.6046\n",
      "Epoch 49/50, Train iteration 3/164: Loss = 1.5803\n",
      "Epoch 49/50, Train iteration 4/164: Loss = 1.5850\n",
      "Epoch 49/50, Train iteration 5/164: Loss = 1.5889\n",
      "Epoch 49/50, Train iteration 6/164: Loss = 1.6238\n",
      "Epoch 49/50, Train iteration 7/164: Loss = 1.6088\n",
      "Epoch 49/50, Train iteration 8/164: Loss = 1.4814\n",
      "Epoch 49/50, Train iteration 9/164: Loss = 1.5942\n",
      "Epoch 49/50, Train iteration 10/164: Loss = 1.6184\n",
      "Epoch 49/50, Train iteration 11/164: Loss = 1.5757\n",
      "Epoch 49/50, Train iteration 12/164: Loss = 1.5462\n",
      "Epoch 49/50, Train iteration 13/164: Loss = 1.4711\n",
      "Epoch 49/50, Train iteration 14/164: Loss = 1.5855\n",
      "Epoch 49/50, Train iteration 15/164: Loss = 1.5719\n",
      "Epoch 49/50, Train iteration 16/164: Loss = 1.5319\n",
      "Epoch 49/50, Train iteration 17/164: Loss = 1.5665\n",
      "Epoch 49/50, Train iteration 18/164: Loss = 1.5202\n",
      "Epoch 49/50, Train iteration 19/164: Loss = 1.5309\n",
      "Epoch 49/50, Train iteration 20/164: Loss = 1.4757\n",
      "Epoch 49/50, Train iteration 21/164: Loss = 1.6314\n",
      "Epoch 49/50, Train iteration 22/164: Loss = 1.5626\n",
      "Epoch 49/50, Train iteration 23/164: Loss = 1.5301\n",
      "Epoch 49/50, Train iteration 24/164: Loss = 1.6127\n",
      "Epoch 49/50, Train iteration 25/164: Loss = 1.5340\n",
      "Epoch 49/50, Train iteration 26/164: Loss = 1.5611\n",
      "Epoch 49/50, Train iteration 27/164: Loss = 1.5204\n",
      "Epoch 49/50, Train iteration 28/164: Loss = 1.5675\n",
      "Epoch 49/50, Train iteration 29/164: Loss = 1.5299\n",
      "Epoch 49/50, Train iteration 30/164: Loss = 1.5615\n",
      "Epoch 49/50, Train iteration 31/164: Loss = 1.5038\n",
      "Epoch 49/50, Train iteration 32/164: Loss = 1.4928\n",
      "Epoch 49/50, Train iteration 33/164: Loss = 1.6017\n",
      "Epoch 49/50, Train iteration 34/164: Loss = 1.5085\n",
      "Epoch 49/50, Train iteration 35/164: Loss = 1.4940\n",
      "Epoch 49/50, Train iteration 36/164: Loss = 1.5006\n",
      "Epoch 49/50, Train iteration 37/164: Loss = 1.5391\n",
      "Epoch 49/50, Train iteration 38/164: Loss = 1.5419\n",
      "Epoch 49/50, Train iteration 39/164: Loss = 1.5748\n",
      "Epoch 49/50, Train iteration 40/164: Loss = 1.4697\n",
      "Epoch 49/50, Train iteration 41/164: Loss = 1.5082\n",
      "Epoch 49/50, Train iteration 42/164: Loss = 1.5561\n",
      "Epoch 49/50, Train iteration 43/164: Loss = 1.5257\n",
      "Epoch 49/50, Train iteration 44/164: Loss = 1.4813\n",
      "Epoch 49/50, Train iteration 45/164: Loss = 1.5809\n",
      "Epoch 49/50, Train iteration 46/164: Loss = 1.5791\n",
      "Epoch 49/50, Train iteration 47/164: Loss = 1.6113\n",
      "Epoch 49/50, Train iteration 48/164: Loss = 1.5183\n",
      "Epoch 49/50, Train iteration 49/164: Loss = 1.4902\n",
      "Epoch 49/50, Train iteration 50/164: Loss = 1.6009\n",
      "Epoch 49/50, Train iteration 51/164: Loss = 1.4861\n",
      "Epoch 49/50, Train iteration 52/164: Loss = 1.5262\n",
      "Epoch 49/50, Train iteration 53/164: Loss = 1.4862\n",
      "Epoch 49/50, Train iteration 54/164: Loss = 1.5612\n",
      "Epoch 49/50, Train iteration 55/164: Loss = 1.5055\n",
      "Epoch 49/50, Train iteration 56/164: Loss = 1.6096\n",
      "Epoch 49/50, Train iteration 57/164: Loss = 1.5078\n",
      "Epoch 49/50, Train iteration 58/164: Loss = 1.6005\n",
      "Epoch 49/50, Train iteration 59/164: Loss = 1.5419\n",
      "Epoch 49/50, Train iteration 60/164: Loss = 1.5351\n",
      "Epoch 49/50, Train iteration 61/164: Loss = 1.4837\n",
      "Epoch 49/50, Train iteration 62/164: Loss = 1.5234\n",
      "Epoch 49/50, Train iteration 63/164: Loss = 1.6112\n",
      "Epoch 49/50, Train iteration 64/164: Loss = 1.5059\n",
      "Epoch 49/50, Train iteration 65/164: Loss = 1.5458\n",
      "Epoch 49/50, Train iteration 66/164: Loss = 1.4549\n",
      "Epoch 49/50, Train iteration 67/164: Loss = 1.5120\n",
      "Epoch 49/50, Train iteration 68/164: Loss = 1.4977\n",
      "Epoch 49/50, Train iteration 69/164: Loss = 1.6080\n",
      "Epoch 49/50, Train iteration 70/164: Loss = 1.5452\n",
      "Epoch 49/50, Train iteration 71/164: Loss = 1.5613\n",
      "Epoch 49/50, Train iteration 72/164: Loss = 1.5648\n",
      "Epoch 49/50, Train iteration 73/164: Loss = 1.5618\n",
      "Epoch 49/50, Train iteration 74/164: Loss = 1.5591\n",
      "Epoch 49/50, Train iteration 75/164: Loss = 1.5138\n",
      "Epoch 49/50, Train iteration 76/164: Loss = 1.5650\n",
      "Epoch 49/50, Train iteration 77/164: Loss = 1.5622\n",
      "Epoch 49/50, Train iteration 78/164: Loss = 1.5340\n",
      "Epoch 49/50, Train iteration 79/164: Loss = 1.5378\n",
      "Epoch 49/50, Train iteration 80/164: Loss = 1.5937\n",
      "Epoch 49/50, Train iteration 81/164: Loss = 1.5395\n",
      "Epoch 49/50, Train iteration 82/164: Loss = 1.5480\n",
      "Epoch 49/50, Train iteration 83/164: Loss = 1.5550\n",
      "Epoch 49/50, Train iteration 84/164: Loss = 1.5251\n",
      "Epoch 49/50, Train iteration 85/164: Loss = 1.5792\n",
      "Epoch 49/50, Train iteration 86/164: Loss = 1.4128\n",
      "Epoch 49/50, Train iteration 87/164: Loss = 1.5013\n",
      "Epoch 49/50, Train iteration 88/164: Loss = 1.5838\n",
      "Epoch 49/50, Train iteration 89/164: Loss = 1.5327\n",
      "Epoch 49/50, Train iteration 90/164: Loss = 1.4768\n",
      "Epoch 49/50, Train iteration 91/164: Loss = 1.6062\n",
      "Epoch 49/50, Train iteration 92/164: Loss = 1.5724\n",
      "Epoch 49/50, Train iteration 93/164: Loss = 1.5872\n",
      "Epoch 49/50, Train iteration 94/164: Loss = 1.5667\n",
      "Epoch 49/50, Train iteration 95/164: Loss = 1.4796\n",
      "Epoch 49/50, Train iteration 96/164: Loss = 1.5662\n",
      "Epoch 49/50, Train iteration 97/164: Loss = 1.5675\n",
      "Epoch 49/50, Train iteration 98/164: Loss = 1.5954\n",
      "Epoch 49/50, Train iteration 99/164: Loss = 1.5017\n",
      "Epoch 49/50, Train iteration 100/164: Loss = 1.4856\n",
      "Epoch 49/50, Train iteration 101/164: Loss = 1.5178\n",
      "Epoch 49/50, Train iteration 102/164: Loss = 1.5268\n",
      "Epoch 49/50, Train iteration 103/164: Loss = 1.6162\n",
      "Epoch 49/50, Train iteration 104/164: Loss = 1.5680\n",
      "Epoch 49/50, Train iteration 105/164: Loss = 1.5755\n",
      "Epoch 49/50, Train iteration 106/164: Loss = 1.6003\n",
      "Epoch 49/50, Train iteration 107/164: Loss = 1.5858\n",
      "Epoch 49/50, Train iteration 108/164: Loss = 1.5631\n",
      "Epoch 49/50, Train iteration 109/164: Loss = 1.5904\n",
      "Epoch 49/50, Train iteration 110/164: Loss = 1.5562\n",
      "Epoch 49/50, Train iteration 111/164: Loss = 1.5591\n",
      "Epoch 49/50, Train iteration 112/164: Loss = 1.5808\n",
      "Epoch 49/50, Train iteration 113/164: Loss = 1.5078\n",
      "Epoch 49/50, Train iteration 114/164: Loss = 1.4358\n",
      "Epoch 49/50, Train iteration 115/164: Loss = 1.5238\n",
      "Epoch 49/50, Train iteration 116/164: Loss = 1.5012\n",
      "Epoch 49/50, Train iteration 117/164: Loss = 1.5090\n",
      "Epoch 49/50, Train iteration 118/164: Loss = 1.5395\n",
      "Epoch 49/50, Train iteration 119/164: Loss = 1.5739\n",
      "Epoch 49/50, Train iteration 120/164: Loss = 1.4857\n",
      "Epoch 49/50, Train iteration 121/164: Loss = 1.5392\n",
      "Epoch 49/50, Train iteration 122/164: Loss = 1.4965\n",
      "Epoch 49/50, Train iteration 123/164: Loss = 1.5043\n",
      "Epoch 49/50, Train iteration 124/164: Loss = 1.5690\n",
      "Epoch 49/50, Train iteration 125/164: Loss = 1.5160\n",
      "Epoch 49/50, Train iteration 126/164: Loss = 1.4883\n",
      "Epoch 49/50, Train iteration 127/164: Loss = 1.5660\n",
      "Epoch 49/50, Train iteration 128/164: Loss = 1.5107\n",
      "Epoch 49/50, Train iteration 129/164: Loss = 1.4990\n",
      "Epoch 49/50, Train iteration 130/164: Loss = 1.5255\n",
      "Epoch 49/50, Train iteration 131/164: Loss = 1.5416\n",
      "Epoch 49/50, Train iteration 132/164: Loss = 1.4742\n",
      "Epoch 49/50, Train iteration 133/164: Loss = 1.5508\n",
      "Epoch 49/50, Train iteration 134/164: Loss = 1.4975\n",
      "Epoch 49/50, Train iteration 135/164: Loss = 1.5322\n",
      "Epoch 49/50, Train iteration 136/164: Loss = 1.5774\n",
      "Epoch 49/50, Train iteration 137/164: Loss = 1.5135\n",
      "Epoch 49/50, Train iteration 138/164: Loss = 1.5591\n",
      "Epoch 49/50, Train iteration 139/164: Loss = 1.6081\n",
      "Epoch 49/50, Train iteration 140/164: Loss = 1.4903\n",
      "Epoch 49/50, Train iteration 141/164: Loss = 1.5474\n",
      "Epoch 49/50, Train iteration 142/164: Loss = 1.6121\n",
      "Epoch 49/50, Train iteration 143/164: Loss = 1.4912\n",
      "Epoch 49/50, Train iteration 144/164: Loss = 1.5765\n",
      "Epoch 49/50, Train iteration 145/164: Loss = 1.5047\n",
      "Epoch 49/50, Train iteration 146/164: Loss = 1.4958\n",
      "Epoch 49/50, Train iteration 147/164: Loss = 1.5444\n",
      "Epoch 49/50, Train iteration 148/164: Loss = 1.4603\n",
      "Epoch 49/50, Train iteration 149/164: Loss = 1.5740\n",
      "Epoch 49/50, Train iteration 150/164: Loss = 1.6107\n",
      "Epoch 49/50, Train iteration 151/164: Loss = 1.5648\n",
      "Epoch 49/50, Train iteration 152/164: Loss = 1.5243\n",
      "Epoch 49/50, Train iteration 153/164: Loss = 1.5526\n",
      "Epoch 49/50, Train iteration 154/164: Loss = 1.5217\n",
      "Epoch 49/50, Train iteration 155/164: Loss = 1.5276\n",
      "Epoch 49/50, Train iteration 156/164: Loss = 1.5133\n",
      "Epoch 49/50, Train iteration 157/164: Loss = 1.5764\n",
      "Epoch 49/50, Train iteration 158/164: Loss = 1.6053\n",
      "Epoch 49/50, Train iteration 159/164: Loss = 1.5441\n",
      "Epoch 49/50, Train iteration 160/164: Loss = 1.5191\n",
      "Epoch 49/50, Train iteration 161/164: Loss = 1.6423\n",
      "Epoch 49/50, Train iteration 162/164: Loss = 1.5318\n",
      "Epoch 49/50, Train iteration 163/164: Loss = 1.5438\n",
      "Epoch 49/50, Train iteration 164/164: Loss = 1.4201\n",
      "Epoch 49/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 49/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 49/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 49/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 49/50, Val iteration 5/27: Loss = 1.6150\n",
      "Epoch 49/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 49/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 49/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 49/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 49/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 49/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 49/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 49/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 49/50, Val iteration 14/27: Loss = 1.5444\n",
      "Epoch 49/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 49/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 49/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 49/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 49/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 49/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 49/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 49/50, Val iteration 22/27: Loss = 1.6040\n",
      "Epoch 49/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 49/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 49/50, Val iteration 25/27: Loss = 1.5854\n",
      "Epoch 49/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 49/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 49/50: Train Loss = 1.5424, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n",
      "Epoch 50/50, Train iteration 1/164: Loss = 1.5246\n",
      "Epoch 50/50, Train iteration 2/164: Loss = 1.5603\n",
      "Epoch 50/50, Train iteration 3/164: Loss = 1.5514\n",
      "Epoch 50/50, Train iteration 4/164: Loss = 1.5247\n",
      "Epoch 50/50, Train iteration 5/164: Loss = 1.5408\n",
      "Epoch 50/50, Train iteration 6/164: Loss = 1.6024\n",
      "Epoch 50/50, Train iteration 7/164: Loss = 1.5959\n",
      "Epoch 50/50, Train iteration 8/164: Loss = 1.5558\n",
      "Epoch 50/50, Train iteration 9/164: Loss = 1.5631\n",
      "Epoch 50/50, Train iteration 10/164: Loss = 1.6399\n",
      "Epoch 50/50, Train iteration 11/164: Loss = 1.5522\n",
      "Epoch 50/50, Train iteration 12/164: Loss = 1.5111\n",
      "Epoch 50/50, Train iteration 13/164: Loss = 1.4833\n",
      "Epoch 50/50, Train iteration 14/164: Loss = 1.5672\n",
      "Epoch 50/50, Train iteration 15/164: Loss = 1.5865\n",
      "Epoch 50/50, Train iteration 16/164: Loss = 1.5890\n",
      "Epoch 50/50, Train iteration 17/164: Loss = 1.5398\n",
      "Epoch 50/50, Train iteration 18/164: Loss = 1.5741\n",
      "Epoch 50/50, Train iteration 19/164: Loss = 1.5220\n",
      "Epoch 50/50, Train iteration 20/164: Loss = 1.5322\n",
      "Epoch 50/50, Train iteration 21/164: Loss = 1.5718\n",
      "Epoch 50/50, Train iteration 22/164: Loss = 1.5709\n",
      "Epoch 50/50, Train iteration 23/164: Loss = 1.4986\n",
      "Epoch 50/50, Train iteration 24/164: Loss = 1.5624\n",
      "Epoch 50/50, Train iteration 25/164: Loss = 1.5851\n",
      "Epoch 50/50, Train iteration 26/164: Loss = 1.5606\n",
      "Epoch 50/50, Train iteration 27/164: Loss = 1.5975\n",
      "Epoch 50/50, Train iteration 28/164: Loss = 1.5379\n",
      "Epoch 50/50, Train iteration 29/164: Loss = 1.5454\n",
      "Epoch 50/50, Train iteration 30/164: Loss = 1.5666\n",
      "Epoch 50/50, Train iteration 31/164: Loss = 1.5092\n",
      "Epoch 50/50, Train iteration 32/164: Loss = 1.5038\n",
      "Epoch 50/50, Train iteration 33/164: Loss = 1.5595\n",
      "Epoch 50/50, Train iteration 34/164: Loss = 1.5457\n",
      "Epoch 50/50, Train iteration 35/164: Loss = 1.5755\n",
      "Epoch 50/50, Train iteration 36/164: Loss = 1.5742\n",
      "Epoch 50/50, Train iteration 37/164: Loss = 1.5523\n",
      "Epoch 50/50, Train iteration 38/164: Loss = 1.4984\n",
      "Epoch 50/50, Train iteration 39/164: Loss = 1.5480\n",
      "Epoch 50/50, Train iteration 40/164: Loss = 1.5220\n",
      "Epoch 50/50, Train iteration 41/164: Loss = 1.4861\n",
      "Epoch 50/50, Train iteration 42/164: Loss = 1.5406\n",
      "Epoch 50/50, Train iteration 43/164: Loss = 1.5241\n",
      "Epoch 50/50, Train iteration 44/164: Loss = 1.5596\n",
      "Epoch 50/50, Train iteration 45/164: Loss = 1.5185\n",
      "Epoch 50/50, Train iteration 46/164: Loss = 1.5857\n",
      "Epoch 50/50, Train iteration 47/164: Loss = 1.5305\n",
      "Epoch 50/50, Train iteration 48/164: Loss = 1.4995\n",
      "Epoch 50/50, Train iteration 49/164: Loss = 1.5170\n",
      "Epoch 50/50, Train iteration 50/164: Loss = 1.6025\n",
      "Epoch 50/50, Train iteration 51/164: Loss = 1.4877\n",
      "Epoch 50/50, Train iteration 52/164: Loss = 1.4921\n",
      "Epoch 50/50, Train iteration 53/164: Loss = 1.5477\n",
      "Epoch 50/50, Train iteration 54/164: Loss = 1.5582\n",
      "Epoch 50/50, Train iteration 55/164: Loss = 1.4681\n",
      "Epoch 50/50, Train iteration 56/164: Loss = 1.5846\n",
      "Epoch 50/50, Train iteration 57/164: Loss = 1.5596\n",
      "Epoch 50/50, Train iteration 58/164: Loss = 1.6081\n",
      "Epoch 50/50, Train iteration 59/164: Loss = 1.5816\n",
      "Epoch 50/50, Train iteration 60/164: Loss = 1.4960\n",
      "Epoch 50/50, Train iteration 61/164: Loss = 1.5496\n",
      "Epoch 50/50, Train iteration 62/164: Loss = 1.5395\n",
      "Epoch 50/50, Train iteration 63/164: Loss = 1.5992\n",
      "Epoch 50/50, Train iteration 64/164: Loss = 1.5648\n",
      "Epoch 50/50, Train iteration 65/164: Loss = 1.5513\n",
      "Epoch 50/50, Train iteration 66/164: Loss = 1.4779\n",
      "Epoch 50/50, Train iteration 67/164: Loss = 1.4746\n",
      "Epoch 50/50, Train iteration 68/164: Loss = 1.4789\n",
      "Epoch 50/50, Train iteration 69/164: Loss = 1.5543\n",
      "Epoch 50/50, Train iteration 70/164: Loss = 1.5345\n",
      "Epoch 50/50, Train iteration 71/164: Loss = 1.5688\n",
      "Epoch 50/50, Train iteration 72/164: Loss = 1.6018\n",
      "Epoch 50/50, Train iteration 73/164: Loss = 1.5749\n",
      "Epoch 50/50, Train iteration 74/164: Loss = 1.5222\n",
      "Epoch 50/50, Train iteration 75/164: Loss = 1.4364\n",
      "Epoch 50/50, Train iteration 76/164: Loss = 1.5398\n",
      "Epoch 50/50, Train iteration 77/164: Loss = 1.5669\n",
      "Epoch 50/50, Train iteration 78/164: Loss = 1.5684\n",
      "Epoch 50/50, Train iteration 79/164: Loss = 1.5493\n",
      "Epoch 50/50, Train iteration 80/164: Loss = 1.5620\n",
      "Epoch 50/50, Train iteration 81/164: Loss = 1.5379\n",
      "Epoch 50/50, Train iteration 82/164: Loss = 1.5457\n",
      "Epoch 50/50, Train iteration 83/164: Loss = 1.5262\n",
      "Epoch 50/50, Train iteration 84/164: Loss = 1.4936\n",
      "Epoch 50/50, Train iteration 85/164: Loss = 1.5715\n",
      "Epoch 50/50, Train iteration 86/164: Loss = 1.4387\n",
      "Epoch 50/50, Train iteration 87/164: Loss = 1.5896\n",
      "Epoch 50/50, Train iteration 88/164: Loss = 1.5773\n",
      "Epoch 50/50, Train iteration 89/164: Loss = 1.5608\n",
      "Epoch 50/50, Train iteration 90/164: Loss = 1.4786\n",
      "Epoch 50/50, Train iteration 91/164: Loss = 1.5607\n",
      "Epoch 50/50, Train iteration 92/164: Loss = 1.5280\n",
      "Epoch 50/50, Train iteration 93/164: Loss = 1.4837\n",
      "Epoch 50/50, Train iteration 94/164: Loss = 1.5687\n",
      "Epoch 50/50, Train iteration 95/164: Loss = 1.5048\n",
      "Epoch 50/50, Train iteration 96/164: Loss = 1.5712\n",
      "Epoch 50/50, Train iteration 97/164: Loss = 1.5808\n",
      "Epoch 50/50, Train iteration 98/164: Loss = 1.4920\n",
      "Epoch 50/50, Train iteration 99/164: Loss = 1.4637\n",
      "Epoch 50/50, Train iteration 100/164: Loss = 1.5188\n",
      "Epoch 50/50, Train iteration 101/164: Loss = 1.5156\n",
      "Epoch 50/50, Train iteration 102/164: Loss = 1.5713\n",
      "Epoch 50/50, Train iteration 103/164: Loss = 1.5090\n",
      "Epoch 50/50, Train iteration 104/164: Loss = 1.5309\n",
      "Epoch 50/50, Train iteration 105/164: Loss = 1.5874\n",
      "Epoch 50/50, Train iteration 106/164: Loss = 1.5163\n",
      "Epoch 50/50, Train iteration 107/164: Loss = 1.5106\n",
      "Epoch 50/50, Train iteration 108/164: Loss = 1.5379\n",
      "Epoch 50/50, Train iteration 109/164: Loss = 1.5865\n",
      "Epoch 50/50, Train iteration 110/164: Loss = 1.5347\n",
      "Epoch 50/50, Train iteration 111/164: Loss = 1.4976\n",
      "Epoch 50/50, Train iteration 112/164: Loss = 1.5254\n",
      "Epoch 50/50, Train iteration 113/164: Loss = 1.4619\n",
      "Epoch 50/50, Train iteration 114/164: Loss = 1.4466\n",
      "Epoch 50/50, Train iteration 115/164: Loss = 1.5413\n",
      "Epoch 50/50, Train iteration 116/164: Loss = 1.4805\n",
      "Epoch 50/50, Train iteration 117/164: Loss = 1.5257\n",
      "Epoch 50/50, Train iteration 118/164: Loss = 1.5833\n",
      "Epoch 50/50, Train iteration 119/164: Loss = 1.5374\n",
      "Epoch 50/50, Train iteration 120/164: Loss = 1.4764\n",
      "Epoch 50/50, Train iteration 121/164: Loss = 1.5354\n",
      "Epoch 50/50, Train iteration 122/164: Loss = 1.4444\n",
      "Epoch 50/50, Train iteration 123/164: Loss = 1.5336\n",
      "Epoch 50/50, Train iteration 124/164: Loss = 1.5146\n",
      "Epoch 50/50, Train iteration 125/164: Loss = 1.4833\n",
      "Epoch 50/50, Train iteration 126/164: Loss = 1.5562\n",
      "Epoch 50/50, Train iteration 127/164: Loss = 1.5978\n",
      "Epoch 50/50, Train iteration 128/164: Loss = 1.4910\n",
      "Epoch 50/50, Train iteration 129/164: Loss = 1.5557\n",
      "Epoch 50/50, Train iteration 130/164: Loss = 1.5439\n",
      "Epoch 50/50, Train iteration 131/164: Loss = 1.5942\n",
      "Epoch 50/50, Train iteration 132/164: Loss = 1.5142\n",
      "Epoch 50/50, Train iteration 133/164: Loss = 1.5484\n",
      "Epoch 50/50, Train iteration 134/164: Loss = 1.5224\n",
      "Epoch 50/50, Train iteration 135/164: Loss = 1.5194\n",
      "Epoch 50/50, Train iteration 136/164: Loss = 1.5569\n",
      "Epoch 50/50, Train iteration 137/164: Loss = 1.5113\n",
      "Epoch 50/50, Train iteration 138/164: Loss = 1.5260\n",
      "Epoch 50/50, Train iteration 139/164: Loss = 1.5816\n",
      "Epoch 50/50, Train iteration 140/164: Loss = 1.5064\n",
      "Epoch 50/50, Train iteration 141/164: Loss = 1.5383\n",
      "Epoch 50/50, Train iteration 142/164: Loss = 1.5570\n",
      "Epoch 50/50, Train iteration 143/164: Loss = 1.4913\n",
      "Epoch 50/50, Train iteration 144/164: Loss = 1.5594\n",
      "Epoch 50/50, Train iteration 145/164: Loss = 1.5296\n",
      "Epoch 50/50, Train iteration 146/164: Loss = 1.5623\n",
      "Epoch 50/50, Train iteration 147/164: Loss = 1.5035\n",
      "Epoch 50/50, Train iteration 148/164: Loss = 1.4760\n",
      "Epoch 50/50, Train iteration 149/164: Loss = 1.5536\n",
      "Epoch 50/50, Train iteration 150/164: Loss = 1.5713\n",
      "Epoch 50/50, Train iteration 151/164: Loss = 1.5463\n",
      "Epoch 50/50, Train iteration 152/164: Loss = 1.4726\n",
      "Epoch 50/50, Train iteration 153/164: Loss = 1.6001\n",
      "Epoch 50/50, Train iteration 154/164: Loss = 1.5207\n",
      "Epoch 50/50, Train iteration 155/164: Loss = 1.5197\n",
      "Epoch 50/50, Train iteration 156/164: Loss = 1.5161\n",
      "Epoch 50/50, Train iteration 157/164: Loss = 1.5188\n",
      "Epoch 50/50, Train iteration 158/164: Loss = 1.5539\n",
      "Epoch 50/50, Train iteration 159/164: Loss = 1.5566\n",
      "Epoch 50/50, Train iteration 160/164: Loss = 1.5361\n",
      "Epoch 50/50, Train iteration 161/164: Loss = 1.5995\n",
      "Epoch 50/50, Train iteration 162/164: Loss = 1.5463\n",
      "Epoch 50/50, Train iteration 163/164: Loss = 1.5679\n",
      "Epoch 50/50, Train iteration 164/164: Loss = 1.2337\n",
      "Epoch 50/50, Val iteration 1/27: Loss = 1.6126\n",
      "Epoch 50/50, Val iteration 2/27: Loss = 1.6205\n",
      "Epoch 50/50, Val iteration 3/27: Loss = 1.5915\n",
      "Epoch 50/50, Val iteration 4/27: Loss = 1.5950\n",
      "Epoch 50/50, Val iteration 5/27: Loss = 1.6150\n",
      "Epoch 50/50, Val iteration 6/27: Loss = 1.5812\n",
      "Epoch 50/50, Val iteration 7/27: Loss = 1.5547\n",
      "Epoch 50/50, Val iteration 8/27: Loss = 1.6138\n",
      "Epoch 50/50, Val iteration 9/27: Loss = 1.5869\n",
      "Epoch 50/50, Val iteration 10/27: Loss = 1.5778\n",
      "Epoch 50/50, Val iteration 11/27: Loss = 1.6002\n",
      "Epoch 50/50, Val iteration 12/27: Loss = 1.5652\n",
      "Epoch 50/50, Val iteration 13/27: Loss = 1.5706\n",
      "Epoch 50/50, Val iteration 14/27: Loss = 1.5444\n",
      "Epoch 50/50, Val iteration 15/27: Loss = 1.5897\n",
      "Epoch 50/50, Val iteration 16/27: Loss = 1.5804\n",
      "Epoch 50/50, Val iteration 17/27: Loss = 1.5942\n",
      "Epoch 50/50, Val iteration 18/27: Loss = 1.5562\n",
      "Epoch 50/50, Val iteration 19/27: Loss = 1.5769\n",
      "Epoch 50/50, Val iteration 20/27: Loss = 1.5972\n",
      "Epoch 50/50, Val iteration 21/27: Loss = 1.5868\n",
      "Epoch 50/50, Val iteration 22/27: Loss = 1.6040\n",
      "Epoch 50/50, Val iteration 23/27: Loss = 1.4852\n",
      "Epoch 50/50, Val iteration 24/27: Loss = 1.5583\n",
      "Epoch 50/50, Val iteration 25/27: Loss = 1.5854\n",
      "Epoch 50/50, Val iteration 26/27: Loss = 1.5933\n",
      "Epoch 50/50, Val iteration 27/27: Loss = 1.6053\n",
      "Epoch 50/50: Train Loss = 1.5366, Val Loss = 1.5830\n",
      "Current learning rate: 6.561e-09\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "# Move model to GPU if available\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "train_loss_history, val_loss_history = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    for iteration, (data, labels) in enumerate(train_dataloader):\n",
    "        # Unpacking of batch\n",
    "        his_input_title, pred_input_title, timestamps = data\n",
    "\n",
    "        # Move data to device\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(pred_input_title, his_input_title)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}, Train iteration {iteration + 1}/{len(train_dataloader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for iteration, (data, labels) in enumerate(val_dataloader):\n",
    "            his_input_title, pred_input_title, timestamps = data\n",
    "\n",
    "            his_input_title = his_input_title.to(device)\n",
    "            pred_input_title = pred_input_title.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(pred_input_title, his_input_title)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}, Val iteration {iteration + 1}/{len(val_dataloader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    val_loss /= len(val_dataloader)\n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    # Log current learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"Current learning rate: {param_group['lr']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(val_loss_history, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test iteration 1/1265: Loss = 1.6424\n",
      "Test iteration 2/1265: Loss = 1.6724\n",
      "Test iteration 3/1265: Loss = 1.6204\n",
      "Test iteration 4/1265: Loss = 1.6005\n",
      "Test iteration 5/1265: Loss = 1.7009\n",
      "Test iteration 6/1265: Loss = 1.5755\n",
      "Test iteration 7/1265: Loss = 1.6895\n",
      "Test iteration 8/1265: Loss = 1.6632\n",
      "Test iteration 9/1265: Loss = 1.6921\n",
      "Test iteration 10/1265: Loss = 1.6146\n",
      "Test iteration 11/1265: Loss = 1.5995\n",
      "Test iteration 12/1265: Loss = 1.5692\n",
      "Test iteration 13/1265: Loss = 1.6395\n",
      "Test iteration 14/1265: Loss = 1.5325\n",
      "Test iteration 15/1265: Loss = 1.5996\n",
      "Test iteration 16/1265: Loss = 1.5587\n",
      "Test iteration 17/1265: Loss = 1.6206\n",
      "Test iteration 18/1265: Loss = 1.6738\n",
      "Test iteration 19/1265: Loss = 1.6200\n",
      "Test iteration 20/1265: Loss = 1.6828\n",
      "Test iteration 21/1265: Loss = 1.6760\n",
      "Test iteration 22/1265: Loss = 1.5057\n",
      "Test iteration 23/1265: Loss = 1.7288\n",
      "Test iteration 24/1265: Loss = 1.6681\n",
      "Test iteration 25/1265: Loss = 1.5692\n",
      "Test iteration 26/1265: Loss = 1.6199\n",
      "Test iteration 27/1265: Loss = 1.4089\n",
      "Test iteration 28/1265: Loss = 1.5552\n",
      "Test iteration 29/1265: Loss = 1.7173\n",
      "Test iteration 30/1265: Loss = 1.5854\n",
      "Test iteration 31/1265: Loss = 1.4690\n",
      "Test iteration 32/1265: Loss = 1.3733\n",
      "Test iteration 33/1265: Loss = 1.5506\n",
      "Test iteration 34/1265: Loss = 1.5498\n",
      "Test iteration 35/1265: Loss = 1.6281\n",
      "Test iteration 36/1265: Loss = 1.5407\n",
      "Test iteration 37/1265: Loss = 1.7185\n",
      "Test iteration 38/1265: Loss = 1.4463\n",
      "Test iteration 39/1265: Loss = 1.6839\n",
      "Test iteration 40/1265: Loss = 1.6321\n",
      "Test iteration 41/1265: Loss = 1.5171\n",
      "Test iteration 42/1265: Loss = 1.5935\n",
      "Test iteration 43/1265: Loss = 1.5833\n",
      "Test iteration 44/1265: Loss = 1.4529\n",
      "Test iteration 45/1265: Loss = 1.7142\n",
      "Test iteration 46/1265: Loss = 1.6044\n",
      "Test iteration 47/1265: Loss = 1.5743\n",
      "Test iteration 48/1265: Loss = 1.6435\n",
      "Test iteration 49/1265: Loss = 1.6105\n",
      "Test iteration 50/1265: Loss = 1.4166\n",
      "Test iteration 51/1265: Loss = 1.6629\n",
      "Test iteration 52/1265: Loss = 1.6633\n",
      "Test iteration 53/1265: Loss = 1.6342\n",
      "Test iteration 54/1265: Loss = 1.6665\n",
      "Test iteration 55/1265: Loss = 1.6811\n",
      "Test iteration 56/1265: Loss = 1.4202\n",
      "Test iteration 57/1265: Loss = 1.6279\n",
      "Test iteration 58/1265: Loss = 1.3805\n",
      "Test iteration 59/1265: Loss = 1.6137\n",
      "Test iteration 60/1265: Loss = 1.6881\n",
      "Test iteration 61/1265: Loss = 1.5948\n",
      "Test iteration 62/1265: Loss = 1.5792\n",
      "Test iteration 63/1265: Loss = 1.7025\n",
      "Test iteration 64/1265: Loss = 1.6742\n",
      "Test iteration 65/1265: Loss = 1.6339\n",
      "Test iteration 66/1265: Loss = 1.5211\n",
      "Test iteration 67/1265: Loss = 1.7720\n",
      "Test iteration 68/1265: Loss = 1.5598\n",
      "Test iteration 69/1265: Loss = 1.5460\n",
      "Test iteration 70/1265: Loss = 1.5420\n",
      "Test iteration 71/1265: Loss = 1.5036\n",
      "Test iteration 72/1265: Loss = 1.7385\n",
      "Test iteration 73/1265: Loss = 1.5534\n",
      "Test iteration 74/1265: Loss = 1.5483\n",
      "Test iteration 75/1265: Loss = 1.5599\n",
      "Test iteration 76/1265: Loss = 1.6553\n",
      "Test iteration 77/1265: Loss = 1.5468\n",
      "Test iteration 78/1265: Loss = 1.5209\n",
      "Test iteration 79/1265: Loss = 1.7396\n",
      "Test iteration 80/1265: Loss = 1.4923\n",
      "Test iteration 81/1265: Loss = 1.5128\n",
      "Test iteration 82/1265: Loss = 1.4960\n",
      "Test iteration 83/1265: Loss = 1.5884\n",
      "Test iteration 84/1265: Loss = 1.6213\n",
      "Test iteration 85/1265: Loss = 1.6472\n",
      "Test iteration 86/1265: Loss = 1.7441\n",
      "Test iteration 87/1265: Loss = 1.7043\n",
      "Test iteration 88/1265: Loss = 1.6165\n",
      "Test iteration 89/1265: Loss = 1.5704\n",
      "Test iteration 90/1265: Loss = 1.6192\n",
      "Test iteration 91/1265: Loss = 1.5964\n",
      "Test iteration 92/1265: Loss = 1.5478\n",
      "Test iteration 93/1265: Loss = 1.6249\n",
      "Test iteration 94/1265: Loss = 1.6007\n",
      "Test iteration 95/1265: Loss = 1.6796\n",
      "Test iteration 96/1265: Loss = 1.6373\n",
      "Test iteration 97/1265: Loss = 1.6475\n",
      "Test iteration 98/1265: Loss = 1.6452\n",
      "Test iteration 99/1265: Loss = 1.4535\n",
      "Test iteration 100/1265: Loss = 1.6929\n",
      "Test iteration 101/1265: Loss = 1.5226\n",
      "Test iteration 102/1265: Loss = 1.5846\n",
      "Test iteration 103/1265: Loss = 1.6367\n",
      "Test iteration 104/1265: Loss = 1.5536\n",
      "Test iteration 105/1265: Loss = 1.6671\n",
      "Test iteration 106/1265: Loss = 1.5624\n",
      "Test iteration 107/1265: Loss = 1.6957\n",
      "Test iteration 108/1265: Loss = 1.6332\n",
      "Test iteration 109/1265: Loss = 1.6764\n",
      "Test iteration 110/1265: Loss = 1.5312\n",
      "Test iteration 111/1265: Loss = 1.6130\n",
      "Test iteration 112/1265: Loss = 1.7319\n",
      "Test iteration 113/1265: Loss = 1.5720\n",
      "Test iteration 114/1265: Loss = 1.6781\n",
      "Test iteration 115/1265: Loss = 1.6727\n",
      "Test iteration 116/1265: Loss = 1.4246\n",
      "Test iteration 117/1265: Loss = 1.6035\n",
      "Test iteration 118/1265: Loss = 1.5736\n",
      "Test iteration 119/1265: Loss = 1.5810\n",
      "Test iteration 120/1265: Loss = 1.4976\n",
      "Test iteration 121/1265: Loss = 1.6047\n",
      "Test iteration 122/1265: Loss = 1.5921\n",
      "Test iteration 123/1265: Loss = 1.5357\n",
      "Test iteration 124/1265: Loss = 1.6055\n",
      "Test iteration 125/1265: Loss = 1.7080\n",
      "Test iteration 126/1265: Loss = 1.4564\n",
      "Test iteration 127/1265: Loss = 1.6988\n",
      "Test iteration 128/1265: Loss = 1.5667\n",
      "Test iteration 129/1265: Loss = 1.4295\n",
      "Test iteration 130/1265: Loss = 1.5640\n",
      "Test iteration 131/1265: Loss = 1.6142\n",
      "Test iteration 132/1265: Loss = 1.5422\n",
      "Test iteration 133/1265: Loss = 1.6619\n",
      "Test iteration 134/1265: Loss = 1.6881\n",
      "Test iteration 135/1265: Loss = 1.6420\n",
      "Test iteration 136/1265: Loss = 1.4720\n",
      "Test iteration 137/1265: Loss = 1.6562\n",
      "Test iteration 138/1265: Loss = 1.5431\n",
      "Test iteration 139/1265: Loss = 1.6610\n",
      "Test iteration 140/1265: Loss = 1.6565\n",
      "Test iteration 141/1265: Loss = 1.6092\n",
      "Test iteration 142/1265: Loss = 1.5841\n",
      "Test iteration 143/1265: Loss = 1.5146\n",
      "Test iteration 144/1265: Loss = 1.6364\n",
      "Test iteration 145/1265: Loss = 1.5920\n",
      "Test iteration 146/1265: Loss = 1.3653\n",
      "Test iteration 147/1265: Loss = 1.5838\n",
      "Test iteration 148/1265: Loss = 1.4918\n",
      "Test iteration 149/1265: Loss = 1.6741\n",
      "Test iteration 150/1265: Loss = 1.6645\n",
      "Test iteration 151/1265: Loss = 1.6157\n",
      "Test iteration 152/1265: Loss = 1.5312\n",
      "Test iteration 153/1265: Loss = 1.6204\n",
      "Test iteration 154/1265: Loss = 1.6313\n",
      "Test iteration 155/1265: Loss = 1.6941\n",
      "Test iteration 156/1265: Loss = 1.6382\n",
      "Test iteration 157/1265: Loss = 1.5901\n",
      "Test iteration 158/1265: Loss = 1.6754\n",
      "Test iteration 159/1265: Loss = 1.5565\n",
      "Test iteration 160/1265: Loss = 1.6287\n",
      "Test iteration 161/1265: Loss = 1.5231\n",
      "Test iteration 162/1265: Loss = 1.5498\n",
      "Test iteration 163/1265: Loss = 1.5201\n",
      "Test iteration 164/1265: Loss = 1.5142\n",
      "Test iteration 165/1265: Loss = 1.4805\n",
      "Test iteration 166/1265: Loss = 1.5403\n",
      "Test iteration 167/1265: Loss = 1.7000\n",
      "Test iteration 168/1265: Loss = 1.5507\n",
      "Test iteration 169/1265: Loss = 1.7653\n",
      "Test iteration 170/1265: Loss = 1.5802\n",
      "Test iteration 171/1265: Loss = 1.7030\n",
      "Test iteration 172/1265: Loss = 1.6345\n",
      "Test iteration 173/1265: Loss = 1.4653\n",
      "Test iteration 174/1265: Loss = 1.6629\n",
      "Test iteration 175/1265: Loss = 1.4492\n",
      "Test iteration 176/1265: Loss = 1.6675\n",
      "Test iteration 177/1265: Loss = 1.6731\n",
      "Test iteration 178/1265: Loss = 1.5760\n",
      "Test iteration 179/1265: Loss = 1.6696\n",
      "Test iteration 180/1265: Loss = 1.7202\n",
      "Test iteration 181/1265: Loss = 1.6945\n",
      "Test iteration 182/1265: Loss = 1.7043\n",
      "Test iteration 183/1265: Loss = 1.4913\n",
      "Test iteration 184/1265: Loss = 1.7065\n",
      "Test iteration 185/1265: Loss = 1.7146\n",
      "Test iteration 186/1265: Loss = 1.6478\n",
      "Test iteration 187/1265: Loss = 1.5658\n",
      "Test iteration 188/1265: Loss = 1.7587\n",
      "Test iteration 189/1265: Loss = 1.6536\n",
      "Test iteration 190/1265: Loss = 1.5608\n",
      "Test iteration 191/1265: Loss = 1.6678\n",
      "Test iteration 192/1265: Loss = 1.4805\n",
      "Test iteration 193/1265: Loss = 1.5998\n",
      "Test iteration 194/1265: Loss = 1.6671\n",
      "Test iteration 195/1265: Loss = 1.7119\n",
      "Test iteration 196/1265: Loss = 1.5116\n",
      "Test iteration 197/1265: Loss = 1.5333\n",
      "Test iteration 198/1265: Loss = 1.6157\n",
      "Test iteration 199/1265: Loss = 1.6229\n",
      "Test iteration 200/1265: Loss = 1.6826\n",
      "Test iteration 201/1265: Loss = 1.6736\n",
      "Test iteration 202/1265: Loss = 1.5435\n",
      "Test iteration 203/1265: Loss = 1.6027\n",
      "Test iteration 204/1265: Loss = 1.5763\n",
      "Test iteration 205/1265: Loss = 1.7060\n",
      "Test iteration 206/1265: Loss = 1.5429\n",
      "Test iteration 207/1265: Loss = 1.5549\n",
      "Test iteration 208/1265: Loss = 1.6465\n",
      "Test iteration 209/1265: Loss = 1.6446\n",
      "Test iteration 210/1265: Loss = 1.7026\n",
      "Test iteration 211/1265: Loss = 1.7027\n",
      "Test iteration 212/1265: Loss = 1.6470\n",
      "Test iteration 213/1265: Loss = 1.6693\n",
      "Test iteration 214/1265: Loss = 1.5462\n",
      "Test iteration 215/1265: Loss = 1.6117\n",
      "Test iteration 216/1265: Loss = 1.5139\n",
      "Test iteration 217/1265: Loss = 1.7316\n",
      "Test iteration 218/1265: Loss = 1.5955\n",
      "Test iteration 219/1265: Loss = 1.6372\n",
      "Test iteration 220/1265: Loss = 1.5260\n",
      "Test iteration 221/1265: Loss = 1.6127\n",
      "Test iteration 222/1265: Loss = 1.6558\n",
      "Test iteration 223/1265: Loss = 1.7097\n",
      "Test iteration 224/1265: Loss = 1.7186\n",
      "Test iteration 225/1265: Loss = 1.5140\n",
      "Test iteration 226/1265: Loss = 1.6692\n",
      "Test iteration 227/1265: Loss = 1.6254\n",
      "Test iteration 228/1265: Loss = 1.6252\n",
      "Test iteration 229/1265: Loss = 1.6642\n",
      "Test iteration 230/1265: Loss = 1.6078\n",
      "Test iteration 231/1265: Loss = 1.6085\n",
      "Test iteration 232/1265: Loss = 1.6874\n",
      "Test iteration 233/1265: Loss = 1.5578\n",
      "Test iteration 234/1265: Loss = 1.5276\n",
      "Test iteration 235/1265: Loss = 1.4324\n",
      "Test iteration 236/1265: Loss = 1.7224\n",
      "Test iteration 237/1265: Loss = 1.5423\n",
      "Test iteration 238/1265: Loss = 1.4428\n",
      "Test iteration 239/1265: Loss = 1.5207\n",
      "Test iteration 240/1265: Loss = 1.7511\n",
      "Test iteration 241/1265: Loss = 1.5359\n",
      "Test iteration 242/1265: Loss = 1.7681\n",
      "Test iteration 243/1265: Loss = 1.6181\n",
      "Test iteration 244/1265: Loss = 1.5389\n",
      "Test iteration 245/1265: Loss = 1.6526\n",
      "Test iteration 246/1265: Loss = 1.6077\n",
      "Test iteration 247/1265: Loss = 1.4914\n",
      "Test iteration 248/1265: Loss = 1.5514\n",
      "Test iteration 249/1265: Loss = 1.5932\n",
      "Test iteration 250/1265: Loss = 1.5901\n",
      "Test iteration 251/1265: Loss = 1.5741\n",
      "Test iteration 252/1265: Loss = 1.5016\n",
      "Test iteration 253/1265: Loss = 1.5479\n",
      "Test iteration 254/1265: Loss = 1.5117\n",
      "Test iteration 255/1265: Loss = 1.6417\n",
      "Test iteration 256/1265: Loss = 1.5320\n",
      "Test iteration 257/1265: Loss = 1.5971\n",
      "Test iteration 258/1265: Loss = 1.6146\n",
      "Test iteration 259/1265: Loss = 1.4988\n",
      "Test iteration 260/1265: Loss = 1.5022\n",
      "Test iteration 261/1265: Loss = 1.4746\n",
      "Test iteration 262/1265: Loss = 1.4385\n",
      "Test iteration 263/1265: Loss = 1.5297\n",
      "Test iteration 264/1265: Loss = 1.5313\n",
      "Test iteration 265/1265: Loss = 1.5294\n",
      "Test iteration 266/1265: Loss = 1.6525\n",
      "Test iteration 267/1265: Loss = 1.5551\n",
      "Test iteration 268/1265: Loss = 1.6053\n",
      "Test iteration 269/1265: Loss = 1.4630\n",
      "Test iteration 270/1265: Loss = 1.5627\n",
      "Test iteration 271/1265: Loss = 1.5065\n",
      "Test iteration 272/1265: Loss = 1.5110\n",
      "Test iteration 273/1265: Loss = 1.6475\n",
      "Test iteration 274/1265: Loss = 1.6529\n",
      "Test iteration 275/1265: Loss = 1.5974\n",
      "Test iteration 276/1265: Loss = 1.5394\n",
      "Test iteration 277/1265: Loss = 1.5137\n",
      "Test iteration 278/1265: Loss = 1.5793\n",
      "Test iteration 279/1265: Loss = 1.3764\n",
      "Test iteration 280/1265: Loss = 1.6806\n",
      "Test iteration 281/1265: Loss = 1.5351\n",
      "Test iteration 282/1265: Loss = 1.5799\n",
      "Test iteration 283/1265: Loss = 1.5182\n",
      "Test iteration 284/1265: Loss = 1.4869\n",
      "Test iteration 285/1265: Loss = 1.6718\n",
      "Test iteration 286/1265: Loss = 1.4771\n",
      "Test iteration 287/1265: Loss = 1.5911\n",
      "Test iteration 288/1265: Loss = 1.6802\n",
      "Test iteration 289/1265: Loss = 1.5560\n",
      "Test iteration 290/1265: Loss = 1.5452\n",
      "Test iteration 291/1265: Loss = 1.6042\n",
      "Test iteration 292/1265: Loss = 1.5194\n",
      "Test iteration 293/1265: Loss = 1.6681\n",
      "Test iteration 294/1265: Loss = 1.5547\n",
      "Test iteration 295/1265: Loss = 1.4934\n",
      "Test iteration 296/1265: Loss = 1.6289\n",
      "Test iteration 297/1265: Loss = 1.6347\n",
      "Test iteration 298/1265: Loss = 1.6731\n",
      "Test iteration 299/1265: Loss = 1.6099\n",
      "Test iteration 300/1265: Loss = 1.4936\n",
      "Test iteration 301/1265: Loss = 1.5746\n",
      "Test iteration 302/1265: Loss = 1.5149\n",
      "Test iteration 303/1265: Loss = 1.3977\n",
      "Test iteration 304/1265: Loss = 1.6433\n",
      "Test iteration 305/1265: Loss = 1.5749\n",
      "Test iteration 306/1265: Loss = 1.6536\n",
      "Test iteration 307/1265: Loss = 1.7467\n",
      "Test iteration 308/1265: Loss = 1.6622\n",
      "Test iteration 309/1265: Loss = 1.5746\n",
      "Test iteration 310/1265: Loss = 1.6067\n",
      "Test iteration 311/1265: Loss = 1.5071\n",
      "Test iteration 312/1265: Loss = 1.4827\n",
      "Test iteration 313/1265: Loss = 1.6386\n",
      "Test iteration 314/1265: Loss = 1.6670\n",
      "Test iteration 315/1265: Loss = 1.5984\n",
      "Test iteration 316/1265: Loss = 1.5352\n",
      "Test iteration 317/1265: Loss = 1.5719\n",
      "Test iteration 318/1265: Loss = 1.6054\n",
      "Test iteration 319/1265: Loss = 1.5619\n",
      "Test iteration 320/1265: Loss = 1.6831\n",
      "Test iteration 321/1265: Loss = 1.5209\n",
      "Test iteration 322/1265: Loss = 1.7282\n",
      "Test iteration 323/1265: Loss = 1.6772\n",
      "Test iteration 324/1265: Loss = 1.5970\n",
      "Test iteration 325/1265: Loss = 1.6873\n",
      "Test iteration 326/1265: Loss = 1.6370\n",
      "Test iteration 327/1265: Loss = 1.6923\n",
      "Test iteration 328/1265: Loss = 1.6322\n",
      "Test iteration 329/1265: Loss = 1.6508\n",
      "Test iteration 330/1265: Loss = 1.4323\n",
      "Test iteration 331/1265: Loss = 1.7233\n",
      "Test iteration 332/1265: Loss = 1.6647\n",
      "Test iteration 333/1265: Loss = 1.6700\n",
      "Test iteration 334/1265: Loss = 1.6224\n",
      "Test iteration 335/1265: Loss = 1.6146\n",
      "Test iteration 336/1265: Loss = 1.5518\n",
      "Test iteration 337/1265: Loss = 1.6003\n",
      "Test iteration 338/1265: Loss = 1.5635\n",
      "Test iteration 339/1265: Loss = 1.6695\n",
      "Test iteration 340/1265: Loss = 1.6398\n",
      "Test iteration 341/1265: Loss = 1.5773\n",
      "Test iteration 342/1265: Loss = 1.7038\n",
      "Test iteration 343/1265: Loss = 1.6890\n",
      "Test iteration 344/1265: Loss = 1.6073\n",
      "Test iteration 345/1265: Loss = 1.5404\n",
      "Test iteration 346/1265: Loss = 1.6624\n",
      "Test iteration 347/1265: Loss = 1.5817\n",
      "Test iteration 348/1265: Loss = 1.5675\n",
      "Test iteration 349/1265: Loss = 1.5876\n",
      "Test iteration 350/1265: Loss = 1.4682\n",
      "Test iteration 351/1265: Loss = 1.5573\n",
      "Test iteration 352/1265: Loss = 1.5972\n",
      "Test iteration 353/1265: Loss = 1.7125\n",
      "Test iteration 354/1265: Loss = 1.6159\n",
      "Test iteration 355/1265: Loss = 1.5983\n",
      "Test iteration 356/1265: Loss = 1.4897\n",
      "Test iteration 357/1265: Loss = 1.5894\n",
      "Test iteration 358/1265: Loss = 1.6070\n",
      "Test iteration 359/1265: Loss = 1.4242\n",
      "Test iteration 360/1265: Loss = 1.6257\n",
      "Test iteration 361/1265: Loss = 1.6295\n",
      "Test iteration 362/1265: Loss = 1.7032\n",
      "Test iteration 363/1265: Loss = 1.5551\n",
      "Test iteration 364/1265: Loss = 1.5031\n",
      "Test iteration 365/1265: Loss = 1.7184\n",
      "Test iteration 366/1265: Loss = 1.6118\n",
      "Test iteration 367/1265: Loss = 1.6904\n",
      "Test iteration 368/1265: Loss = 1.5735\n",
      "Test iteration 369/1265: Loss = 1.4850\n",
      "Test iteration 370/1265: Loss = 1.5006\n",
      "Test iteration 371/1265: Loss = 1.5886\n",
      "Test iteration 372/1265: Loss = 1.5689\n",
      "Test iteration 373/1265: Loss = 1.6900\n",
      "Test iteration 374/1265: Loss = 1.3165\n",
      "Test iteration 375/1265: Loss = 1.6026\n",
      "Test iteration 376/1265: Loss = 1.5147\n",
      "Test iteration 377/1265: Loss = 1.6320\n",
      "Test iteration 378/1265: Loss = 1.6433\n",
      "Test iteration 379/1265: Loss = 1.5792\n",
      "Test iteration 380/1265: Loss = 1.5764\n",
      "Test iteration 381/1265: Loss = 1.7644\n",
      "Test iteration 382/1265: Loss = 1.6709\n",
      "Test iteration 383/1265: Loss = 1.4706\n",
      "Test iteration 384/1265: Loss = 1.6673\n",
      "Test iteration 385/1265: Loss = 1.6249\n",
      "Test iteration 386/1265: Loss = 1.7285\n",
      "Test iteration 387/1265: Loss = 1.4545\n",
      "Test iteration 388/1265: Loss = 1.5763\n",
      "Test iteration 389/1265: Loss = 1.6838\n",
      "Test iteration 390/1265: Loss = 1.6531\n",
      "Test iteration 391/1265: Loss = 1.5699\n",
      "Test iteration 392/1265: Loss = 1.6366\n",
      "Test iteration 393/1265: Loss = 1.6175\n",
      "Test iteration 394/1265: Loss = 1.4947\n",
      "Test iteration 395/1265: Loss = 1.3718\n",
      "Test iteration 396/1265: Loss = 1.7261\n",
      "Test iteration 397/1265: Loss = 1.5088\n",
      "Test iteration 398/1265: Loss = 1.7012\n",
      "Test iteration 399/1265: Loss = 1.6628\n",
      "Test iteration 400/1265: Loss = 1.6341\n",
      "Test iteration 401/1265: Loss = 1.7788\n",
      "Test iteration 402/1265: Loss = 1.6312\n",
      "Test iteration 403/1265: Loss = 1.5751\n",
      "Test iteration 404/1265: Loss = 1.3880\n",
      "Test iteration 405/1265: Loss = 1.5673\n",
      "Test iteration 406/1265: Loss = 1.4704\n",
      "Test iteration 407/1265: Loss = 1.5549\n",
      "Test iteration 408/1265: Loss = 1.6010\n",
      "Test iteration 409/1265: Loss = 1.6721\n",
      "Test iteration 410/1265: Loss = 1.6465\n",
      "Test iteration 411/1265: Loss = 1.5959\n",
      "Test iteration 412/1265: Loss = 1.6056\n",
      "Test iteration 413/1265: Loss = 1.5593\n",
      "Test iteration 414/1265: Loss = 1.4043\n",
      "Test iteration 415/1265: Loss = 1.6066\n",
      "Test iteration 416/1265: Loss = 1.6849\n",
      "Test iteration 417/1265: Loss = 1.5341\n",
      "Test iteration 418/1265: Loss = 1.5549\n",
      "Test iteration 419/1265: Loss = 1.6837\n",
      "Test iteration 420/1265: Loss = 1.6328\n",
      "Test iteration 421/1265: Loss = 1.6774\n",
      "Test iteration 422/1265: Loss = 1.6563\n",
      "Test iteration 423/1265: Loss = 1.7597\n",
      "Test iteration 424/1265: Loss = 1.7076\n",
      "Test iteration 425/1265: Loss = 1.7428\n",
      "Test iteration 426/1265: Loss = 1.6724\n",
      "Test iteration 427/1265: Loss = 1.6116\n",
      "Test iteration 428/1265: Loss = 1.6300\n",
      "Test iteration 429/1265: Loss = 1.7631\n",
      "Test iteration 430/1265: Loss = 1.6539\n",
      "Test iteration 431/1265: Loss = 1.6472\n",
      "Test iteration 432/1265: Loss = 1.5508\n",
      "Test iteration 433/1265: Loss = 1.5098\n",
      "Test iteration 434/1265: Loss = 1.7302\n",
      "Test iteration 435/1265: Loss = 1.6589\n",
      "Test iteration 436/1265: Loss = 1.6824\n",
      "Test iteration 437/1265: Loss = 1.5154\n",
      "Test iteration 438/1265: Loss = 1.6165\n",
      "Test iteration 439/1265: Loss = 1.6106\n",
      "Test iteration 440/1265: Loss = 1.5922\n",
      "Test iteration 441/1265: Loss = 1.5200\n",
      "Test iteration 442/1265: Loss = 1.5357\n",
      "Test iteration 443/1265: Loss = 1.6050\n",
      "Test iteration 444/1265: Loss = 1.6324\n",
      "Test iteration 445/1265: Loss = 1.6692\n",
      "Test iteration 446/1265: Loss = 1.4687\n",
      "Test iteration 447/1265: Loss = 1.5854\n",
      "Test iteration 448/1265: Loss = 1.6516\n",
      "Test iteration 449/1265: Loss = 1.5903\n",
      "Test iteration 450/1265: Loss = 1.6061\n",
      "Test iteration 451/1265: Loss = 1.4935\n",
      "Test iteration 452/1265: Loss = 1.5457\n",
      "Test iteration 453/1265: Loss = 1.5088\n",
      "Test iteration 454/1265: Loss = 1.5416\n",
      "Test iteration 455/1265: Loss = 1.6337\n",
      "Test iteration 456/1265: Loss = 1.6620\n",
      "Test iteration 457/1265: Loss = 1.4189\n",
      "Test iteration 458/1265: Loss = 1.7138\n",
      "Test iteration 459/1265: Loss = 1.6447\n",
      "Test iteration 460/1265: Loss = 1.6680\n",
      "Test iteration 461/1265: Loss = 1.6660\n",
      "Test iteration 462/1265: Loss = 1.6026\n",
      "Test iteration 463/1265: Loss = 1.6182\n",
      "Test iteration 464/1265: Loss = 1.6422\n",
      "Test iteration 465/1265: Loss = 1.6439\n",
      "Test iteration 466/1265: Loss = 1.6364\n",
      "Test iteration 467/1265: Loss = 1.5138\n",
      "Test iteration 468/1265: Loss = 1.7006\n",
      "Test iteration 469/1265: Loss = 1.5433\n",
      "Test iteration 470/1265: Loss = 1.6986\n",
      "Test iteration 471/1265: Loss = 1.6570\n",
      "Test iteration 472/1265: Loss = 1.7120\n",
      "Test iteration 473/1265: Loss = 1.5086\n",
      "Test iteration 474/1265: Loss = 1.5803\n",
      "Test iteration 475/1265: Loss = 1.5067\n",
      "Test iteration 476/1265: Loss = 1.5893\n",
      "Test iteration 477/1265: Loss = 1.4665\n",
      "Test iteration 478/1265: Loss = 1.5320\n",
      "Test iteration 479/1265: Loss = 1.6265\n",
      "Test iteration 480/1265: Loss = 1.4155\n",
      "Test iteration 481/1265: Loss = 1.7129\n",
      "Test iteration 482/1265: Loss = 1.6096\n",
      "Test iteration 483/1265: Loss = 1.6407\n",
      "Test iteration 484/1265: Loss = 1.6643\n",
      "Test iteration 485/1265: Loss = 1.5386\n",
      "Test iteration 486/1265: Loss = 1.4626\n",
      "Test iteration 487/1265: Loss = 1.4185\n",
      "Test iteration 488/1265: Loss = 1.5161\n",
      "Test iteration 489/1265: Loss = 1.5862\n",
      "Test iteration 490/1265: Loss = 1.6770\n",
      "Test iteration 491/1265: Loss = 1.6502\n",
      "Test iteration 492/1265: Loss = 1.5993\n",
      "Test iteration 493/1265: Loss = 1.4662\n",
      "Test iteration 494/1265: Loss = 1.4989\n",
      "Test iteration 495/1265: Loss = 1.7200\n",
      "Test iteration 496/1265: Loss = 1.6013\n",
      "Test iteration 497/1265: Loss = 1.5301\n",
      "Test iteration 498/1265: Loss = 1.7066\n",
      "Test iteration 499/1265: Loss = 1.6032\n",
      "Test iteration 500/1265: Loss = 1.5918\n",
      "Test iteration 501/1265: Loss = 1.6578\n",
      "Test iteration 502/1265: Loss = 1.5389\n",
      "Test iteration 503/1265: Loss = 1.6927\n",
      "Test iteration 504/1265: Loss = 1.6774\n",
      "Test iteration 505/1265: Loss = 1.4113\n",
      "Test iteration 506/1265: Loss = 1.7081\n",
      "Test iteration 507/1265: Loss = 1.6297\n",
      "Test iteration 508/1265: Loss = 1.6619\n",
      "Test iteration 509/1265: Loss = 1.5531\n",
      "Test iteration 510/1265: Loss = 1.5008\n",
      "Test iteration 511/1265: Loss = 1.6616\n",
      "Test iteration 512/1265: Loss = 1.5448\n",
      "Test iteration 513/1265: Loss = 1.6842\n",
      "Test iteration 514/1265: Loss = 1.6778\n",
      "Test iteration 515/1265: Loss = 1.6135\n",
      "Test iteration 516/1265: Loss = 1.5625\n",
      "Test iteration 517/1265: Loss = 1.4758\n",
      "Test iteration 518/1265: Loss = 1.5855\n",
      "Test iteration 519/1265: Loss = 1.4709\n",
      "Test iteration 520/1265: Loss = 1.5593\n",
      "Test iteration 521/1265: Loss = 1.6012\n",
      "Test iteration 522/1265: Loss = 1.5713\n",
      "Test iteration 523/1265: Loss = 1.6112\n",
      "Test iteration 524/1265: Loss = 1.6801\n",
      "Test iteration 525/1265: Loss = 1.4524\n",
      "Test iteration 526/1265: Loss = 1.6097\n",
      "Test iteration 527/1265: Loss = 1.5162\n",
      "Test iteration 528/1265: Loss = 1.6238\n",
      "Test iteration 529/1265: Loss = 1.6295\n",
      "Test iteration 530/1265: Loss = 1.6315\n",
      "Test iteration 531/1265: Loss = 1.6816\n",
      "Test iteration 532/1265: Loss = 1.7330\n",
      "Test iteration 533/1265: Loss = 1.6411\n",
      "Test iteration 534/1265: Loss = 1.6997\n",
      "Test iteration 535/1265: Loss = 1.6744\n",
      "Test iteration 536/1265: Loss = 1.4574\n",
      "Test iteration 537/1265: Loss = 1.5358\n",
      "Test iteration 538/1265: Loss = 1.5022\n",
      "Test iteration 539/1265: Loss = 1.5029\n",
      "Test iteration 540/1265: Loss = 1.7396\n",
      "Test iteration 541/1265: Loss = 1.5783\n",
      "Test iteration 542/1265: Loss = 1.5980\n",
      "Test iteration 543/1265: Loss = 1.5784\n",
      "Test iteration 544/1265: Loss = 1.6225\n",
      "Test iteration 545/1265: Loss = 1.5004\n",
      "Test iteration 546/1265: Loss = 1.5428\n",
      "Test iteration 547/1265: Loss = 1.3980\n",
      "Test iteration 548/1265: Loss = 1.5413\n",
      "Test iteration 549/1265: Loss = 1.5629\n",
      "Test iteration 550/1265: Loss = 1.5607\n",
      "Test iteration 551/1265: Loss = 1.5961\n",
      "Test iteration 552/1265: Loss = 1.5605\n",
      "Test iteration 553/1265: Loss = 1.6189\n",
      "Test iteration 554/1265: Loss = 1.5036\n",
      "Test iteration 555/1265: Loss = 1.6483\n",
      "Test iteration 556/1265: Loss = 1.5531\n",
      "Test iteration 557/1265: Loss = 1.5027\n",
      "Test iteration 558/1265: Loss = 1.5477\n",
      "Test iteration 559/1265: Loss = 1.6118\n",
      "Test iteration 560/1265: Loss = 1.5709\n",
      "Test iteration 561/1265: Loss = 1.6297\n",
      "Test iteration 562/1265: Loss = 1.5583\n",
      "Test iteration 563/1265: Loss = 1.6318\n",
      "Test iteration 564/1265: Loss = 1.5294\n",
      "Test iteration 565/1265: Loss = 1.4481\n",
      "Test iteration 566/1265: Loss = 1.5532\n",
      "Test iteration 567/1265: Loss = 1.6013\n",
      "Test iteration 568/1265: Loss = 1.7218\n",
      "Test iteration 569/1265: Loss = 1.5435\n",
      "Test iteration 570/1265: Loss = 1.6633\n",
      "Test iteration 571/1265: Loss = 1.6336\n",
      "Test iteration 572/1265: Loss = 1.6643\n",
      "Test iteration 573/1265: Loss = 1.6794\n",
      "Test iteration 574/1265: Loss = 1.5040\n",
      "Test iteration 575/1265: Loss = 1.6281\n",
      "Test iteration 576/1265: Loss = 1.5248\n",
      "Test iteration 577/1265: Loss = 1.5611\n",
      "Test iteration 578/1265: Loss = 1.6924\n",
      "Test iteration 579/1265: Loss = 1.6553\n",
      "Test iteration 580/1265: Loss = 1.6533\n",
      "Test iteration 581/1265: Loss = 1.5416\n",
      "Test iteration 582/1265: Loss = 1.5683\n",
      "Test iteration 583/1265: Loss = 1.7387\n",
      "Test iteration 584/1265: Loss = 1.5557\n",
      "Test iteration 585/1265: Loss = 1.5666\n",
      "Test iteration 586/1265: Loss = 1.6482\n",
      "Test iteration 587/1265: Loss = 1.4677\n",
      "Test iteration 588/1265: Loss = 1.5711\n",
      "Test iteration 589/1265: Loss = 1.5900\n",
      "Test iteration 590/1265: Loss = 1.5499\n",
      "Test iteration 591/1265: Loss = 1.5583\n",
      "Test iteration 592/1265: Loss = 1.7067\n",
      "Test iteration 593/1265: Loss = 1.5663\n",
      "Test iteration 594/1265: Loss = 1.6209\n",
      "Test iteration 595/1265: Loss = 1.5873\n",
      "Test iteration 596/1265: Loss = 1.7284\n",
      "Test iteration 597/1265: Loss = 1.5170\n",
      "Test iteration 598/1265: Loss = 1.4773\n",
      "Test iteration 599/1265: Loss = 1.6520\n",
      "Test iteration 600/1265: Loss = 1.6486\n",
      "Test iteration 601/1265: Loss = 1.6397\n",
      "Test iteration 602/1265: Loss = 1.5134\n",
      "Test iteration 603/1265: Loss = 1.7147\n",
      "Test iteration 604/1265: Loss = 1.5107\n",
      "Test iteration 605/1265: Loss = 1.6394\n",
      "Test iteration 606/1265: Loss = 1.7243\n",
      "Test iteration 607/1265: Loss = 1.5483\n",
      "Test iteration 608/1265: Loss = 1.6684\n",
      "Test iteration 609/1265: Loss = 1.4668\n",
      "Test iteration 610/1265: Loss = 1.5928\n",
      "Test iteration 611/1265: Loss = 1.6350\n",
      "Test iteration 612/1265: Loss = 1.4060\n",
      "Test iteration 613/1265: Loss = 1.4743\n",
      "Test iteration 614/1265: Loss = 1.5394\n",
      "Test iteration 615/1265: Loss = 1.7462\n",
      "Test iteration 616/1265: Loss = 1.5896\n",
      "Test iteration 617/1265: Loss = 1.6673\n",
      "Test iteration 618/1265: Loss = 1.5867\n",
      "Test iteration 619/1265: Loss = 1.6834\n",
      "Test iteration 620/1265: Loss = 1.5945\n",
      "Test iteration 621/1265: Loss = 1.5504\n",
      "Test iteration 622/1265: Loss = 1.6426\n",
      "Test iteration 623/1265: Loss = 1.6546\n",
      "Test iteration 624/1265: Loss = 1.6163\n",
      "Test iteration 625/1265: Loss = 1.6080\n",
      "Test iteration 626/1265: Loss = 1.5951\n",
      "Test iteration 627/1265: Loss = 1.6519\n",
      "Test iteration 628/1265: Loss = 1.6784\n",
      "Test iteration 629/1265: Loss = 1.5506\n",
      "Test iteration 630/1265: Loss = 1.5800\n",
      "Test iteration 631/1265: Loss = 1.5757\n",
      "Test iteration 632/1265: Loss = 1.5977\n",
      "Test iteration 633/1265: Loss = 1.4984\n",
      "Test iteration 634/1265: Loss = 1.6818\n",
      "Test iteration 635/1265: Loss = 1.6902\n",
      "Test iteration 636/1265: Loss = 1.5693\n",
      "Test iteration 637/1265: Loss = 1.7181\n",
      "Test iteration 638/1265: Loss = 1.6924\n",
      "Test iteration 639/1265: Loss = 1.6164\n",
      "Test iteration 640/1265: Loss = 1.6511\n",
      "Test iteration 641/1265: Loss = 1.6935\n",
      "Test iteration 642/1265: Loss = 1.6792\n",
      "Test iteration 643/1265: Loss = 1.6403\n",
      "Test iteration 644/1265: Loss = 1.5444\n",
      "Test iteration 645/1265: Loss = 1.5376\n",
      "Test iteration 646/1265: Loss = 1.6749\n",
      "Test iteration 647/1265: Loss = 1.6697\n",
      "Test iteration 648/1265: Loss = 1.5805\n",
      "Test iteration 649/1265: Loss = 1.6335\n",
      "Test iteration 650/1265: Loss = 1.6084\n",
      "Test iteration 651/1265: Loss = 1.6568\n",
      "Test iteration 652/1265: Loss = 1.6726\n",
      "Test iteration 653/1265: Loss = 1.6105\n",
      "Test iteration 654/1265: Loss = 1.7474\n",
      "Test iteration 655/1265: Loss = 1.4582\n",
      "Test iteration 656/1265: Loss = 1.6092\n",
      "Test iteration 657/1265: Loss = 1.5554\n",
      "Test iteration 658/1265: Loss = 1.5771\n",
      "Test iteration 659/1265: Loss = 1.5727\n",
      "Test iteration 660/1265: Loss = 1.6089\n",
      "Test iteration 661/1265: Loss = 1.7187\n",
      "Test iteration 662/1265: Loss = 1.6726\n",
      "Test iteration 663/1265: Loss = 1.7705\n",
      "Test iteration 664/1265: Loss = 1.6501\n",
      "Test iteration 665/1265: Loss = 1.5136\n",
      "Test iteration 666/1265: Loss = 1.4907\n",
      "Test iteration 667/1265: Loss = 1.7045\n",
      "Test iteration 668/1265: Loss = 1.5220\n",
      "Test iteration 669/1265: Loss = 1.5470\n",
      "Test iteration 670/1265: Loss = 1.5219\n",
      "Test iteration 671/1265: Loss = 1.5773\n",
      "Test iteration 672/1265: Loss = 1.6192\n",
      "Test iteration 673/1265: Loss = 1.6350\n",
      "Test iteration 674/1265: Loss = 1.7336\n",
      "Test iteration 675/1265: Loss = 1.6243\n",
      "Test iteration 676/1265: Loss = 1.6458\n",
      "Test iteration 677/1265: Loss = 1.3810\n",
      "Test iteration 678/1265: Loss = 1.6202\n",
      "Test iteration 679/1265: Loss = 1.5625\n",
      "Test iteration 680/1265: Loss = 1.6446\n",
      "Test iteration 681/1265: Loss = 1.6240\n",
      "Test iteration 682/1265: Loss = 1.7000\n",
      "Test iteration 683/1265: Loss = 1.6981\n",
      "Test iteration 684/1265: Loss = 1.6471\n",
      "Test iteration 685/1265: Loss = 1.7253\n",
      "Test iteration 686/1265: Loss = 1.5931\n",
      "Test iteration 687/1265: Loss = 1.5958\n",
      "Test iteration 688/1265: Loss = 1.6196\n",
      "Test iteration 689/1265: Loss = 1.6495\n",
      "Test iteration 690/1265: Loss = 1.5239\n",
      "Test iteration 691/1265: Loss = 1.6919\n",
      "Test iteration 692/1265: Loss = 1.5761\n",
      "Test iteration 693/1265: Loss = 1.4674\n",
      "Test iteration 694/1265: Loss = 1.6787\n",
      "Test iteration 695/1265: Loss = 1.6043\n",
      "Test iteration 696/1265: Loss = 1.5288\n",
      "Test iteration 697/1265: Loss = 1.5855\n",
      "Test iteration 698/1265: Loss = 1.5012\n",
      "Test iteration 699/1265: Loss = 1.4625\n",
      "Test iteration 700/1265: Loss = 1.5944\n",
      "Test iteration 701/1265: Loss = 1.5316\n",
      "Test iteration 702/1265: Loss = 1.6808\n",
      "Test iteration 703/1265: Loss = 1.5015\n",
      "Test iteration 704/1265: Loss = 1.5919\n",
      "Test iteration 705/1265: Loss = 1.5004\n",
      "Test iteration 706/1265: Loss = 1.5066\n",
      "Test iteration 707/1265: Loss = 1.5104\n",
      "Test iteration 708/1265: Loss = 1.6752\n",
      "Test iteration 709/1265: Loss = 1.6003\n",
      "Test iteration 710/1265: Loss = 1.5486\n",
      "Test iteration 711/1265: Loss = 1.5617\n",
      "Test iteration 712/1265: Loss = 1.5947\n",
      "Test iteration 713/1265: Loss = 1.6458\n",
      "Test iteration 714/1265: Loss = 1.7283\n",
      "Test iteration 715/1265: Loss = 1.6987\n",
      "Test iteration 716/1265: Loss = 1.4606\n",
      "Test iteration 717/1265: Loss = 1.5001\n",
      "Test iteration 718/1265: Loss = 1.7657\n",
      "Test iteration 719/1265: Loss = 1.5770\n",
      "Test iteration 720/1265: Loss = 1.7503\n",
      "Test iteration 721/1265: Loss = 1.5899\n",
      "Test iteration 722/1265: Loss = 1.5403\n",
      "Test iteration 723/1265: Loss = 1.5325\n",
      "Test iteration 724/1265: Loss = 1.6031\n",
      "Test iteration 725/1265: Loss = 1.4791\n",
      "Test iteration 726/1265: Loss = 1.4387\n",
      "Test iteration 727/1265: Loss = 1.5159\n",
      "Test iteration 728/1265: Loss = 1.5873\n",
      "Test iteration 729/1265: Loss = 1.5558\n",
      "Test iteration 730/1265: Loss = 1.5012\n",
      "Test iteration 731/1265: Loss = 1.6018\n",
      "Test iteration 732/1265: Loss = 1.5499\n",
      "Test iteration 733/1265: Loss = 1.6009\n",
      "Test iteration 734/1265: Loss = 1.3245\n",
      "Test iteration 735/1265: Loss = 1.7189\n",
      "Test iteration 736/1265: Loss = 1.6457\n",
      "Test iteration 737/1265: Loss = 1.5964\n",
      "Test iteration 738/1265: Loss = 1.5092\n",
      "Test iteration 739/1265: Loss = 1.6572\n",
      "Test iteration 740/1265: Loss = 1.5774\n",
      "Test iteration 741/1265: Loss = 1.6879\n",
      "Test iteration 742/1265: Loss = 1.6536\n",
      "Test iteration 743/1265: Loss = 1.6848\n",
      "Test iteration 744/1265: Loss = 1.5173\n",
      "Test iteration 745/1265: Loss = 1.5628\n",
      "Test iteration 746/1265: Loss = 1.5640\n",
      "Test iteration 747/1265: Loss = 1.6419\n",
      "Test iteration 748/1265: Loss = 1.6965\n",
      "Test iteration 749/1265: Loss = 1.6784\n",
      "Test iteration 750/1265: Loss = 1.5434\n",
      "Test iteration 751/1265: Loss = 1.5078\n",
      "Test iteration 752/1265: Loss = 1.4944\n",
      "Test iteration 753/1265: Loss = 1.6292\n",
      "Test iteration 754/1265: Loss = 1.5162\n",
      "Test iteration 755/1265: Loss = 1.5884\n",
      "Test iteration 756/1265: Loss = 1.5372\n",
      "Test iteration 757/1265: Loss = 1.6302\n",
      "Test iteration 758/1265: Loss = 1.6395\n",
      "Test iteration 759/1265: Loss = 1.5022\n",
      "Test iteration 760/1265: Loss = 1.4757\n",
      "Test iteration 761/1265: Loss = 1.6719\n",
      "Test iteration 762/1265: Loss = 1.5276\n",
      "Test iteration 763/1265: Loss = 1.6121\n",
      "Test iteration 764/1265: Loss = 1.4774\n",
      "Test iteration 765/1265: Loss = 1.5219\n",
      "Test iteration 766/1265: Loss = 1.5578\n",
      "Test iteration 767/1265: Loss = 1.5664\n",
      "Test iteration 768/1265: Loss = 1.5186\n",
      "Test iteration 769/1265: Loss = 1.5017\n",
      "Test iteration 770/1265: Loss = 1.5635\n",
      "Test iteration 771/1265: Loss = 1.6594\n",
      "Test iteration 772/1265: Loss = 1.5965\n",
      "Test iteration 773/1265: Loss = 1.3942\n",
      "Test iteration 774/1265: Loss = 1.6449\n",
      "Test iteration 775/1265: Loss = 1.6650\n",
      "Test iteration 776/1265: Loss = 1.6415\n",
      "Test iteration 777/1265: Loss = 1.3618\n",
      "Test iteration 778/1265: Loss = 1.6812\n",
      "Test iteration 779/1265: Loss = 1.6641\n",
      "Test iteration 780/1265: Loss = 1.5828\n",
      "Test iteration 781/1265: Loss = 1.6684\n",
      "Test iteration 782/1265: Loss = 1.6033\n",
      "Test iteration 783/1265: Loss = 1.6619\n",
      "Test iteration 784/1265: Loss = 1.6332\n",
      "Test iteration 785/1265: Loss = 1.4467\n",
      "Test iteration 786/1265: Loss = 1.4987\n",
      "Test iteration 787/1265: Loss = 1.4867\n",
      "Test iteration 788/1265: Loss = 1.5820\n",
      "Test iteration 789/1265: Loss = 1.5430\n",
      "Test iteration 790/1265: Loss = 1.4908\n",
      "Test iteration 791/1265: Loss = 1.6608\n",
      "Test iteration 792/1265: Loss = 1.5905\n",
      "Test iteration 793/1265: Loss = 1.5950\n",
      "Test iteration 794/1265: Loss = 1.6719\n",
      "Test iteration 795/1265: Loss = 1.6780\n",
      "Test iteration 796/1265: Loss = 1.4148\n",
      "Test iteration 797/1265: Loss = 1.5749\n",
      "Test iteration 798/1265: Loss = 1.6337\n",
      "Test iteration 799/1265: Loss = 1.3903\n",
      "Test iteration 800/1265: Loss = 1.5720\n",
      "Test iteration 801/1265: Loss = 1.6892\n",
      "Test iteration 802/1265: Loss = 1.6794\n",
      "Test iteration 803/1265: Loss = 1.5858\n",
      "Test iteration 804/1265: Loss = 1.6902\n",
      "Test iteration 805/1265: Loss = 1.6000\n",
      "Test iteration 806/1265: Loss = 1.4392\n",
      "Test iteration 807/1265: Loss = 1.6417\n",
      "Test iteration 808/1265: Loss = 1.5352\n",
      "Test iteration 809/1265: Loss = 1.3794\n",
      "Test iteration 810/1265: Loss = 1.6092\n",
      "Test iteration 811/1265: Loss = 1.6834\n",
      "Test iteration 812/1265: Loss = 1.7024\n",
      "Test iteration 813/1265: Loss = 1.5112\n",
      "Test iteration 814/1265: Loss = 1.7235\n",
      "Test iteration 815/1265: Loss = 1.6274\n",
      "Test iteration 816/1265: Loss = 1.6031\n",
      "Test iteration 817/1265: Loss = 1.5374\n",
      "Test iteration 818/1265: Loss = 1.6668\n",
      "Test iteration 819/1265: Loss = 1.4892\n",
      "Test iteration 820/1265: Loss = 1.4160\n",
      "Test iteration 821/1265: Loss = 1.6351\n",
      "Test iteration 822/1265: Loss = 1.6204\n",
      "Test iteration 823/1265: Loss = 1.5677\n",
      "Test iteration 824/1265: Loss = 1.6754\n",
      "Test iteration 825/1265: Loss = 1.5070\n",
      "Test iteration 826/1265: Loss = 1.6413\n",
      "Test iteration 827/1265: Loss = 1.4178\n",
      "Test iteration 828/1265: Loss = 1.6218\n",
      "Test iteration 829/1265: Loss = 1.5316\n",
      "Test iteration 830/1265: Loss = 1.6545\n",
      "Test iteration 831/1265: Loss = 1.6663\n",
      "Test iteration 832/1265: Loss = 1.5798\n",
      "Test iteration 833/1265: Loss = 1.6793\n",
      "Test iteration 834/1265: Loss = 1.5495\n",
      "Test iteration 835/1265: Loss = 1.4831\n",
      "Test iteration 836/1265: Loss = 1.6192\n",
      "Test iteration 837/1265: Loss = 1.5677\n",
      "Test iteration 838/1265: Loss = 1.5377\n",
      "Test iteration 839/1265: Loss = 1.5497\n",
      "Test iteration 840/1265: Loss = 1.5726\n",
      "Test iteration 841/1265: Loss = 1.6886\n",
      "Test iteration 842/1265: Loss = 1.5021\n",
      "Test iteration 843/1265: Loss = 1.5541\n",
      "Test iteration 844/1265: Loss = 1.6959\n",
      "Test iteration 845/1265: Loss = 1.5530\n",
      "Test iteration 846/1265: Loss = 1.5503\n",
      "Test iteration 847/1265: Loss = 1.6051\n",
      "Test iteration 848/1265: Loss = 1.6134\n",
      "Test iteration 849/1265: Loss = 1.5104\n",
      "Test iteration 850/1265: Loss = 1.6664\n",
      "Test iteration 851/1265: Loss = 1.5795\n",
      "Test iteration 852/1265: Loss = 1.5978\n",
      "Test iteration 853/1265: Loss = 1.7421\n",
      "Test iteration 854/1265: Loss = 1.5256\n",
      "Test iteration 855/1265: Loss = 1.4859\n",
      "Test iteration 856/1265: Loss = 1.7474\n",
      "Test iteration 857/1265: Loss = 1.6840\n",
      "Test iteration 858/1265: Loss = 1.5896\n",
      "Test iteration 859/1265: Loss = 1.6133\n",
      "Test iteration 860/1265: Loss = 1.5650\n",
      "Test iteration 861/1265: Loss = 1.6273\n",
      "Test iteration 862/1265: Loss = 1.5745\n",
      "Test iteration 863/1265: Loss = 1.7696\n",
      "Test iteration 864/1265: Loss = 1.5940\n",
      "Test iteration 865/1265: Loss = 1.6876\n",
      "Test iteration 866/1265: Loss = 1.5693\n",
      "Test iteration 867/1265: Loss = 1.5957\n",
      "Test iteration 868/1265: Loss = 1.6534\n",
      "Test iteration 869/1265: Loss = 1.6062\n",
      "Test iteration 870/1265: Loss = 1.5515\n",
      "Test iteration 871/1265: Loss = 1.5535\n",
      "Test iteration 872/1265: Loss = 1.5317\n",
      "Test iteration 873/1265: Loss = 1.5232\n",
      "Test iteration 874/1265: Loss = 1.6222\n",
      "Test iteration 875/1265: Loss = 1.6671\n",
      "Test iteration 876/1265: Loss = 1.5345\n",
      "Test iteration 877/1265: Loss = 1.5903\n",
      "Test iteration 878/1265: Loss = 1.3297\n",
      "Test iteration 879/1265: Loss = 1.5950\n",
      "Test iteration 880/1265: Loss = 1.6183\n",
      "Test iteration 881/1265: Loss = 1.5525\n",
      "Test iteration 882/1265: Loss = 1.5722\n",
      "Test iteration 883/1265: Loss = 1.6429\n",
      "Test iteration 884/1265: Loss = 1.4239\n",
      "Test iteration 885/1265: Loss = 1.6038\n",
      "Test iteration 886/1265: Loss = 1.5956\n",
      "Test iteration 887/1265: Loss = 1.6470\n",
      "Test iteration 888/1265: Loss = 1.5697\n",
      "Test iteration 889/1265: Loss = 1.7458\n",
      "Test iteration 890/1265: Loss = 1.6066\n",
      "Test iteration 891/1265: Loss = 1.6514\n",
      "Test iteration 892/1265: Loss = 1.5566\n",
      "Test iteration 893/1265: Loss = 1.5915\n",
      "Test iteration 894/1265: Loss = 1.6122\n",
      "Test iteration 895/1265: Loss = 1.6802\n",
      "Test iteration 896/1265: Loss = 1.6125\n",
      "Test iteration 897/1265: Loss = 1.5960\n",
      "Test iteration 898/1265: Loss = 1.6117\n",
      "Test iteration 899/1265: Loss = 1.4300\n",
      "Test iteration 900/1265: Loss = 1.5679\n",
      "Test iteration 901/1265: Loss = 1.5063\n",
      "Test iteration 902/1265: Loss = 1.5642\n",
      "Test iteration 903/1265: Loss = 1.4622\n",
      "Test iteration 904/1265: Loss = 1.5588\n",
      "Test iteration 905/1265: Loss = 1.5581\n",
      "Test iteration 906/1265: Loss = 1.5255\n",
      "Test iteration 907/1265: Loss = 1.5445\n",
      "Test iteration 908/1265: Loss = 1.5357\n",
      "Test iteration 909/1265: Loss = 1.4583\n",
      "Test iteration 910/1265: Loss = 1.6345\n",
      "Test iteration 911/1265: Loss = 1.5977\n",
      "Test iteration 912/1265: Loss = 1.5599\n",
      "Test iteration 913/1265: Loss = 1.6124\n",
      "Test iteration 914/1265: Loss = 1.7196\n",
      "Test iteration 915/1265: Loss = 1.5236\n",
      "Test iteration 916/1265: Loss = 1.6556\n",
      "Test iteration 917/1265: Loss = 1.5933\n",
      "Test iteration 918/1265: Loss = 1.5966\n",
      "Test iteration 919/1265: Loss = 1.4806\n",
      "Test iteration 920/1265: Loss = 1.5836\n",
      "Test iteration 921/1265: Loss = 1.6542\n",
      "Test iteration 922/1265: Loss = 1.6992\n",
      "Test iteration 923/1265: Loss = 1.5380\n",
      "Test iteration 924/1265: Loss = 1.3655\n",
      "Test iteration 925/1265: Loss = 1.5590\n",
      "Test iteration 926/1265: Loss = 1.6908\n",
      "Test iteration 927/1265: Loss = 1.7041\n",
      "Test iteration 928/1265: Loss = 1.5073\n",
      "Test iteration 929/1265: Loss = 1.5760\n",
      "Test iteration 930/1265: Loss = 1.5164\n",
      "Test iteration 931/1265: Loss = 1.6113\n",
      "Test iteration 932/1265: Loss = 1.7166\n",
      "Test iteration 933/1265: Loss = 1.7459\n",
      "Test iteration 934/1265: Loss = 1.5445\n",
      "Test iteration 935/1265: Loss = 1.6214\n",
      "Test iteration 936/1265: Loss = 1.5695\n",
      "Test iteration 937/1265: Loss = 1.6473\n",
      "Test iteration 938/1265: Loss = 1.6930\n",
      "Test iteration 939/1265: Loss = 1.6234\n",
      "Test iteration 940/1265: Loss = 1.6030\n",
      "Test iteration 941/1265: Loss = 1.6239\n",
      "Test iteration 942/1265: Loss = 1.4742\n",
      "Test iteration 943/1265: Loss = 1.6373\n",
      "Test iteration 944/1265: Loss = 1.5512\n",
      "Test iteration 945/1265: Loss = 1.4613\n",
      "Test iteration 946/1265: Loss = 1.5541\n",
      "Test iteration 947/1265: Loss = 1.5399\n",
      "Test iteration 948/1265: Loss = 1.6395\n",
      "Test iteration 949/1265: Loss = 1.5648\n",
      "Test iteration 950/1265: Loss = 1.6854\n",
      "Test iteration 951/1265: Loss = 1.6220\n",
      "Test iteration 952/1265: Loss = 1.7247\n",
      "Test iteration 953/1265: Loss = 1.6039\n",
      "Test iteration 954/1265: Loss = 1.6163\n",
      "Test iteration 955/1265: Loss = 1.5048\n",
      "Test iteration 956/1265: Loss = 1.6078\n",
      "Test iteration 957/1265: Loss = 1.5239\n",
      "Test iteration 958/1265: Loss = 1.7095\n",
      "Test iteration 959/1265: Loss = 1.6858\n",
      "Test iteration 960/1265: Loss = 1.5836\n",
      "Test iteration 961/1265: Loss = 1.6375\n",
      "Test iteration 962/1265: Loss = 1.6307\n",
      "Test iteration 963/1265: Loss = 1.6808\n",
      "Test iteration 964/1265: Loss = 1.4779\n",
      "Test iteration 965/1265: Loss = 1.5127\n",
      "Test iteration 966/1265: Loss = 1.5463\n",
      "Test iteration 967/1265: Loss = 1.7279\n",
      "Test iteration 968/1265: Loss = 1.5182\n",
      "Test iteration 969/1265: Loss = 1.6080\n",
      "Test iteration 970/1265: Loss = 1.6103\n",
      "Test iteration 971/1265: Loss = 1.3383\n",
      "Test iteration 972/1265: Loss = 1.5835\n",
      "Test iteration 973/1265: Loss = 1.5551\n",
      "Test iteration 974/1265: Loss = 1.5922\n",
      "Test iteration 975/1265: Loss = 1.4365\n",
      "Test iteration 976/1265: Loss = 1.5198\n",
      "Test iteration 977/1265: Loss = 1.4895\n",
      "Test iteration 978/1265: Loss = 1.6418\n",
      "Test iteration 979/1265: Loss = 1.3762\n",
      "Test iteration 980/1265: Loss = 1.5939\n",
      "Test iteration 981/1265: Loss = 1.5400\n",
      "Test iteration 982/1265: Loss = 1.5005\n",
      "Test iteration 983/1265: Loss = 1.5357\n",
      "Test iteration 984/1265: Loss = 1.6341\n",
      "Test iteration 985/1265: Loss = 1.5788\n",
      "Test iteration 986/1265: Loss = 1.5805\n",
      "Test iteration 987/1265: Loss = 1.5409\n",
      "Test iteration 988/1265: Loss = 1.5450\n",
      "Test iteration 989/1265: Loss = 1.7181\n",
      "Test iteration 990/1265: Loss = 1.6033\n",
      "Test iteration 991/1265: Loss = 1.6235\n",
      "Test iteration 992/1265: Loss = 1.4927\n",
      "Test iteration 993/1265: Loss = 1.6723\n",
      "Test iteration 994/1265: Loss = 1.4604\n",
      "Test iteration 995/1265: Loss = 1.6241\n",
      "Test iteration 996/1265: Loss = 1.7523\n",
      "Test iteration 997/1265: Loss = 1.5828\n",
      "Test iteration 998/1265: Loss = 1.4764\n",
      "Test iteration 999/1265: Loss = 1.6308\n",
      "Test iteration 1000/1265: Loss = 1.5440\n",
      "Test iteration 1001/1265: Loss = 1.5375\n",
      "Test iteration 1002/1265: Loss = 1.6757\n",
      "Test iteration 1003/1265: Loss = 1.6421\n",
      "Test iteration 1004/1265: Loss = 1.5879\n",
      "Test iteration 1005/1265: Loss = 1.6987\n",
      "Test iteration 1006/1265: Loss = 1.5200\n",
      "Test iteration 1007/1265: Loss = 1.6173\n",
      "Test iteration 1008/1265: Loss = 1.6228\n",
      "Test iteration 1009/1265: Loss = 1.6453\n",
      "Test iteration 1010/1265: Loss = 1.4511\n",
      "Test iteration 1011/1265: Loss = 1.5138\n",
      "Test iteration 1012/1265: Loss = 1.6087\n",
      "Test iteration 1013/1265: Loss = 1.5445\n",
      "Test iteration 1014/1265: Loss = 1.5899\n",
      "Test iteration 1015/1265: Loss = 1.6675\n",
      "Test iteration 1016/1265: Loss = 1.5930\n",
      "Test iteration 1017/1265: Loss = 1.7293\n",
      "Test iteration 1018/1265: Loss = 1.6327\n",
      "Test iteration 1019/1265: Loss = 1.6913\n",
      "Test iteration 1020/1265: Loss = 1.5451\n",
      "Test iteration 1021/1265: Loss = 1.4683\n",
      "Test iteration 1022/1265: Loss = 1.6493\n",
      "Test iteration 1023/1265: Loss = 1.6117\n",
      "Test iteration 1024/1265: Loss = 1.4896\n",
      "Test iteration 1025/1265: Loss = 1.6556\n",
      "Test iteration 1026/1265: Loss = 1.4500\n",
      "Test iteration 1027/1265: Loss = 1.5677\n",
      "Test iteration 1028/1265: Loss = 1.4603\n",
      "Test iteration 1029/1265: Loss = 1.6165\n",
      "Test iteration 1030/1265: Loss = 1.5276\n",
      "Test iteration 1031/1265: Loss = 1.4653\n",
      "Test iteration 1032/1265: Loss = 1.6237\n",
      "Test iteration 1033/1265: Loss = 1.5329\n",
      "Test iteration 1034/1265: Loss = 1.5827\n",
      "Test iteration 1035/1265: Loss = 1.5294\n",
      "Test iteration 1036/1265: Loss = 1.6491\n",
      "Test iteration 1037/1265: Loss = 1.6445\n",
      "Test iteration 1038/1265: Loss = 1.6534\n",
      "Test iteration 1039/1265: Loss = 1.6498\n",
      "Test iteration 1040/1265: Loss = 1.6545\n",
      "Test iteration 1041/1265: Loss = 1.6902\n",
      "Test iteration 1042/1265: Loss = 1.5544\n",
      "Test iteration 1043/1265: Loss = 1.6231\n",
      "Test iteration 1044/1265: Loss = 1.5792\n",
      "Test iteration 1045/1265: Loss = 1.6111\n",
      "Test iteration 1046/1265: Loss = 1.6060\n",
      "Test iteration 1047/1265: Loss = 1.6776\n",
      "Test iteration 1048/1265: Loss = 1.5139\n",
      "Test iteration 1049/1265: Loss = 1.5557\n",
      "Test iteration 1050/1265: Loss = 1.5398\n",
      "Test iteration 1051/1265: Loss = 1.4875\n",
      "Test iteration 1052/1265: Loss = 1.5955\n",
      "Test iteration 1053/1265: Loss = 1.6596\n",
      "Test iteration 1054/1265: Loss = 1.6955\n",
      "Test iteration 1055/1265: Loss = 1.6295\n",
      "Test iteration 1056/1265: Loss = 1.5659\n",
      "Test iteration 1057/1265: Loss = 1.5198\n",
      "Test iteration 1058/1265: Loss = 1.5550\n",
      "Test iteration 1059/1265: Loss = 1.5940\n",
      "Test iteration 1060/1265: Loss = 1.5330\n",
      "Test iteration 1061/1265: Loss = 1.6039\n",
      "Test iteration 1062/1265: Loss = 1.4881\n",
      "Test iteration 1063/1265: Loss = 1.5417\n",
      "Test iteration 1064/1265: Loss = 1.6471\n",
      "Test iteration 1065/1265: Loss = 1.5635\n",
      "Test iteration 1066/1265: Loss = 1.7306\n",
      "Test iteration 1067/1265: Loss = 1.6392\n",
      "Test iteration 1068/1265: Loss = 1.5140\n",
      "Test iteration 1069/1265: Loss = 1.7423\n",
      "Test iteration 1070/1265: Loss = 1.5999\n",
      "Test iteration 1071/1265: Loss = 1.5195\n",
      "Test iteration 1072/1265: Loss = 1.7463\n",
      "Test iteration 1073/1265: Loss = 1.6909\n",
      "Test iteration 1074/1265: Loss = 1.6672\n",
      "Test iteration 1075/1265: Loss = 1.5318\n",
      "Test iteration 1076/1265: Loss = 1.5250\n",
      "Test iteration 1077/1265: Loss = 1.5798\n",
      "Test iteration 1078/1265: Loss = 1.6759\n",
      "Test iteration 1079/1265: Loss = 1.4837\n",
      "Test iteration 1080/1265: Loss = 1.6226\n",
      "Test iteration 1081/1265: Loss = 1.6442\n",
      "Test iteration 1082/1265: Loss = 1.6008\n",
      "Test iteration 1083/1265: Loss = 1.5250\n",
      "Test iteration 1084/1265: Loss = 1.6048\n",
      "Test iteration 1085/1265: Loss = 1.6226\n",
      "Test iteration 1086/1265: Loss = 1.6011\n",
      "Test iteration 1087/1265: Loss = 1.4849\n",
      "Test iteration 1088/1265: Loss = 1.6959\n",
      "Test iteration 1089/1265: Loss = 1.6362\n",
      "Test iteration 1090/1265: Loss = 1.6917\n",
      "Test iteration 1091/1265: Loss = 1.4925\n",
      "Test iteration 1092/1265: Loss = 1.6867\n",
      "Test iteration 1093/1265: Loss = 1.6186\n",
      "Test iteration 1094/1265: Loss = 1.5180\n",
      "Test iteration 1095/1265: Loss = 1.5991\n",
      "Test iteration 1096/1265: Loss = 1.5524\n",
      "Test iteration 1097/1265: Loss = 1.7232\n",
      "Test iteration 1098/1265: Loss = 1.5486\n",
      "Test iteration 1099/1265: Loss = 1.6640\n",
      "Test iteration 1100/1265: Loss = 1.6303\n",
      "Test iteration 1101/1265: Loss = 1.5365\n",
      "Test iteration 1102/1265: Loss = 1.5095\n",
      "Test iteration 1103/1265: Loss = 1.5803\n",
      "Test iteration 1104/1265: Loss = 1.5320\n",
      "Test iteration 1105/1265: Loss = 1.5484\n",
      "Test iteration 1106/1265: Loss = 1.5798\n",
      "Test iteration 1107/1265: Loss = 1.6288\n",
      "Test iteration 1108/1265: Loss = 1.5289\n",
      "Test iteration 1109/1265: Loss = 1.6023\n",
      "Test iteration 1110/1265: Loss = 1.7043\n",
      "Test iteration 1111/1265: Loss = 1.4913\n",
      "Test iteration 1112/1265: Loss = 1.5571\n",
      "Test iteration 1113/1265: Loss = 1.6649\n",
      "Test iteration 1114/1265: Loss = 1.5885\n",
      "Test iteration 1115/1265: Loss = 1.7145\n",
      "Test iteration 1116/1265: Loss = 1.6764\n",
      "Test iteration 1117/1265: Loss = 1.5732\n",
      "Test iteration 1118/1265: Loss = 1.6270\n",
      "Test iteration 1119/1265: Loss = 1.5789\n",
      "Test iteration 1120/1265: Loss = 1.5206\n",
      "Test iteration 1121/1265: Loss = 1.8159\n",
      "Test iteration 1122/1265: Loss = 1.5026\n",
      "Test iteration 1123/1265: Loss = 1.6621\n",
      "Test iteration 1124/1265: Loss = 1.4461\n",
      "Test iteration 1125/1265: Loss = 1.5974\n",
      "Test iteration 1126/1265: Loss = 1.6143\n",
      "Test iteration 1127/1265: Loss = 1.5428\n",
      "Test iteration 1128/1265: Loss = 1.5398\n",
      "Test iteration 1129/1265: Loss = 1.7168\n",
      "Test iteration 1130/1265: Loss = 1.5576\n",
      "Test iteration 1131/1265: Loss = 1.7135\n",
      "Test iteration 1132/1265: Loss = 1.7240\n",
      "Test iteration 1133/1265: Loss = 1.5756\n",
      "Test iteration 1134/1265: Loss = 1.6674\n",
      "Test iteration 1135/1265: Loss = 1.6730\n",
      "Test iteration 1136/1265: Loss = 1.5411\n",
      "Test iteration 1137/1265: Loss = 1.6809\n",
      "Test iteration 1138/1265: Loss = 1.5292\n",
      "Test iteration 1139/1265: Loss = 1.3023\n",
      "Test iteration 1140/1265: Loss = 1.6750\n",
      "Test iteration 1141/1265: Loss = 1.6033\n",
      "Test iteration 1142/1265: Loss = 1.7157\n",
      "Test iteration 1143/1265: Loss = 1.4076\n",
      "Test iteration 1144/1265: Loss = 1.6681\n",
      "Test iteration 1145/1265: Loss = 1.5793\n",
      "Test iteration 1146/1265: Loss = 1.5032\n",
      "Test iteration 1147/1265: Loss = 1.5885\n",
      "Test iteration 1148/1265: Loss = 1.5726\n",
      "Test iteration 1149/1265: Loss = 1.6466\n",
      "Test iteration 1150/1265: Loss = 1.5125\n",
      "Test iteration 1151/1265: Loss = 1.6945\n",
      "Test iteration 1152/1265: Loss = 1.5420\n",
      "Test iteration 1153/1265: Loss = 1.6050\n",
      "Test iteration 1154/1265: Loss = 1.6532\n",
      "Test iteration 1155/1265: Loss = 1.5394\n",
      "Test iteration 1156/1265: Loss = 1.6850\n",
      "Test iteration 1157/1265: Loss = 1.6846\n",
      "Test iteration 1158/1265: Loss = 1.5250\n",
      "Test iteration 1159/1265: Loss = 1.5702\n",
      "Test iteration 1160/1265: Loss = 1.5007\n",
      "Test iteration 1161/1265: Loss = 1.5320\n",
      "Test iteration 1162/1265: Loss = 1.5796\n",
      "Test iteration 1163/1265: Loss = 1.7254\n",
      "Test iteration 1164/1265: Loss = 1.5885\n",
      "Test iteration 1165/1265: Loss = 1.7805\n",
      "Test iteration 1166/1265: Loss = 1.6039\n",
      "Test iteration 1167/1265: Loss = 1.6056\n",
      "Test iteration 1168/1265: Loss = 1.6448\n",
      "Test iteration 1169/1265: Loss = 1.3631\n",
      "Test iteration 1170/1265: Loss = 1.5957\n",
      "Test iteration 1171/1265: Loss = 1.5625\n",
      "Test iteration 1172/1265: Loss = 1.5088\n",
      "Test iteration 1173/1265: Loss = 1.6852\n",
      "Test iteration 1174/1265: Loss = 1.5758\n",
      "Test iteration 1175/1265: Loss = 1.6075\n",
      "Test iteration 1176/1265: Loss = 1.6411\n",
      "Test iteration 1177/1265: Loss = 1.5195\n",
      "Test iteration 1178/1265: Loss = 1.5278\n",
      "Test iteration 1179/1265: Loss = 1.5720\n",
      "Test iteration 1180/1265: Loss = 1.5987\n",
      "Test iteration 1181/1265: Loss = 1.6767\n",
      "Test iteration 1182/1265: Loss = 1.5732\n",
      "Test iteration 1183/1265: Loss = 1.7123\n",
      "Test iteration 1184/1265: Loss = 1.6625\n",
      "Test iteration 1185/1265: Loss = 1.5146\n",
      "Test iteration 1186/1265: Loss = 1.5067\n",
      "Test iteration 1187/1265: Loss = 1.7061\n",
      "Test iteration 1188/1265: Loss = 1.6893\n",
      "Test iteration 1189/1265: Loss = 1.7135\n",
      "Test iteration 1190/1265: Loss = 1.6786\n",
      "Test iteration 1191/1265: Loss = 1.5795\n",
      "Test iteration 1192/1265: Loss = 1.6384\n",
      "Test iteration 1193/1265: Loss = 1.5414\n",
      "Test iteration 1194/1265: Loss = 1.6604\n",
      "Test iteration 1195/1265: Loss = 1.6400\n",
      "Test iteration 1196/1265: Loss = 1.6323\n",
      "Test iteration 1197/1265: Loss = 1.6283\n",
      "Test iteration 1198/1265: Loss = 1.4902\n",
      "Test iteration 1199/1265: Loss = 1.6828\n",
      "Test iteration 1200/1265: Loss = 1.6095\n",
      "Test iteration 1201/1265: Loss = 1.7026\n",
      "Test iteration 1202/1265: Loss = 1.5529\n",
      "Test iteration 1203/1265: Loss = 1.5705\n",
      "Test iteration 1204/1265: Loss = 1.6352\n",
      "Test iteration 1205/1265: Loss = 1.6849\n",
      "Test iteration 1206/1265: Loss = 1.5520\n",
      "Test iteration 1207/1265: Loss = 1.4658\n",
      "Test iteration 1208/1265: Loss = 1.4913\n",
      "Test iteration 1209/1265: Loss = 1.3534\n",
      "Test iteration 1210/1265: Loss = 1.4813\n",
      "Test iteration 1211/1265: Loss = 1.5340\n",
      "Test iteration 1212/1265: Loss = 1.5392\n",
      "Test iteration 1213/1265: Loss = 1.7132\n",
      "Test iteration 1214/1265: Loss = 1.3322\n",
      "Test iteration 1215/1265: Loss = 1.5837\n",
      "Test iteration 1216/1265: Loss = 1.5304\n",
      "Test iteration 1217/1265: Loss = 1.5869\n",
      "Test iteration 1218/1265: Loss = 1.5493\n",
      "Test iteration 1219/1265: Loss = 1.5684\n",
      "Test iteration 1220/1265: Loss = 1.4962\n",
      "Test iteration 1221/1265: Loss = 1.6648\n",
      "Test iteration 1222/1265: Loss = 1.4477\n",
      "Test iteration 1223/1265: Loss = 1.5120\n",
      "Test iteration 1224/1265: Loss = 1.5902\n",
      "Test iteration 1225/1265: Loss = 1.3789\n",
      "Test iteration 1226/1265: Loss = 1.5423\n",
      "Test iteration 1227/1265: Loss = 1.5391\n",
      "Test iteration 1228/1265: Loss = 1.5910\n",
      "Test iteration 1229/1265: Loss = 1.7485\n",
      "Test iteration 1230/1265: Loss = 1.4944\n",
      "Test iteration 1231/1265: Loss = 1.5834\n",
      "Test iteration 1232/1265: Loss = 1.4979\n",
      "Test iteration 1233/1265: Loss = 1.6851\n",
      "Test iteration 1234/1265: Loss = 1.6492\n",
      "Test iteration 1235/1265: Loss = 1.4789\n",
      "Test iteration 1236/1265: Loss = 1.5496\n",
      "Test iteration 1237/1265: Loss = 1.7415\n",
      "Test iteration 1238/1265: Loss = 1.6172\n",
      "Test iteration 1239/1265: Loss = 1.6023\n",
      "Test iteration 1240/1265: Loss = 1.6140\n",
      "Test iteration 1241/1265: Loss = 1.6663\n",
      "Test iteration 1242/1265: Loss = 1.6062\n",
      "Test iteration 1243/1265: Loss = 1.6183\n",
      "Test iteration 1244/1265: Loss = 1.4627\n",
      "Test iteration 1245/1265: Loss = 1.6510\n",
      "Test iteration 1246/1265: Loss = 1.5364\n",
      "Test iteration 1247/1265: Loss = 1.5932\n",
      "Test iteration 1248/1265: Loss = 1.6592\n",
      "Test iteration 1249/1265: Loss = 1.6391\n",
      "Test iteration 1250/1265: Loss = 1.6194\n",
      "Test iteration 1251/1265: Loss = 1.5971\n",
      "Test iteration 1252/1265: Loss = 1.5345\n",
      "Test iteration 1253/1265: Loss = 1.5725\n",
      "Test iteration 1254/1265: Loss = 1.5874\n",
      "Test iteration 1255/1265: Loss = 1.2956\n",
      "Test iteration 1256/1265: Loss = 1.6308\n",
      "Test iteration 1257/1265: Loss = 1.6113\n",
      "Test iteration 1258/1265: Loss = 1.5042\n",
      "Test iteration 1259/1265: Loss = 1.5955\n",
      "Test iteration 1260/1265: Loss = 1.6389\n",
      "Test iteration 1261/1265: Loss = 1.5998\n",
      "Test iteration 1262/1265: Loss = 1.6955\n",
      "Test iteration 1263/1265: Loss = 1.6184\n",
      "Test iteration 1264/1265: Loss = 1.6433\n",
      "Test iteration 1265/1265: Loss = 1.6478\n",
      "Test loss: 1.5936765962909805\n",
      "[[0.07025973498821259, 0.011165430769324303, 0.0005727264797315001, 0.07025973498821259, 0.8477424383163452], [0.00031474456773139536, 0.014823805540800095, 0.05667494237422943, 0.9278717041015625, 0.00031474456773139536], [0.267086386680603, 0.10571374744176865, 0.10571374744176865, 0.37163421511650085, 0.14985185861587524], [0.0002993957605212927, 0.273624449968338, 0.029938964173197746, 0.666198194026947, 0.029938964173197746], [0.2684602439403534, 0.0318310521543026, 0.06087717413902283, 0.0318310521543026, 0.6070004105567932], [0.8255305290222168, 0.029045727103948593, 0.03532155230641365, 0.08105650544166565, 0.029045727103948593], [0.13376756012439728, 0.13376756012439728, 0.10231584310531616, 0.012584682554006577, 0.6175643801689148], [0.5423609614372253, 0.21232283115386963, 0.21232283115386963, 0.017451494932174683, 0.015541930682957172], [0.10814280062913895, 0.12970148026943207, 0.3804329037666321, 0.3804329037666321, 0.0012899719877168536], [0.14445874094963074, 0.4417571723461151, 0.24398647248744965, 0.02533884160220623, 0.14445874094963074], [0.0005856573698110878, 0.02260497212409973, 0.0005856573698110878, 0.9734338521957397, 0.002789872232824564], [0.025715777650475502, 0.3525705933570862, 0.289561003446579, 0.042591601610183716, 0.289561003446579], [0.4575178921222687, 0.03585568070411682, 0.04785694181919098, 0.001251597423106432, 0.4575178921222687], [0.03160636126995087, 0.45302918553352356, 0.0022162143141031265, 0.06011904031038284, 0.45302918553352356], [0.4678601026535034, 0.21225185692310333, 0.21225185692310333, 0.10751847177743912, 0.0001177487283712253], [0.2695636451244354, 0.2654000222682953, 0.1915527731180191, 0.2654000222682953, 0.008083540014922619], [0.0004668744804803282, 0.0032962511759251356, 0.0004668744804803282, 0.34053313732147217, 0.6552368998527527], [0.24040620028972626, 0.042391106486320496, 0.24040620028972626, 0.28225648403167725, 0.19453996419906616], [0.1346481442451477, 0.04378356784582138, 0.1346481442451477, 0.06736858189105988, 0.6195515394210815], [0.04307493194937706, 0.33951011300086975, 0.122471384704113, 0.15543347597122192, 0.33951011300086975], [0.085344597697258, 0.00010283297160640359, 0.0047153583727777, 0.45491859316825867, 0.45491859316825867], [0.4294983446598053, 0.2676033675670624, 0.0016308045014739037, 0.03366415575146675, 0.2676033675670624], [0.033355940133333206, 0.00254199025221169, 0.08027920126914978, 0.44191139936447144, 0.44191139936447144], [0.31371864676475525, 0.31371864676475525, 0.009029955603182316, 0.35016506910324097, 0.013367687352001667], [0.006397280842065811, 0.8330826163291931, 0.00026964652352035046, 0.08012521266937256, 0.08012521266937256], [0.06868814677000046, 0.15781418979167938, 0.4232276976108551, 0.15781418979167938, 0.19245578348636627], [0.4329747259616852, 0.07545226812362671, 0.4329747259616852, 0.04226813465356827, 0.01633012853562832], [0.003909727092832327, 0.08171478658914566, 0.005978072993457317, 0.003909727092832327, 0.9044877290725708], [0.10446194559335709, 0.46146929264068604, 0.20208431780338287, 0.20208431780338287, 0.029900139197707176], [0.24016740918159485, 0.061674814671278, 0.5764530301094055, 0.060029901564121246, 0.061674814671278], [0.007095359731465578, 0.36793234944343567, 0.019679026678204536, 0.007095359731465578, 0.598197877407074], [0.0316290520131588, 0.40007737278938293, 0.0007362040923908353, 0.40007737278938293, 0.1674799621105194], [0.049296438694000244, 0.7287358641624451, 0.10359204560518265, 0.014783656224608421, 0.10359204560518265], [0.019339514896273613, 0.03262683004140854, 0.9270841479301453, 0.019339514896273613, 0.0016099679050967097], [0.017574168741703033, 0.08392453193664551, 0.1787942498922348, 0.1787942498922348, 0.5409127473831177], [0.10232775658369064, 0.08318497240543365, 0.3638354539871216, 0.08681632578372955, 0.3638354539871216], [0.030756065621972084, 0.0603545680642128, 0.45435285568237305, 0.45435285568237305, 0.00018359544628765434], [0.011412544175982475, 0.006748830899596214, 0.4897593557834625, 0.0023198951967060566, 0.4897593557834625], [0.7973781824111938, 0.002894243923947215, 0.0576956532895565, 0.08433625102043152, 0.0576956532895565], [0.0423099510371685, 0.2340126633644104, 0.057555027306079865, 0.057555027306079865, 0.6085672974586487], [0.20152610540390015, 0.17716975510120392, 0.20152610540390015, 0.0038910889998078346, 0.41588690876960754], [0.13823488354682922, 0.04689951613545418, 0.04689951613545418, 0.6174409985542297, 0.1505250185728073], [0.07275568693876266, 0.13927499949932098, 0.07275568693876266, 0.6753172874450684, 0.0398963987827301], [0.06594602018594742, 0.21892282366752625, 0.06594602018594742, 0.1362583339214325, 0.5129268765449524], [0.008157361298799515, 0.8784751892089844, 0.008157361298799515, 0.09893207252025604, 0.00627799890935421], [0.3140006363391876, 0.0004838044405914843, 0.3367830812931061, 0.011949400417506695, 0.3367830812931061], [0.33435705304145813, 0.06809817254543304, 0.5011520981788635, 0.06809817254543304, 0.028294526040554047], [0.003108840435743332, 0.9745867252349854, 0.013815469108521938, 0.0042444574646651745, 0.0042444574646651745], [0.024811435490846634, 0.005483726970851421, 0.9076844453811646, 0.024811435490846634, 0.03720894083380699], [0.8001354932785034, 0.008318902924656868, 0.08857949078083038, 0.01438655611127615, 0.08857949078083038], [0.6243395805358887, 0.005539875477552414, 0.005539875477552414, 0.32956990599632263, 0.035010721534490585], [0.1821521818637848, 0.7873449921607971, 0.012587280943989754, 0.008957790210843086, 0.008957790210843086], [0.14850005507469177, 0.0018267660634592175, 0.14850005507469177, 0.700981616973877, 0.0001915135362651199], [0.07330776751041412, 0.2190067619085312, 0.005221004132181406, 0.4834577143192291, 0.2190067619085312], [0.6630030870437622, 0.16673022508621216, 0.1506006270647049, 0.009833035990595818, 0.009833035990595818], [0.4181775450706482, 0.11640667170286179, 0.11640667170286179, 0.27023303508758545, 0.0787760391831398], [0.389477401971817, 0.013893323950469494, 0.013893323950469494, 0.4678555130958557, 0.11488039046525955], [0.059850774705410004, 0.8598445057868958, 0.00947569590061903, 0.059850774705410004, 0.010978213511407375], [0.16481956839561462, 0.6764639019966125, 0.0037814180832356215, 0.07746759057044983, 0.07746759057044983], [0.04149662330746651, 0.7700923681259155, 0.06343170255422592, 0.0007844061474315822, 0.12419481575489044], [0.48678115010261536, 0.48678115010261536, 0.015070948749780655, 0.0005219070590101182, 0.01084484439343214], [0.3815290033817291, 0.04002491757273674, 0.5381401181221008, 0.0002810135774780065, 0.04002491757273674], [0.3653465509414673, 0.21299371123313904, 0.002957081189379096, 0.0533561147749424, 0.3653465509414673], [0.0517619252204895, 0.3339865207672119, 0.06618020683526993, 0.0517619252204895, 0.4963094890117645], [0.020428407937288284, 0.3000012934207916, 0.5720807313919067, 0.020428407937288284, 0.08706115931272507], [0.13083986937999725, 0.02996131218969822, 0.014102512039244175, 0.014102512039244175, 0.8109938502311707], [0.3957523703575134, 0.09393718838691711, 0.026810383424162865, 0.08774761110544205, 0.3957523703575134], [0.2131165862083435, 0.16748131811618805, 0.20468761026859283, 0.2131165862083435, 0.20159785449504852], [0.457459956407547, 0.08350075781345367, 0.457459956407547, 0.001476371893659234, 0.00010293751256540418], [0.0498892106115818, 0.471445769071579, 0.471445769071579, 0.004091562237590551, 0.003127642907202244], [0.4595656096935272, 0.26163655519485474, 0.014683655463159084, 0.0024776055943220854, 0.26163655519485474], [0.4028622508049011, 0.4028622508049011, 0.17139337956905365, 0.01488754153251648, 0.007994595915079117], [0.29348474740982056, 0.31882444024086, 0.19021661579608917, 0.007257645484060049, 0.19021661579608917], [0.42064934968948364, 0.14676694571971893, 0.008068260736763477, 0.0038660746067762375, 0.42064934968948364], [0.05897556617856026, 0.05897556617856026, 0.8696817755699158, 0.008267272263765335, 0.004099797923117876], [0.000983761390671134, 0.4212460219860077, 0.03524315729737282, 0.12128107249736786, 0.4212460219860077], [0.04039241746068001, 0.0029505216516554356, 0.0029505216516554356, 0.9256764650344849, 0.02803010307252407], [0.2349369376897812, 0.010169419459998608, 0.15617120265960693, 0.44255131483078003, 0.15617120265960693], [0.030756620690226555, 0.6674388647079468, 0.030756620690226555, 0.10581532120704651, 0.16523264348506927], [0.06919564306735992, 0.031090043485164642, 0.42832010984420776, 0.04307408630847931, 0.42832010984420776], [0.000504709838423878, 0.020028622820973396, 0.0370892658829689, 0.9223487377166748, 0.020028622820973396], [0.08121521025896072, 0.12233497202396393, 0.08121521025896072, 0.014187938533723354, 0.7010465860366821], [0.003388467710465193, 0.004857669118791819, 0.49446380138397217, 0.002826193580403924, 0.49446380138397217], [0.4316571354866028, 0.0060376375913619995, 0.001291030552238226, 0.0060376375913619995, 0.5549765825271606], [0.03307604417204857, 0.017338184639811516, 0.017923519015312195, 0.2286226451396942, 0.7030395865440369], [0.004466325975954533, 0.029421210289001465, 0.4784267246723175, 0.009258982725441456, 0.4784267246723175], [0.15712910890579224, 0.12528356909751892, 0.12528356909751892, 0.5206934809684753, 0.07161028683185577], [0.00812211912125349, 0.3990251421928406, 0.14767447113990784, 0.04615309461951256, 0.3990251421928406], [0.009989515878260136, 0.0038970408495515585, 0.03681885078549385, 0.051474928855895996, 0.8978196382522583], [0.22755496203899384, 0.3463708162307739, 0.22755496203899384, 0.06014211103320122, 0.13837715983390808], [0.02668084017932415, 0.20317812263965607, 0.2874695658683777, 0.27949339151382446, 0.20317812263965607], [0.0014087141025811434, 0.6420814394950867, 0.008297585882246494, 0.33991461992263794, 0.008297585882246494], [0.016451114788651466, 0.02357357181608677, 0.10511596500873566, 0.13368718326091766, 0.7211721539497375], [0.3359264135360718, 0.3359264135360718, 0.027398807927966118, 0.00903039425611496, 0.2917180061340332], [0.010696275159716606, 0.0169510617852211, 0.901677131652832, 0.05997924506664276, 0.010696275159716606], [0.05658472329378128, 0.0033277973998337984, 0.05658472329378128, 0.877919614315033, 0.005583193618804216], [0.26939767599105835, 0.003509653965011239, 0.0028865428175777197, 0.0028865428175777197, 0.7213196158409119], [0.4076390266418457, 0.17181771993637085, 0.2208198457956314, 0.027905697003006935, 0.17181771993637085], [0.15133319795131683, 0.22047480940818787, 0.004985362756997347, 0.4027317762374878, 0.22047480940818787], [0.13042303919792175, 9.821748972171918e-05, 0.35633382201194763, 0.04331105947494507, 0.4698337912559509], [0.7890745997428894, 0.016382597386837006, 0.016382597386837006, 0.009062535129487514, 0.1690976470708847], [0.1035018265247345, 0.003819412784650922, 0.00026426577824167907, 0.4462072551250458, 0.4462072551250458], [0.02858201414346695, 0.41132891178131104, 0.07797981053590775, 0.07078038901090622, 0.41132891178131104], [0.1839180588722229, 0.005923093296587467, 0.5802335143089294, 0.0333741270005703, 0.19655117392539978], [0.2525230646133423, 0.45868292450904846, 0.1431565284729004, 0.0024809904862195253, 0.1431565284729004], [0.32303303480148315, 0.32303303480148315, 0.01856091432273388, 0.24934814870357513, 0.08602485060691833], [0.6927563548088074, 0.0001476206525694579, 0.008179804310202599, 0.2907363474369049, 0.008179804310202599], [0.0008634953992441297, 0.12324010580778122, 0.0008634953992441297, 0.6858514547348022, 0.18918147683143616], [0.009615355171263218, 0.008134618401527405, 0.24507853388786316, 0.4920930564403534, 0.24507853388786316], [0.08535008132457733, 2.1149493477423675e-05, 0.020360736176371574, 0.44713401794433594, 0.44713401794433594], [0.7190282940864563, 0.12248346209526062, 0.012842131778597832, 0.012842131778597832, 0.13280397653579712], [0.6043100357055664, 0.1523490697145462, 0.11388789117336273, 0.04534246027469635, 0.08411051332950592], [0.2500764727592468, 0.6798293590545654, 0.01160886138677597, 0.046876460313797, 0.01160886138677597], [0.019082434475421906, 0.01973203755915165, 0.2702488899230957, 0.6712046265602112, 0.01973203755915165], [0.022234035655856133, 0.24845264852046967, 0.48054853081703186, 0.0003121061308775097, 0.24845264852046967], [0.00011092078784713522, 0.00011092078784713522, 0.004015546292066574, 0.27640196681022644, 0.7193606495857239], [0.4702970087528229, 0.004850724246352911, 0.00485594104975462, 0.04969934746623039, 0.4702970087528229], [0.15157127380371094, 0.00692199869081378, 0.00692199869081378, 0.7060486078262329, 0.12853607535362244], [0.07866261899471283, 0.2290988713502884, 0.03215503320097923, 0.43098458647727966, 0.2290988713502884], [0.5523268580436707, 0.3452828526496887, 0.0022836027201265097, 0.09782308340072632, 0.0022836027201265097], [0.0446406714618206, 0.002953466959297657, 0.1115790382027626, 0.8378733396530151, 0.002953466959297657], [0.015332596376538277, 0.015332596376538277, 0.38686466217041016, 0.17009752988815308, 0.4123726785182953], [0.7913841605186462, 0.005986666772514582, 0.09225461632013321, 0.05518728494644165, 0.05518728494644165], [0.006440270692110062, 0.7176865339279175, 0.22578531503677368, 0.006440270692110062, 0.0436476394534111], [0.2230241894721985, 0.23784230649471283, 0.2780751585960388, 0.02321602590382099, 0.23784230649471283], [0.5985161662101746, 0.10937545448541641, 0.06437642127275467, 0.10937545448541641, 0.11835651844739914], [0.6789082288742065, 0.01550271362066269, 0.00011362299119355157, 0.15273767709732056, 0.15273767709732056], [0.5277839303016663, 0.007446485571563244, 0.45658308267593384, 0.007446485571563244, 0.0007400274043902755], [0.0037589892745018005, 0.03334570303559303, 0.8929629921913147, 0.06869562715291977, 0.0012367184972390532], [0.35276827216148376, 0.0237965676933527, 0.0237965676933527, 0.2761977016925812, 0.32344093918800354], [0.12589670717716217, 0.5392928123474121, 0.03799113258719444, 0.03799113258719444, 0.25882816314697266], [0.8180184364318848, 0.035302579402923584, 0.06183931604027748, 0.04953707754611969, 0.035302579402923584], [0.12700435519218445, 0.12700435519218445, 0.5064273476600647, 0.00922893825918436, 0.23033499717712402], [0.057526085525751114, 0.022441456094384193, 0.4593256413936615, 0.0013811871176585555, 0.4593256413936615], [0.05438174307346344, 0.005463757086545229, 0.02528720535337925, 0.742750346660614, 0.17211690545082092], [0.040555696934461594, 0.3051500618457794, 0.04142644256353378, 0.5723121166229248, 0.040555696934461594], [0.06364542990922928, 0.06364542990922928, 0.25680696964263916, 0.06537771970033646, 0.5505244731903076], [0.687501072883606, 0.13236548006534576, 0.010919582098722458, 0.1680372655391693, 0.0011766782263293862], [0.27213987708091736, 0.006098463665693998, 0.27364349365234375, 0.006098463665693998, 0.44201967120170593], [0.07839948683977127, 0.09957343339920044, 0.4337545335292816, 0.07839948683977127, 0.3098730444908142], [0.022444527596235275, 0.09503861516714096, 0.27977254986763, 0.32297173142433167, 0.27977254986763], [0.02121783047914505, 0.11906404793262482, 0.7320660948753357, 0.11906404793262482, 0.00858796201646328], [0.5845308899879456, 0.003512569237500429, 0.399270623922348, 0.006342989392578602, 0.006342989392578602], [0.19424976408481598, 0.0009862500010058284, 6.074623524909839e-05, 6.074623524909839e-05, 0.8046425580978394], [0.10056129097938538, 0.15822173655033112, 0.5600194931030273, 0.08063619583845139, 0.10056129097938538], [0.2968076169490814, 0.20757685601711273, 0.004894438199698925, 0.19391348958015442, 0.2968076169490814], [0.11028420180082321, 0.15281689167022705, 0.3814210891723633, 0.11028420180082321, 0.24519358575344086], [0.6172880530357361, 0.3497920632362366, 0.004242734517902136, 0.0002993373782373965, 0.028377844020724297], [0.30978140234947205, 0.013075074180960655, 0.2978651821613312, 0.1896391659975052, 0.1896391659975052], [0.27481427788734436, 0.0957377478480339, 0.27481427788734436, 0.0012447170447558165, 0.3533889651298523], [0.4202083647251129, 0.4202083647251129, 0.09261812269687653, 0.058826979249715805, 0.008138203993439674], [0.0005078190588392317, 0.0007133476319722831, 0.4838675260543823, 0.03104378469288349, 0.4838675260543823], [0.4784943461418152, 0.05674330145120621, 0.012838621623814106, 0.012838621623814106, 0.43908509612083435], [0.01983610726892948, 0.07226444780826569, 0.012033438310027122, 0.012033438310027122, 0.883832573890686], [0.6610888242721558, 7.287499465746805e-05, 0.003167282324284315, 0.003167282324284315, 0.3325037658214569], [0.0074830795638263226, 0.5184502601623535, 0.17850171029567719, 0.1170632541179657, 0.17850171029567719], [0.3837330639362335, 0.026056064292788506, 0.035993557423353195, 0.3837330639362335, 0.1704842895269394], [0.7068145871162415, 0.0127714229747653, 0.12859420478343964, 0.02322555147111416, 0.12859420478343964], [0.7480834722518921, 0.01966439001262188, 0.05518552288413048, 0.08853330463171005, 0.08853330463171005], [0.07003740966320038, 0.07003740966320038, 0.39166370034217834, 0.46043914556503296, 0.007822342216968536], [0.0838315337896347, 0.0055230651050806046, 0.005695387255400419, 0.005695387255400419, 0.8992546796798706], [0.11281246691942215, 0.024281760677695274, 0.020718064159154892, 0.11281246691942215, 0.7293753027915955], [0.0006379491533152759, 0.48994705080986023, 0.012903021648526192, 0.48994705080986023, 0.00656492542475462], [0.026363492012023926, 0.01767503283917904, 0.008230063132941723, 0.9213679432868958, 0.026363492012023926], [0.053747083991765976, 0.3245514929294586, 0.23047830164432526, 0.23047830164432526, 0.1607448011636734], [0.056603096425533295, 0.23344358801841736, 0.3461684286594391, 0.3461684286594391, 0.017616484314203262], [0.0212735366076231, 0.4297361373901367, 0.03769778460264206, 0.4735947847366333, 0.03769778460264206], [0.018547728657722473, 0.01475290022790432, 0.21528376638889313, 0.3757077753543854, 0.3757077753543854], [0.028534330427646637, 0.26263681054115295, 0.3372710943222046, 0.26263681054115295, 0.10892088711261749], [0.07035521417856216, 0.3591250777244568, 0.06407415121793747, 0.3591250777244568, 0.1473204642534256], [0.3522694408893585, 0.29304102063179016, 8.975201126304455e-06, 0.3522694408893585, 0.0024110982194542885], [0.4073145389556885, 0.00042078265687450767, 0.0009984170319512486, 0.0009984170319512486, 0.5902678370475769], [0.6984766125679016, 0.00030906792380847037, 0.00030906792380847037, 0.04253702983260155, 0.2583681344985962], [0.03329341486096382, 0.004876011982560158, 0.03530164435505867, 0.029999971389770508, 0.896528959274292], [0.0944042056798935, 0.6948614716529846, 0.07124821841716766, 0.13853798806667328, 0.0009481909219175577], [0.00015308710862882435, 0.04951683059334755, 2.4768083676462993e-05, 0.4751526415348053, 0.4751526415348053], [0.05056408792734146, 0.6242109537124634, 0.19790883362293243, 0.05056408792734146, 0.07675201445817947], [0.07698283344507217, 0.10377182811498642, 0.5369782447814941, 0.23305784165859222, 0.04920925572514534], [0.010180067270994186, 0.1114577203989029, 0.3017527461051941, 0.27485668659210205, 0.3017527461051941], [0.20016829669475555, 0.020134542137384415, 0.3692036271095276, 0.014354592189192772, 0.3961389362812042], [0.00023092859191820025, 0.16919361054897308, 0.002162918681278825, 0.04197317361831665, 0.7864394187927246], [0.05655951797962189, 0.23152673244476318, 0.32690146565437317, 0.32690146565437317, 0.058110788464546204], [0.4787895977497101, 0.008497611619532108, 0.4787895977497101, 0.032418690621852875, 0.0015044553438201547], [0.0979163870215416, 0.11803542077541351, 0.3286293148994446, 0.337383508682251, 0.11803542077541351], [0.13648265600204468, 0.39273589849472046, 0.27102214097976685, 0.13648265600204468, 0.06327670067548752], [0.3237592279911041, 0.053646959364414215, 0.07983981817960739, 0.3237592279911041, 0.21899478137493134], [0.42054837942123413, 0.42054837942123413, 0.004954835865646601, 0.010074586607515812, 0.14387384057044983], [0.1839219629764557, 0.2218151092529297, 0.2218151092529297, 0.2202407270669937, 0.15220707654953003], [0.598015308380127, 0.03339175507426262, 0.13704530894756317, 0.092125304043293, 0.13942234218120575], [0.07901158183813095, 0.15790633857250214, 0.002070934046059847, 0.3805055618286133, 0.3805055618286133], [0.1110188439488411, 0.019642921164631844, 0.02051139436662197, 0.1110188439488411, 0.7378079891204834], [0.5131471753120422, 0.04167250171303749, 0.12253714352846146, 0.16132159531116486, 0.16132159531116486], [0.5300655364990234, 0.2610158324241638, 0.19367575645446777, 0.002796970074996352, 0.01244598999619484], [0.006563203409314156, 0.9811466932296753, 0.006563203409314156, 0.0012967603979632258, 0.004430086817592382], [0.13796252012252808, 0.13184817135334015, 0.11409882456064224, 0.11409882456064224, 0.5019916296005249], [0.7766254544258118, 0.07815664261579514, 0.011315971612930298, 0.06695092469453812, 0.06695092469453812], [0.07804638892412186, 0.001979799009859562, 0.001979799009859562, 0.38172903656959534, 0.536264955997467], [0.02573498524725437, 0.7824687957763672, 0.16323110461235046, 0.02573498524725437, 0.002830097684636712], [0.0018511756788939238, 0.06634124368429184, 0.4604031443595886, 0.4604031443595886, 0.011001301929354668], [0.6108916401863098, 0.10224725306034088, 0.13944466412067413, 0.13944466412067413, 0.007971677929162979], [0.0051695541478693485, 0.2748859226703644, 0.00043313278001733124, 0.44462546706199646, 0.2748859226703644], [0.0036308234557509422, 0.26641523838043213, 0.26641523838043213, 0.4508289694786072, 0.01270969770848751], [0.3930971026420593, 0.0008662044419907033, 0.3930971026420593, 0.0005997948464937508, 0.21233978867530823], [0.0049289073795080185, 0.35866469144821167, 0.014531433582305908, 0.35866469144821167, 0.2632102966308594], [0.21041055023670197, 0.45141637325286865, 0.2935310900211334, 0.02232096903026104, 0.02232096903026104], [0.459734708070755, 0.056937508285045624, 0.006083502899855375, 0.01750958152115345, 0.459734708070755], [0.8465233445167542, 0.0038475266192108393, 0.14727498590946198, 0.0011770607670769095, 0.0011770607670769095], [0.16548405587673187, 0.17846430838108063, 0.17846430838108063, 0.466043621301651, 0.011543716304004192], [0.0033241284545511007, 0.7629435062408447, 0.0033241284545511007, 0.142890065908432, 0.08751820772886276], [0.29300588369369507, 0.024893609806895256, 0.08421191573143005, 0.29300588369369507, 0.30488264560699463], [0.6064118146896362, 0.0034034985583275557, 0.22360403835773468, 0.16317714750766754, 0.0034034985583275557], [0.016968516632914543, 0.6516507267951965, 0.30588072538375854, 0.008531521074473858, 0.016968516632914543], [0.35108011960983276, 0.07619551569223404, 0.12227445095777512, 0.0020848852582275867, 0.44836506247520447], [0.000341105303959921, 0.0786685198545456, 0.000341105303959921, 0.7888960838317871, 0.13175319135189056], [0.28103265166282654, 0.43539103865623474, 0.0023875851184129715, 0.0001560527307447046, 0.28103265166282654], [0.045160841196775436, 0.21656747162342072, 0.5101579427719116, 0.011546305380761623, 0.21656747162342072], [0.7856149077415466, 0.08184969425201416, 0.01346645224839449, 0.036263175308704376, 0.08280570805072784], [0.22485895454883575, 0.2700669467449188, 0.2700669467449188, 0.11232616752386093, 0.12268093228340149], [0.019103070721030235, 0.019103070721030235, 0.10948759317398071, 0.4696253538131714, 0.38268086314201355], [0.001418686704710126, 0.43456029891967773, 0.30890631675720215, 0.003107856260612607, 0.252006858587265], [0.03390243649482727, 0.015872152522206306, 0.009917650371789932, 0.9303900599479675, 0.009917650371789932], [0.07604213804006577, 0.0020017412025481462, 0.0006970893009565771, 0.25576335191726685, 0.6654956340789795], [0.0378173366189003, 0.0378173366189003, 0.9161015152931213, 0.0029878916684538126, 0.005275811068713665], [0.06287410855293274, 0.06945091485977173, 0.42699503898620605, 0.42699503898620605, 0.01368488185107708], [0.04688585177063942, 0.4667772650718689, 0.019027480855584145, 0.4667772650718689, 0.0005321985227055848], [0.4841288924217224, 0.02625219151377678, 0.005077821668237448, 0.00041222438449040055, 0.4841288924217224], [0.0004826305666938424, 0.4711747169494629, 0.032316215336322784, 0.4711747169494629, 0.02485167793929577], [0.015094554983079433, 0.08812826126813889, 0.5904814004898071, 0.08812826126813889, 0.21816758811473846], [0.004853622056543827, 0.4888462722301483, 0.028678910806775093, 0.22293172776699066, 0.2546895444393158], [0.002696789102628827, 0.04498711973428726, 0.002476644003763795, 0.27438196539878845, 0.6754574179649353], [0.3616766929626465, 0.19339486956596375, 0.050539325922727585, 0.19719451665878296, 0.19719451665878296], [0.13109764456748962, 0.2895181179046631, 0.2898329198360443, 3.322186603327282e-05, 0.2895181179046631], [0.17672677338123322, 0.33094361424446106, 0.16003933548927307, 0.001346615026704967, 0.33094361424446106], [0.004679059609770775, 0.18787527084350586, 0.004679059609770775, 0.4174230098724365, 0.3853435814380646], [0.01302036177366972, 0.004217835143208504, 0.9088369607925415, 0.04833473637700081, 0.02559002861380577], [0.24025684595108032, 0.22845393419265747, 0.22845393419265747, 0.004327069967985153, 0.2985082268714905], [0.22327572107315063, 0.0030234716832637787, 0.6728031039237976, 0.05044884979724884, 0.05044884979724884], [0.11066402494907379, 0.3799212574958801, 0.3799212574958801, 0.09689511358737946, 0.03259841352701187], [0.33508023619651794, 0.007137532811611891, 0.654306948184967, 0.00173761579208076, 0.00173761579208076], [0.35688507556915283, 0.35688507556915283, 0.10685676336288452, 0.026157760992646217, 0.15321531891822815], [0.03838246688246727, 0.5732871294021606, 0.03838246688246727, 0.3053896427154541, 0.04455825313925743], [0.0029994070064276457, 0.4382920265197754, 0.4382920265197754, 0.09939371049404144, 0.02102283388376236], [0.3589720129966736, 0.06406692415475845, 0.14331109821796417, 0.14331109821796417, 0.2903388738632202], [0.06015390157699585, 0.2653733789920807, 0.3297194838523865, 0.3297194838523865, 0.015033787116408348], [0.4447471797466278, 0.060512740164995193, 0.000416686903918162, 0.049576204270124435, 0.4447471797466278], [0.006328387651592493, 0.13125380873680115, 0.21948133409023285, 0.21948133409023285, 0.4234551191329956], [0.004687416832894087, 0.02665688656270504, 0.02665688656270504, 0.3165343403816223, 0.6254644393920898], [0.40913087129592896, 0.40913087129592896, 0.15075357258319855, 0.005916705820709467, 0.025067949667572975], [0.0022862558253109455, 0.04867391288280487, 0.4021133780479431, 0.44910621643066406, 0.09782026708126068], [0.46978697180747986, 0.055742524564266205, 0.46978697180747986, 0.0014827018603682518, 0.0032009780406951904], [0.28308895230293274, 0.28308895230293274, 0.32980799674987793, 0.09853247553110123, 0.005481637082993984], [0.39341437816619873, 0.28171107172966003, 0.28171107172966003, 0.033923398703336716, 0.00923999771475792], [0.45980554819107056, 0.23977458477020264, 0.051197320222854614, 0.23977458477020264, 0.00944786798208952], [0.10911484062671661, 0.5365285277366638, 0.012713003903627396, 0.10911484062671661, 0.23252880573272705], [0.036679986864328384, 0.354758620262146, 0.15367016196250916, 0.354758620262146, 0.10013256967067719], [0.0063098641112446785, 0.2117433249950409, 0.7323247194290161, 0.04331221431493759, 0.0063098641112446785], [0.12216747552156448, 0.4072033166885376, 0.00292203645221889, 0.06050391122698784, 0.4072033166885376], [0.9774311184883118, 0.009788544848561287, 0.007063285913318396, 0.0028585703112185, 0.0028585703112185], [0.18567945063114166, 0.01854444295167923, 0.1446501612663269, 0.46544650197029114, 0.18567945063114166], [0.011663527227938175, 0.028783680871129036, 0.9067604541778564, 0.022401241585612297, 0.030391089618206024], [0.005024474114179611, 0.005024474114179611, 0.03675180301070213, 0.20034770667552948, 0.7528515458106995], [0.06629014760255814, 0.003929605707526207, 0.003929605707526207, 0.001086273929104209, 0.9247643947601318], [0.7461597919464111, 0.1842275708913803, 0.01966901496052742, 0.03027472458779812, 0.01966901496052742], [0.01382127683609724, 0.0125745739787817, 0.0125745739787817, 0.16755826771259308, 0.7934712767601013], [0.028248457238078117, 0.2569589614868164, 0.03158959001302719, 0.0283143762499094, 0.6548886895179749], [0.7136259078979492, 0.07768583297729492, 0.0868535190820694, 0.03498133271932602, 0.0868535190820694], [0.023522334173321724, 0.4582211673259735, 0.023522334173321724, 0.40326011180877686, 0.0914740264415741], [0.0456237830221653, 0.054068781435489655, 0.5085031390190125, 0.0456237830221653, 0.3461805582046509], [0.17800213396549225, 0.17800213396549225, 0.5034172534942627, 0.08590630441904068, 0.05467214062809944], [0.0015318099176511168, 0.03739370405673981, 0.47841179370880127, 0.004250910598784685, 0.47841179370880127], [0.024845166131854057, 0.0342145636677742, 0.0342145636677742, 0.9059017896652222, 0.0008239492308348417], [0.488808274269104, 0.4035090208053589, 0.05365859717130661, 0.00036548369098454714, 0.05365859717130661], [0.030712179839611053, 0.37838679552078247, 0.030712179839611053, 0.0016503451624885201, 0.5585384368896484], [0.6086593866348267, 0.0022494294680655003, 0.018985697999596596, 0.3511198163032532, 0.018985697999596596], [0.05691327154636383, 0.01165830623358488, 0.05691327154636383, 0.5151347517967224, 0.35938045382499695], [0.07934035360813141, 0.03488459810614586, 0.8489031791687012, 0.010747261345386505, 0.026124726980924606], [0.0021577661391347647, 0.08096084743738174, 0.7176219820976257, 0.08096084743738174, 0.11829855293035507], [0.09444941580295563, 0.018201729282736778, 0.7775486707687378, 0.05490010604262352, 0.05490010604262352], [0.056514862924814224, 0.24706383049488068, 0.33909842371940613, 0.056514862924814224, 0.30080798268318176], [0.004807611461728811, 0.153594508767128, 0.09641989320516586, 0.648758053779602, 0.09641989320516586], [0.00415200786665082, 0.09662407636642456, 0.8940771222114563, 0.00415200786665082, 0.0009947177022695541], [0.003728084731847048, 0.3304516673088074, 0.3304516673088074, 0.3194829225540161, 0.01588565483689308], [0.3110238313674927, 0.3110238313674927, 0.2766297459602356, 0.001212917733937502, 0.10010968893766403], [0.36906856298446655, 0.09531708061695099, 0.25123131275177, 0.2842053771018982, 0.00017763250798452646], [0.00902174599468708, 0.08724314719438553, 0.00902174599468708, 0.8318803310394287, 0.0628330335021019], [0.05281265452504158, 0.03961094096302986, 4.5441505790222436e-05, 0.9074856042861938, 4.5441505790222436e-05], [0.027367565780878067, 0.009273655712604523, 0.009273655712604523, 0.02183586359024048, 0.9322492480278015], [0.8074522018432617, 0.046964362263679504, 0.046964362263679504, 0.02841014787554741, 0.0702088475227356], [0.4483143985271454, 0.0005752724246121943, 0.4483143985271454, 0.08229389786720276, 0.020501984283328056], [0.4114978313446045, 0.022322680801153183, 0.009199426509439945, 0.5477806329727173, 0.009199426509439945], [0.03514458239078522, 0.7619657516479492, 0.03514458239078522, 0.04043452441692352, 0.1273106038570404], [0.22683215141296387, 0.019411655142903328, 0.2184615582227707, 0.019411655142903328, 0.5158830285072327], [0.0010938652558252215, 0.23666086792945862, 0.5224996209144592, 0.23666086792945862, 0.00308474013581872], [0.0294132512062788, 0.09740198403596878, 0.009357813745737076, 0.8344137072563171, 0.0294132512062788], [0.2731951177120209, 0.7071044445037842, 0.0024071098305284977, 0.0024071098305284977, 0.01488624420017004], [0.01621459797024727, 0.06100184842944145, 0.07838210463523865, 0.7833995819091797, 0.06100184842944145], [0.3373292088508606, 0.04004741460084915, 0.24820801615715027, 0.12620733678340912, 0.24820801615715027], [0.03341452032327652, 0.21526992321014404, 0.35687050223350525, 0.35687050223350525, 0.037574540823698044], [0.00334800872951746, 0.20465588569641113, 0.20465588569641113, 0.13859178125858307, 0.448748379945755], [0.14189012348651886, 0.13551753759384155, 0.01934267394244671, 0.614413857460022, 0.08883591741323471], [0.018901022151112556, 0.018901022151112556, 0.025149118155241013, 0.9088123440742493, 0.02823648229241371], [0.02517927624285221, 0.4710307717323303, 0.006865369156002998, 0.4710307717323303, 0.02589377388358116], [0.230469211935997, 0.12431790679693222, 0.10551981627941132, 0.26984652876853943, 0.26984652876853943], [0.017918342724442482, 0.009320731274783611, 0.12296750396490097, 0.8404726386070251, 0.009320731274783611], [0.007167857605963945, 0.007167857605963945, 0.19860953092575073, 0.783176600933075, 0.0038780998438596725], [0.35186323523521423, 0.022791894152760506, 0.6252768635749817, 3.399856359465048e-05, 3.399856359465048e-05], [0.338263601064682, 0.25409555435180664, 0.08281766623258591, 0.25409555435180664, 0.07072763890028], [0.3222309648990631, 0.14351490139961243, 0.3456852436065674, 0.09428443759679794, 0.09428443759679794], [0.7798331379890442, 0.0032096393406391144, 0.21296125650405884, 0.0032096393406391144, 0.0007862705970183015], [0.0641646608710289, 0.02433084324002266, 0.3029356896877289, 0.3029356896877289, 0.3056330978870392], [0.05065368860960007, 0.04466405138373375, 0.05065368860960007, 0.7881584167480469, 0.06587016582489014], [0.30193671584129333, 0.32703256607055664, 0.1628856658935547, 0.1628856658935547, 0.045259423553943634], [0.19037099182605743, 0.06680282205343246, 0.5469628572463989, 0.19037099182605743, 0.005492350086569786], [0.8334614038467407, 0.010054531507194042, 0.1198086217045784, 0.010054531507194042, 0.02662096917629242], [0.048969414085149765, 0.5378620624542236, 0.2732107639312744, 0.0011603242019191384, 0.13879743218421936], [0.1908808946609497, 0.15439236164093018, 0.005315865855664015, 0.4585299491882324, 0.1908808946609497], [0.0019166000420227647, 0.019322622567415237, 0.9495644569396973, 0.009873729199171066, 0.019322622567415237], [0.7432059645652771, 0.002267134143039584, 0.2460850030183792, 0.004220908507704735, 0.004220908507704735], [0.25516095757484436, 0.16462214291095734, 0.17165100574493408, 0.17165100574493408, 0.23691494762897491], [0.20217524468898773, 0.659376859664917, 0.056691303849220276, 0.056691303849220276, 0.025065314024686813], [0.010776566341519356, 0.04087480902671814, 0.010776566341519356, 0.9365209341049194, 0.0010511401342228055], [0.0942208468914032, 0.06897993385791779, 0.008766516111791134, 0.2556890845298767, 0.5723435878753662], [0.13223367929458618, 0.0014316252199932933, 0.0018317175563424826, 0.13223367929458618, 0.7322693467140198], [0.2230776846408844, 3.6119366995990276e-05, 0.3879828155040741, 0.0009206777322106063, 0.3879828155040741], [0.01588553376495838, 0.21705399453639984, 0.4873330593109131, 0.062673419713974, 0.21705399453639984], [0.0013618420343846083, 0.165735125541687, 0.083465076982975, 0.7356721758842468, 0.01376572996377945], [0.17801770567893982, 0.17938248813152313, 0.17938248813152313, 0.0004651312483474612, 0.46275219321250916], [0.18128816783428192, 0.04114202782511711, 0.18128816783428192, 0.49875855445861816, 0.09752305597066879], [0.054205022752285004, 0.18149465322494507, 0.5431727766990662, 0.0396328940987587, 0.18149465322494507], [0.1258244812488556, 0.1258244812488556, 0.026002755388617516, 0.5965238213539124, 0.1258244812488556], [0.22573411464691162, 0.0021725597325712442, 0.22573411464691162, 0.47187039256095886, 0.07448886334896088], [0.05581289529800415, 0.2964025139808655, 0.25857093930244446, 0.09281116724014282, 0.2964025139808655], [0.00025896760053001344, 0.13163870573043823, 0.7372767925262451, 0.00025896760053001344, 0.1305665820837021], [0.335002601146698, 0.29187843203544617, 0.335002601146698, 0.0344310887157917, 0.003685223637148738], [0.00032121833646669984, 0.0003125781659036875, 0.498477041721344, 0.498477041721344, 0.0024121215101331472], [0.011256683617830276, 0.4774594306945801, 0.03192983195185661, 0.4774594306945801, 0.0018945629708468914], [0.05106014013290405, 0.05106014013290405, 0.32196569442749023, 0.5679787993431091, 0.007935206405818462], [0.002056464785709977, 9.987773410102818e-06, 0.44140174984931946, 0.44140174984931946, 0.11513007432222366], [0.0003699804365169257, 2.1560330424108543e-05, 0.04269016161561012, 0.0003699804365169257, 0.956548273563385], [0.0010804414050653577, 0.018815968185663223, 0.16974537074565887, 0.16974537074565887, 0.6406128406524658], [0.0810166746377945, 0.0810166746377945, 0.009443492628633976, 0.8201695680618286, 0.008353582583367825], [0.021967869251966476, 0.2927244305610657, 0.2927244305610657, 0.38952288031578064, 0.0030604107305407524], [0.908260703086853, 0.00239066150970757, 0.08180786669254303, 0.0005553598166443408, 0.006985480431467295], [0.017103539779782295, 0.4782552719116211, 0.017103539779782295, 0.05764929950237274, 0.42988836765289307], [0.04087148606777191, 0.6436763405799866, 0.1440449357032776, 0.1440449357032776, 0.027362283319234848], [0.0866677388548851, 0.0866677388548851, 0.21127410233020782, 0.17060260474681854, 0.4447878301143646], [0.010352034121751785, 0.3035380244255066, 0.3559863865375519, 0.32872527837753296, 0.0013982316013425589], [0.007584684528410435, 0.00167727074585855, 0.0013329599751159549, 0.9818204045295715, 0.007584684528410435], [0.03097584843635559, 0.013767293654382229, 0.026020973920822144, 0.46461793780326843, 0.46461793780326843], [0.011645564809441566, 0.43170487880706787, 0.09532400220632553, 0.43170487880706787, 0.029620671644806862], [0.025825398042798042, 0.4741147458553314, 0.2566182017326355, 0.025825398042798042, 0.21761630475521088], [0.0659792348742485, 0.40310630202293396, 0.0659792348742485, 0.4361666440963745, 0.02876861020922661], [0.06818461418151855, 0.0595543198287487, 0.00812473427504301, 0.0595543198287487, 0.8045819997787476], [0.009278910234570503, 0.4466683566570282, 0.033035553991794586, 0.009278910234570503, 0.5017382502555847], [0.03799091652035713, 0.053716085851192474, 0.13717949390411377, 0.6339340209960938, 0.13717949390411377], [0.28648653626441956, 0.28648653626441956, 0.017098678275942802, 0.35611531138420105, 0.05381294712424278], [0.003147158771753311, 0.003147158771753311, 0.0016966245602816343, 0.4550066292285919, 0.537002444267273], [0.14752939343452454, 0.8337955474853516, 0.0011610810179263353, 0.016352815553545952, 0.0011610810179263353], [0.02744278870522976, 0.30854788422584534, 0.09410540759563446, 0.47579848766326904, 0.09410540759563446], [0.25453218817710876, 0.016185365617275238, 0.08130869269371033, 0.5666650533676147, 0.08130869269371033], [0.05188627168536186, 0.08891000598669052, 0.05188627168536186, 0.8041528463363647, 0.003164616646245122], [0.3272208571434021, 0.03551797196269035, 0.026688318699598312, 0.30528637766838074, 0.30528637766838074], [0.002188736340031028, 0.12443205714225769, 0.21048612892627716, 0.0017116935923695564, 0.6611813902854919], [0.9449832439422607, 0.01867513172328472, 0.008909069932997227, 0.008909069932997227, 0.01852336712181568], [0.15403924882411957, 0.4732724130153656, 0.11132477968931198, 0.15003876388072968, 0.11132477968931198], [0.4756905138492584, 0.008435752242803574, 0.003710784250870347, 0.4756905138492584, 0.036472488194704056], [0.09969379007816315, 0.029149359092116356, 0.029149359092116356, 0.8152194619178772, 0.02678809128701687], [0.4890577495098114, 0.4890577495098114, 0.0018163948552682996, 0.004898157436400652, 0.015169967897236347], [0.007200061809271574, 0.023103641346096992, 0.9117437601089478, 0.03484886512160301, 0.023103641346096992], [0.330127477645874, 0.01589358039200306, 0.08036961406469345, 0.08036961406469345, 0.49323973059654236], [0.0122793884947896, 0.5731495022773743, 0.21638274192810059, 0.1859089583158493, 0.0122793884947896], [0.08149527758359909, 0.3751116096973419, 0.30321797728538513, 0.15867982804775238, 0.08149527758359909], [0.1951484978199005, 0.2420468032360077, 0.2420468032360077, 0.00886926893144846, 0.3118886351585388], [0.0007208875613287091, 0.08327287435531616, 0.46504199504852295, 0.08327287435531616, 0.3676914572715759], [0.1957014948129654, 0.03169900178909302, 0.7387421727180481, 0.03169900178909302, 0.0021582702174782753], [0.42572468519210815, 0.00018725708650890738, 0.00018725708650890738, 0.1074407771229744, 0.4664599597454071], [0.24463219940662384, 0.3569667637348175, 0.006561457645148039, 0.3569667637348175, 0.03487281873822212], [0.2711554169654846, 0.00195997953414917, 0.2711554169654846, 0.2720653712749481, 0.18366387486457825], [0.9282154440879822, 0.00850298348814249, 0.03254072740674019, 0.00850298348814249, 0.022237857803702354], [0.01904311776161194, 0.06126437336206436, 0.25138044357299805, 0.6070476770401001, 0.06126437336206436], [0.6634506583213806, 0.050416797399520874, 0.09870941936969757, 0.050416797399520874, 0.13700629770755768], [0.02260935865342617, 0.11317235976457596, 0.02260935865342617, 0.7998303771018982, 0.041778601706027985], [0.17432774603366852, 0.17432774603366852, 0.013526847586035728, 0.41102463006973267, 0.2267930507659912], [0.5065186023712158, 0.044709812849760056, 0.079466812312603, 0.079466812312603, 0.28983792662620544], [0.07044093310832977, 0.018528131768107414, 0.4051464796066284, 0.4051464796066284, 0.10073795914649963], [0.19532260298728943, 0.059193722903728485, 0.26328590512275696, 0.059193722903728485, 0.42300403118133545], [0.0003827805630862713, 0.35893452167510986, 0.0951831117272377, 0.18656504154205322, 0.35893452167510986], [0.26863548159599304, 0.2432330697774887, 0.2414565533399582, 0.003441829700022936, 0.2432330697774887], [0.4084639251232147, 0.4084639251232147, 0.007673223037272692, 0.0026305492501705885, 0.17276839911937714], [0.01021532341837883, 0.416883647441864, 0.04807807132601738, 0.416883647441864, 0.10793931037187576], [0.05962291732430458, 0.5932421088218689, 0.2826195955276489, 0.05962291732430458, 0.004892406519502401], [0.014314690604805946, 0.03472588211297989, 0.37783846259117126, 0.37783846259117126, 0.19528251886367798], [0.1495245397090912, 0.1495245397090912, 0.31895947456359863, 0.09032609313726425, 0.29166534543037415], [0.008110849186778069, 0.16512498259544373, 0.6408005952835083, 0.0929817482829094, 0.0929817482829094], [0.04265939071774483, 0.1765722930431366, 0.31108155846595764, 0.31108155846595764, 0.15860521793365479], [0.09912604838609695, 0.19456304609775543, 0.19444639980793, 0.3174181282520294, 0.19444639980793], [0.20354793965816498, 0.6897831559181213, 0.048062313348054886, 0.048062313348054886, 0.010544249787926674], [0.17304086685180664, 0.15320566296577454, 0.15320566296577454, 0.005190555937588215, 0.5153573155403137], [0.05228340998291969, 0.869009256362915, 0.0059689912013709545, 0.05228340998291969, 0.020454982295632362], [0.03889884427189827, 0.03889884427189827, 0.6411762833595276, 0.2561134994029999, 0.024912551045417786], [0.5163518786430359, 0.002594157587736845, 0.027757836505770683, 0.23501671850681305, 0.2182794213294983], [0.023344431072473526, 0.022514859214425087, 0.24286432564258575, 0.35563814640045166, 0.35563814640045166], [0.00902846921235323, 0.7362306714057922, 0.050724875181913376, 0.15329109132289886, 0.050724875181913376], [0.10105657577514648, 0.3021038770675659, 0.2709142565727234, 0.2709142565727234, 0.05501103773713112], [0.013384301215410233, 0.37307009100914, 0.37307009100914, 0.18697188794612885, 0.05350359529256821], [0.0069601042196154594, 0.0023050259333103895, 0.0069601042196154594, 0.5774725675582886, 0.40630215406417847], [0.4305276870727539, 0.10102439671754837, 0.10102439671754837, 0.2930145859718323, 0.07440892606973648], [0.8487540483474731, 0.04173995926976204, 0.015280837193131447, 0.04173995926976204, 0.05248513072729111], [0.11277249455451965, 0.058380529284477234, 0.4014231860637665, 0.21371187269687653, 0.21371187269687653], [0.05892832949757576, 0.11130983382463455, 0.49166378378868103, 0.05892832949757576, 0.2791697680950165], [0.43108540773391724, 0.052293747663497925, 0.163091242313385, 0.052293747663497925, 0.30123594403266907], [0.5712422728538513, 0.17493821680545807, 0.09975870698690414, 0.05430210009217262, 0.09975870698690414], [0.009837967343628407, 0.07756786793470383, 0.009837967343628407, 0.813987672328949, 0.08876848965883255], [0.0028668451122939587, 0.8326665163040161, 0.001976361032575369, 0.08124515414237976, 0.08124515414237976], [0.39527276158332825, 0.014078568667173386, 0.000420050579123199, 0.1949559450149536, 0.39527276158332825], [0.11923731863498688, 0.0008700046455487609, 0.13380543887615204, 0.6844350695610046, 0.06165216863155365], [0.05776471644639969, 0.06706264615058899, 0.35427820682525635, 0.16661623120307922, 0.35427820682525635], [0.18191349506378174, 0.141861692070961, 0.1574838012456894, 0.18191349506378174, 0.3368276059627533], [0.35478320717811584, 0.29608461260795593, 0.016777468845248222, 0.29608461260795593, 0.036270108073949814], [0.027029067277908325, 0.3843558430671692, 0.0054822443053126335, 0.3843558430671692, 0.1987769603729248], [0.017714794725179672, 0.14493399858474731, 0.017714794725179672, 0.8180158138275146, 0.0016205572756007314], [0.022052373737096786, 0.41453880071640015, 0.30397844314575195, 0.022052373737096786, 0.23737801611423492], [0.00010388169903308153, 0.00010388169903308153, 0.0012692156014963984, 0.9980465173721313, 0.00047651471686549485], [0.3332759439945221, 0.13407130539417267, 0.2554587423801422, 0.02173525281250477, 0.2554587423801422], [0.021828453987836838, 0.04290681332349777, 0.8701920509338379, 0.04324426129460335, 0.021828453987836838], [0.021665291860699654, 0.833259105682373, 0.03920595720410347, 0.06666363775730133, 0.03920595720410347], [0.0057153282687067986, 0.02809586189687252, 0.9399781823158264, 0.020495325326919556, 0.0057153282687067986], [0.0016961616929620504, 0.0007739989669062197, 0.6893122792243958, 0.02574741654098034, 0.282470166683197], [0.002239685971289873, 0.32406333088874817, 0.32406333088874817, 0.20151370763778687, 0.1481199860572815], [0.19483767449855804, 0.3707922101020813, 0.011927789077162743, 0.3707922101020813, 0.051650092005729675], [0.025444354861974716, 0.48251599073410034, 0.40784984827041626, 0.0587453730404377, 0.025444354861974716], [0.0071007730439305305, 0.2400917410850525, 0.10191190987825394, 0.5489836931228638, 0.10191190987825394], [0.4265776574611664, 0.3697251081466675, 0.0026438983622938395, 0.05314619466662407, 0.14790712296962738], [0.007911344058811665, 0.8587703704833984, 0.04272991791367531, 0.08267705142498016, 0.007911344058811665], [0.004566429648548365, 0.860308825969696, 0.0960114523768425, 0.019556676968932152, 0.019556676968932152], [0.04115169495344162, 0.04479456692934036, 0.445370078086853, 0.445370078086853, 0.023313535377383232], [0.004574579652398825, 0.20037947595119476, 0.7801845073699951, 0.004574579652398825, 0.01028683315962553], [0.07677122205495834, 0.00011899413220817223, 0.46024712920188904, 0.46024712920188904, 0.0026155179366469383], [0.0014777592150494456, 0.011162007227540016, 0.0014777592150494456, 0.0966387391090393, 0.8892438411712646], [0.10267601162195206, 0.6791988015174866, 0.06878990679979324, 0.04665924236178398, 0.10267601162195206], [0.20353728532791138, 0.04716060683131218, 0.37453189492225647, 0.37453189492225647, 0.00023833078739698976], [9.995041909860447e-05, 0.846278190612793, 9.995041909860447e-05, 0.12554475665092468, 0.02797716110944748], [0.0063711791299283504, 0.44902944564819336, 0.44902944564819336, 0.03587360307574272, 0.059696298092603683], [0.08456529676914215, 0.448616623878479, 0.08456529676914215, 0.0024261667858809233, 0.3798266649246216], [0.0006952592520974576, 0.7985312342643738, 0.0006952592520974576, 0.02161381207406521, 0.17846448719501495], [0.23891957104206085, 0.37143853306770325, 0.23891957104206085, 0.14905668795108795, 0.0016656374791637063], [0.056297630071640015, 0.056297630071640015, 0.12529191374778748, 0.6879470348358154, 0.07416582852602005], [0.007313287816941738, 0.5754741430282593, 0.007313287816941738, 0.0706104263663292, 0.3392888307571411], [0.39787203073501587, 0.0105049479752779, 0.37716272473335266, 0.20395541191101074, 0.0105049479752779], [0.17449958622455597, 0.31044068932533264, 0.09504128247499466, 0.10957776755094528, 0.31044068932533264], [0.15887945890426636, 0.1458490490913391, 0.004388817120343447, 0.5450336933135986, 0.1458490490913391], [0.06796952337026596, 0.0002651559771038592, 0.106089748442173, 0.0002651559771038592, 0.8254104256629944], [0.838932454586029, 0.04648847505450249, 0.002735887886956334, 0.06535464525222778, 0.04648847505450249], [0.530518651008606, 0.22995531558990479, 0.0034004179760813713, 0.006170223467051983, 0.22995531558990479], [0.3467271625995636, 0.11414595693349838, 0.04147965833544731, 0.11414595693349838, 0.38350123167037964], [0.07565432786941528, 0.12121639400720596, 0.05074814334511757, 0.37619057297706604, 0.37619057297706604], [0.22833578288555145, 0.043918102979660034, 0.18260793387889862, 0.18260793387889862, 0.36253029108047485], [0.8035964369773865, 0.14391253888607025, 0.02331017144024372, 0.014590388163924217, 0.014590388163924217], [0.15795685350894928, 0.02141384780406952, 0.0031961507629603148, 0.017514405772089958, 0.7999187707901001], [0.006576453801244497, 0.42137575149536133, 0.42137575149536133, 0.1501721441745758, 0.0004998768563382328], [0.2767469882965088, 0.02891935035586357, 0.40794479846954346, 0.2767469882965088, 0.00964183546602726], [0.6729770302772522, 0.1931493580341339, 0.0211043544113636, 0.09166495501995087, 0.0211043544113636], [0.03003779985010624, 0.869251549243927, 0.04566942900419235, 0.04566942900419235, 0.009371836669743061], [0.03803725913167, 0.13994191586971283, 0.13994191586971283, 0.5033205151557922, 0.1787584125995636], [0.4855267107486725, 0.016796374693512917, 0.005812216084450483, 0.24593238532543182, 0.24593238532543182], [0.006430873181670904, 0.6889960169792175, 0.006430873181670904, 0.13801153004169464, 0.16013069450855255], [0.33628031611442566, 0.33628031611442566, 0.006257161498069763, 0.32018721103668213, 0.000995009089820087], [0.018121736124157906, 0.044465865939855576, 0.09277886152267456, 0.044465865939855576, 0.8001677393913269], [0.07326294481754303, 0.015535875223577023, 0.36664852499961853, 0.36664852499961853, 0.17790409922599792], [0.274505615234375, 0.3350633978843689, 0.002090784488245845, 0.11383460462093353, 0.274505615234375], [0.6827466487884521, 0.025751275941729546, 0.25819626450538635, 0.01665293239057064, 0.01665293239057064], [0.3822590708732605, 0.22800549864768982, 0.003474252065643668, 0.22800549864768982, 0.1582557111978531], [0.0011254724813625216, 0.3603638708591461, 0.22095060348510742, 0.19660942256450653, 0.22095060348510742], [0.013849983923137188, 0.04435861110687256, 0.013849983923137188, 0.0024213672149926424, 0.9255200028419495], [0.02827775850892067, 0.612671971321106, 0.3066123127937317, 0.02827775850892067, 0.02416018210351467], [0.04415872320532799, 0.6419420838356018, 0.22642986476421356, 0.04331057891249657, 0.04415872320532799], [0.8496385216712952, 0.06260097026824951, 0.06260097026824951, 0.02480693906545639, 0.00035257803392596543], [0.2574082911014557, 0.14395073056221008, 0.22321949899196625, 0.14395073056221008, 0.23147070407867432], [0.1766999512910843, 0.17430563271045685, 0.1766999512910843, 0.004175999667495489, 0.46811845898628235], [1.588960731169209e-05, 0.9686874747276306, 0.007927173748612404, 0.007927173748612404, 0.015442349947988987], [0.08604941517114639, 0.27268508076667786, 0.46821001172065735, 0.08652777224779129, 0.08652777224779129], [0.007069602608680725, 0.011663476936519146, 0.5284057259559631, 0.445791631937027, 0.007069602608680725], [0.10848044604063034, 0.2389812171459198, 0.4140346944332123, 0.0039838687516748905, 0.2345198094844818], [0.00019087338296230882, 0.004859894048422575, 0.3820327818393707, 0.004859894048422575, 0.6080565452575684], [0.03735793009400368, 0.0069037145003676414, 0.0069037145003676414, 0.4441852569580078, 0.5046494007110596], [0.0028992909938097, 0.031063782051205635, 0.8350038528442383, 0.06551654636859894, 0.06551654636859894], [0.0003201239160262048, 0.00040460488526150584, 0.00040460488526150584, 0.04163245111703873, 0.9572382569313049], [0.508653998374939, 0.08195570111274719, 0.40292462706565857, 0.0032328038942068815, 0.0032328038942068815], [0.07638918608427048, 0.26041775941848755, 0.12740513682365417, 0.26041775941848755, 0.27537015080451965], [0.017305897548794746, 0.017305897548794746, 0.9246445894241333, 0.004667940549552441, 0.03607567399740219], [0.16274280846118927, 0.37844952940940857, 0.21162500977516174, 0.21162500977516174, 0.03555760532617569], [0.5720431208610535, 0.24136300384998322, 0.0328509621322155, 0.0328509621322155, 0.12089195847511292], [0.40634268522262573, 0.2088095098733902, 0.19197532534599304, 0.19197532534599304, 0.0008971891365945339], [0.26236864924430847, 0.4812912344932556, 0.12296903133392334, 0.010402059182524681, 0.12296903133392334], [0.10590922832489014, 0.0029408473055809736, 0.0899086445569992, 0.7113326191902161, 0.0899086445569992], [0.32776346802711487, 0.08971918374300003, 0.3735879361629486, 0.11921018362045288, 0.08971918374300003], [0.21461829543113708, 0.5211584568023682, 0.00206177681684494, 0.26009973883628845, 0.00206177681684494], [0.09840348362922668, 0.0674319639801979, 0.019164197146892548, 0.40750017762184143, 0.40750017762184143], [0.010089372284710407, 0.024363305419683456, 0.9594689011573792, 0.00597626157104969, 0.00010216833470622078], [0.20826584100723267, 0.02830401435494423, 0.20826584100723267, 0.1720200926065445, 0.38314417004585266], [0.011037998832762241, 0.07761427015066147, 0.028116218745708466, 0.4416157603263855, 0.4416157603263855], [0.02407955192029476, 0.2431006133556366, 0.02407955192029476, 0.16109372675418854, 0.5476465821266174], [0.00012213773152325302, 0.9951410293579102, 0.003489620750769973, 0.0006236249464564025, 0.0006236249464564025], [0.1882794052362442, 0.0033039338886737823, 0.1882794052362442, 0.40489253401756287, 0.21524472534656525], [0.17917679250240326, 0.1336033195257187, 0.1336033195257187, 0.24989303946495056, 0.30372342467308044], [0.01055116020143032, 0.0020087016746401787, 0.48788022994995117, 0.48788022994995117, 0.011679614894092083], [0.07522713392972946, 0.07522713392972946, 0.014406383037567139, 0.8278793692588806, 0.007259933277964592], [0.3156493902206421, 0.0381399542093277, 0.0381399542093277, 0.5983097553253174, 0.009760918095707893], [0.7386622428894043, 0.0236018355935812, 0.02162913791835308, 0.033962149173021317, 0.1821446269750595], [0.2106851190328598, 0.3814004361629486, 0.18807300925254822, 0.18807300925254822, 0.031768497079610825], [0.02776745706796646, 0.5613704323768616, 0.2051062434911728, 0.0006496802670881152, 0.2051062434911728], [0.032818056643009186, 0.11484277248382568, 0.0005585156613960862, 0.032818056643009186, 0.8189626336097717], [0.31649765372276306, 0.0639166310429573, 0.0639166310429573, 0.17102833092212677, 0.38464075326919556], [0.13876450061798096, 0.42811086773872375, 0.044259488582611084, 0.044259488582611084, 0.34460559487342834], [0.44337570667266846, 0.000997397000901401, 0.11171407252550125, 0.0005370946018956602, 0.44337570667266846], [0.07113027572631836, 0.07158718258142471, 0.7165364027023315, 0.07113027572631836, 0.06961583346128464], [0.07334213703870773, 0.1287127137184143, 0.1287127137184143, 0.3937859535217285, 0.27544644474983215], [0.0254862979054451, 0.0254862979054451, 0.006740013603121042, 0.7172685861587524, 0.2250187247991562], [0.25585082173347473, 0.13007481396198273, 0.011003981344401836, 0.3472195565700531, 0.25585082173347473], [0.00450682919472456, 0.44726651906967163, 0.10081225633621216, 0.44726651906967163, 0.00014787317195441574], [0.0058959489688277245, 0.41638198494911194, 0.41638198494911194, 0.09257489442825317, 0.06876520812511444], [0.31473663449287415, 0.06370173394680023, 0.2803661823272705, 0.31473663449287415, 0.026458797976374626], [0.30569547414779663, 0.027501048520207405, 0.3188641667366028, 0.3204382359981537, 0.027501048520207405], [0.024891039356589317, 0.14162491261959076, 0.14162491261959076, 0.4893319606781006, 0.20252712070941925], [0.08734645694494247, 0.2709417939186096, 0.3959980905056, 0.12285680323839188, 0.12285680323839188], [0.05838916078209877, 0.432963103055954, 0.04259771108627319, 0.432963103055954, 0.03308691456913948], [0.3162113428115845, 0.053418200463056564, 0.30792373418807983, 0.3162113428115845, 0.0062354267574846745], [0.04632946103811264, 0.10068488866090775, 0.3489944040775299, 0.3489944040775299, 0.1549968272447586], [0.7164297103881836, 0.05407561734318733, 0.22107607126235962, 0.007518636994063854, 0.0008999565616250038], [0.3708367645740509, 0.3708367645740509, 0.02823813632130623, 0.18858405947685242, 0.04150428995490074], [0.2580329477787018, 0.0027799909003078938, 0.3321983814239502, 0.14895570278167725, 0.2580329477787018], [0.2881462574005127, 0.03893335908651352, 0.007495096419006586, 0.33271265029907227, 0.33271265029907227], [0.009397797286510468, 0.02722904086112976, 0.30735865235328674, 0.009397797286510468, 0.6466167569160461], [0.3542606830596924, 0.27091172337532043, 0.08031336218118668, 0.023602530360221863, 0.27091172337532043], [0.08335284888744354, 0.034195125102996826, 0.3611764907836914, 0.16009899973869324, 0.3611764907836914], [0.7081877589225769, 0.06347796320915222, 0.013237428851425648, 0.013237428851425648, 0.20185938477516174], [0.013325711712241173, 0.03477600961923599, 0.03477600961923599, 0.9168900847434998, 0.00023216049885377288], [0.43668410181999207, 0.19892412424087524, 0.2546398937702179, 0.0548759289085865, 0.0548759289085865], [0.3177834451198578, 0.2927442491054535, 0.3177834451198578, 0.06241330876946449, 0.009275552816689014], [0.11796873807907104, 0.28699544072151184, 0.27575141191482544, 0.28699544072151184, 0.03228895738720894], [0.00021453746012412012, 0.00021453746012412012, 0.04392436891794205, 0.0003854444366879761, 0.9552611112594604], [0.029039345681667328, 0.029039345681667328, 0.6531597971916199, 0.004710816778242588, 0.28405073285102844], [0.0011024564737454057, 0.5307208299636841, 0.3629363179206848, 0.004164489451795816, 0.10107595473527908], [0.14347074925899506, 0.14347074925899506, 0.47659164667129517, 0.21378374099731445, 0.022683026269078255], [0.04648226127028465, 0.5122215747833252, 0.06169943884015083, 0.06169943884015083, 0.3178972899913788], [0.6300135850906372, 2.993584166688379e-05, 0.1145651638507843, 0.1145651638507843, 0.14082612097263336], [0.0006989912362769246, 0.0008817128837108612, 0.003399588167667389, 0.16615217924118042, 0.8288675546646118], [0.02637682482600212, 0.08235951513051987, 0.001336475252173841, 0.8885906934738159, 0.001336475252173841], [0.46201467514038086, 8.324984082719311e-05, 0.09587395191192627, 0.22101406753063202, 0.22101406753063202], [0.21507476270198822, 0.07866611331701279, 0.5838766098022461, 0.04371640831232071, 0.07866611331701279], [0.9393656849861145, 0.0052229175344109535, 0.017624707892537117, 0.017624707892537117, 0.020161956548690796], [0.08173182606697083, 0.053183529525995255, 0.25541603565216064, 0.5564850568771362, 0.053183529525995255], [0.7199618220329285, 0.026738476008176804, 0.2009219080209732, 0.02563931979238987, 0.026738476008176804], [0.6384949684143066, 0.22080360352993011, 0.05042307823896408, 0.03985527157783508, 0.05042307823896408], [0.53343266248703, 0.1088881567120552, 0.09472578763961792, 0.09472578763961792, 0.1682276725769043], [0.028879914432764053, 0.8224058747291565, 0.03310340642929077, 0.03310340642929077, 0.08250736445188522], [0.26504161953926086, 0.37975001335144043, 0.00659515243023634, 0.17430658638477325, 0.17430658638477325], [0.2939937710762024, 0.21494707465171814, 0.2939937710762024, 0.00015076973068062216, 0.19691456854343414], [0.033755313605070114, 0.033755313605070114, 0.08318395167589188, 0.8121073246002197, 0.03719812259078026], [0.49739131331443787, 0.04775277525186539, 0.37345045804977417, 0.033652644604444504, 0.04775277525186539], [0.03745801001787186, 0.3597424328327179, 0.0029143975116312504, 0.5624271631240845, 0.03745801001787186], [0.417004257440567, 0.14560118317604065, 0.005217870231717825, 0.0151723837479949, 0.417004257440567], [0.015775639563798904, 0.07917558401823044, 0.4467785060405731, 0.4467785060405731, 0.011491772718727589], [0.2070666402578354, 0.0008395445183850825, 0.774247944355011, 0.01700640842318535, 0.0008395445183850825], [0.02628091350197792, 0.38546130061149597, 0.18904103338718414, 0.013755342923104763, 0.38546130061149597], [0.12571778893470764, 0.21626733243465424, 0.2267061024904251, 0.21504148840904236, 0.21626733243465424], [0.006556323263794184, 0.495337575674057, 0.0022584921680390835, 0.495337575674057, 0.0005100317066535354], [0.2458847612142563, 0.6017417311668396, 0.07114773988723755, 0.07114773988723755, 0.010078055784106255], [0.5280179381370544, 0.0006222000811249018, 0.020873162895441055, 0.4296136200428009, 0.020873162895441055], [0.5734546780586243, 0.00130468572024256, 0.208326518535614, 0.008587627671658993, 0.208326518535614], [0.000343925814377144, 0.008690248243510723, 0.7205891609191895, 0.2522317171096802, 0.018144948408007622], [0.008272289298474789, 0.02020503394305706, 0.963235080242157, 1.5389859981951304e-05, 0.008272289298474789], [0.08190795034170151, 0.6494618058204651, 0.18657520413398743, 0.00014709898096043617, 0.08190795034170151], [0.03619464859366417, 0.1336713284254074, 0.19174346327781677, 0.19174346327781677, 0.446647047996521], [0.01802927814424038, 0.01802927814424038, 0.8692599534988403, 0.012402485124766827, 0.0822790190577507], [0.056151602417230606, 0.17481374740600586, 0.6784761548042297, 0.034406878054142, 0.056151602417230606], [0.06833456456661224, 0.006288031116127968, 0.5006060600280762, 0.08479306846857071, 0.33997833728790283], [0.2622827887535095, 0.015190157108008862, 0.2622827887535095, 0.3509020507335663, 0.10934227705001831], [0.18263937532901764, 0.08821248263120651, 0.11284991353750229, 0.5034483075141907, 0.11284991353750229], [0.015618348494172096, 0.20093558728694916, 0.02530832402408123, 0.20093558728694916, 0.557202160358429], [0.2358921468257904, 0.053749918937683105, 0.2358921468257904, 0.41568928956985474, 0.05877654626965523], [0.005455344449728727, 0.27784615755081177, 0.06353773921728134, 0.6477054357528687, 0.005455344449728727], [0.4385795593261719, 0.4385795593261719, 0.029701678082346916, 0.08204765617847443, 0.011091579683125019], [0.2932177186012268, 0.009150332771241665, 0.009150332771241665, 0.6351214647293091, 0.053360164165496826], [0.30252766609191895, 0.048282962292432785, 0.3202730715274811, 0.3202730715274811, 0.008643195033073425], [0.21427340805530548, 0.06925089657306671, 0.21427340805530548, 0.07670623064041138, 0.425495982170105], [0.47031015157699585, 0.026903141289949417, 0.47031015157699585, 0.011653882451355457, 0.020822614431381226], [0.5561869740486145, 0.2940264344215393, 0.07213862985372543, 0.07213862985372543, 0.0055093420669436455], [0.7236655354499817, 0.23767723143100739, 0.015353837981820107, 0.015353837981820107, 0.00794956274330616], [0.4964686334133148, 0.00011687642836477607, 0.00011687642836477607, 0.01797442138195038, 0.48532313108444214], [0.09188194572925568, 0.022591816261410713, 0.022591816261410713, 0.6937333941459656, 0.16920101642608643], [0.17625784873962402, 0.23486950993537903, 0.1851675659418106, 0.21853749454021454, 0.1851675659418106], [0.19602487981319427, 0.27265989780426025, 0.18155761063098907, 0.27265989780426025, 0.07709775865077972], [0.27968934178352356, 0.34088873863220215, 0.038083478808403015, 0.06164906919002533, 0.27968934178352356], [0.00338195962831378, 0.023231569677591324, 0.33611756563186646, 0.3186344504356384, 0.3186344504356384], [0.035265229642391205, 0.05211418494582176, 0.06601084768772125, 0.42330485582351685, 0.42330485582351685], [0.7188491821289062, 0.016410265117883682, 0.13666732609272003, 0.06403660774230957, 0.06403660774230957], [0.039500944316387177, 0.0007522754603996873, 0.17189189791679382, 0.3939274251461029, 0.3939274251461029], [0.7060233950614929, 0.08524040132761002, 0.18862350285053253, 0.0020006531849503517, 0.01811203919351101], [0.18914052844047546, 0.18914052844047546, 0.1816578507423401, 0.3616674244403839, 0.07839374244213104], [0.5470482707023621, 0.17261458933353424, 0.17261458933353424, 0.0070650046691298485, 0.10065754503011703], [0.07540597766637802, 0.31910863518714905, 0.2477443516254425, 0.31910863518714905, 0.0386323481798172], [0.4917129874229431, 0.04798417165875435, 0.38601797819137573, 0.014769406989216805, 0.059515465050935745], [0.2725782096385956, 0.3586985170841217, 0.009205342270433903, 0.086939737200737, 0.2725782096385956], [0.17292287945747375, 0.038592495024204254, 0.5996112823486328, 0.01595044508576393, 0.17292287945747375], [0.3145071864128113, 0.007039722055196762, 0.06055011600255966, 0.018112489953637123, 0.5997904539108276], [0.6034073829650879, 0.07735852897167206, 0.1087343767285347, 0.07735852897167206, 0.13314126431941986], [0.006618209183216095, 0.6651520729064941, 0.12642045319080353, 0.19519110023975372, 0.006618209183216095], [0.01872163824737072, 0.18489733338356018, 0.21046662330627441, 0.01872163824737072, 0.567192792892456], [0.011539128609001637, 0.007444152142852545, 0.0889689177274704, 0.0889689177274704, 0.803078830242157], [0.007744159083813429, 0.0032789830584079027, 0.0011530956253409386, 0.4939119219779968, 0.4939119219779968], [0.3210456371307373, 0.17198076844215393, 0.09072751551866531, 0.09520043432712555, 0.3210456371307373], [0.04612613841891289, 0.003418893087655306, 0.04612613841891289, 0.8912186622619629, 0.013110170140862465], [0.5859902501106262, 0.02907915599644184, 0.3248315751552582, 0.00527573237195611, 0.05482330173254013], [0.005407991353422403, 0.05044536665081978, 0.7960801720619202, 0.05044536665081978, 0.0976211354136467], [0.01772753894329071, 0.08205566555261612, 0.022133445367217064, 0.8559499382972717, 0.022133445367217064], [0.23779620230197906, 0.049250561743974686, 0.0062803057953715324, 0.7003926038742065, 0.0062803057953715324], [0.7737328410148621, 0.031155498698353767, 0.12333307415246964, 0.04062305763363838, 0.031155498698353767], [0.17582367360591888, 0.04762057587504387, 0.16929489374160767, 0.30363038182258606, 0.30363038182258606], [0.00034310834598727524, 0.1785573959350586, 0.1785573959350586, 0.5743685364723206, 0.06817352771759033], [0.0174311101436615, 0.01305606309324503, 0.0720837339758873, 0.0720837339758873, 0.8253453373908997], [0.12032145261764526, 0.12032145261764526, 0.23122180998325348, 0.5279573798179626, 0.0001779076410457492], [0.00010958586062770337, 0.5011860728263855, 0.00010958586062770337, 0.179108127951622, 0.31948670744895935], [0.4082757234573364, 0.00033755713957361877, 0.02196487970650196, 0.16114604473114014, 0.4082757234573364], [0.008048960007727146, 0.0018796579679474235, 0.9872999787330627, 0.0018796579679474235, 0.0008917563245631754], [0.0053947013802826405, 0.013788764365017414, 0.48961523175239563, 0.48961523175239563, 0.0015860944986343384], [0.016636408865451813, 0.6269962787628174, 0.016636408865451813, 0.2348344922065735, 0.10489639639854431], [0.1267722249031067, 0.11899826675653458, 0.00044766769860871136, 0.6347835063934326, 0.11899826675653458], [0.12009386718273163, 0.04579448699951172, 0.04579448699951172, 0.4920501112937927, 0.29626700282096863], [0.020125532522797585, 0.8406367301940918, 0.02919418178498745, 0.08084943145513535, 0.02919418178498745], [0.008548238314688206, 0.01331200823187828, 0.9182614088058472, 0.01331200823187828, 0.04656631872057915], [0.3548815846443176, 0.24647070467472076, 0.3773992359638214, 0.010624237358570099, 0.010624237358570099], [0.003246885957196355, 0.4761096239089966, 0.0036339007783681154, 0.04089989885687828, 0.4761096239089966], [0.3622148931026459, 0.0001946939737536013, 0.24961891770362854, 0.025756556540727615, 0.3622148931026459], [0.38330841064453125, 0.0472550243139267, 0.44055265188217163, 0.06444196403026581, 0.06444196403026581], [0.0005566608160734177, 0.4267061650753021, 0.13684779405593872, 0.4267061650753021, 0.009183244779706001], [0.2871367931365967, 0.02885359153151512, 0.26788854598999023, 0.2871367931365967, 0.12898428738117218], [0.49348539113998413, 0.014787893742322922, 0.21818451583385468, 0.27272480726242065, 0.0008174482500180602], [0.0002602795429993421, 0.11765283346176147, 0.7886751294136047, 3.0211860575946048e-05, 0.09338151663541794], [0.04238608106970787, 0.25658926367759705, 0.24221424758434296, 0.2165961116552353, 0.24221424758434296], [0.2518775761127472, 0.20394572615623474, 0.20394572615623474, 0.2956007719039917, 0.04463014751672745], [0.28883329033851624, 0.07570359110832214, 0.005284951068460941, 0.6248932480812073, 0.005284951068460941], [0.3407139182090759, 0.048473723232746124, 0.11472056061029434, 0.15537789463996887, 0.3407139182090759], [0.02374499849975109, 0.02374499849975109, 0.11426834017038345, 0.7378610372543335, 0.10038058459758759], [0.020682575181126595, 0.1323709338903427, 0.020682575181126595, 0.08645351976156235, 0.7398104071617126], [0.256989449262619, 0.256989449262619, 0.007246623281389475, 0.3722410798072815, 0.10653344541788101], [0.1391156166791916, 0.1920580267906189, 0.47520583868026733, 0.0015625734813511372, 0.1920580267906189], [0.011478300206363201, 0.00302260834723711, 0.00302260834723711, 0.009057128801941872, 0.9734193682670593], [0.003145761089399457, 0.0006719708908349276, 0.9533810019493103, 0.003145761089399457, 0.03965550661087036], [0.12923237681388855, 0.40393170714378357, 0.40393170714378357, 0.006007720250636339, 0.05689641833305359], [0.5275769829750061, 0.22254705429077148, 0.0012663645902648568, 0.026062477380037308, 0.22254705429077148], [0.025849031284451485, 0.004134997725486755, 0.4399300813674927, 0.4399300813674927, 0.09015586227178574], [0.08267343044281006, 0.7969532012939453, 0.008692101575434208, 0.08267343044281006, 0.02900790050625801], [0.0015608258545398712, 0.15312202274799347, 0.4762164354324341, 0.21597862243652344, 0.15312202274799347], [0.03551819175481796, 0.21166697144508362, 0.41590505838394165, 0.03551819175481796, 0.3013915717601776], [0.04498844966292381, 0.007133312989026308, 0.04498844966292381, 0.010270938277244568, 0.8926188349723816], [0.016119251027703285, 0.7812249660491943, 0.11015650629997253, 0.07637995481491089, 0.016119251027703285], [0.26264554262161255, 0.10103904455900192, 0.0692235603928566, 0.49786829948425293, 0.0692235603928566], [0.21772398054599762, 0.07994344830513, 0.34426790475845337, 0.34426790475845337, 0.013796805404126644], [0.003111910307779908, 0.2688523530960083, 0.7081094980239868, 0.009963128715753555, 0.009963128715753555], [0.23280413448810577, 0.142214834690094, 0.5280436873435974, 0.09525001049041748, 0.0016873443964868784], [0.005143775139003992, 0.18918932974338531, 0.18918932974338531, 0.4945463538169861, 0.1219312846660614], [0.32822680473327637, 0.09901260584592819, 0.023956436663866043, 0.27440205216407776, 0.27440205216407776], [0.17877617478370667, 0.5198523998260498, 0.14480285346508026, 0.14480285346508026, 0.011765724048018456], [0.0001553449546918273, 0.9066032767295837, 0.07773582637310028, 0.0001553449546918273, 0.015350249595940113], [0.9250657558441162, 0.02512253448367119, 0.001597873866558075, 0.023091360926628113, 0.02512253448367119], [0.10221444815397263, 0.05001730099320412, 0.2503323554992676, 0.2987179458141327, 0.2987179458141327], [0.0047382935881614685, 0.07126139104366302, 0.8752074837684631, 0.02439645305275917, 0.02439645305275917], [0.38499292731285095, 0.38499292731285095, 0.12066397070884705, 0.10884299874305725, 0.0005071168416179717], [0.004129704553633928, 0.004129704553633928, 0.30511024594306946, 0.2977588474750519, 0.3888714909553528], [0.0013027990935370326, 0.03683026134967804, 0.053549040108919144, 0.0029514580965042114, 0.9053663611412048], [0.1304287165403366, 0.20609641075134277, 0.2372552752494812, 0.2372552752494812, 0.18896432220935822], [0.05299912393093109, 0.3536265790462494, 0.0027161051984876394, 0.012392746284604073, 0.5782654881477356], [0.017674198374152184, 0.017674198374152184, 0.004253591876477003, 0.770729660987854, 0.18966828286647797], [0.03015105426311493, 0.008494825102388859, 0.001823293510824442, 0.9577075242996216, 0.001823293510824442], [0.472196102142334, 0.011240070685744286, 0.472196102142334, 0.03835446015000343, 0.006013243459165096], [0.27851662039756775, 0.04732026532292366, 0.27851662039756775, 0.38506123423576355, 0.010585341602563858], [0.1214921623468399, 0.41486117243766785, 0.22530479729175568, 0.11917094141244888, 0.11917094141244888], [0.00012885777687188238, 0.17166736721992493, 0.18722447752952576, 0.46931192278862, 0.17166736721992493], [0.14875899255275726, 0.14875899255275726, 0.5141155123710632, 0.09461887925863266, 0.09374768286943436], [0.02289815992116928, 0.330325186252594, 0.3154427707195282, 0.330325186252594, 0.0010087330592796206], [0.0034764548763632774, 0.0898117944598198, 0.7259799242019653, 0.09092004597187042, 0.0898117944598198], [0.06004800647497177, 0.18194811046123505, 0.18194811046123505, 0.05091294273734093, 0.5251428484916687], [0.8142207860946655, 0.000987218925729394, 0.05552397295832634, 0.07374411076307297, 0.05552397295832634], [0.6253925561904907, 0.12211580574512482, 0.12211580574512482, 0.07802940160036087, 0.052346471697092056], [0.045633599162101746, 0.03047971799969673, 0.8745735883712769, 0.0036794382613152266, 0.045633599162101746], [0.0018016265239566565, 0.050129108130931854, 0.1278996467590332, 0.0018016265239566565, 0.8183680176734924], [0.06041959673166275, 0.044987984001636505, 0.8262476325035095, 0.03417237848043442, 0.03417237848043442], [0.03260684758424759, 0.5097408890724182, 0.03779708966612816, 0.3820580542087555, 0.03779708966612816], [0.39033153653144836, 0.39033153653144836, 0.07349102199077606, 0.12016651779413223, 0.025679416954517365], [0.011488782241940498, 0.011488782241940498, 0.23175746202468872, 0.6831721663475037, 0.062092773616313934], [0.001565745216794312, 0.00014109343464951962, 0.9340892434120178, 0.00014109343464951962, 0.06406288594007492], [0.013193866237998009, 0.014686508104205132, 0.18408457934856415, 0.013193866237998009, 0.7748411893844604], [5.316330134519376e-05, 0.30454587936401367, 0.3899204134941101, 0.30454587936401367, 0.0009346819133497775], [0.5466535091400146, 0.30910158157348633, 0.01786619983613491, 0.10851246118545532, 0.01786619983613491], [0.4117954671382904, 0.19026514887809753, 0.08756007999181747, 0.12011408805847168, 0.19026514887809753], [0.10629907250404358, 0.3437901735305786, 0.3437901735305786, 0.00040201362571679056, 0.20571862161159515], [0.1414874643087387, 0.2581311762332916, 0.2079949676990509, 0.17915299534797668, 0.2132333517074585], [0.10492924600839615, 0.6903047561645508, 0.09618444740772247, 0.09618444740772247, 0.012397155165672302], [0.06945372372865677, 0.6380696296691895, 0.06945372372865677, 0.013832109980285168, 0.2091907411813736], [0.03333963081240654, 0.042080171406269073, 0.03333963081240654, 0.19033551216125488, 0.7009050846099854], [0.05417819321155548, 0.8932176232337952, 0.004746338352560997, 0.023928912356495857, 0.023928912356495857], [0.7779349684715271, 0.1568332016468048, 0.016373410820961, 0.0012250865111127496, 0.0476333424448967], [0.050347261130809784, 0.6262544989585876, 0.050347261130809784, 0.2722713053226471, 0.0007797040743753314], [0.0002617490536067635, 0.2762512266635895, 0.009396134875714779, 0.0002617490536067635, 0.7138291597366333], [0.055173564702272415, 0.861969530582428, 0.03883231803774834, 0.03883231803774834, 0.005192261189222336], [0.76908278465271, 0.007839879021048546, 0.007839879021048546, 0.000382623024052009, 0.2148548811674118], [0.16301493346691132, 0.043133679777383804, 0.3972308039665222, 0.35348692536354065, 0.043133679777383804], [0.018172310665249825, 0.23286299407482147, 0.0036374840419739485, 0.0036374840419739485, 0.7416898012161255], [0.1589004099369049, 0.02028653211891651, 0.02028653211891651, 0.0935979038476944, 0.706928551197052], [0.012932932935655117, 0.2138291448354721, 0.6916483044624329, 0.014319248497486115, 0.06727038323879242], [0.004370987415313721, 0.31300511956214905, 0.10589087009429932, 0.28836649656295776, 0.28836649656295776], [0.07233677059412003, 0.3449659049510956, 0.01620091125369072, 0.2832482159137726, 0.2832482159137726], [0.04043355584144592, 0.13190239667892456, 0.4085603952407837, 0.010543243028223515, 0.4085603952407837], [0.0003614021698012948, 0.12050885707139969, 0.0007110908627510071, 0.12050885707139969, 0.7579098343849182], [0.02576478384435177, 0.6865997910499573, 0.20685268938541412, 0.04039134457707405, 0.04039134457707405], [0.20793260633945465, 0.20793260633945465, 0.002433203859254718, 0.5793813467025757, 0.0023202509619295597], [0.043304525315761566, 0.3610316514968872, 0.17476485669612885, 0.059867389500141144, 0.3610316514968872], [0.0787099078297615, 6.141616904642433e-05, 0.46051961183547974, 0.46051961183547974, 0.00018944888142868876], [0.0069528548046946526, 0.0860859602689743, 0.38816115260124207, 0.13063880801200867, 0.38816115260124207], [0.4415091574192047, 0.01849057525396347, 0.23310580849647522, 0.01849057525396347, 0.2884038984775543], [0.2636106014251709, 0.12320047616958618, 0.3074490427970886, 0.04212925583124161, 0.2636106014251709], [0.45688027143478394, 0.45688027143478394, 0.0011680900352075696, 0.04485836997628212, 0.0402129627764225], [0.8577728271484375, 0.00509618129581213, 0.015317535027861595, 0.06090676784515381, 0.06090676784515381], [0.006265528500080109, 0.25788605213165283, 0.1350613683462143, 0.3429010212421417, 0.25788605213165283], [0.038472529500722885, 0.008698278106749058, 0.034231897443532944, 0.008698278106749058, 0.9098989963531494], [0.2318793386220932, 0.4779236614704132, 0.012272152118384838, 0.2318793386220932, 0.046045418828725815], [0.10249215364456177, 0.4435153603553772, 0.010069717653095722, 0.00040738924872130156, 0.4435153603553772], [0.04793301224708557, 0.2539972960948944, 0.16645489633083344, 0.16645489633083344, 0.36515989899635315], [0.005522490479052067, 0.8465755581855774, 0.004285684786736965, 0.05514451488852501, 0.08847177773714066], [0.03610832244157791, 0.0017715474823489785, 0.0017715474823489785, 0.06469649076461792, 0.8956520557403564], [0.00582949398085475, 0.4619414806365967, 0.11733806878328323, 0.11733806878328323, 0.29755285382270813], [0.469552606344223, 0.2282363921403885, 0.028065849095582962, 0.045908719301223755, 0.2282363921403885], [0.0006740368553437293, 6.305908300419105e-06, 0.0006740368553437293, 0.06217248737812042, 0.9364731311798096], [0.19834081828594208, 0.3824009895324707, 0.20956511795520782, 0.20956511795520782, 0.00012800713011529297], [0.4536714255809784, 7.437272415700136e-06, 0.0022409327793866396, 0.4536714255809784, 0.09040867537260056], [0.6076019406318665, 0.023733751848340034, 0.022768564522266388, 0.17294786870479584, 0.17294786870479584], [0.6080374717712402, 0.11698643863201141, 0.046788815408945084, 0.046788815408945084, 0.18139848113059998], [0.054891474545001984, 0.1561054140329361, 0.046461787074804306, 0.1561054140329361, 0.5864359140396118], [0.21222741901874542, 0.44061481952667236, 0.04215504974126816, 0.09277526289224625, 0.21222741901874542], [0.09345351904630661, 0.41919031739234924, 0.41919031739234924, 0.06107395887374878, 0.007091844920068979], [0.016076980158686638, 0.3167341351509094, 0.6506987810134888, 0.016076980158686638, 0.0004131865862291306], [0.037262603640556335, 0.23010025918483734, 0.23010025918483734, 0.09836400300264359, 0.4041728675365448], [0.08421111106872559, 0.4097195863723755, 0.009621776640415192, 0.08672796189785004, 0.4097195863723755], [0.0003906076308339834, 0.008150680921971798, 0.8495375514030457, 0.008150680921971798, 0.13377052545547485], [0.0029170711059123278, 0.011906119994819164, 0.23940791189670563, 0.23940791189670563, 0.5063609480857849], [0.3467291593551636, 0.36330828070640564, 0.014458156190812588, 0.26104623079299927, 0.014458156190812588], [0.010717327706515789, 0.010717327706515789, 0.2171890288591385, 0.01164086814969778, 0.749735414981842], [0.5853205323219299, 0.008194481953978539, 0.009516041725873947, 0.009516041725873947, 0.3874528706073761], [0.8755851984024048, 0.0002651452086865902, 0.0004771309031639248, 0.0002651452086865902, 0.12340743094682693], [0.40731364488601685, 0.40731364488601685, 0.050204865634441376, 0.13095854222774506, 0.004209296312183142], [0.036882299929857254, 0.20699433982372284, 0.012784779071807861, 0.20699433982372284, 0.5363442301750183], [0.3632478713989258, 0.2156146615743637, 0.2156146615743637, 0.02367096208035946, 0.18185177445411682], [0.6697342991828918, 0.1624666154384613, 0.1624666154384613, 0.004719784948974848, 0.0006127429660409689], [0.9237669706344604, 0.0002116702526109293, 0.07060477882623672, 0.0002116702526109293, 0.005204950459301472], [0.020830247551202774, 0.004785516764968634, 0.9163405895233154, 0.03721337392926216, 0.020830247551202774], [0.8398128151893616, 0.0007050568237900734, 0.0007050568237900734, 0.1578877717256546, 0.0008892177720554173], [0.21748465299606323, 0.07623317837715149, 0.24525144696235657, 0.24525144696235657, 0.21577921509742737], [0.005314899142831564, 0.10294795781373978, 3.066976205445826e-05, 0.01351767498999834, 0.8781887292861938], [0.001867333659902215, 0.44682830572128296, 0.001867333659902215, 0.029007863253355026, 0.5204291343688965], [0.07583756744861603, 0.0022016079165041447, 0.8391408324241638, 0.07583756744861603, 0.006982451304793358], [0.16667456924915314, 0.005069606937468052, 0.40038561820983887, 0.005069606937468052, 0.42280054092407227], [0.2775174677371979, 0.2404385805130005, 0.175779327750206, 0.028747159987688065, 0.2775174677371979], [0.314382404088974, 0.001654000603593886, 0.36662641167640686, 0.0029547326266765594, 0.314382404088974], [0.06631214171648026, 0.0018159467726945877, 0.06807470321655273, 0.06807470321655273, 0.7957225441932678], [0.7664597034454346, 0.07473369687795639, 0.0834573432803154, 0.07473369687795639, 0.0006155761075206101], [0.35701295733451843, 0.2480035275220871, 0.0077948253601789474, 0.030175721272826195, 0.35701295733451843], [0.000699068361427635, 0.18970057368278503, 0.18970057368278503, 0.6046454906463623, 0.015254324302077293], [0.09980250149965286, 0.6079240441322327, 0.01857815869152546, 0.2242708057165146, 0.04942452907562256], [0.008276700973510742, 0.21535296738147736, 0.5983615517616272, 0.008276700973510742, 0.16973207890987396], [0.1483478546142578, 0.4431847035884857, 0.26006588339805603, 0.1483478546142578, 5.371891165850684e-05], [0.0007663266733288765, 0.32070308923721313, 0.32070308923721313, 0.09225065261125565, 0.2655767798423767], [0.4270493984222412, 0.16279399394989014, 0.2056916058063507, 0.16279399394989014, 0.04167106747627258], [0.015581727959215641, 0.07062698900699615, 0.7792584300041199, 0.07062698900699615, 0.06390585750341415], [0.4184826910495758, 0.011928342282772064, 0.3544577658176422, 0.09905468672513962, 0.11607644706964493], [0.3126415014266968, 0.34488460421562195, 0.029800256714224815, 3.2153737265616655e-05, 0.3126415014266968], [0.9851495027542114, 0.0005197282298468053, 0.0001674242812441662, 0.0001674242812441662, 0.013995863497257233], [7.732764970569406e-06, 0.6734287142753601, 0.29246699810028076, 0.024823201820254326, 0.009273333474993706], [0.17587068676948547, 0.3378232419490814, 0.1357368528842926, 0.3378232419490814, 0.012745899148285389], [0.4256284534931183, 9.387828322360292e-05, 0.09302270412445068, 0.4256284534931183, 0.05562653765082359], [0.001453509903512895, 0.1484614759683609, 0.1599707454442978, 0.01626436412334442, 0.6738499402999878], [0.0042165727354586124, 0.4561959505081177, 0.4561959505081177, 0.08129759132862091, 0.0020938883535563946], [0.009545559994876385, 0.05658397451043129, 0.1447049379348755, 0.1447049379348755, 0.6444605588912964], [0.3440776765346527, 0.24800963699817657, 0.062141720205545425, 0.24800963699817657, 0.09776129573583603], [0.900642454624176, 0.028429506346583366, 0.034410811960697174, 0.034410811960697174, 0.0021064775064587593], [0.033011529594659805, 0.6014888286590576, 0.1720346212387085, 0.033011529594659805, 0.16045349836349487], [0.26551946997642517, 0.26551946997642517, 0.2950667440891266, 0.03381825238466263, 0.14007604122161865], [0.45286956429481506, 0.45286956429481506, 0.027470402419567108, 0.03982914239168167, 0.026961378753185272], [0.8245055675506592, 0.0006314198253676295, 0.007261920254677534, 0.1669696569442749, 0.0006314198253676295], [0.3985865116119385, 0.07810772210359573, 0.44345057010650635, 0.0017474140040576458, 0.07810772210359573], [0.013336732052266598, 0.45519161224365234, 0.3272392749786377, 0.19089560210704803, 0.013336732052266598], [0.02760707028210163, 2.4879491320461966e-05, 0.9714239239692688, 2.4879491320461966e-05, 0.0009191500139422715], [0.4172927737236023, 0.28724661469459534, 0.000133836452732794, 0.28724661469459534, 0.008080117404460907], [0.1036057397723198, 0.7464159727096558, 0.1036057397723198, 0.033782415091991425, 0.01259014941751957], [0.1931937336921692, 0.37560802698135376, 0.12493322789669037, 0.11307127773761749, 0.1931937336921692], [0.24222147464752197, 0.4128568470478058, 0.05824272334575653, 0.05824272334575653, 0.22843626141548157], [0.46496549248695374, 0.06081433221697807, 0.0032186824828386307, 0.006035934202373028, 0.46496549248695374], [0.18808259069919586, 0.1550389975309372, 0.03847404941916466, 0.03847404941916466, 0.579930305480957], [0.04540523886680603, 0.04540523886680603, 0.005862967111170292, 0.6701055765151978, 0.23322103917598724], [0.008391623385250568, 0.00017974937509279698, 0.008391623385250568, 0.8907809257507324, 0.09225605428218842], [0.861240565776825, 0.005134924780577421, 1.4438675862038508e-05, 1.4438675862038508e-05, 0.1335955560207367], [0.1929013878107071, 0.5924620628356934, 0.018870104104280472, 0.002865066984668374, 0.1929013878107071], [0.40365907549858093, 0.06721052527427673, 0.0017052043695002794, 0.06721052527427673, 0.4602147340774536], [0.23026156425476074, 0.25664210319519043, 0.13086256384849548, 0.25664210319519043, 0.1255916953086853], [0.4076140820980072, 0.1607666164636612, 0.02247215434908867, 0.0015330828027799726, 0.4076140820980072], [0.052460890263319016, 0.23312488198280334, 0.48052525520324707, 0.000764132069889456, 0.23312488198280334], [0.01776697486639023, 0.17465704679489136, 0.7827450037002563, 0.012415469624102116, 0.012415469624102116], [0.23647086322307587, 0.19741593301296234, 0.22728854417800903, 0.23647086322307587, 0.1023537665605545], [0.0037767377216368914, 0.3659853935241699, 0.1459912210702896, 0.3382554054260254, 0.1459912210702896], [0.08776871114969254, 0.21603703498840332, 0.5976042747497559, 0.01082119531929493, 0.08776871114969254], [0.033115748316049576, 0.46708741784095764, 0.02588570863008499, 0.46708741784095764, 0.006823734845966101], [0.2525816559791565, 0.006613627541810274, 0.2525816559791565, 0.4323461353778839, 0.05587691813707352], [0.4236995279788971, 0.03107334114611149, 0.08783093094825745, 0.03107334114611149, 0.4263227581977844], [0.19677585363388062, 0.0020856624469161034, 0.7844054698944092, 0.014647337608039379, 0.0020856624469161034], [0.834603488445282, 0.07077518850564957, 0.002537404652684927, 0.07077518850564957, 0.021308837458491325], [0.27084261178970337, 0.04660139977931976, 0.0008359087514691055, 0.04660139977931976, 0.6351186037063599], [0.04705153405666351, 0.9443421959877014, 0.0013753868406638503, 0.0036154186818748713, 0.0036154186818748713], [0.20793163776397705, 0.5559234023094177, 0.014946475625038147, 0.013266935013234615, 0.20793163776397705], [0.08898597955703735, 0.10080351680517197, 0.29961511492729187, 0.08898597955703735, 0.42160940170288086], [0.0002922198036685586, 0.0002922198036685586, 0.1246393546462059, 0.35748371481895447, 0.5172924995422363], [0.007201244588941336, 0.3469168245792389, 0.30229875445365906, 0.1420808583498001, 0.20150232315063477], [0.004988641478121281, 0.9776284098625183, 0.008621889166533947, 0.008621889166533947, 0.0001390911202179268], [0.032290052622556686, 0.005751288961619139, 0.005751288961619139, 0.0013087750412523746, 0.9548986554145813], [0.2968817353248596, 0.0036227416712790728, 0.299426406621933, 0.2968817353248596, 0.10318738967180252], [0.00015345880819950253, 0.00023040696396492422, 0.2782575190067291, 0.44310107827186584, 0.2782575190067291], [0.13335315883159637, 0.02251959778368473, 0.13335315883159637, 0.2547663748264313, 0.45600777864456177], [0.844397783279419, 0.07661762833595276, 0.07661762833595276, 0.0003312115150038153, 0.0020357922185212374], [0.3623604476451874, 0.3623604476451874, 0.014958584681153297, 0.25883224606513977, 0.001488247187808156], [0.03207569941878319, 0.003513284493237734, 0.03207569941878319, 0.9182330369949341, 0.014102236367762089], [0.31943103671073914, 0.31943103671073914, 0.3160263001918793, 0.020982738584280014, 0.0241288710385561], [0.32889294624328613, 0.23815351724624634, 0.09155072271823883, 0.012509801425039768, 0.32889294624328613], [0.40662911534309387, 0.168845072388649, 0.0022212755866348743, 0.015675431117415428, 0.40662911534309387], [0.23682597279548645, 0.27551066875457764, 0.24889472126960754, 0.23682597279548645, 0.0019426678773015738], [0.15408091247081757, 0.09382762759923935, 0.003379384521394968, 0.654884397983551, 0.09382762759923935], [0.052651841193437576, 0.4248344600200653, 0.052334852516651154, 0.4248344600200653, 0.04534437507390976], [0.07978614419698715, 0.3077888488769531, 0.30574336647987366, 0.0009382821735925972, 0.30574336647987366], [0.35748055577278137, 0.05326196923851967, 0.5313737988471985, 0.004621716681867838, 0.05326196923851967], [0.06964680552482605, 0.851371169090271, 0.07099751383066177, 0.003992273937910795, 0.003992273937910795], [0.2956641614437103, 0.18112652003765106, 0.01847366988658905, 0.01847366988658905, 0.4862619638442993], [0.010073415003716946, 0.01742321066558361, 0.010073415003716946, 0.45405611395835876, 0.5083738565444946], [0.05980437248945236, 0.019223185256123543, 0.19079719483852386, 0.05980437248945236, 0.670370876789093], [0.03744747117161751, 0.39448848366737366, 0.39448848366737366, 0.006998950149863958, 0.16657666862010956], [0.3365817070007324, 0.3070676028728485, 0.14318214356899261, 0.10658425092697144, 0.10658425092697144], [8.252623956650496e-05, 8.252623956650496e-05, 0.2611999213695526, 0.7284749746322632, 0.010160050354897976], [0.007326907012611628, 0.4222317337989807, 0.0012884052703157067, 0.14692118763923645, 0.4222317337989807], [0.11414328962564468, 0.40813133120536804, 0.40813133120536804, 0.004096366930752993, 0.06549771130084991], [0.04206979647278786, 0.4654415249824524, 0.0014344333903864026, 0.4654415249824524, 0.02561270073056221], [0.025525299832224846, 0.025525299832224846, 0.003780202241614461, 0.11917766183614731, 0.8259915113449097], [0.17787428200244904, 0.6160240769386292, 0.016537724062800407, 0.01168958842754364, 0.17787428200244904], [0.06038802117109299, 0.06038802117109299, 0.29335737228393555, 0.0762053057551384, 0.5096613168716431], [0.022085417062044144, 0.010394139215350151, 0.09391899406909943, 0.779682457447052, 0.09391899406909943], [0.8870854377746582, 0.0587223544716835, 0.026365552097558975, 0.0014612271916121244, 0.026365552097558975], [0.022467076778411865, 0.12442905455827713, 0.12442905455827713, 0.6556805372238159, 0.07299430668354034], [0.4575346112251282, 0.014570694416761398, 0.05890260264277458, 0.4575346112251282, 0.011457421816885471], [0.0004296940751373768, 0.1023598164319992, 0.16663050651550293, 0.36528995633125305, 0.36528995633125305], [0.3486310541629791, 0.010481218807399273, 0.47075238823890686, 0.08506768196821213, 0.08506768196821213], [0.16507332026958466, 0.019513247534632683, 0.16507332026958466, 0.4203808009624481, 0.22995921969413757], [0.01854289509356022, 0.5228504538536072, 0.01854289509356022, 0.15576079487800598, 0.2843029499053955], [0.8515912294387817, 0.06709521263837814, 0.03435584530234337, 0.035946477204561234, 0.011011186055839062], [0.054028771817684174, 0.01950092241168022, 0.7831786274909973, 0.08926291763782501, 0.054028771817684174], [0.15676957368850708, 0.0439937487244606, 0.15676957368850708, 0.1105317771434784, 0.5319352746009827], [0.07203473895788193, 0.24308422207832336, 0.572831928730011, 0.07203473895788193, 0.04001437500119209], [0.03379508852958679, 0.25612005591392517, 0.00040391599759459496, 0.25612005591392517, 0.45356085896492004], [0.1344958245754242, 0.21929359436035156, 0.21929359436035156, 0.006088718306273222, 0.42082831263542175], [0.10657985508441925, 0.038292016834020615, 0.8149697184562683, 0.038292016834020615, 0.00186637113802135], [0.16180093586444855, 0.27281877398490906, 0.14126230776309967, 0.2623169720172882, 0.16180093586444855], [0.003877994604408741, 0.4225844144821167, 0.4225844144821167, 0.1339518427848816, 0.017001362517476082], [0.7133251428604126, 0.052292779088020325, 0.052292779088020325, 0.1819184571504593, 0.0001708195632090792], [0.23246429860591888, 0.23246429860591888, 0.17035184800624847, 0.13333508372306824, 0.2313845008611679], [0.3125559687614441, 0.0036967198830097914, 0.3125559687614441, 0.0038851548451930285, 0.36730626225471497], [0.204142227768898, 0.018219003453850746, 0.37986207008361816, 0.01791464537382126, 0.37986207008361816], [0.05188741162419319, 0.03456316143274307, 0.28979238867759705, 0.3118785321712494, 0.3118785321712494], [0.0180551465600729, 0.29785430431365967, 0.4029848277568817, 0.14055287837982178, 0.14055287837982178], [0.03928905725479126, 0.4153124988079071, 0.035797085613012314, 0.4153124988079071, 0.09428882598876953], [0.01015936303883791, 5.81568201596383e-05, 0.08295689523220062, 5.81568201596383e-05, 0.9067674279212952], [0.023643823340535164, 0.023643823340535164, 0.2304459810256958, 0.07288313657045364, 0.6493833661079407], [0.17369897663593292, 0.41107138991355896, 0.0016422190237790346, 0.41107138991355896, 0.0025160613004118204], [0.40719345211982727, 0.40719345211982727, 0.16256342828273773, 0.019089045003056526, 0.00396061223000288], [0.18171338737010956, 0.49969547986984253, 0.1454419493675232, 0.08523866534233093, 0.08791055530309677], [0.00014708972594235092, 0.9073749780654907, 0.0710444301366806, 0.00014708972594235092, 0.021286454051733017], [0.43181365728378296, 0.04694811999797821, 0.057173263281583786, 0.03225128725171089, 0.43181365728378296], [0.22919611632823944, 0.0504678376019001, 0.3492281436920166, 0.18555396795272827, 0.18555396795272827], [0.9123460054397583, 0.0003495400014799088, 0.06826755404472351, 0.009518447332084179, 0.009518447332084179], [0.01698724366724491, 0.939832866191864, 0.01698724366724491, 0.014969952404499054, 0.011222707107663155], [0.20753636956214905, 0.2576430141925812, 0.017151394858956337, 0.5005178451538086, 0.017151394858956337], [0.07237464934587479, 0.07237464934587479, 0.0007997587090358138, 0.006152472924441099, 0.8482983708381653], [0.4767543375492096, 0.006127380765974522, 0.5078888535499573, 0.0031020885799080133, 0.006127380765974522], [0.0507061742246151, 0.2290167361497879, 0.00675363140180707, 0.7067698240280151, 0.00675363140180707], [0.03130058944225311, 0.1548718959093094, 0.7517986297607422, 1.6556534319533966e-05, 0.06201241537928581], [0.33893290162086487, 0.07117463648319244, 0.36479973793029785, 0.1539181023836136, 0.07117463648319244], [0.012110617011785507, 0.006663930602371693, 0.4838353097438812, 0.4838353097438812, 0.013554830104112625], [0.4637569785118103, 0.14859607815742493, 0.102597676217556, 0.1824515461921692, 0.102597676217556], [0.47105151414871216, 0.24959473311901093, 0.07418869435787201, 0.1309763491153717, 0.07418869435787201], [0.006175655871629715, 0.2403322011232376, 0.27755653858184814, 0.006175655871629715, 0.4697599709033966], [0.004566099960356951, 0.018599968403577805, 0.9692812561988831, 0.004566099960356951, 0.0029864958487451077], [0.6863817572593689, 0.2627764642238617, 0.0049950191751122475, 0.022923370823264122, 0.022923370823264122], [0.050743747502565384, 0.44917407631874084, 0.04543986916542053, 0.44917407631874084, 0.0054681864567101], [0.00029806545353494585, 0.3566891551017761, 0.2792871296405792, 0.3566891551017761, 0.007036466151475906], [0.26321324706077576, 6.643711094511673e-05, 0.30880460143089294, 0.30880460143089294, 0.11911111325025558], [0.006663343403488398, 0.0022750934585928917, 0.10848560929298401, 0.006663343403488398, 0.875912606716156], [0.08594320714473724, 0.81712406873703, 0.009734861552715302, 0.08594320714473724, 0.0012546584475785494], [0.003965312615036964, 0.023608561605215073, 0.47893860936164856, 0.47893860936164856, 0.014548891223967075], [0.19479700922966003, 0.36472031474113464, 0.36472031474113464, 0.07347125560045242, 0.00229114992544055], [0.002083299681544304, 0.36771342158317566, 0.2580588459968567, 0.36771342158317566, 0.004431012086570263], [0.9238796234130859, 0.013448241166770458, 2.2847152649774216e-05, 0.03132466971874237, 0.03132466971874237], [0.04406864196062088, 0.45499715209007263, 0.3449888229370117, 0.04406864196062088, 0.1118767261505127], [0.07685286551713943, 0.03544300049543381, 0.07685286551713943, 0.45389747619628906, 0.35695382952690125], [0.00529706384986639, 0.22124066948890686, 0.05005115643143654, 0.5021703839302063, 0.22124066948890686], [0.6533792018890381, 0.08214971423149109, 0.11003117263317108, 0.07229020446538925, 0.08214971423149109], [0.30119988322257996, 0.036156557500362396, 0.46257224678993225, 0.1000356525182724, 0.1000356525182724], [0.0028100721538066864, 0.07480156421661377, 0.6722299456596375, 0.07480156421661377, 0.17535685002803802], [0.3525063693523407, 0.006547634955495596, 0.07307793945074081, 0.2839340567588806, 0.2839340567588806], [0.9066317081451416, 0.0010011526755988598, 0.0010011526755988598, 0.0807897299528122, 0.010576232336461544], [0.9263213872909546, 0.0038188861217349768, 0.05824864283204079, 0.0077922288328409195, 0.0038188861217349768], [0.29468515515327454, 0.0911472961306572, 0.20821544528007507, 0.20821544528007507, 0.19773666560649872], [0.01602800562977791, 0.10864382237195969, 0.01602800562977791, 0.6328919529914856, 0.2264081835746765], [0.038011178374290466, 0.03690182790160179, 0.5428743362426758, 0.3442015051841736, 0.038011178374290466], [0.5303317904472351, 0.0056929015554487705, 0.24277955293655396, 0.11059785634279251, 0.11059785634279251], [0.3459418714046478, 0.0020826240070164204, 0.1412188708782196, 0.1412188708782196, 0.36953771114349365], [0.15747086703777313, 0.038272175937891006, 0.32450026273727417, 0.32228586077690125, 0.15747086703777313], [0.10522489249706268, 0.17470142245292664, 0.5354591012001038, 0.17470142245292664, 0.009913128800690174], [0.4347352683544159, 0.4347352683544159, 0.05231551453471184, 0.0027529748622328043, 0.07546096295118332], [0.12136095017194748, 0.7125837206840515, 0.08243630081415176, 0.001182673149742186, 0.08243630081415176], [2.615238145153853e-06, 0.0005929699400439858, 2.615238145153853e-06, 0.001990429125726223, 0.9974114298820496], [0.35381925106048584, 0.21630381047725677, 0.35381925106048584, 0.0753166601061821, 0.000741010473575443], [0.24607639014720917, 0.004453495144844055, 0.4874902367591858, 0.015903517603874207, 0.24607639014720917], [0.003160242224112153, 0.48750343918800354, 0.3577403128147125, 0.1484357714653015, 0.003160242224112153], [0.031057944521307945, 0.031057944521307945, 0.18657030165195465, 0.044314924627542496, 0.7069989442825317], [0.2834017276763916, 0.10731963068246841, 0.12253084033727646, 0.3642169237136841, 0.12253084033727646], [0.09535972774028778, 0.4397790729999542, 0.25131356716156006, 0.10677381604909897, 0.10677381604909897], [0.2206861823797226, 0.17914612591266632, 0.06460201740264893, 0.314879447221756, 0.2206861823797226], [0.46580588817596436, 0.000309971219394356, 0.32898688316345215, 0.20458726584911346, 0.000309971219394356], [0.15252433717250824, 0.04318072646856308, 0.5447025299072266, 0.21028727293014526, 0.04930516704916954], [0.013791704550385475, 0.04695279151201248, 0.0017504192655906081, 0.0017504192655906081, 0.935754656791687], [0.13957451283931732, 0.4227759838104248, 0.15516948699951172, 0.12731051445007324, 0.15516948699951172], [0.8218924403190613, 0.07013601064682007, 0.09474796056747437, 0.004715767223387957, 0.008507806807756424], [0.09692559391260147, 0.6546083688735962, 0.0008678397280164063, 0.15067262947559357, 0.09692559391260147], [0.003490225877612829, 0.0934680700302124, 0.0934680700302124, 0.02087273821234703, 0.7887008190155029], [0.8073139786720276, 0.039453063160181046, 0.02210024558007717, 0.02210024558007717, 0.10903247445821762], [0.008075306192040443, 0.3637145161628723, 0.20369853079319, 0.20369853079319, 0.22081318497657776], [0.3339030146598816, 0.004879440180957317, 0.2112276405096054, 0.2249949723482132, 0.2249949723482132], [0.37431594729423523, 0.0020922855474054813, 0.011304568499326706, 0.4956018924713135, 0.11668535321950912], [0.054207030683755875, 0.07375193387269974, 0.4526010751724243, 0.34568801522254944, 0.07375193387269974], [0.004788773134350777, 0.9013680815696716, 0.039019953459501266, 0.039019953459501266, 0.015803253278136253], [0.04528515040874481, 0.1651732623577118, 0.018368326127529144, 0.01323078852146864, 0.7579424977302551], [0.6308339834213257, 0.00015802473353687674, 0.12596580386161804, 0.1170763149857521, 0.12596580386161804], [0.081331767141819, 0.07440606504678726, 0.081331767141819, 0.2143503576517105, 0.5485800504684448], [0.037934813648462296, 0.0014907729346305132, 0.443655788898468, 0.5154278874397278, 0.0014907729346305132], [0.3050411641597748, 0.008033988997340202, 0.34336739778518677, 0.34336739778518677, 0.00019002410408575088], [0.15626201033592224, 0.054884664714336395, 0.12017208337783813, 0.5485091805458069, 0.12017208337783813], [0.748576819896698, 0.07424333691596985, 0.05391696095466614, 0.07424333691596985, 0.04901943728327751], [0.6552408337593079, 0.2482096403837204, 0.0015166844241321087, 0.047516416758298874, 0.047516416758298874], [0.7540457248687744, 0.07209809124469757, 0.09700296074151993, 0.004755022004246712, 0.07209809124469757], [0.07902978360652924, 0.00717611750587821, 0.07289457321166992, 0.8337234258651733, 0.00717611750587821], [0.45874181389808655, 0.030619625002145767, 0.031900979578495026, 0.45874181389808655, 0.019995778799057007], [0.049549881368875504, 0.1771485060453415, 0.1771485060453415, 0.5500923991203308, 0.04606073349714279], [0.5285660624504089, 0.19819113612174988, 0.2284577637910843, 0.004052928648889065, 0.040732141584157944], [0.20795243978500366, 0.4517650902271271, 0.004874763078987598, 0.20795243978500366, 0.12745532393455505], [0.3224376142024994, 0.30259042978286743, 0.30259042978286743, 0.06096173822879791, 0.011419713497161865], [0.01379469595849514, 0.006240955553948879, 0.04692941531538963, 0.8861055374145508, 0.04692941531538963], [0.9466314911842346, 0.005622861906886101, 0.018942425027489662, 0.018942425027489662, 0.009860786609351635], [0.03729761019349098, 0.1579539179801941, 0.24041375517845154, 0.5036637783050537, 0.060670968145132065], [0.8892801403999329, 0.03928440809249878, 0.01788521558046341, 0.03566502407193184, 0.01788521558046341], [0.005762305576354265, 0.009332172572612762, 0.2571618854999542, 0.36387184262275696, 0.36387184262275696], [0.6520868539810181, 6.834442319814116e-05, 0.019931741058826447, 0.16395655274391174, 0.16395655274391174], [0.04187503084540367, 0.0713672786951065, 0.04187503084540367, 0.7117984890937805, 0.13308410346508026], [0.018702702596783638, 0.14433933794498444, 0.018702702596783638, 0.15509995818138123, 0.663155198097229], [0.3492724895477295, 0.3492724895477295, 0.15271638333797455, 0.06160273402929306, 0.0871359184384346], [0.20006689429283142, 0.1445770561695099, 0.08799249678850174, 0.08799249678850174, 0.479371041059494], [0.5024321675300598, 0.057640329003334045, 0.11567538231611252, 0.11567538231611252, 0.2085767537355423], [2.7111722374684177e-05, 0.3782200813293457, 0.23090429604053497, 0.3782200813293457, 0.012628444470465183], [0.0009590241825208068, 0.033745285123586655, 0.005697658285498619, 0.009968262165784836, 0.9496296644210815], [0.07080531865358353, 0.6686457395553589, 0.08012261241674423, 0.07080531865358353, 0.10962101817131042], [0.021240878850221634, 0.1450001746416092, 0.0012203133665025234, 0.6875384449958801, 0.1450001746416092], [0.014121441170573235, 0.19339439272880554, 0.014121441170573235, 0.5877218246459961, 0.19064083695411682], [0.0597139410674572, 0.463853657245636, 0.2285526841878891, 0.019327079877257347, 0.2285526841878891], [0.33794447779655457, 0.30352312326431274, 0.009160732850432396, 0.04584846273064613, 0.30352312326431274], [0.0009479316067881882, 0.3654484152793884, 0.0009479316067881882, 0.2901805639266968, 0.34247520565986633], [0.13044889271259308, 3.068524529226124e-05, 0.011068676598370075, 3.068524529226124e-05, 0.8584210276603699], [5.484528173838044e-06, 0.36723875999450684, 0.00104817864485085, 0.26446881890296936, 0.36723875999450684], [0.061908431351184845, 0.006849018391221762, 0.006849018391221762, 0.09030136466026306, 0.8340921401977539], [0.30166980624198914, 0.6673049926757812, 0.008197997696697712, 0.008197997696697712, 0.014629192650318146], [0.5242239832878113, 0.01469452679157257, 0.43554213643074036, 0.01469452679157257, 0.010844822973012924], [0.4918754994869232, 0.20584215223789215, 0.07657001167535782, 0.20584215223789215, 0.019870135933160782], [0.0029121979605406523, 0.4093988239765167, 0.4093988239765167, 0.04947439581155777, 0.12881579995155334], [0.4613398015499115, 0.4613398015499115, 0.0758160725235939, 0.0005500278784893453, 0.0009542664629407227], [0.008265168406069279, 0.027104614302515984, 0.027104614302515984, 0.22370648384094238, 0.7138190865516663], [0.40595749020576477, 0.15290963649749756, 0.14193245768547058, 0.15290963649749756, 0.14629076421260834], [0.00021323423425201327, 0.02018696628510952, 0.015149549581110477, 0.015149549581110477, 0.9493007659912109], [0.027354616671800613, 0.3406079411506653, 0.05384821444749832, 0.28909462690353394, 0.28909462690353394], [0.029010768979787827, 0.022954223677515984, 0.47252750396728516, 0.0029799945186823606, 0.47252750396728516], [0.00044722508755512536, 0.3638467788696289, 0.027198806405067444, 0.2446604073047638, 0.3638467788696289], [0.5180604457855225, 0.3199489712715149, 0.003493859665468335, 0.07125566154718399, 0.0872410237789154], [0.123550184071064, 0.30752527713775635, 0.051981791853904724, 0.30752527713775635, 0.20941750705242157], [0.3515035808086395, 0.279379665851593, 0.08834179490804672, 0.001395308063365519, 0.279379665851593], [0.05049353465437889, 0.1681331843137741, 0.7800063490867615, 0.0006834433297626674, 0.0006834433297626674], [0.23611435294151306, 0.23611435294151306, 0.08781853318214417, 0.4086908996105194, 0.03126184642314911], [0.3370859622955322, 0.0006970742251724005, 0.06584406644105911, 0.25928688049316406, 0.3370859622955322], [0.18747016787528992, 0.05386994779109955, 0.4355303943157196, 0.18747016787528992, 0.13565924763679504], [0.08100539445877075, 0.7448520660400391, 0.0516609326004982, 0.08100539445877075, 0.04147624224424362], [0.3405209183692932, 0.00024364341516047716, 0.3405209183692932, 0.03381409868597984, 0.284900426864624], [0.13281162083148956, 0.06280042231082916, 0.6262131333351135, 0.05534498393535614, 0.12282978743314743], [0.04012615606188774, 0.5196083188056946, 0.04012615606188774, 0.034677594900131226, 0.3654618263244629], [0.06040219962596893, 0.0016784637700766325, 0.6386300325393677, 0.2547009289264679, 0.04458834230899811], [0.9026446342468262, 0.0008953198557719588, 0.006406375672668219, 0.04502682015299797, 0.04502682015299797], [0.08814552426338196, 0.2493491768836975, 0.2493491768836975, 0.00819301512092352, 0.4049631655216217], [0.058538634330034256, 0.13073639571666718, 0.6372222900390625, 0.13073639571666718, 0.04276633262634277], [0.03784779831767082, 0.9217926263809204, 0.01721457578241825, 0.01721457578241825, 0.005930378567427397], [0.3760952949523926, 0.06850530207157135, 0.07112481445074081, 0.07112481445074081, 0.4131496846675873], [0.40779098868370056, 0.40779098868370056, 0.051060937345027924, 0.1324435919523239, 0.0009135334985330701], [0.0043529001995921135, 0.02128249779343605, 0.3438316583633423, 0.315266489982605, 0.315266489982605], [0.006273309700191021, 0.006273309700191021, 0.004314871039241552, 0.213212788105011, 0.7699256539344788], [0.043337274342775345, 0.45813921093940735, 0.005862878635525703, 0.034521397203207016, 0.45813921093940735], [0.36093997955322266, 0.02426517754793167, 0.2965394854545593, 0.021715866401791573, 0.2965394854545593], [0.26388534903526306, 0.704330325126648, 5.2692466852022335e-05, 5.2692466852022335e-05, 0.031678956001996994], [0.01300106942653656, 0.4979795515537262, 0.14543966948986053, 0.14543966948986053, 0.19814002513885498], [0.05237720534205437, 0.015529656782746315, 0.8450012803077698, 0.05237720534205437, 0.0347147062420845], [0.008497925475239754, 0.05573961138725281, 0.26977601647377014, 0.3962104022502899, 0.26977601647377014], [0.35935255885124207, 0.2547844648361206, 0.2547844648361206, 0.025546371936798096, 0.10553215444087982], [0.24251089990139008, 0.42317280173301697, 0.008221333846449852, 0.24251089990139008, 0.08358407020568848], [0.014246921055018902, 0.7118701934814453, 0.02254955656826496, 0.2370864301919937, 0.014246921055018902], [0.04725383594632149, 0.08417698740959167, 0.0014155892422422767, 0.7829766273498535, 0.08417698740959167], [0.09150314331054688, 0.09150314331054688, 0.005886448081582785, 0.8087158203125, 0.002391465473920107], [0.5513401031494141, 8.651102689327672e-05, 0.4473285675048828, 0.0011196378618478775, 0.0001252643414773047], [0.35434985160827637, 0.00023497865186072886, 0.004818689078092575, 0.286246657371521, 0.35434985160827637], [0.01994010992348194, 0.01994010992348194, 0.6954740285873413, 0.07307923585176468, 0.19156648218631744], [0.05538102984428406, 0.20664510130882263, 0.5008909702301025, 0.20664510130882263, 0.030437832698225975], [0.2986394166946411, 0.0019579632207751274, 0.6834070682525635, 0.01403758767992258, 0.0019579632207751274], [0.12449178844690323, 0.12449178844690323, 0.022275002673268318, 0.6978862285614014, 0.030855149030685425], [0.14738763868808746, 0.6927996277809143, 0.14738763868808746, 0.0037525449879467487, 0.008672475814819336], [0.2725638449192047, 0.654261589050293, 0.039547208696603775, 0.016813678666949272, 0.016813678666949272], [0.01873961091041565, 0.30506739020347595, 0.02254091203212738, 0.33214467763900757, 0.32150739431381226], [0.0012690770672634244, 0.01512405090034008, 0.0012690770672634244, 0.006048010662198067, 0.9762899279594421], [0.14485964179039001, 0.016163865104317665, 0.5916451215744019, 0.03305699676275253, 0.2142743617296219], [0.30521392822265625, 0.30521392822265625, 0.027400808408856392, 0.2330062836408615, 0.12916508316993713], [0.08330578356981277, 0.00043987075332552195, 0.8115735650062561, 0.08330578356981277, 0.021375004202127457], [0.47172337770462036, 0.006388583220541477, 0.05005593225359917, 0.00010869225661735982, 0.47172337770462036], [0.02702728472650051, 0.06413546204566956, 0.02702728472650051, 0.8509535193443298, 0.030856508761644363], [0.7698144316673279, 0.0540386363863945, 0.09146276861429214, 0.042342014610767365, 0.042342014610767365], [0.00804304052144289, 0.6631267070770264, 0.026559917256236076, 0.27571049332618713, 0.026559917256236076], [0.03057646006345749, 0.09657454490661621, 0.0015573580749332905, 0.7747170329093933, 0.09657454490661621], [0.0027892484795302153, 0.06270400434732437, 0.13403290510177612, 0.7976845502853394, 0.0027892484795302153], [0.013015075586736202, 0.007348610088229179, 0.007348610088229179, 0.877982497215271, 0.09430523961782455], [0.3646743893623352, 0.11642390489578247, 0.054993655532598495, 0.09923357516527176, 0.3646743893623352], [0.784351646900177, 0.07405128329992294, 0.05063436180353165, 0.01691148243844509, 0.07405128329992294], [0.006161524914205074, 0.08765597641468048, 0.581808865070343, 0.16218681633472443, 0.16218681633472443], [0.0003273914335295558, 0.00045237166341394186, 0.06774695217609406, 0.46573662757873535, 0.46573662757873535], [0.002516446402296424, 2.1047391783213243e-05, 0.3083783686161041, 0.11874569207429886, 0.5703384876251221], [0.8674747943878174, 0.033045440912246704, 0.033045440912246704, 0.06349636614322662, 0.002937988145276904], [0.42696288228034973, 0.006760289426892996, 0.18801476061344147, 0.18913105130195618, 0.18913105130195618], [0.009923592209815979, 0.03763751685619354, 0.010759052820503712, 0.009923592209815979, 0.9317562580108643], [0.2084151804447174, 0.5882987380027771, 0.10523229092359543, 0.04902688041329384, 0.04902688041329384], [0.18054260313510895, 0.06120605394244194, 0.10824348032474518, 0.3250039517879486, 0.3250039517879486], [0.04556277394294739, 0.04556277394294739, 0.520776629447937, 0.23764263093471527, 0.15045520663261414], [0.14235544204711914, 0.035695791244506836, 0.4702894687652588, 0.035695791244506836, 0.3159635066986084], [6.395742821041495e-05, 5.988428893033415e-05, 0.0002894366916734725, 6.395742821041495e-05, 0.9995228052139282], [0.4546409845352173, 0.4546409845352173, 0.046250369399785995, 0.01146166492253542, 0.033005960285663605], [0.00847818236798048, 0.0006854715174995363, 0.7554817795753479, 0.0006854715174995363, 0.23466914892196655], [0.8650403618812561, 0.039553556591272354, 0.039690207690000534, 0.039553556591272354, 0.016162360087037086], [0.35341283679008484, 0.019682325422763824, 0.18986228108406067, 0.35341283679008484, 0.08362968266010284], [0.23619124293327332, 0.23619124293327332, 0.40212032198905945, 0.06540611386299133, 0.0600910410284996], [0.15325698256492615, 0.005275118164718151, 0.15325698256492615, 0.016279306262731552, 0.6719316244125366], [0.09848066419363022, 0.8460843563079834, 0.00014614115934818983, 0.00014614115934818983, 0.05514271929860115], [0.0739026665687561, 0.2590210437774658, 0.22548037767410278, 0.18257492780685425, 0.2590210437774658], [0.12077400833368301, 0.09469843655824661, 0.09469843655824661, 0.37525615096092224, 0.3145729601383209], [0.15452009439468384, 0.15452009439468384, 0.4518775939941406, 0.10488353669643402, 0.13419869542121887], [0.00010747624764917418, 0.00010747624764917418, 0.05936029553413391, 0.030762167647480965, 0.9096625447273254], [0.00028774625388905406, 0.00028774625388905406, 0.9805164933204651, 0.010041363537311554, 0.008866562508046627], [0.11278367787599564, 0.022094326093792915, 0.11278367787599564, 0.005751126911491156, 0.7465870976448059], [0.01514577679336071, 0.0379614494740963, 0.44958409667015076, 0.44958409667015076, 0.04772457107901573], [0.31643614172935486, 0.35321810841560364, 0.09088029712438583, 0.02066527120769024, 0.2188001275062561], [0.3088148534297943, 0.3088148534297943, 0.017425430938601494, 0.009750699624419212, 0.35519421100616455], [0.09546910226345062, 0.38257336616516113, 0.10452913492918015, 0.38257336616516113, 0.034854989498853683], [0.010301155038177967, 0.3345976769924164, 0.3345976769924164, 0.14951245486736298, 0.17099103331565857], [0.006260587368160486, 0.35592135787010193, 0.6287983655929565, 0.006260587368160486, 0.0027591425459831953], [0.06953895837068558, 0.8576783537864685, 0.014752330258488655, 0.04327806457877159, 0.014752330258488655], [0.0017441249219700694, 0.07704940438270569, 0.005739062093198299, 0.9137232303619385, 0.0017441249219700694], [0.41261813044548035, 0.004846607800573111, 0.41261813044548035, 0.020671702921390533, 0.1492454558610916], [0.3909340798854828, 0.09254936128854752, 0.3909340798854828, 0.05786558985710144, 0.06771697849035263], [0.6425387859344482, 0.04750686138868332, 0.030449209734797478, 0.030449209734797478, 0.2490559071302414], [0.03504478931427002, 0.5327811241149902, 0.03504478931427002, 0.1471368372440338, 0.2499925047159195], [0.6551389694213867, 0.0017202520975843072, 0.0017202520975843072, 0.25714248418807983, 0.08427799493074417], [0.017886092886328697, 0.07876225560903549, 0.25064682960510254, 0.07876225560903549, 0.5739425420761108], [0.085165835916996, 0.16388128697872162, 0.0072625987231731415, 0.37184515595436096, 0.37184515595436096], [0.12859682738780975, 0.2899457514286041, 0.027111606672406197, 0.4257490336894989, 0.12859682738780975], [0.12893183529376984, 0.4494805932044983, 0.24733436107635498, 0.12893183529376984, 0.045321330428123474], [0.07974497973918915, 0.3705489933490753, 0.549488365650177, 0.00010883054346777499, 0.00010883054346777499], [0.7471624612808228, 0.02598571591079235, 0.000356826203642413, 0.11324750632047653, 0.11324750632047653], [0.002238562563434243, 0.07178150862455368, 0.0029705616179853678, 0.002238562563434243, 0.9207708239555359], [0.05115656182169914, 0.3153733015060425, 0.18989834189414978, 0.3153733015060425, 0.12819848954677582], [0.061466459184885025, 0.061466459184885025, 0.8664777874946594, 0.009827308356761932, 0.0007620700635015965], [0.0019124567043036222, 0.11959008872509003, 0.11959008872509003, 0.756213903427124, 0.002693501766771078], [0.23699495196342468, 0.23699495196342468, 0.01017959974706173, 0.5051569938659668, 0.01067353319376707], [0.02401307411491871, 0.8923320174217224, 0.05531878396868706, 0.02401307411491871, 0.004323142115026712], [0.01672418974339962, 0.009270833805203438, 0.12432532012462616, 0.01672418974339962, 0.8329554796218872], [0.8619658946990967, 0.006582609843462706, 0.006582609843462706, 0.021865088492631912, 0.10300371050834656], [0.0015426776371896267, 0.0015426776371896267, 0.027928730472922325, 0.6057031154632568, 0.36328282952308655], [0.2915043234825134, 0.2915043234825134, 0.11490285396575928, 0.0010922563960775733, 0.30099624395370483], [0.05840301141142845, 0.004307495430111885, 0.010709057562053204, 0.9222730398178101, 0.004307495430111885], [0.0065318867564201355, 8.265814540209249e-05, 0.8295145034790039, 8.265814540209249e-05, 0.16378825902938843], [0.3953636884689331, 0.014477282762527466, 0.438029944896698, 0.13765178620815277, 0.014477282762527466], [0.8272842764854431, 0.05607285723090172, 0.004113640170544386, 0.05607285723090172, 0.05645642802119255], [0.013309280388057232, 0.013309280388057232, 0.001803732244297862, 0.3089073598384857, 0.662670373916626], [0.4357239603996277, 0.11248838901519775, 0.4357239603996277, 0.0004119764198549092, 0.015651782974600792], [0.6643823981285095, 0.10647466033697128, 0.19642184674739838, 0.016360513865947723, 0.016360513865947723], [0.16069340705871582, 0.4272403419017792, 0.14879770576953888, 0.009914976544678211, 0.2533535659313202], [0.12245539575815201, 0.007876516319811344, 0.30963629484176636, 0.2503955066204071, 0.30963629484176636], [0.005582126788794994, 0.002327033318579197, 0.026884369552135468, 0.005582126788794994, 0.9596244692802429], [0.46093228459358215, 0.15761223435401917, 0.019282786175608635, 0.2777467668056488, 0.0844259038567543], [0.07289132475852966, 0.001561107230372727, 0.01085207611322403, 0.001561107230372727, 0.9131343364715576], [0.1390354335308075, 0.07928744703531265, 0.1570138931274414, 0.3123316168785095, 0.3123316168785095], [0.011510982178151608, 0.10727354884147644, 0.1263989508152008, 0.1263989508152008, 0.6284175515174866], [0.03503822162747383, 0.42232632637023926, 4.489859929890372e-05, 0.42232632637023926, 0.12026418745517731], [0.5413590669631958, 0.2164267599582672, 0.2164267599582672, 0.012576350010931492, 0.013211052864789963], [0.012383642606437206, 0.0059678079560399055, 0.48714107275009155, 0.48714107275009155, 0.0073664383962750435], [0.0012476133415475488, 0.4120260775089264, 0.4120260775089264, 0.004338924773037434, 0.17036131024360657], [0.3646619915962219, 0.2609977424144745, 0.004763324279338121, 0.3646619915962219, 0.00491487979888916], [0.46873173117637634, 0.330393522977829, 0.006238099653273821, 0.18216292560100555, 0.012473751790821552], [0.0002483499702066183, 0.016028326004743576, 0.0698433592915535, 0.8440365791320801, 0.0698433592915535], [0.24660474061965942, 0.2264142632484436, 0.24660474061965942, 0.008264637552201748, 0.2721116244792938], [0.14207640290260315, 0.027735799551010132, 0.04624474421143532, 0.39197152853012085, 0.39197152853012085], [0.2864539325237274, 0.036229208111763, 0.2864539325237274, 0.1921762377023697, 0.19868668913841248], [0.18767619132995605, 0.001271258806809783, 0.16106688976287842, 0.488918662071228, 0.16106688976287842], [0.08823949098587036, 0.22400492429733276, 0.08040159940719604, 0.38334906101226807, 0.22400492429733276], [0.8148720264434814, 0.002170395804569125, 0.1390576809644699, 0.04359286651015282, 0.00030700035858899355], [0.3547787666320801, 0.020747166126966476, 0.15357360243797302, 0.020747166126966476, 0.45015326142311096], [0.3272356688976288, 0.06402121484279633, 0.0006153529975563288, 0.3272356688976288, 0.2808920741081238], [0.2430647611618042, 0.463422954082489, 0.2430647611618042, 0.05031399428844452, 0.00013353473332244903], [0.5456170439720154, 0.01010675448924303, 0.19478633999824524, 0.05470344424247742, 0.19478633999824524], [0.02844618260860443, 0.06411002576351166, 0.02844618260860443, 0.2906552851200104, 0.5883423089981079], [0.0489744134247303, 0.5669922232627869, 0.0489744134247303, 0.08449636399745941, 0.2505625784397125], [0.18959099054336548, 0.01378887239843607, 0.01378887239843607, 0.00829851534217596, 0.7745327353477478], [0.00010140689118998125, 0.12021145224571228, 0.4684026539325714, 0.4111831486225128, 0.00010140689118998125], [0.001849195803515613, 0.34701985120773315, 0.001849195803515613, 0.26049691438674927, 0.38878482580184937], [0.008837095461785793, 0.480168879032135, 0.04345274344086647, 0.04629494249820709, 0.42124637961387634], [0.6228164434432983, 0.013804009184241295, 8.577996777603403e-05, 0.013804009184241295, 0.3494897484779358], [0.49364346265792847, 0.05376890301704407, 0.3964419960975647, 0.0023768008686602116, 0.05376890301704407], [0.020402319729328156, 0.4649621844291687, 0.016534533351659775, 0.033138666301965714, 0.4649621844291687], [0.28606942296028137, 0.025382187217473984, 0.06594852358102798, 0.28606942296028137, 0.336530476808548], [0.45071327686309814, 0.45071327686309814, 0.04536718875169754, 0.05142119899392128, 0.0017850697040557861], [0.20921851694583893, 0.029356935992836952, 0.384721577167511, 0.20921851694583893, 0.16748447716236115], [0.49313831329345703, 0.004643842577934265, 0.008998319506645203, 8.12262442195788e-05, 0.49313831329345703], [0.05276783928275108, 0.1792609542608261, 0.2917945086956024, 0.2917945086956024, 0.1843821257352829], [0.02240455523133278, 0.02240455523133278, 0.29692089557647705, 0.23724444210529327, 0.4210255444049835], [0.13259480893611908, 0.6667808890342712, 0.020480360835790634, 0.09007196128368378, 0.09007196128368378], [0.018565339967608452, 0.39212244749069214, 0.39212244749069214, 0.07704862952232361, 0.12014111876487732], [0.0007054631132632494, 0.03317611292004585, 0.19656315445899963, 0.5729921460151672, 0.19656315445899963], [0.3310524821281433, 0.3335411548614502, 0.3335411548614502, 0.0014636637642979622, 0.00040160652133636177], [0.04737502336502075, 0.09929510951042175, 0.7912207841873169, 0.02293836884200573, 0.0391707643866539], [0.09901168942451477, 0.09901168942451477, 0.25862154364585876, 0.01589544303715229, 0.5274596214294434], [0.09780550748109818, 0.6220623850822449, 0.013918416574597359, 0.09780550748109818, 0.16840825974941254], [0.030048752203583717, 0.8953652381896973, 0.039019446820020676, 0.017783310264348984, 0.017783310264348984], [0.3985198736190796, 0.04789433255791664, 0.0022331103682518005, 0.5034583806991577, 0.04789433255791664], [0.001095031388103962, 0.9682839512825012, 0.026766523718833923, 0.001095031388103962, 0.002759366761893034], [0.9280275702476501, 0.0004475520399864763, 0.0004475520399864763, 0.06921474635601044, 0.0018625572556629777], [0.14850309491157532, 0.44947001338005066, 0.19848783314228058, 0.005051236134022474, 0.19848783314228058], [0.19430404901504517, 0.00013537911581806839, 0.00013537911581806839, 0.19589416682720184, 0.6095309853553772], [0.2426607757806778, 0.01135947648435831, 0.2426607757806778, 0.49604541063308716, 0.007273622322827578], [0.36083731055259705, 0.02311827801167965, 0.2181909680366516, 0.37473514676094055, 0.02311827801167965], [0.03833511471748352, 0.09166152775287628, 0.0015714603941887617, 0.8300967812538147, 0.03833511471748352], [0.7433698177337646, 0.0011866933200508356, 0.24843323230743408, 0.005823568440973759, 0.0011866933200508356], [0.3081819713115692, 0.37710368633270264, 0.3081819713115692, 0.0064191860146820545, 0.00011314603762002662], [0.27389615774154663, 0.044773928821086884, 0.2549591660499573, 0.15247462689876556, 0.27389615774154663], [0.14035101234912872, 0.38160088658332825, 0.06163664907217026, 0.034810617566108704, 0.38160088658332825], [0.004035924095660448, 5.040644100517966e-05, 5.040644100517966e-05, 0.9947456121444702, 0.0011176317930221558], [0.36016231775283813, 0.0022681469563394785, 0.4215807020664215, 0.2137206494808197, 0.0022681469563394785], [0.050882190465927124, 0.03394926339387894, 0.040585316717624664, 0.823701024055481, 0.050882190465927124], [0.14074039459228516, 0.0029192829970270395, 0.14074039459228516, 0.005397730972617865, 0.7102022171020508], [0.22127249836921692, 0.33652782440185547, 0.33652782440185547, 0.0009855058742687106, 0.10468633472919464], [0.10729283839464188, 0.10729283839464188, 0.3300324082374573, 0.034153394401073456, 0.42122846841812134], [0.7694905400276184, 0.004628343041986227, 0.07132754474878311, 0.08322601020336151, 0.07132754474878311], [0.023144995793700218, 0.20318526029586792, 0.5569944381713867, 0.013490049168467522, 0.20318526029586792], [0.6573674082756042, 0.03367064520716667, 0.12961170077323914, 0.04973845183849335, 0.12961170077323914], [0.12515020370483398, 0.00031420058803632855, 0.12515020370483398, 0.6150291562080383, 0.1343563050031662], [0.014558413065969944, 0.005432426929473877, 0.7795144319534302, 0.1950623244047165, 0.005432426929473877], [0.06841782480478287, 0.16684748232364655, 0.011806320399045944, 0.6845105886459351, 0.06841782480478287], [0.0026990226469933987, 0.27079901099205017, 0.3406445384025574, 0.3406445384025574, 0.045212868601083755], [0.20275624096393585, 0.030223311856389046, 0.20275624096393585, 0.3846896290779114, 0.17957451939582825], [0.8191379308700562, 0.054003410041332245, 0.01123872585594654, 0.042012885212898254, 0.07360710203647614], [0.19805513322353363, 0.08859653770923615, 0.4984130859375, 0.08859653770923615, 0.12633873522281647], [0.161338210105896, 0.2283756136894226, 0.3035595715045929, 0.3035595715045929, 0.0031670373864471912], [0.42874759435653687, 0.42874759435653687, 0.1215735673904419, 0.00015317097131628543, 0.020778009667992592], [0.3705288767814636, 0.2341982126235962, 0.04553970322012901, 0.2341982126235962, 0.11553496867418289], [0.028099413961172104, 0.1353314071893692, 0.6315878033638, 0.06964992731809616, 0.1353314071893692], [0.45589855313301086, 0.13873767852783203, 0.19816365838050842, 0.19816365838050842, 0.009036368690431118], [0.07892031967639923, 0.04842851683497429, 0.04842851683497429, 0.13007065653800964, 0.6941520571708679], [0.49276450276374817, 0.28683656454086304, 0.08693217486143112, 0.046534594148397446, 0.08693217486143112], [0.9181725382804871, 0.01111564226448536, 0.01587606966495514, 0.01587606966495514, 0.038959626108407974], [0.23360423743724823, 0.7628453969955444, 0.00037055567372590303, 0.0028092965949326754, 0.00037055567372590303], [0.2835204303264618, 0.6014194488525391, 0.0954674780368805, 0.0097963260486722, 0.0097963260486722], [0.04823935031890869, 0.04823935031890869, 0.27352333068847656, 0.5487728118896484, 0.08122508972883224], [0.05102856084704399, 0.8555498123168945, 0.036778371781110764, 0.005614681169390678, 0.05102856084704399], [0.1605009287595749, 0.5201916694641113, 0.1605009287595749, 0.002229176228865981, 0.15657728910446167], [0.1880996823310852, 0.2180672436952591, 0.1860249638557434, 0.2197084128856659, 0.1880996823310852], [0.006170766428112984, 0.050892021507024765, 0.0017336895689368248, 0.9394698739051819, 0.0017336895689368248], [0.2922026515007019, 0.6413511037826538, 0.0244497898966074, 0.02099822834134102, 0.02099822834134102], [0.008113667368888855, 0.029587240889668465, 0.04821047559380531, 0.04821047559380531, 0.8658781051635742], [0.0024422998540103436, 0.9676560163497925, 0.006029867101460695, 0.006029867101460695, 0.01784198358654976], [0.1618584841489792, 0.015394461341202259, 0.678780734539032, 0.005221787840127945, 0.13874445855617523], [0.09862133115530014, 0.0007709028432145715, 0.31543824076652527, 0.48654815554618835, 0.09862133115530014], [0.0015819799154996872, 0.01062770001590252, 0.002439752919599414, 0.5292631387710571, 0.4560874402523041], [0.13480576872825623, 0.07599935680627823, 0.21824254095554352, 0.13480576872825623, 0.4361465573310852], [0.06186748296022415, 0.26468345522880554, 0.06186748296022415, 0.57881098985672, 0.032770559191703796], [0.0022033245768398046, 0.14783348143100739, 0.004444583784788847, 0.14783348143100739, 0.697685182094574], [0.12572935223579407, 0.12572935223579407, 0.0001338733418378979, 0.009416881017386913, 0.7389904260635376], [0.34551483392715454, 0.020794609561562538, 0.27579236030578613, 0.34551483392715454, 0.012383325025439262], [0.03980284184217453, 0.03636845201253891, 0.03636845201253891, 0.1923227310180664, 0.6951375007629395], [0.09535366296768188, 0.021099554374814034, 0.05607982724905014, 0.41373345255851746, 0.41373345255851746], [0.10605452209711075, 0.10605452209711075, 0.051084596663713455, 0.5778568983078003, 0.15894944965839386], [0.3515363037586212, 0.12400300800800323, 0.3515363037586212, 0.1580798327922821, 0.014844548888504505], [0.07845062017440796, 0.04645715653896332, 0.817879319190979, 0.056034255772829056, 0.0011785972164943814], [0.0455932691693306, 0.10961903631687164, 0.0455932691693306, 0.4154684245586395, 0.38372600078582764], [0.010644684545695782, 0.12859897315502167, 0.7992408275604248, 0.05087082087993622, 0.010644684545695782], [0.4411250948905945, 0.014133209362626076, 0.014133209362626076, 0.15251249074935913, 0.37809595465660095], [0.08025982230901718, 0.09760250896215439, 0.6877036690711975, 0.0368315614759922, 0.09760250896215439], [0.14130966365337372, 0.313798725605011, 0.212800070643425, 0.1192915067076683, 0.212800070643425], [0.3952082097530365, 0.009370592422783375, 0.0037703050766140223, 0.0037703050766140223, 0.5878806114196777], [0.024162352085113525, 8.536790846846998e-05, 0.697563111782074, 0.2777216136455536, 0.00046753580681979656], [7.903615914983675e-05, 0.7498911023139954, 7.903615914983675e-05, 0.13020098209381104, 0.11974984407424927], [0.21684002876281738, 0.027099139988422394, 0.18314778804779053, 0.3560730218887329, 0.21684002876281738], [0.05632481724023819, 0.29939207434654236, 0.1553374081850052, 0.1553374081850052, 0.33360832929611206], [0.026353593915700912, 0.70006263256073, 0.09193427860736847, 0.11027706414461136, 0.07137250155210495], [0.3672240674495697, 0.10098423063755035, 0.16057750582695007, 0.3672240674495697, 0.003990203142166138], [0.027400420978665352, 0.030378147959709167, 0.4700855016708374, 0.4700855016708374, 0.0020504172425717115], [0.05855569243431091, 0.2658182978630066, 0.05855569243431091, 0.023036761209368706, 0.5940335392951965], [0.24676573276519775, 0.0006690132431685925, 0.07029245793819427, 0.4355071485042572, 0.24676573276519775], [0.00023543293355032802, 0.00947547797113657, 0.4412252902984619, 0.4412252902984619, 0.10783849656581879], [0.07695040851831436, 0.001723526045680046, 0.0009565027430653572, 0.8434191346168518, 0.07695040851831436], [0.018079597502946854, 0.018079597502946854, 0.4354464113712311, 0.5158538222312927, 0.012540580704808235], [0.39970168471336365, 0.16810709238052368, 0.4215601980686188, 0.005315524060279131, 0.005315524060279131], [0.2821486294269562, 0.052939124405384064, 0.17266227304935455, 0.21010135114192963, 0.2821486294269562], [0.37591636180877686, 0.37591636180877686, 0.0003730875323526561, 0.21359367668628693, 0.034200578927993774], [0.5729274749755859, 0.0027261499781161547, 0.1285318285226822, 0.1285318285226822, 0.16728271543979645], [0.2510501742362976, 0.2635291814804077, 0.013100020587444305, 0.22127042710781097, 0.2510501742362976], [0.1300884187221527, 0.0014553545042872429, 0.0004812967963516712, 0.1300884187221527, 0.7378864288330078], [0.39011654257774353, 0.1013084277510643, 0.058711085468530655, 0.059747397899627686, 0.39011654257774353], [0.006607748102396727, 0.20190709829330444, 0.023410186171531677, 0.20190709829330444, 0.566167950630188], [0.6645210981369019, 0.12696704268455505, 0.05933426320552826, 0.05933426320552826, 0.08984337747097015], [0.8764785528182983, 0.11126358062028885, 0.010320533998310566, 0.0009686620905995369, 0.0009686620905995369], [0.06607342511415482, 0.11187821626663208, 0.709777295589447, 0.0003928034275304526, 0.11187821626663208], [0.32229918241500854, 0.013833640143275261, 0.30180272459983826, 0.32229918241500854, 0.03976524993777275], [0.4131164252758026, 0.074221670627594, 0.09579502046108246, 0.20843344926834106, 0.20843344926834106], [0.914143443107605, 0.007032397668808699, 0.03934474289417267, 0.03934474289417267, 0.0001346963836112991], [0.016723960638046265, 0.064053475856781, 2.6140698537346907e-05, 0.064053475856781, 0.8551430702209473], [0.0016644314164295793, 0.08949727565050125, 0.058944739401340485, 0.0016644314164295793, 0.848229169845581], [0.5638107657432556, 0.025830429047346115, 0.025830429047346115, 0.2191583514213562, 0.16537001729011536], [0.34061792492866516, 0.015296009369194508, 0.34061792492866516, 0.08904467523097992, 0.21442346274852753], [0.8477436304092407, 0.02624715492129326, 0.04544440284371376, 0.04544440284371376, 0.0351203978061676], [0.3172484338283539, 0.049311090260744095, 0.3149120509624481, 0.001279979245737195, 0.3172484338283539], [4.943620660924353e-05, 0.04490184411406517, 0.060024429112672806, 0.060024429112672806, 0.8349998593330383], [0.030150404199957848, 0.08145738393068314, 0.2889147102832794, 0.5693270564079285, 0.030150404199957848], [0.3751814365386963, 0.19468528032302856, 0.05326002091169357, 0.001691842800937593, 0.3751814365386963], [0.19871431589126587, 0.32565954327583313, 0.32565954327583313, 0.09735985100269318, 0.0526067279279232], [0.06622166931629181, 0.011866586282849312, 0.8516832590103149, 0.06622166931629181, 0.004006887320429087], [0.0014757025055587292, 0.002122910926118493, 0.0009880029829218984, 0.9932904243469238, 0.002122910926118493], [0.0026819189079105854, 0.4488877058029175, 0.07997920364141464, 0.4488877058029175, 0.019563447684049606], [0.3025185167789459, 0.02417149767279625, 0.5905014276504517, 0.02417149767279625, 0.05863703414797783], [0.051891956478357315, 0.1289132684469223, 0.3959214687347412, 0.027351830154657364, 0.3959214687347412], [0.08766119182109833, 0.3461361229419708, 0.08766119182109833, 0.05969483032822609, 0.41884660720825195], [0.578153669834137, 0.020365647971630096, 0.024254247546195984, 0.020365647971630096, 0.35686081647872925], [0.17431935667991638, 0.014450475573539734, 0.006931764539331198, 0.7973666191101074, 0.006931764539331198], [0.29599887132644653, 0.007717831060290337, 0.011089854873716831, 0.007717831060290337, 0.67747563123703], [0.0004002198693342507, 0.9919628500938416, 0.0037343590520322323, 0.0004002198693342507, 0.003502492792904377], [0.011862462386488914, 0.43178579211235046, 0.43178579211235046, 0.08900483697652817, 0.035561077296733856], [0.39687666296958923, 0.11382299661636353, 0.11382299661636353, 0.3375045955181122, 0.03797279670834541], [0.7882091403007507, 0.0058891247026622295, 0.004291852004826069, 0.100804902613163, 0.100804902613163], [0.3136153221130371, 0.001970697194337845, 0.2016144096851349, 0.2016144096851349, 0.28118517994880676], [0.004155136179178953, 0.6978085041046143, 0.004155136179178953, 0.06434158980846405, 0.22953957319259644], [0.026886586099863052, 0.41786661744117737, 0.1904982328414917, 0.1742502897977829, 0.1904982328414917], [0.05119502171874046, 0.5668165683746338, 0.08560780435800552, 0.006286535877734423, 0.2900940477848053], [0.015529301017522812, 0.7721148729324341, 0.21222086250782013, 6.747265433659777e-05, 6.747265433659777e-05], [0.07976938039064407, 0.07976938039064407, 0.6284915208816528, 0.020496312528848648, 0.19147337973117828], [0.00010784693586174399, 0.15109990537166595, 0.15109990537166595, 0.00553202023729682, 0.6921603083610535], [0.7128831148147583, 0.04484250769019127, 0.007914840243756771, 0.04484250769019127, 0.18951702117919922], [0.4149830639362335, 0.4149830639362335, 9.023792517837137e-05, 0.16153259575366974, 0.008411068469285965], [0.03718715161085129, 0.4730752408504486, 0.015923090279102325, 0.0007392318220809102, 0.4730752408504486], [0.012652689591050148, 0.15727287530899048, 0.13123120367527008, 0.3494216203689575, 0.3494216203689575], [0.6437039375305176, 0.03460061922669411, 0.029976842924952507, 0.25711789727211, 0.03460061922669411], [0.5796220302581787, 0.13340650498867035, 0.010366309434175491, 0.13340650498867035, 0.14319869875907898], [0.027824752032756805, 0.012281646020710468, 0.08948899060487747, 0.8425799608230591, 0.027824752032756805], [0.5208117961883545, 0.03347255662083626, 0.03347255662083626, 0.3437054455280304, 0.06853760778903961], [0.3400653898715973, 0.3400653898715973, 0.00024780555395409465, 0.3060469329357147, 0.013574467040598392], [0.8272472620010376, 0.11083011329174042, 0.0260995551943779, 0.017911525443196297, 0.017911525443196297], [0.2482447326183319, 0.4786646068096161, 0.003819450968876481, 0.2482447326183319, 0.021026482805609703], [0.20133888721466064, 0.0036912597715854645, 0.08846971392631531, 0.0036912597715854645, 0.7028089761734009], [0.5926539301872253, 0.000863345165271312, 0.052628595381975174, 0.1769271045923233, 0.1769271045923233], [0.2888019382953644, 0.03185218200087547, 0.2888019382953644, 0.22228795289993286, 0.16825595498085022], [0.33787211775779724, 0.10674270242452621, 0.11910529434680939, 0.33787211775779724, 0.09840770065784454], [0.5364484190940857, 0.09420716762542725, 0.26479852199554443, 0.09420716762542725, 0.01033873576670885], [0.3892066478729248, 0.06138383969664574, 0.16710929572582245, 0.16710929572582245, 0.21519094705581665], [0.05074620991945267, 0.2577859163284302, 0.622550904750824, 0.018170759081840515, 0.05074620991945267], [0.19356659054756165, 0.01911837048828602, 0.14389635622501373, 0.44985219836235046, 0.19356659054756165], [0.0007414754945784807, 0.8659101128578186, 0.0288995411247015, 0.0007414754945784807, 0.10370740294456482], [0.9652697443962097, 0.005125012714415789, 0.01747811771929264, 0.007002129219472408, 0.005125012714415789], [0.05396613851189613, 0.8412214517593384, 0.03562242537736893, 0.05396613851189613, 0.015223845839500427], [0.8089948296546936, 0.05672445520758629, 0.05011898651719093, 0.05011898651719093, 0.03404277190566063], [0.05266634747385979, 0.04258767142891884, 0.3914104998111725, 0.1219250038266182, 0.3914104998111725], [0.00043026256025768816, 0.002811441197991371, 0.002811441197991371, 0.012213201262056828, 0.9817336797714233], [0.000416310882428661, 0.009614460170269012, 0.000416310882428661, 0.9386065006256104, 0.05094640702009201], [0.08116137236356735, 0.05392763391137123, 0.23354928195476532, 0.05392763391137123, 0.5774340629577637], [0.3660019040107727, 0.4346010982990265, 0.1991540491580963, 0.00012148929090471938, 0.00012148929090471938], [0.3595973551273346, 0.05254800245165825, 0.21072067320346832, 0.3595973551273346, 0.01753666065633297], [0.05643511936068535, 8.19531996967271e-05, 0.04247419536113739, 0.4505043923854828, 0.4505043923854828], [0.2201027125120163, 0.023787526413798332, 0.29824408888816833, 0.2201027125120163, 0.2377629578113556], [0.0814022570848465, 0.09174546599388123, 0.09174546599388123, 0.7331480383872986, 0.0019587050192058086], [0.3557914197444916, 0.3557914197444916, 0.04120757430791855, 0.05830269679427147, 0.1889069676399231], [0.10816503316164017, 0.5882917642593384, 0.3028687834739685, 0.00033719599014148116, 0.00033719599014148116], [0.07444900274276733, 0.007117671892046928, 0.032389238476753235, 0.032389238476753235, 0.8536549210548401], [0.13568678498268127, 0.45002272725105286, 0.12287822365760803, 0.16853399574756622, 0.12287822365760803], [0.09893456846475601, 0.5855085253715515, 0.30475834012031555, 0.005399270448833704, 0.005399270448833704], [0.1273340880870819, 0.1273340880870819, 0.08168352395296097, 0.622544527053833, 0.0411037802696228], [0.19214680790901184, 0.24622337520122528, 0.2774600684642792, 0.2774600684642792, 0.006709713488817215], [0.054661743342876434, 0.5792670249938965, 0.14007508754730225, 0.14007508754730225, 0.0859210416674614], [0.6537888646125793, 0.29861927032470703, 0.047256119549274445, 0.00016788067296147346, 0.00016788067296147346], [0.013523253612220287, 5.535346645046957e-05, 0.013523253612220287, 0.3371327817440033, 0.6357653141021729], [0.4306110441684723, 0.06731359660625458, 0.1039431244134903, 0.19906610250473022, 0.19906610250473022], [0.5054812431335449, 0.0558779239654541, 0.34702202677726746, 0.0357409343123436, 0.0558779239654541], [0.02915150858461857, 0.2789725065231323, 0.2789725065231323, 1.684848939476069e-05, 0.41288667917251587], [0.1044674664735794, 0.04255150631070137, 0.029642757028341293, 0.029642757028341293, 0.7936954498291016], [0.17613033950328827, 0.17613033950328827, 0.019312946125864983, 0.02583407796919346, 0.6025922894477844], [0.0005935825756751001, 0.44854211807250977, 0.0662778988480568, 0.44854211807250977, 0.036044295877218246], [0.05712450295686722, 0.31910648941993713, 0.542305588722229, 0.04121464490890503, 0.04024876281619072], [0.03377159312367439, 0.14662110805511475, 0.03377159312367439, 0.13852018117904663, 0.6473155617713928], [0.0673215240240097, 0.3330661356449127, 0.3330661356449127, 0.052789416164159775, 0.21375672519207], [0.34881991147994995, 0.0916844978928566, 0.1998700052499771, 0.34881991147994995, 0.010805675759911537], [0.004526727832853794, 0.6235698461532593, 0.003892662236467004, 0.003892662236467004, 0.36411812901496887], [0.5306272506713867, 0.15198872983455658, 0.04245643690228462, 0.15198872983455658, 0.12293883413076401], [0.07319530099630356, 0.46900928020477295, 0.2120458483695984, 0.2120458483695984, 0.03370373323559761], [0.26554495096206665, 0.26554495096206665, 0.028692997992038727, 0.4249561131000519, 0.015260937623679638], [0.03195512667298317, 0.42315202951431274, 0.0069324057549238205, 0.11480844020843506, 0.42315202951431274], [5.155960752745159e-05, 0.39985188841819763, 0.39985188841819763, 0.0002502242277842015, 0.19999437034130096], [0.3606509268283844, 0.03682590648531914, 0.20684485137462616, 0.2359583079814911, 0.1597200483083725], [0.03748952969908714, 0.040503423660993576, 0.615236759185791, 0.266266793012619, 0.040503423660993576], [0.0010024867951869965, 0.18983173370361328, 0.0011204291367903352, 0.4040226638317108, 0.4040226638317108], [0.012897535227239132, 0.04209397733211517, 0.0003746266011148691, 0.0003746266011148691, 0.9442592263221741], [0.004764166194945574, 0.0019054757431149483, 0.15933963656425476, 0.8320851922035217, 0.0019054757431149483], [0.08789247274398804, 0.014844459481537342, 0.08789247274398804, 0.751164972782135, 0.05820566043257713], [0.23395037651062012, 0.23098042607307434, 0.23395037651062012, 0.00018472556257620454, 0.3009341061115265], [0.017752110958099365, 0.05819061025977135, 0.4014248847961426, 0.017752110958099365, 0.5048802495002747], [0.019823668524622917, 0.6591235995292664, 0.0038569378666579723, 0.0038569378666579723, 0.31333890557289124], [0.11654195189476013, 0.1279415637254715, 0.29904550313949585, 0.15742547810077667, 0.29904550313949585], [0.012801063247025013, 0.13537181913852692, 0.20279145240783691, 0.13537181913852692, 0.5136638879776001], [0.036346565932035446, 0.036346565932035446, 0.14832109212875366, 0.765018880367279, 0.013966955244541168], [0.00496766297146678, 0.01636681891977787, 0.4046114385128021, 0.16944269835948944, 0.4046114385128021], [0.015009090304374695, 0.015009090304374695, 0.00209341524168849, 0.8941770792007446, 0.07371131330728531], [0.0025209346786141396, 0.20152609050273895, 0.3190774619579315, 0.3190774619579315, 0.15779803693294525], [0.40476125478744507, 0.19543425738811493, 0.19543425738811493, 0.0006917822756804526, 0.2036784440279007], [0.33770233392715454, 0.022287750616669655, 0.24464641511440277, 0.057661138474941254, 0.33770233392715454], [0.40767666697502136, 0.0076910704374313354, 0.16641652584075928, 0.16641652584075928, 0.25179919600486755], [0.020368443801999092, 0.39882177114486694, 0.20875602960586548, 0.16329775750637054, 0.20875602960586548], [0.012722250074148178, 0.012722250074148178, 0.3312002718448639, 0.6320727467536926, 0.011282501742243767], [0.2075595259666443, 0.19865266978740692, 0.15414462983608246, 0.28549855947494507, 0.15414462983608246], [0.2624569833278656, 0.2624569833278656, 0.24020248651504517, 0.18595711886882782, 0.04892642796039581], [0.6764382719993591, 0.12133260816335678, 0.07983983308076859, 0.0010566742857918143, 0.12133260816335678], [0.06601478159427643, 0.013491489924490452, 0.01655196025967598, 0.013491489924490452, 0.8904502987861633], [0.3082442283630371, 0.6416810154914856, 0.02162599191069603, 0.006822783965617418, 0.02162599191069603], [0.2224961668252945, 0.013533358462154865, 0.43317487835884094, 0.16539780795574188, 0.16539780795574188], [0.003019982948899269, 0.003842846257612109, 0.21594485640525818, 0.21594485640525818, 0.5612474679946899], [0.10655677318572998, 0.4018262028694153, 0.047120850533246994, 0.4018262028694153, 0.042670004069805145], [0.04288578778505325, 4.729805368697271e-05, 0.427089661359787, 0.1028876081109047, 0.427089661359787], [0.2735191881656647, 0.03845081105828285, 0.33629319071769714, 0.33629319071769714, 0.01544361375272274], [0.000279989413684234, 0.00867514405399561, 0.6305385828018188, 0.000279989413684234, 0.3602263629436493], [0.04998917505145073, 0.08817969262599945, 0.047219134867191315, 0.7646228671073914, 0.04998917505145073], [0.40986353158950806, 0.14392171800136566, 9.551776020089164e-05, 0.036255769431591034, 0.40986353158950806], [0.021401938050985336, 0.00036536063998937607, 0.03613847866654396, 0.03613847866654396, 0.9059556722640991], [0.9684281349182129, 8.936116500990465e-06, 0.015183317475020885, 0.008189798332750797, 0.008189798332750797], [0.6418979167938232, 0.04554975777864456, 0.04554975777864456, 0.07833271473646164, 0.18866978585720062], [0.18646599352359772, 0.04985494911670685, 0.0162343792617321, 0.5609786510467529, 0.18646599352359772], [0.021732868626713753, 0.5113901495933533, 0.021732868626713753, 0.01256418414413929, 0.4325799345970154], [0.0021219828631728888, 0.49606630206108093, 0.49606630206108093, 0.0038113603368401527, 0.0019341364968568087], [0.24027547240257263, 0.12937678396701813, 0.026057802140712738, 0.026057802140712738, 0.5782321691513062], [0.006734553724527359, 0.006734553724527359, 0.09513052552938461, 0.4118751585483551, 0.4795251786708832], [0.2903425097465515, 0.08929654210805893, 0.05361521989107132, 0.2764032185077667, 0.2903425097465515], [0.02194174937903881, 0.029162025079131126, 0.02194174937903881, 0.9144062995910645, 0.012548184022307396], [0.08017583936452866, 0.6111316680908203, 0.0784132182598114, 0.11513961106538773, 0.11513961106538773], [0.11796382069587708, 0.4292736351490021, 0.006889817304909229, 0.4292736351490021, 0.01659902185201645], [0.2386135756969452, 0.2386135756969452, 0.06789325922727585, 0.09529227018356323, 0.35958734154701233], [0.11614006757736206, 0.17407892644405365, 0.17407892644405365, 0.4863886535167694, 0.049313437193632126], [0.014057000167667866, 0.7191992402076721, 0.004484049044549465, 0.13112986087799072, 0.13112986087799072], [0.0030966883059591055, 0.1160055547952652, 0.018778424710035324, 0.018778424710035324, 0.8433408737182617], [0.006003691349178553, 0.47520673274993896, 0.04345780983567238, 0.00012509179941844195, 0.47520673274993896], [0.008683796972036362, 0.7213218808174133, 0.008683796972036362, 0.23081889748573303, 0.030491599813103676], [0.5240640640258789, 0.0014817819464951754, 0.26807358860969543, 0.20489874482154846, 0.0014817819464951754], [0.5838054418563843, 0.19982963800430298, 0.023380471393465996, 0.16268089413642883, 0.03030361235141754], [0.8370354771614075, 0.06143958866596222, 0.034171994775533676, 0.06143958866596222, 0.005913423839956522], [0.00016059770132414997, 0.03226132690906525, 0.48014190793037415, 0.48014190793037415, 0.007294307462871075], [0.010509500280022621, 0.5864443778991699, 0.16141121089458466, 0.16141121089458466, 0.0802237018942833], [0.033564697951078415, 0.3776509463787079, 0.28890421986579895, 0.010975993238389492, 0.28890421986579895], [0.3009941279888153, 0.14231380820274353, 0.23630450665950775, 0.3009941279888153, 0.019393442198634148], [0.0011621988378465176, 0.04686171934008598, 0.26809459924697876, 0.26809459924697876, 0.41578683257102966], [0.49028560519218445, 0.15894196927547455, 0.15894196927547455, 0.18334144353866577, 0.008489012718200684], [0.005380725022405386, 0.397989958524704, 0.397989958524704, 0.010647566057741642, 0.18799181282520294], [0.5074943900108337, 0.15856701135635376, 0.15856701135635376, 0.1743389219045639, 0.0010326580377295613], [0.6616017818450928, 0.0777667835354805, 0.01717357710003853, 0.0777667835354805, 0.1656910628080368], [0.010754131712019444, 0.02375737391412258, 0.4800282120704651, 0.4800282120704651, 0.005432075820863247], [0.4415113925933838, 0.02160053327679634, 0.10263614356517792, 0.10263614356517792, 0.33161574602127075], [0.7699563503265381, 0.0010887495009228587, 0.09650280326604843, 0.10506932437419891, 0.027382763102650642], [0.2028486132621765, 0.2028486132621765, 0.004486898425966501, 0.5153123140335083, 0.0745035856962204], [0.3180910348892212, 0.03346117213368416, 0.3180910348892212, 0.17737559974193573, 0.1529812067747116], [0.2826828062534332, 0.1121598333120346, 0.2826828062534332, 0.25803202390670776, 0.06444248557090759], [0.3886224329471588, 0.1729094386100769, 0.009025828912854195, 0.040819961577653885, 0.3886224329471588], [0.0023423070088028908, 0.009082335978746414, 0.24390703439712524, 0.5007612109184265, 0.24390703439712524], [0.037830621004104614, 0.671265184879303, 0.22637410461902618, 0.026699384674429893, 0.037830621004104614], [0.3014359772205353, 0.3014359772205353, 0.00687295151874423, 0.3880617320537567, 0.002193397842347622], [0.4216465353965759, 0.08490952104330063, 0.00041070362203754485, 0.00041070362203754485, 0.49262258410453796], [0.18337184190750122, 0.04731447994709015, 0.046570125967264175, 0.53937166929245, 0.18337184190750122], [0.3328312933444977, 0.2688046395778656, 0.11741149425506592, 0.2688046395778656, 0.012147905305027962], [0.16099120676517487, 0.42415446043014526, 0.03996879607439041, 0.21389436721801758, 0.16099120676517487], [0.009679729118943214, 0.009679729118943214, 0.40506115555763245, 0.5518873929977417, 0.023692026734352112], [0.5942431688308716, 0.2992405295372009, 0.0837821513414383, 0.012180612422525883, 0.010553591884672642], [0.48853060603141785, 0.38346996903419495, 0.059564776718616486, 0.00886981189250946, 0.059564776718616486], [0.15800108015537262, 0.32101595401763916, 0.19936423003673553, 0.32101595401763916, 0.0006027306080795825], [0.0022647283039987087, 0.11415717005729675, 0.11415717005729675, 0.13552990555763245, 0.6338910460472107], [0.00369360507465899, 0.09832693636417389, 0.4470575749874115, 0.4470575749874115, 0.0038643383886665106], [0.07066328078508377, 0.0002493163337931037, 0.8477621078491211, 0.010661949403584003, 0.07066328078508377], [0.04172057285904884, 0.38137784600257874, 0.19524909555912018, 0.00027458404656499624, 0.38137784600257874], [0.5330594182014465, 0.027581116184592247, 0.416230171918869, 0.0065805185586214066, 0.01654883287847042], [0.39813321828842163, 0.1509454846382141, 0.1509454846382141, 0.2981993556022644, 0.0017764385556802154], [0.03100936859846115, 0.03100936859846115, 0.00016489121480844915, 0.8757925629615784, 0.062023818492889404], [0.6349231600761414, 0.05368071421980858, 0.0112184202298522, 0.0981283187866211, 0.20204932987689972], [0.00015494167746510357, 0.9001508355140686, 0.09912465512752533, 0.00041463697561994195, 0.00015494167746510357], [0.353287011384964, 0.008852249011397362, 0.008852249011397362, 0.06796731054782867, 0.5610411167144775], [0.21736060082912445, 0.037731628865003586, 0.04263976588845253, 0.037731628865003586, 0.6645364761352539], [0.0011634834809228778, 0.15537329018115997, 0.4856165945529938, 0.0011634834809228778, 0.3566831648349762], [0.030294300988316536, 0.3855869472026825, 0.3855869472026825, 0.010622816160321236, 0.18790900707244873], [0.27705609798431396, 0.26677176356315613, 0.2318907380104065, 0.1886949986219406, 0.03558637946844101], [0.27464327216148376, 0.4069942831993103, 0.27464327216148376, 0.0020428686402738094, 0.04167630895972252], [0.36978697776794434, 0.05369957536458969, 0.047967031598091125, 0.1587594896554947, 0.36978697776794434], [0.9593612551689148, 0.0019282097928225994, 0.021074093878269196, 0.00881816353648901, 0.00881816353648901], [0.01047723088413477, 0.008309200406074524, 0.3939206600189209, 0.19337226450443268, 0.3939206600189209], [0.1864055097103119, 0.01047520525753498, 0.733109712600708, 0.0010854086140170693, 0.06892421096563339], [0.6880248188972473, 0.0004004667862318456, 0.0004004667862318456, 0.00010767995263449848, 0.31106656789779663], [0.07590778917074203, 0.01332438550889492, 0.7886332869529724, 0.07590778917074203, 0.04622670263051987], [0.034999553114175797, 0.04462461918592453, 0.3267329931259155, 0.2669098377227783, 0.3267329931259155], [0.10028644651174545, 6.321781984297559e-05, 0.8760402798652649, 0.023546749725937843, 6.321781984297559e-05], [0.14813263714313507, 0.011002804152667522, 0.011002804152667522, 0.8102370500564575, 0.019624650478363037], [0.025846343487501144, 0.34260204434394836, 0.07893950492143631, 0.47367265820503235, 0.07893950492143631], [0.0037558276671916246, 0.23892174661159515, 0.7450392246246338, 0.00852733850479126, 0.0037558276671916246], [0.2856625020503998, 0.07433802634477615, 0.012033430859446526, 0.2856625020503998, 0.3423035740852356], [0.001500226790085435, 0.49684789776802063, 0.49684789776802063, 7.879231998231262e-05, 0.004725202452391386], [0.2232557237148285, 0.334511399269104, 0.028765296563506126, 0.19021189212799072, 0.2232557237148285], [0.1807587444782257, 0.0013284896267578006, 0.06760821491479874, 0.7489760518074036, 0.0013284896267578006], [0.03820675238966942, 0.0006607715622521937, 0.47641053795814514, 0.008311465382575989, 0.47641053795814514], [0.003927131649106741, 0.13644754886627197, 0.13644754886627197, 0.7225092053413391, 0.0006685230764560401], [0.39295774698257446, 0.015494887717068195, 0.0001804119674488902, 0.19840919971466064, 0.39295774698257446], [0.11207491159439087, 0.0514877550303936, 0.30660656094551086, 0.5192123055458069, 0.010618484579026699], [0.5216885805130005, 0.02453683689236641, 0.1564026176929474, 0.2598385810852051, 0.037533339112997055], [0.16375620663166046, 0.002384959487244487, 0.6278461813926697, 0.002384959487244487, 0.20362770557403564], [0.0006432709633372724, 0.501832127571106, 0.00010283519077347592, 0.49731892347335815, 0.00010283519077347592], [0.0006330319447442889, 0.02315310575067997, 0.0006330319447442889, 0.8622660636901855, 0.11331484466791153], [0.03876131772994995, 0.43545976281166077, 0.004406468011438847, 0.08591276407241821, 0.43545976281166077], [0.1682451218366623, 0.6369045376777649, 0.1682451218366623, 0.00976214837282896, 0.016843078657984734], [0.06679298728704453, 0.25141769647598267, 0.22935359179973602, 0.25141769647598267, 0.2010180801153183], [0.028174839913845062, 0.0073914481326937675, 0.0073914481326937675, 0.6971468329429626, 0.259895384311676], [0.18734169006347656, 0.004708675667643547, 0.3886201083660126, 0.030709411948919296, 0.3886201083660126], [0.001515532610937953, 0.8356662392616272, 0.09151488542556763, 0.001515532610937953, 0.0697878748178482], [0.3483008146286011, 0.022024940699338913, 0.5761387348175049, 0.0315106175839901, 0.022024940699338913], [0.0033656610175967216, 0.020201565697789192, 0.11097587645053864, 0.8452553153038025, 0.020201565697789192], [0.014039561152458191, 0.17491023242473602, 0.5970449447631836, 0.1999656856060028, 0.014039561152458191], [0.011779493652284145, 0.02175583690404892, 0.011779493652284145, 0.22441208362579346, 0.7302731871604919], [0.1783948838710785, 0.00243798503652215, 0.1783948838710785, 0.35200318694114685, 0.28876906633377075], [0.37201622128486633, 0.23482125997543335, 0.0182175375521183, 0.0029287429060786963, 0.37201622128486633], [0.12285064160823822, 0.07934938371181488, 0.7102622389793396, 0.07934938371181488, 0.008188387379050255], [0.0004862617061007768, 0.4279213845729828, 0.017205459997057915, 0.017205459997057915, 0.5371814370155334], [0.16979260742664337, 0.053459249436855316, 0.053459249436855316, 0.48331910371780396, 0.23996980488300323], [0.05359071493148804, 0.8478766083717346, 0.0033875172957777977, 0.0033875172957777977, 0.091757632791996], [0.0724673941731453, 0.6425848007202148, 0.13473419845104218, 0.07510678470134735, 0.07510678470134735], [0.3510526716709137, 0.32660722732543945, 0.315515398979187, 0.003412355436012149, 0.003412355436012149], [0.4949323832988739, 0.009374943561851978, 0.4949323832988739, 3.0081006116233766e-05, 0.0007302104495465755], [0.24955621361732483, 0.4835716187953949, 0.1316676139831543, 0.003536969656124711, 0.1316676139831543], [0.241956427693367, 0.03996217995882034, 0.4737756848335266, 0.03996217995882034, 0.20434348285198212], [0.43417084217071533, 0.05409105867147446, 0.057716064155101776, 0.39993104338645935, 0.05409105867147446], [0.3663216233253479, 0.5702287554740906, 0.0030223391950130463, 0.03021363355219364, 0.03021363355219364], [0.08543021976947784, 0.0020030022133141756, 0.05289275199174881, 0.7742438316345215, 0.08543021976947784], [0.8928490877151489, 0.036763422191143036, 0.06307138502597809, 0.003658051136881113, 0.003658051136881113], [0.07306499779224396, 0.3164559602737427, 0.07306499779224396, 0.5364850759506226, 0.0009290467132814229], [0.11967116594314575, 0.0012786901788786054, 0.0012786901788786054, 0.8456044793128967, 0.032166969031095505], [0.07264744490385056, 0.3058733642101288, 0.03235170990228653, 0.03235170990228653, 0.5567757487297058], [0.38389626145362854, 0.042374689131975174, 0.161884605884552, 0.161884605884552, 0.2499598264694214], [0.22046124935150146, 0.05469995737075806, 0.279533714056015, 0.16577135026454926, 0.279533714056015], [0.026622872799634933, 0.1563156098127365, 0.4078938066959381, 0.0012739092344418168, 0.4078938066959381], [0.3060183823108673, 0.30404773354530334, 0.004737332928925753, 0.3060183823108673, 0.07917813211679459], [0.019550440832972527, 0.08338391035795212, 0.767422080039978, 0.019550440832972527, 0.11009316891431808], [0.21301721036434174, 0.11783911287784576, 0.11783911287784576, 0.019520729780197144, 0.5317838191986084], [0.06276092678308487, 0.2685980200767517, 0.5283941626548767, 0.07748591899871826, 0.06276092678308487], [0.8172218799591064, 0.04621509835124016, 0.005812826566398144, 0.005812826566398144, 0.12493748217821121], [0.24554848670959473, 0.24554848670959473, 0.008302439004182816, 0.011343777179718018, 0.4892568290233612], [0.0018464402528479695, 0.018877774477005005, 0.5188866257667542, 0.4446207880973816, 0.015768390148878098], [0.4850565195083618, 0.14903585612773895, 0.1458384245634079, 0.14903585612773895, 0.07103327661752701], [0.17864197492599487, 0.17864197492599487, 0.38594648241996765, 0.10519776493310928, 0.1515718251466751], [0.008196367882192135, 0.47276633977890015, 0.014550573192536831, 0.47276633977890015, 0.03172040358185768], [0.1375574916601181, 0.029215721413493156, 0.1375574916601181, 0.5852000117301941, 0.1104692667722702], [0.4870081841945648, 0.4870081841945648, 0.0008016006322577596, 0.004617763217538595, 0.020564263686537743], [0.29471850395202637, 0.042594946920871735, 0.042594946920871735, 0.0073908246122300625, 0.6127007603645325], [0.4434111714363098, 0.004145896062254906, 0.0702211856842041, 0.03881058841943741, 0.4434111714363098], [0.3004588782787323, 0.17077535390853882, 0.3004588782787323, 0.16545429825782776, 0.06285260617733002], [0.2759817838668823, 0.08495982736349106, 0.0227896049618721, 0.3402870297431946, 0.2759817838668823], [0.015149061568081379, 0.46037545800209045, 0.01006469875574112, 0.05403532460331917, 0.46037545800209045], [0.03754357248544693, 0.21518474817276, 0.2002553939819336, 0.21518474817276, 0.33183157444000244], [0.22669032216072083, 0.187709778547287, 0.1156720444560051, 0.3542558252811432, 0.1156720444560051], [0.012539221905171871, 0.7201552391052246, 0.12043420970439911, 0.12043420970439911, 0.026437098160386086], [0.05455334484577179, 0.4641170799732208, 0.433561235666275, 0.00201174383983016, 0.045756567269563675], [0.08691616356372833, 0.0066519370302557945, 0.08691616356372833, 0.07908318936824799, 0.7404325604438782], [0.024920441210269928, 0.024920441210269928, 0.19875644147396088, 0.7493264079093933, 0.0020762647036463022], [0.28442177176475525, 0.28442177176475525, 0.15051645040512085, 0.014274580404162407, 0.2663653790950775], [0.010038581676781178, 0.20524483919143677, 0.20524483919143677, 0.00486899446696043, 0.5746027827262878], [0.037666454911231995, 0.3130451440811157, 0.14283537864685059, 0.3130451440811157, 0.1934078484773636], [0.3344367742538452, 0.3239220678806305, 0.0026238677091896534, 0.0045805517584085464, 0.3344367742538452], [0.010930423624813557, 0.4301580786705017, 0.007131743710488081, 0.4301580786705017, 0.12162171304225922], [0.16257348656654358, 0.6398127675056458, 0.024047618731856346, 0.010992692783474922, 0.16257348656654358], [0.4695960283279419, 0.4695960283279419, 0.02055535465478897, 0.007428840734064579, 0.03282378613948822], [6.947350630071014e-05, 0.052104439586400986, 0.1738610565662384, 6.947350630071014e-05, 0.7738956212997437], [0.18534424901008606, 0.20830915868282318, 0.5527083873748779, 0.0268191359937191, 0.0268191359937191], [0.17408056557178497, 0.27686694264411926, 0.22946225106716156, 0.22946225106716156, 0.09012798219919205], [0.12538641691207886, 0.2726879417896271, 0.31896770000457764, 0.010270007885992527, 0.2726879417896271], [0.0014958985848352313, 0.0012585287913680077, 0.0012585287913680077, 0.017365815117955208, 0.978621244430542], [0.7986658811569214, 0.029323015362024307, 0.05769530311226845, 0.05769530311226845, 0.056620482355356216], [0.2606286108493805, 0.0005915868678130209, 7.277451368281618e-05, 0.00016878788301255554, 0.7385382056236267], [0.03934356942772865, 0.4543863534927368, 0.00018358936358708888, 0.25304320454597473, 0.25304320454597473], [0.3485448658466339, 0.294630229473114, 0.3485448658466339, 0.0031440197490155697, 0.0051359799690544605], [0.006654823198914528, 0.009196048602461815, 0.9702029824256897, 0.006654823198914528, 0.007291401270776987], [0.26392197608947754, 0.5669461488723755, 0.06572573632001877, 0.03768041729927063, 0.06572573632001877], [0.09799535572528839, 0.09529164433479309, 0.3162574768066406, 0.007239246275275946, 0.4832163155078888], [0.39230287075042725, 0.41591066122055054, 0.09556958824396133, 0.09556958824396133, 0.0006473311805166304], [0.03521503508090973, 0.03521503508090973, 0.10574326664209366, 0.39203909039497375, 0.4317876100540161], [0.003952878061681986, 0.09272927790880203, 0.08358320593833923, 0.7270053625106812, 0.09272927790880203], [0.047605760395526886, 0.07551901042461395, 0.300639808177948, 0.2881176769733429, 0.2881176769733429], [0.021080613136291504, 0.13975027203559875, 0.028914347290992737, 0.021080613136291504, 0.7891740798950195], [0.1517522931098938, 0.1517522931098938, 0.0018312458414584398, 0.08156314492225647, 0.613101065158844], [0.006253818050026894, 0.5514942407608032, 0.1557750552892685, 0.1557750552892685, 0.13070181012153625], [0.2517668604850769, 0.0654623880982399, 0.2517668604850769, 0.14924290776252747, 0.28176096081733704], [0.3376373052597046, 0.20899485051631927, 0.0058400556445121765, 0.10989049822092056, 0.3376373052597046], [0.21526415646076202, 0.21526415646076202, 0.3855780363082886, 0.03610318526625633, 0.14779046177864075], [0.030594782903790474, 0.08261425048112869, 0.010315646417438984, 0.010315646417438984, 0.8661597371101379], [0.4584296941757202, 0.053270671516656876, 0.4584296941757202, 0.02455606870353222, 0.005313796456903219], [0.00045695665176026523, 0.10713369399309158, 0.10713369399309158, 0.7675985097885132, 0.01767713390290737], [0.055668603628873825, 0.13352403044700623, 0.06526003777980804, 0.15790025889873505, 0.5876470804214478], [0.02815883979201317, 0.2667241096496582, 0.02815883979201317, 0.5806484818458557, 0.09630970656871796], [0.009912136010825634, 0.9275345802307129, 0.018401693552732468, 0.009912136010825634, 0.034239523112773895], [0.15386396646499634, 0.010376298800110817, 0.08964233100414276, 0.17491939663887024, 0.5711979866027832], [0.2928283214569092, 0.25812822580337524, 0.18345953524112701, 0.007455730810761452, 0.25812822580337524], [0.38043564558029175, 0.046740490943193436, 0.03712267428636551, 0.48896071314811707, 0.046740490943193436], [0.22585001587867737, 0.017571914941072464, 0.16229596734046936, 0.5767102241516113, 0.017571914941072464], [0.0008398315403610468, 0.3389643728733063, 0.6578060388565063, 0.001549950917251408, 0.0008398315403610468], [0.005081635434180498, 0.8293478488922119, 0.11785168200731277, 0.003477242775261402, 0.044241584837436676], [0.03447914868593216, 0.0020180405117571354, 0.0020180405117571354, 0.9129760265350342, 0.04850881174206734], [0.014598355628550053, 0.015789899975061417, 0.023633267730474472, 0.4729892313480377, 0.4729892313480377], [0.2784690260887146, 0.2784690260887146, 0.37633317708969116, 0.00013451441191136837, 0.0665942057967186], [0.09635467827320099, 0.8535218238830566, 0.016329899430274963, 0.017463698983192444, 0.016329899430274963], [0.0819733515381813, 0.11601881682872772, 0.10480907559394836, 0.6152253746986389, 0.0819733515381813], [0.25620466470718384, 0.49370959401130676, 0.0007943262462504208, 0.2484971135854721, 0.0007943262462504208], [0.6912544369697571, 0.06831493973731995, 0.11796926707029343, 0.11796926707029343, 0.004492174368351698], [0.30085453391075134, 0.055131882429122925, 0.3143822252750397, 0.028776859864592552, 0.30085453391075134], [0.6652605533599854, 0.07871083170175552, 0.06947103887796402, 0.1078467071056366, 0.07871083170175552], [0.16262954473495483, 0.27749374508857727, 0.2212960124015808, 0.11728464066982269, 0.2212960124015808], [0.0736953467130661, 0.2721731662750244, 0.2721731662750244, 0.1381102055311203, 0.24384813010692596], [0.014223146252334118, 0.8155990839004517, 0.1339031457901001, 0.01813727803528309, 0.01813727803528309], [0.007895764894783497, 0.36588746309280396, 0.3602045178413391, 0.007895764894783497, 0.2581164836883545], [0.020406849682331085, 0.020406849682331085, 0.012606259435415268, 0.44597768783569336, 0.5006024241447449], [0.3151693344116211, 0.32555949687957764, 0.015676084905862808, 0.01803554594516754, 0.32555949687957764], [0.03340422362089157, 0.0005229489179328084, 0.47931116819381714, 0.007450490724295378, 0.47931116819381714], [0.46375468373298645, 0.006339455023407936, 0.46375468373298645, 0.03895954415202141, 0.027191590517759323], [0.19216734170913696, 0.0010128921130672097, 0.035979222506284714, 0.0010128921130672097, 0.769827663898468], [0.010954616591334343, 0.3872336745262146, 0.29617977142333984, 0.29617977142333984, 0.00945214182138443], [0.015861911699175835, 0.015861911699175835, 0.5859740972518921, 0.22281023859977722, 0.15949180722236633], [0.033650610595941544, 0.025472361594438553, 0.9071319103240967, 9.449541539652273e-05, 0.033650610595941544], [0.26364997029304504, 0.0027676154859364033, 0.4084608554840088, 0.16256074607372284, 0.16256074607372284], [0.4920457899570465, 0.11890087276697159, 0.05853535234928131, 0.11890087276697159, 0.2116171419620514], [0.06773664802312851, 0.09486982226371765, 0.09486982226371765, 0.5393801927566528, 0.20314349234104156], [0.6383223533630371, 0.13103267550468445, 0.05825875699520111, 0.05825875699520111, 0.11412745714187622], [0.021817896515130997, 0.23047779500484467, 0.3272191286087036, 0.09326609969139099, 0.3272191286087036], [0.019844556227326393, 0.44960567355155945, 0.44960567355155945, 0.067923903465271, 0.013020094484090805], [0.06527315825223923, 0.0031415033154189587, 0.37946420907974243, 0.17265690863132477, 0.37946420907974243], [0.11030108481645584, 0.10862578451633453, 0.4865531325340271, 0.14726005494594574, 0.14726005494594574], [0.0016259495168924332, 0.2230435311794281, 0.0016259495168924332, 0.17584563791751862, 0.5978589057922363], [0.46208706498146057, 0.007026234641671181, 0.5028628706932068, 0.007026234641671181, 0.020997578278183937], [0.03479746729135513, 0.1657949686050415, 0.03479746729135513, 0.3853345215320587, 0.37927550077438354], [0.26738661527633667, 0.005871751811355352, 0.5777145624160767, 0.005871751811355352, 0.1431553214788437], [0.29855239391326904, 0.22843442857265472, 0.22843442857265472, 0.20889104902744293, 0.035687752068042755], [0.20048630237579346, 0.07697814702987671, 0.35994112491607666, 0.18129722774028778, 0.18129722774028778], [0.37588173151016235, 0.020836805924773216, 0.2790546715259552, 0.16211341321468353, 0.16211341321468353], [0.8407434821128845, 0.1359897255897522, 0.002305264351889491, 0.018656309694051743, 0.002305264351889491], [0.012561431154608727, 0.4715152978897095, 0.009895135648548603, 0.034512851387262344, 0.4715152978897095], [0.740426778793335, 0.0030704750679433346, 0.0034275958314538, 0.12653756141662598, 0.12653756141662598], [0.026453407481312752, 0.026453407481312752, 0.023074248805642128, 0.9127097725868225, 0.011309188790619373], [0.4432848393917084, 0.0017665497725829482, 0.0017665497725829482, 0.47070273756980896, 0.08247946947813034], [0.024774674326181412, 0.9142703413963318, 0.03519485145807266, 0.0009853964438661933, 0.024774674326181412], [0.9248361587524414, 0.028714237734675407, 0.0008796376059763134, 0.04469025135040283, 0.0008796376059763134], [0.07854391634464264, 0.2982757091522217, 0.07854391634464264, 0.4970119297504425, 0.047624554485082626], [5.162897286936641e-05, 0.9352571964263916, 5.162897286936641e-05, 0.004231426399201155, 0.0604080930352211], [0.014036488719284534, 0.004502494353801012, 0.8873901963233948, 0.014036488719284534, 0.08003438264131546], [0.308094322681427, 0.308094322681427, 0.0017940141260623932, 0.004752823617309332, 0.37726446986198425], [0.6112778186798096, 0.12129631638526917, 0.036174412816762924, 0.1099550798535347, 0.12129631638526917], [0.32168152928352356, 0.053946707397699356, 0.28907641768455505, 0.013613860122859478, 0.32168152928352356], [0.43842315673828125, 0.335867315530777, 0.013508975505828857, 0.013508975505828857, 0.19869165122509003], [0.1076645627617836, 0.03389161452651024, 0.8245014548301697, 5.079595575807616e-05, 0.03389161452651024], [0.14119257032871246, 0.06998617202043533, 0.0391540490090847, 0.608474612236023, 0.14119257032871246], [0.09635773301124573, 0.014784899540245533, 0.09635773301124573, 0.21235999464988708, 0.5801396369934082], [0.32866740226745605, 0.04186469689011574, 0.054462794214487076, 0.32866740226745605, 0.24633771181106567], [0.17244897782802582, 0.11324168741703033, 0.11324168741703033, 0.45419177412986755, 0.14687582850456238], [0.0022216783836483955, 0.8634732365608215, 0.012595107778906822, 0.0025054633151739836, 0.11920459568500519], [0.294285386800766, 0.12971854209899902, 0.4424813687801361, 0.003796099219471216, 0.12971854209899902], [0.08967360109090805, 0.39964622259140015, 0.00481468765065074, 0.39964622259140015, 0.10621922463178635], [0.0012193465372547507, 0.16728779673576355, 0.4153822064399719, 0.0007284447201527655, 0.4153822064399719], [0.40155431628227234, 0.28326931595802307, 0.01393905933946371, 0.28326931595802307, 0.017967909574508667], [0.24875864386558533, 0.29180464148521423, 0.04454294592142105, 0.29180464148521423, 0.12308918684720993], [0.8468067049980164, 0.10474884510040283, 0.039650991559028625, 0.004396752454340458, 0.004396752454340458], [0.6442861557006836, 0.15693344175815582, 0.04177961125969887, 0.15693344175815582, 6.732230394845828e-05], [0.032130759209394455, 0.032130759209394455, 0.13992102444171906, 0.013117664493620396, 0.7826998233795166], [0.00907894130796194, 0.00960848294198513, 0.02508729323744774, 0.7593864798545837, 0.196838840842247], [0.011153553612530231, 0.9851964712142944, 0.00023651038645766675, 0.00023651038645766675, 0.0031769699417054653], [0.08283165842294693, 0.11025368422269821, 0.002274333033710718, 0.8023660778999329, 0.002274333033710718], [0.433311402797699, 0.2444489300251007, 0.00019015402358490974, 0.07760056108236313, 0.2444489300251007], [0.03377855569124222, 0.2700045108795166, 0.40654057264328003, 0.019671812653541565, 0.2700045108795166], [0.021791044622659683, 0.00015983519551809877, 0.021791044622659683, 0.9527308940887451, 0.00352724501863122], [0.4823731482028961, 0.19123777747154236, 0.13187144696712494, 0.19123777747154236, 0.0032797944732010365], [0.715804398059845, 0.13721194863319397, 0.028084272518754005, 0.09081517159938812, 0.028084272518754005], [0.03332466632127762, 0.35596099495887756, 0.14241424202919006, 0.14241424202919006, 0.32588592171669006], [0.23094376921653748, 0.6623152494430542, 0.00034454523120075464, 0.10605191439390182, 0.00034454523120075464], [0.05018145963549614, 0.19825927913188934, 0.403779000043869, 0.19825927913188934, 0.14952103793621063], [0.004212514031678438, 0.2129632979631424, 0.2129632979631424, 0.012307809665799141, 0.5575530529022217], [0.005785801913589239, 0.03470822796225548, 0.005785801913589239, 0.010980261489748955, 0.9427397847175598], [0.16847601532936096, 0.20206184685230255, 0.2044772207736969, 0.25650888681411743, 0.16847601532936096], [0.07053133845329285, 0.07053133845329285, 0.3525187373161316, 0.4679611623287201, 0.03845744952559471], [0.44093459844589233, 0.08489744365215302, 0.01324848085641861, 0.44093459844589233, 0.019984891638159752], [0.40967240929603577, 0.0803179070353508, 0.013710384257137775, 0.40967240929603577, 0.08662688732147217], [0.004384757950901985, 0.516831636428833, 0.1512387990951538, 0.3231600522994995, 0.004384757950901985], [0.01926279254257679, 0.1439792811870575, 0.0025086798705160618, 0.4171246290206909, 0.4171246290206909], [0.2746615707874298, 0.18648627400398254, 0.26694291830062866, 0.26694291830062866, 0.004966269712895155], [0.15140479803085327, 0.1019095703959465, 0.5905290246009827, 0.15140479803085327, 0.004751799628138542], [0.32626575231552124, 0.027320407330989838, 0.036294035613536835, 0.32626575231552124, 0.2838541269302368], [0.016204267740249634, 0.028532855212688446, 0.004730814136564732, 0.028532855212688446, 0.9219992160797119], [0.010463325306773186, 0.024254072457551956, 0.352466881275177, 0.2603488564491272, 0.352466881275177], [0.9668777585029602, 0.009139960631728172, 0.01091674529016018, 0.009139960631728172, 0.003925709053874016], [0.0990515649318695, 0.0029229288920760155, 0.32166022062301636, 0.2547050416469574, 0.32166022062301636], [0.2034914791584015, 0.013765253126621246, 8.212160173570737e-05, 0.2034914791584015, 0.579169750213623], [0.01819012686610222, 0.02000725083053112, 0.3804587125778198, 0.3804587125778198, 0.20088526606559753], [0.02696715109050274, 0.05464106798171997, 0.13011115789413452, 0.7613134980201721, 0.02696715109050274], [0.00479520671069622, 0.00479520671069622, 0.8480927348136902, 0.13483990728855133, 0.007476953789591789], [0.18112990260124207, 0.6821731328964233, 0.023047173395752907, 0.023047173395752907, 0.0906025618314743], [0.016307000070810318, 0.10991115123033524, 0.052496716380119324, 0.10991115123033524, 0.7113739848136902], [0.053830742835998535, 0.5167744159698486, 0.1762925088405609, 0.0768098533153534, 0.1762925088405609], [0.01005514059215784, 0.07762958854436874, 0.23735901713371277, 0.3374781608581543, 0.3374781608581543], [0.1452576071023941, 0.11067374050617218, 0.004884414840489626, 0.1452576071023941, 0.5939266681671143], [0.5804173350334167, 0.10258537530899048, 0.0006956613506190479, 0.3084658980369568, 0.0078357495367527], [0.436861515045166, 0.07216371595859528, 0.3414425253868103, 0.0773685872554779, 0.07216371595859528], [0.00021090339578222483, 0.00566552858799696, 0.00021090339578222483, 2.1309444491635077e-05, 0.9938913583755493], [0.0797528326511383, 0.1695021539926529, 0.17465177178382874, 0.15931959450244904, 0.41677364706993103], [0.1899309605360031, 0.3605579733848572, 0.1713421791791916, 0.1899309605360031, 0.08823787420988083], [0.008397863246500492, 0.14374110102653503, 0.8141266703605652, 0.025336477905511856, 0.008397863246500492], [0.004294979386031628, 0.20954261720180511, 0.20954261720180511, 0.35343286395072937, 0.2231869250535965], [0.8008055686950684, 0.007621288765221834, 0.16761061549186707, 0.007621288765221834, 0.016341274604201317], [0.0015381579287350178, 0.16020213067531586, 0.32003623247146606, 0.16020213067531586, 0.3580212891101837], [0.09590974450111389, 0.8621459603309631, 0.019440241158008575, 0.019440241158008575, 0.0030637956224381924], [0.05585081875324249, 0.03708856552839279, 0.0963391661643982, 0.7584455609321594, 0.05227597802877426], [0.34673407673835754, 0.006475877948105335, 0.2868826985359192, 0.07302463799715042, 0.2868826985359192], [0.0026227422058582306, 0.8486573696136475, 0.027422264218330383, 0.0026227422058582306, 0.1186748743057251], [0.01709442213177681, 0.01709442213177681, 0.7989702820777893, 0.05145308002829552, 0.11538781225681305], [0.45542648434638977, 0.025556892156600952, 0.034206878393888474, 0.45542648434638977, 0.02938329242169857], [0.3416402339935303, 0.011659919284284115, 0.19796642661094666, 0.3416402339935303, 0.10709314793348312], [0.03580489382147789, 0.03580489382147789, 0.7235114574432373, 0.2010275423526764, 0.0038512495812028646], [0.10061699897050858, 0.10061699897050858, 0.7723756432533264, 0.025226714089512825, 0.001163613167591393], [0.13749675452709198, 0.13749675452709198, 0.23465301096439362, 0.07557682693004608, 0.41477665305137634], [0.5256837606430054, 0.002139517106115818, 0.002139517106115818, 0.04132821038365364, 0.4287090003490448], [0.30814802646636963, 0.02811369299888611, 0.0004987942520529032, 0.30814802646636963, 0.355091392993927], [0.013955440372228622, 0.7455682158470154, 0.20159244537353516, 0.03499487042427063, 0.003889014245942235], [0.04376666992902756, 0.007603015284985304, 0.07127705216407776, 0.8060762286186218, 0.07127705216407776], [0.005501673556864262, 0.46415141224861145, 0.49652788043022156, 0.028317367658019066, 0.005501673556864262], [0.426256388425827, 0.426256388425827, 0.006400568876415491, 0.12493019551038742, 0.01615649089217186], [0.027841849252581596, 0.3664122223854065, 0.11851110309362411, 0.027841849252581596, 0.4593929946422577], [0.0015775858191773295, 0.013519097119569778, 0.0015775858191773295, 0.857483446598053, 0.12584228813648224], [0.10533218830823898, 0.08080445230007172, 0.7029246091842651, 0.08080445230007172, 0.03013433888554573], [4.439682743395679e-05, 0.2954693138599396, 0.3714779317378998, 0.2954693138599396, 0.037539031356573105], [0.3412337899208069, 0.08672076463699341, 0.06701865792274475, 0.08672076463699341, 0.4183060824871063], [0.15462790429592133, 0.009580333717167377, 0.15462790429592133, 0.4975587725639343, 0.18360503017902374], [0.00014973821816965938, 0.2847909927368164, 0.12786532938480377, 0.5229595899581909, 0.06423430889844894], [0.4510321617126465, 0.21958912909030914, 0.028173774480819702, 0.2839294373989105, 0.01727556250989437], [0.00552256079390645, 0.6513105630874634, 0.02260749228298664, 0.31503674387931824, 0.00552256079390645], [0.19397394359111786, 0.46259647607803345, 0.06315881758928299, 0.08629675954580307, 0.19397394359111786], [0.02445661835372448, 0.6465076208114624, 0.2331443578004837, 0.07143478840589523, 0.02445661835372448], [0.14600923657417297, 0.09029825776815414, 0.3570813536643982, 0.3570813536643982, 0.04952975735068321], [0.5056597590446472, 0.12048943340778351, 0.06616951525211334, 0.18719181418418884, 0.12048943340778351], [0.4476783573627472, 0.4476783573627472, 0.026751451194286346, 0.021868376061320305, 0.056023381650447845], [0.0026105432771146297, 0.00011260539758950472, 0.2850521504878998, 0.2850521504878998, 0.4271725118160248], [0.015656158328056335, 0.016438258811831474, 0.005835548974573612, 0.005835548974573612, 0.9562344551086426], [0.485748291015625, 0.0017439922085031867, 0.02628810703754425, 0.0004712788504548371, 0.485748291015625], [0.03643864393234253, 0.7910106778144836, 0.048682793974876404, 0.03643864393234253, 0.0874292328953743], [0.0011619313154369593, 0.10715683549642563, 0.3992159366607666, 0.3992159366607666, 0.09324932843446732], [0.18882252275943756, 0.33812785148620605, 0.04900509491562843, 0.3750394582748413, 0.04900509491562843], [9.60829493124038e-05, 0.16917528212070465, 0.04178352653980255, 0.20629706978797913, 0.5826480984687805], [0.0017256750725209713, 0.10917230695486069, 0.0017256750725209713, 0.15207767486572266, 0.7352986931800842], [0.046486251056194305, 0.4207448959350586, 0.4207448959350586, 0.11086829751729965, 0.0011556555982679129], [0.0051248944364488125, 0.08063383400440216, 0.13465344905853271, 0.13465344905853271, 0.6449344158172607], [0.3816170394420624, 0.3079995810985565, 0.0010064850794151425, 0.0013772969832643867, 0.3079995810985565], [0.0003650016733445227, 0.09349019080400467, 0.16264258325099945, 0.6500120162963867, 0.09349019080400467], [0.0046871379017829895, 0.8882659673690796, 0.0374559722840786, 0.06490378826856613, 0.0046871379017829895], [0.45425623655319214, 0.015964841470122337, 0.07208287715911865, 0.45425623655319214, 0.0034397628623992205], [0.18810324370861053, 0.18810324370861053, 0.4294595718383789, 0.07142708450555801, 0.12290683388710022], [0.25416284799575806, 0.056867633014917374, 0.16737878322601318, 0.4469788670539856, 0.07461188733577728], [0.6791377067565918, 0.02298424020409584, 0.02081611007452011, 0.02081611007452011, 0.25624579191207886], [0.007749880198389292, 0.4875381588935852, 0.01976805552840233, 0.47719401121139526, 0.007749880198389292], [0.05258369445800781, 0.04019487276673317, 0.45354196429252625, 0.00013743210001848638, 0.45354196429252625], [0.1681768298149109, 0.41758742928504944, 0.1969463974237442, 0.020343013107776642, 0.1969463974237442], [0.8214453458786011, 0.0027206018567085266, 0.015086036175489426, 0.02823272906243801, 0.13251525163650513], [0.0439574159681797, 0.0914112776517868, 0.4079088568687439, 0.4079088568687439, 0.0488135889172554], [0.016144661232829094, 0.40203675627708435, 0.141539067029953, 0.03824269026517868, 0.40203675627708435], [0.9204080104827881, 0.010072674602270126, 0.0012498783180490136, 0.010072674602270126, 0.058196816593408585], [0.3084660470485687, 0.008369349874556065, 0.057660654187202454, 0.31703782081604004, 0.3084660470485687], [0.15845200419425964, 0.1591121256351471, 0.14102810621261597, 0.1591121256351471, 0.3822956085205078], [0.006640139035880566, 0.003734145313501358, 0.6821869015693665, 0.3007986843585968, 0.006640139035880566], [0.02326774410903454, 0.6251962184906006, 0.07146010547876358, 0.02123994007706642, 0.2588360011577606], [0.1474984884262085, 0.5333640575408936, 0.007549817208200693, 0.1474984884262085, 0.16408909857273102], [0.07117532193660736, 0.07117532193660736, 0.13101987540721893, 0.1425742357969284, 0.5840551853179932], [0.0015551485121250153, 0.0001315542758675292, 0.09054221957921982, 0.09054221957921982, 0.8172288537025452], [0.16061317920684814, 0.3861754536628723, 0.27155131101608276, 0.16061317920684814, 0.021046921610832214], [0.022440850734710693, 0.11010432988405228, 0.022440850734710693, 0.7361838817596436, 0.10883000493049622], [0.6956037282943726, 0.0033080317080020905, 0.13650892674922943, 0.13650892674922943, 0.02807028964161873], [0.004626669455319643, 0.004626669455319643, 0.17399227619171143, 0.7559738755226135, 0.0607805959880352], [0.43863996863365173, 0.024129122495651245, 0.04039693996310234, 0.020740168169140816, 0.4760937988758087], [0.005488509777933359, 0.31253746151924133, 0.01783379167318344, 0.005488509777933359, 0.6586517095565796], [0.3575466275215149, 0.08084824681282043, 0.19977743923664093, 0.18091383576393127, 0.18091383576393127], [0.7577898502349854, 0.07140300422906876, 0.007679477799683809, 0.07140300422906876, 0.09172463417053223], [0.7948215007781982, 0.001649584504775703, 0.18884257972240448, 0.001649584504775703, 0.013036791235208511], [0.13790397346019745, 0.1792929619550705, 0.06041985750198364, 0.06041985750198364, 0.5619633793830872], [0.1393483728170395, 0.07923910766839981, 0.25239497423171997, 0.25239497423171997, 0.27662256360054016], [0.04150404408574104, 0.04150404408574104, 0.24425752460956573, 0.5818657875061035, 0.09086859971284866], [0.004689574241638184, 0.004689574241638184, 0.06264358013868332, 0.016378218308091164, 0.9115990400314331], [0.7678664326667786, 0.0359015166759491, 0.04101329669356346, 0.0359015166759491, 0.11931731551885605], [0.42367157340049744, 0.06543770432472229, 0.3140607476234436, 0.06543770432472229, 0.13139227032661438], [0.03439544513821602, 0.016313111409544945, 0.23721344769001007, 0.6957648992538452, 0.016313111409544945], [0.0007044131634756923, 0.06330659240484238, 0.9158468842506409, 0.0029086293652653694, 0.017233453691005707], [0.02747228741645813, 0.4383356273174286, 0.03473737835884094, 0.061119113117456436, 0.4383356273174286], [0.20724616944789886, 0.24116501212120056, 0.019472716376185417, 0.2909510135650635, 0.24116501212120056], [0.02449197880923748, 0.24541287124156952, 0.24541287124156952, 0.030490558594465256, 0.4541916847229004], [0.6778956055641174, 0.1352950930595398, 0.018613234162330627, 0.1352950930595398, 0.032900989055633545], [0.0013886536471545696, 0.918250322341919, 0.07867308706045151, 0.0013886536471545696, 0.0002992608642671257], [0.030197422951459885, 0.01567978598177433, 0.34874993562698364, 0.25662291049957275, 0.34874993562698364], [9.382577263750136e-05, 0.20356455445289612, 0.20356455445289612, 0.3991198241710663, 0.1936572790145874], [0.06730008870363235, 0.8362936973571777, 0.02616308629512787, 0.0029429802671074867, 0.06730008870363235], [0.20396672189235687, 0.20396672189235687, 0.02365979366004467, 0.00024282262893393636, 0.5681638717651367], [0.12599992752075195, 0.21977929770946503, 0.0003226319677196443, 0.5278982520103455, 0.12599992752075195], [0.4103008210659027, 0.5497632622718811, 0.033619463443756104, 0.0031582487281411886, 0.0031582487281411886], [0.025607546791434288, 0.10215005278587341, 0.025607546791434288, 0.24073512852191925, 0.6058998107910156], [0.5299181938171387, 0.007048285566270351, 0.007048285566270351, 0.02298000082373619, 0.43300530314445496], [0.023539572954177856, 0.24251367151737213, 0.023539572954177856, 0.07324215769767761, 0.6371649503707886], [0.07552184909582138, 0.009613747708499432, 0.009613747708499432, 0.07896120846271515, 0.8262895345687866], [0.27792415022850037, 0.27792415022850037, 0.03645804524421692, 0.3968883454799652, 0.01080539170652628], [0.5307323336601257, 0.007671399507671595, 0.09656817466020584, 0.09656817466020584, 0.26845991611480713], [0.11672110110521317, 0.06278152763843536, 0.0013766518095508218, 0.0013766518095508218, 0.8177441358566284], [0.022442977875471115, 0.6377096176147461, 0.022442977875471115, 0.1356572061777115, 0.18174730241298676], [0.3893859386444092, 0.04255044087767601, 0.04742101579904556, 0.1312566101551056, 0.3893859386444092], [0.370006799697876, 3.6638168239733204e-05, 0.3139811158180237, 0.3139811158180237, 0.001994374906644225], [0.3709600865840912, 0.16999001801013947, 0.036920905113220215, 0.05116892606019974, 0.3709600865840912], [0.0012147256638854742, 0.8233476281166077, 0.0048982929438352585, 0.08526971936225891, 0.08526971936225891], [0.30931609869003296, 0.06358619034290314, 0.2831340432167053, 0.06358619034290314, 0.28037750720977783], [0.13868139684200287, 0.4191378951072693, 0.38347285985946655, 0.029353925958275795, 0.029353925958275795], [0.03325195237994194, 0.0013824544148519635, 0.46498993039131165, 0.46498993039131165, 0.03538568317890167], [0.13830487430095673, 0.08180311322212219, 0.13830487430095673, 0.2412126064300537, 0.40037456154823303], [0.26531583070755005, 0.26531583070755005, 0.010971265845000744, 0.29863306879997253, 0.15976400673389435], [0.0021692784503102303, 0.06857115030288696, 0.4230418801307678, 0.08317582309246063, 0.4230418801307678], [0.04959781467914581, 0.18354767560958862, 0.05626979470252991, 0.6609869003295898, 0.04959781467914581], [0.018721546977758408, 0.018721546977758408, 0.47203829884529114, 0.011050602421164513, 0.4794679284095764], [0.14978431165218353, 0.18972830474376678, 0.4785580635070801, 0.17665816843509674, 0.005271187052130699], [0.6279745101928711, 0.306883841753006, 0.011730167083442211, 0.04168125241994858, 0.011730167083442211], [0.014169507659971714, 0.012295708991587162, 0.4677373766899109, 0.4677373766899109, 0.03805997595191002], [0.05605005845427513, 0.031329039484262466, 0.031329039484262466, 0.17851512134075165, 0.7027767300605774], [0.016124991700053215, 0.23668380081653595, 0.4822610020637512, 0.13246513903141022, 0.13246513903141022], [0.6333052515983582, 0.2678162455558777, 0.006547898985445499, 0.046165309846401215, 0.046165309846401215], [0.017216002568602562, 0.4032192826271057, 0.025821344926953316, 0.5389083623886108, 0.014834944158792496], [0.08815653622150421, 0.162566140294075, 0.3577083647251129, 0.3577083647251129, 0.033860594034194946], [0.20333178341388702, 0.026345528662204742, 0.026345528662204742, 0.5818961262702942, 0.16208100318908691], [0.31332987546920776, 0.036254990845918655, 0.09731068462133408, 0.23977451026439667, 0.31332987546920776], [0.02237728051841259, 0.02237728051841259, 0.8795748353004456, 0.0006404055166058242, 0.07503020018339157], [0.010398195125162601, 0.30360355973243713, 0.010398195125162601, 0.0016346618067473173, 0.673965334892273], [0.10164244472980499, 0.36313754320144653, 0.10114340484142303, 0.3329331576824188, 0.10114340484142303], [0.025913963094353676, 0.47047263383865356, 0.03462803736329079, 0.234492689371109, 0.234492689371109], [0.6940003633499146, 0.10709337890148163, 0.01057434268295765, 0.09416594356298447, 0.09416594356298447], [0.4829636812210083, 0.0032725411001592875, 0.09213035553693771, 0.0032725411001592875, 0.4183608293533325], [0.19527336955070496, 0.06193401291966438, 0.6253249645233154, 0.05553369224071503, 0.06193401291966438], [0.006440121214836836, 0.3731127679347992, 0.3731127679347992, 0.12840013206005096, 0.11893417686223984], [0.11932734400033951, 0.7505382299423218, 0.08640165627002716, 0.021866416558623314, 0.021866416558623314], [0.4470737874507904, 0.040421098470687866, 0.4470737874507904, 0.056141991168260574, 0.009289344772696495], [0.2587493062019348, 0.007711401674896479, 0.24085378646850586, 0.24085378646850586, 0.25183168053627014], [0.7762798070907593, 0.03623564541339874, 0.00021447715698741376, 0.03623564541339874, 0.1510343849658966], [0.05749162659049034, 0.02096049301326275, 0.02096049301326275, 0.25284716486930847, 0.647740364074707], [0.26168376207351685, 0.26168376207351685, 0.014363840222358704, 0.10405779629945755, 0.35821083188056946], [0.2585136592388153, 0.48217225074768066, 0.00026013111346401274, 0.2585136592388153, 0.0005403755931183696], [0.006307675037533045, 0.28434309363365173, 0.006307675037533045, 0.4557340741157532, 0.24730752408504486], [0.0764213278889656, 0.08431211858987808, 0.6544733047485352, 0.08431211858987808, 0.10048110038042068], [0.2020399123430252, 0.1438421607017517, 0.00983232632279396, 0.4422456920146942, 0.2020399123430252], [0.06493090093135834, 0.0015374317299574614, 0.8392840623855591, 0.02931671030819416, 0.06493090093135834], [0.015220432542264462, 0.15468157827854156, 0.15468157827854156, 0.5432187914848328, 0.13219764828681946], [0.28061988949775696, 0.007734361104667187, 0.6115291118621826, 0.0923822745680809, 0.007734361104667187], [0.26852044463157654, 0.7038906812667847, 0.006704913917928934, 0.014179063029587269, 0.006704913917928934], [0.002780505456030369, 0.3689150810241699, 0.12522660195827484, 0.3689150810241699, 0.1341627687215805], [0.8271605968475342, 0.03721776232123375, 0.05251985788345337, 0.05251985788345337, 0.030581798404455185], [0.13182435929775238, 0.003561401041224599, 0.12466557323932648, 0.003561401041224599, 0.7363871932029724], [0.028992071747779846, 0.3421621322631836, 0.07990613579750061, 0.3421621322631836, 0.20677752792835236], [0.17514759302139282, 0.6286176443099976, 0.17514759302139282, 0.009240943938493729, 0.011846193112432957], [0.04489210993051529, 0.11866220086812973, 0.11866220086812973, 0.5426017045974731, 0.1751818060874939], [0.8808301687240601, 0.06701246649026871, 0.004436676390469074, 0.04328398033976555, 0.004436676390469074], [0.0002840239030774683, 0.049698442220687866, 0.29738888144493103, 0.2034897804260254, 0.4491387605667114], [0.36647021770477295, 0.06406036019325256, 0.28188806772232056, 0.28188806772232056, 0.005693287122994661], [0.037644948810338974, 0.037644948810338974, 0.8831644058227539, 0.03138256072998047, 0.010163168422877789], [0.11459113657474518, 0.07548489421606064, 0.009635718539357185, 0.07548489421606064, 0.7248033285140991], [0.0005839164950884879, 0.0005839164950884879, 0.3239404261112213, 0.4116719961166382, 0.26321977376937866], [0.008047524839639664, 0.4896988570690155, 0.0124445091933012, 0.00011030797031708062, 0.4896988570690155], [0.20165380835533142, 0.2680410146713257, 0.2544022798538208, 0.2680410146713257, 0.007861921563744545], [0.2340378612279892, 0.0064262570813298225, 0.49260732531547546, 0.03289072588086128, 0.2340378612279892], [0.4178071916103363, 0.2828066945075989, 0.010606181807816029, 0.005973304621875286, 0.2828066945075989], [0.0040452429093420506, 0.013150730170309544, 0.36655738949775696, 0.0009260248625651002, 0.61532062292099], [0.0276250671595335, 0.3213222920894623, 0.16426263749599457, 0.32252731919288635, 0.16426263749599457], [0.29890117049217224, 0.31417644023895264, 0.31417644023895264, 0.005808748304843903, 0.06693713366985321], [0.003703553695231676, 0.04490714520215988, 0.10781290382146835, 0.10781290382146835, 0.7357634902000427], [1.906124634842854e-05, 1.906124634842854e-05, 0.0005235952557995915, 0.36155879497528076, 0.6378794312477112], [0.06119368225336075, 0.8143463134765625, 0.002303660148754716, 0.11115525662899017, 0.011001083999872208], [0.3312928378582001, 0.08374594151973724, 0.3312928378582001, 0.2256821244955063, 0.027986204251646996], [0.051045678555965424, 0.03439097851514816, 0.1126197874546051, 0.1126197874546051, 0.6893237233161926], [0.6599330306053162, 0.05870937183499336, 0.1350809931755066, 0.05870937183499336, 0.0875672698020935], [0.007167811505496502, 0.009361186064779758, 0.9021834135055542, 0.07411975413560867, 0.007167811505496502], [0.9179061055183411, 0.029469214379787445, 0.01287373062223196, 0.029469214379787445, 0.010281727649271488], [0.0017064502462744713, 0.6898289918899536, 0.00016509137640241534, 0.3079789876937866, 0.0003205236280336976], [0.1742197871208191, 0.09271466732025146, 0.3880265951156616, 0.17081916332244873, 0.1742197871208191], [0.3254479467868805, 0.10322624444961548, 0.04238276928663254, 0.3254479467868805, 0.2034951001405716], [0.008711040019989014, 0.03516062721610069, 0.8164467215538025, 0.13097049295902252, 0.008711040019989014], [0.12911508977413177, 0.012611610814929008, 0.560795247554779, 0.12911508977413177, 0.16836297512054443], [0.00037113699363544583, 0.009264128282666206, 0.3943139910697937, 0.00037113699363544583, 0.5956795811653137], [2.1455747628351673e-05, 0.007656497415155172, 0.03008415549993515, 0.9598409533500671, 0.002396912779659033], [0.008870571851730347, 0.4949944019317627, 0.4949944019317627, 5.846433850820176e-06, 0.0011347441468387842], [0.008327949792146683, 0.8843448758125305, 0.03477482870221138, 0.03477482870221138, 0.03777746483683586], [0.022447053343057632, 0.022447053343057632, 0.0069033438339829445, 0.4169274568557739, 0.5312751531600952], [0.13283245265483856, 0.3265070617198944, 0.13387079536914825, 0.0802825540304184, 0.3265070617198944], [0.0016411057440564036, 0.00415396224707365, 0.4249397814273834, 0.1443253606557846, 0.4249397814273834], [0.01701693795621395, 0.4861893057823181, 0.010236921720206738, 0.4861893057823181, 0.0003675437765195966], [0.13420775532722473, 0.13420775532722473, 0.17397460341453552, 0.46776747703552246, 0.08984240144491196], [0.0011617199052125216, 0.052954964339733124, 0.4404590129852295, 0.06496530771255493, 0.4404590129852295], [0.31926000118255615, 0.24495354294776917, 0.2155352681875229, 0.004715882707387209, 0.2155352681875229], [0.07921508699655533, 0.5992520451545715, 0.23921281099319458, 0.003104973118752241, 0.07921508699655533], [0.25124818086624146, 0.7070677876472473, 0.0005218217265792191, 0.020581070333719254, 0.020581070333719254], [0.08704231679439545, 0.08429602533578873, 0.10392454266548157, 0.637694776058197, 0.08704231679439545], [0.008089852519333363, 0.020621752366423607, 0.9603878855705261, 0.0028107038233429193, 0.008089852519333363], [0.12960970401763916, 0.12960970401763916, 0.02449224703013897, 0.06448497623205185, 0.6518033742904663], [0.38770848512649536, 0.38770848512649536, 0.01114470511674881, 0.02706797607243061, 0.18637040257453918], [0.007428350858390331, 0.4905621111392975, 0.4905621111392975, 0.009601712226867676, 0.0018457963597029448], [0.017267951741814613, 0.1060706302523613, 0.1799663007259369, 0.1060706302523613, 0.5906244516372681], [0.19070081412792206, 0.48305442929267883, 0.052085936069488525, 0.052085936069488525, 0.22207288444042206], [0.040727753192186356, 0.4034363329410553, 0.14420300722122192, 0.4034363329410553, 0.008196618407964706], [0.030873974785208702, 0.8504888415336609, 0.056154150515794754, 0.0063287946395576, 0.056154150515794754], [0.0045881313271820545, 0.47932055592536926, 0.018786627799272537, 0.017984190955758095, 0.47932055592536926], [0.0004967870772816241, 0.00304973847232759, 0.04535406082868576, 0.940613329410553, 0.010486061684787273], [0.43429329991340637, 0.0008015950443223119, 0.21469666063785553, 0.13551172614097595, 0.21469666063785553], [0.4347415566444397, 0.006766483187675476, 0.09113141149282455, 0.4347415566444397, 0.0326189361512661], [0.059611476957798004, 0.059611476957798004, 0.0014360368950292468, 0.07743392139673233, 0.8019071817398071], [1.1683399861794896e-05, 0.011324968189001083, 0.0032682891469448805, 0.492697536945343, 0.492697536945343], [0.07503625750541687, 0.5555734038352966, 0.07503625750541687, 0.0036267549730837345, 0.2907273471355438], [0.5926130414009094, 0.025251999497413635, 0.025251999497413635, 0.28781858086586, 0.06906440109014511], [0.13538961112499237, 0.11256178468465805, 0.1066710501909256, 0.2863365709781647, 0.3590410053730011], [0.001332099549472332, 0.0366801917552948, 0.0366801917552948, 0.5201212167739868, 0.4051862955093384], [0.07152219861745834, 0.08991354703903198, 0.18262647092342377, 0.32796892523765564, 0.32796892523765564], [0.004194251727312803, 0.00011750846897484735, 0.10509812086820602, 0.10509812086820602, 0.7854920625686646], [0.0014750062255188823, 0.60792076587677, 0.0014750062255188823, 0.13818080723285675, 0.250948429107666], [0.0016203488921746612, 0.9432723522186279, 0.0016203488921746612, 0.007758214604109526, 0.04572869837284088], [0.6182270646095276, 0.34406062960624695, 0.01846640184521675, 0.01846640184521675, 0.0007796058198437095], [5.918960596318357e-06, 5.918960596318357e-06, 0.0006015700055286288, 0.3680102229118347, 0.6313762664794922], [0.3507625460624695, 0.05480499938130379, 0.3507625460624695, 0.0029600965790450573, 0.2407098114490509], [0.22006115317344666, 0.49639999866485596, 0.20534737408161163, 0.07652589678764343, 0.0016655995277687907], [0.05335365608334541, 0.5878817439079285, 0.3514569401741028, 0.0036538189742714167, 0.0036538189742714167], [0.24122202396392822, 0.10148648172616959, 0.03488792106509209, 0.03488792106509209, 0.587515652179718], [0.05933406949043274, 0.05991916358470917, 0.012999456375837326, 0.7237019538879395, 0.14404535293579102], [0.32200559973716736, 0.32200559973716736, 0.30531516671180725, 0.037175025790929794, 0.013498615473508835], [0.34234386682510376, 0.3080822229385376, 0.0009070555679500103, 0.3080822229385376, 0.040584612637758255], [0.01826673187315464, 0.1228245198726654, 0.0003363946743775159, 0.0005064476281404495, 0.8580658435821533], [0.4554711878299713, 0.4554711878299713, 0.08481738716363907, 0.0014494976494461298, 0.0027906910981982946], [0.02732784114778042, 0.7349261045455933, 0.09006340056657791, 0.09006340056657791, 0.05761919543147087], [0.0961519107222557, 0.033754680305719376, 0.11470862478017807, 0.6406762003898621, 0.11470862478017807], [0.11201167106628418, 0.6378597021102905, 0.12907911837100983, 0.11201167106628418, 0.009037759155035019], [0.7856045365333557, 0.20656101405620575, 0.003713596612215042, 0.0020604687742888927, 0.0020604687742888927], [0.0985531359910965, 0.2671559453010559, 0.2741985321044922, 0.08589381724596024, 0.2741985321044922], [0.00021069201466161758, 0.32981768250465393, 0.5958260893821716, 0.07393482327461243, 0.00021069201466161758], [0.04964812472462654, 0.7416958212852478, 0.007972984574735165, 0.09297700971364975, 0.10770604759454727], [0.10180619359016418, 0.06788837164640427, 0.2386961579322815, 0.2386961579322815, 0.35291311144828796], [0.08413364738225937, 0.08413364738225937, 0.08397917449474335, 0.7355015873908997, 0.012251912616193295], [0.003798673627898097, 0.006355235353112221, 0.2511427700519562, 0.006355235353112221, 0.7323480248451233], [0.20922820270061493, 0.0011183788301423192, 0.0011183788301423192, 0.7012101411819458, 0.08732489496469498], [0.45618054270744324, 0.25781476497650146, 0.02649611420929432, 0.001693848753347993, 0.25781476497650146], [0.20875105261802673, 0.17796170711517334, 0.17796170711517334, 0.044822197407484055, 0.39050331711769104], [0.012003263458609581, 0.015856845304369926, 0.48485565185546875, 0.002428552135825157, 0.48485565185546875], [0.11695661395788193, 0.383609801530838, 0.23988965153694153, 0.23988965153694153, 0.019654283300042152], [0.0006931435782462358, 0.6654670238494873, 0.0006931435782462358, 0.08569220453500748, 0.2474544793367386], [0.0014565670862793922, 0.9751879572868347, 0.0023763985373079777, 0.018602658063173294, 0.0023763985373079777], [0.03636637702584267, 0.22648312151432037, 0.03636637702584267, 0.544603168964386, 0.1561809629201889], [0.06644957512617111, 0.06644957512617111, 0.14585478603839874, 0.36310505867004395, 0.3581410348415375], [0.04386444017291069, 0.04386444017291069, 0.3932943642139435, 0.009142812341451645, 0.5098339915275574], [0.03370174765586853, 0.47688931226730347, 0.0021835248917341232, 0.47688931226730347, 0.0103361327201128], [0.42447564005851746, 0.0265059657394886, 0.20021656155586243, 0.1744009256362915, 0.1744009256362915], [0.11981907486915588, 0.017149802297353745, 0.7142480611801147, 0.13163326680660248, 0.017149802297353745], [0.2593158781528473, 0.6906878352165222, 0.037703003734350204, 0.005414873361587524, 0.0068784612230956554], [0.19418123364448547, 0.17586453258991241, 0.29419758915901184, 0.29419758915901184, 0.04155906289815903], [0.5277117490768433, 0.010679886676371098, 0.11985727399587631, 0.11985727399587631, 0.22189384698867798], [0.05086486414074898, 0.029636060819029808, 0.2483397275209427, 0.33557966351509094, 0.33557966351509094], [0.41151830554008484, 0.0065772351808846, 0.04778345674276352, 0.1226026639342308, 0.41151830554008484], [0.03219149261713028, 0.9389562606811523, 0.014036372303962708, 0.0007795285782776773, 0.014036372303962708], [0.9886707067489624, 0.00021641640341840684, 0.00021641640341840684, 0.008870881050825119, 0.002025596797466278], [0.14698025584220886, 0.14698025584220886, 0.01829402521252632, 0.6259468793869019, 0.0617985799908638], [0.15000495314598083, 0.19949379563331604, 0.19278296828269958, 0.3077132999897003, 0.15000495314598083], [0.0004244211595505476, 0.0018010903149843216, 0.9873327612876892, 0.0018010903149843216, 0.00864068791270256], [0.016308778896927834, 0.016308778896927834, 0.07039724290370941, 0.8743166327476501, 0.022668607532978058], [0.015808137133717537, 0.015808137133717537, 0.32918956875801086, 0.21622014045715332, 0.4229740798473358], [0.0965062752366066, 0.0965062752366066, 0.19134873151779175, 0.4937615692615509, 0.12187711894512177], [0.002443089848384261, 0.3406795859336853, 0.3406795859336853, 0.30116239190101624, 0.015035301446914673], [0.28219830989837646, 0.03169512748718262, 0.03169512748718262, 0.07357010245323181, 0.5808413028717041], [0.028047209605574608, 0.2920241951942444, 0.11812952160835266, 0.5337518453598022, 0.028047209605574608], [0.03669468313455582, 0.027904294431209564, 0.027904294431209564, 0.09744773805141449, 0.8100490570068359], [0.016304541379213333, 0.026575373485684395, 0.8347107768058777, 0.09583397954702377, 0.026575373485684395], [0.020726032555103302, 0.6374573111534119, 0.03097330592572689, 0.03097330592572689, 0.27987000346183777], [0.1965484619140625, 0.1470867395401001, 0.45004695653915405, 0.1965484619140625, 0.009769368916749954], [0.011032271198928356, 0.19723859429359436, 0.0007293106173165143, 0.7902705669403076, 0.0007293106173165143], [0.29101458191871643, 0.29101458191871643, 0.06688637286424637, 0.005821909289807081, 0.3452625870704651], [0.20152708888053894, 0.09091635793447495, 0.027091134339571, 0.47893840074539185, 0.20152708888053894], [0.020326459780335426, 0.12726931273937225, 0.7506405711174011, 0.05088183283805847, 0.05088183283805847], [0.060597971081733704, 0.4013497829437256, 0.4013497829437256, 0.007192827761173248, 0.12950962781906128], [0.004079657141119242, 0.0921594426035881, 0.004671946633607149, 0.4495444893836975, 0.4495444893836975], [0.1745186448097229, 0.14732645452022552, 0.019578181207180023, 0.5112502574920654, 0.14732645452022552], [0.003390865633264184, 0.20243722200393677, 0.2925485074520111, 0.2925485074520111, 0.20907489955425262], [0.1542247086763382, 0.0004086818662472069, 0.016679469496011734, 0.016679469496011734, 0.8120076060295105], [0.0001389605167787522, 0.024674735963344574, 0.2591165602207184, 0.024674735963344574, 0.6913949847221375], [0.0002352385490667075, 0.2893601357936859, 0.15578380227088928, 0.2652606964111328, 0.2893601357936859], [0.47281867265701294, 0.0076783341355621815, 0.47281867265701294, 0.012447498738765717, 0.03423687815666199], [0.008221156895160675, 0.38800540566444397, 0.005469389725476503, 0.21029862761497498, 0.38800540566444397], [0.005054797045886517, 0.005054797045886517, 0.08712788671255112, 0.00656161829829216, 0.8962008953094482], [0.04816022142767906, 0.28350991010665894, 0.12067063897848129, 0.28350991010665894, 0.26414933800697327], [0.36822816729545593, 0.020883595570921898, 0.07738091796636581, 0.4561264216899872, 0.07738091796636581], [0.28395596146583557, 0.027141524478793144, 0.31619444489479065, 0.31619444489479065, 0.05651358515024185], [0.8706526160240173, 0.04318802431225777, 0.01824842393398285, 0.03395549952983856, 0.03395549952983856], [0.5383918285369873, 0.013368692249059677, 0.0029021743685007095, 0.013368692249059677, 0.43196865916252136], [0.01198252197355032, 0.01198252197355032, 0.12979085743427277, 0.061926815658807755, 0.7843172550201416], [0.3437640368938446, 0.2259950339794159, 0.3437640368938446, 0.04438482224941254, 0.042092058807611465], [0.6624363660812378, 0.0077279177494347095, 0.0077279177494347095, 0.30824849009513855, 0.013859326019883156], [0.07194938510656357, 0.3406183123588562, 0.037421055138111115, 0.2093929648399353, 0.3406183123588562], [0.3570351004600525, 0.007271524053066969, 0.007271524053066969, 0.04408437758684158, 0.5843374729156494], [0.0006091471877880394, 0.06853897869586945, 0.021635068580508232, 0.9019494652748108, 0.007267313543707132], [0.3223132789134979, 0.3223132789134979, 0.029466334730386734, 0.21448351442813873, 0.11142357438802719], [0.010870958678424358, 0.330059677362442, 0.330059677362442, 0.30449795722961426, 0.024511683732271194], [0.031134307384490967, 0.7021636366844177, 0.06856918334960938, 0.12956367433071136, 0.06856918334960938], [0.1183522418141365, 0.030952908098697662, 0.6760146617889404, 0.05632786452770233, 0.1183522418141365], [0.3107151985168457, 0.009725447744131088, 0.3582068681716919, 0.3107151985168457, 0.010637277737259865], [0.8389732241630554, 0.012710411101579666, 0.0740957036614418, 0.0740957036614418, 0.00012487413187045604], [0.059967681765556335, 0.059967681765556335, 0.3115079998970032, 0.5492422580718994, 0.019314389675855637], [0.6484141945838928, 0.056290216743946075, 0.056290216743946075, 0.033867668360471725, 0.205137699842453], [0.39098718762397766, 0.19384299218654633, 0.1631317287683487, 0.08890640735626221, 0.1631317287683487], [0.0004802687035407871, 0.0017951063346117735, 0.0017951063346117735, 0.6353044509887695, 0.36062511801719666], [0.41891124844551086, 0.13392317295074463, 0.020010052248835564, 0.41891124844551086, 0.008244289085268974], [0.0005086524761281908, 0.02586185932159424, 0.0005086524761281908, 0.9626356363296509, 0.010485212318599224], [0.2955620288848877, 0.002303033834323287, 0.0396912656724453, 0.35847043991088867, 0.3039732575416565], [0.01708061806857586, 0.0010536584304645658, 0.5169245600700378, 0.0010536584304645658, 0.4638875126838684], [0.0013521101791411638, 0.019064361229538918, 0.0011075594229623675, 0.4892379641532898, 0.4892379641532898], [0.04467611387372017, 0.9534146189689636, 0.0010370563250035048, 0.0004360641760285944, 0.0004360641760285944], [0.03757396340370178, 0.29512083530426025, 0.3478608727455139, 0.29512083530426025, 0.02432350069284439], [0.013643519952893257, 0.013643519952893257, 0.2548219561576843, 0.35044094920158386, 0.3674500584602356], [0.2561616003513336, 0.1976969689130783, 0.002554059959948063, 0.28742578625679016, 0.2561616003513336], [0.06181134283542633, 0.5232505202293396, 0.14609479904174805, 0.12274853140115738, 0.14609479904174805], [0.015220639295876026, 0.08604300022125244, 0.1300274282693863, 0.38435444235801697, 0.38435444235801697], [0.06458225101232529, 0.42015159130096436, 0.09357640892267227, 0.42015159130096436, 0.001538125448860228], [0.4913586676120758, 0.010327361524105072, 0.001014367095194757, 0.005940914154052734, 0.4913586676120758], [0.002391628222540021, 0.09774485975503922, 0.7247634530067444, 0.07735522091388702, 0.09774485975503922], [0.037198785692453384, 0.09866736829280853, 0.4668942093849182, 0.298572301864624, 0.09866736829280853], [0.17222902178764343, 0.11069487035274506, 0.11069487035274506, 0.5998402237892151, 0.006540984380990267], [0.06142740324139595, 0.0008174825925379992, 0.16296730935573578, 0.736312747001648, 0.03847505524754524], [0.3790695071220398, 0.013673239387571812, 0.1876310110092163, 0.040556684136390686, 0.3790695071220398], [0.005860794335603714, 0.005860794335603714, 0.5497716069221497, 0.0071251182816922665, 0.43138161301612854], [0.593490719795227, 0.19286715984344482, 0.004163286183029413, 0.01661163941025734, 0.19286715984344482], [0.7373495697975159, 0.0017775072483345866, 0.031123043969273567, 0.1148749589920044, 0.1148749589920044], [0.0020454442128539085, 0.09071341156959534, 0.0020454442128539085, 0.880574107170105, 0.02462148293852806], [0.7111411094665527, 0.13017919659614563, 0.0044158934615552425, 0.0044158934615552425, 0.14984790980815887], [0.2385338991880417, 0.18987849354743958, 0.09555763006210327, 0.12154795974493027, 0.3544820249080658], [0.16763880848884583, 0.0032878988422453403, 0.0734124705195427, 0.0015070055378600955, 0.7541537880897522], [0.4091835021972656, 8.569524652557448e-05, 0.5896285176277161, 0.0010165548883378506, 8.569524652557448e-05], [0.09450329840183258, 0.3656242787837982, 0.5139847993850708, 0.012943803332746029, 0.012943803332746029], [0.04711683467030525, 0.20503661036491394, 0.2633492946624756, 0.2633492946624756, 0.22114796936511993], [0.4433514177799225, 0.22323700785636902, 0.007031840272247791, 0.22323700785636902, 0.10314273834228516], [0.00866449810564518, 0.07346443831920624, 0.09023401886224747, 0.7374029755592346, 0.09023401886224747], [0.27726730704307556, 0.022154174745082855, 0.00336543470621109, 0.6938475966453552, 0.00336543470621109], [0.020649388432502747, 0.0010985222179442644, 0.48723047971725464, 0.0037910854443907738, 0.48723047971725464], [0.005325670354068279, 0.37076452374458313, 0.6235948801040649, 0.00015743933909107, 0.00015743933909107], [0.5270481705665588, 0.010002298280596733, 0.10415693372488022, 0.34879037737846375, 0.010002298280596733], [0.10971276462078094, 0.09084562957286835, 0.535955011844635, 0.09084562957286835, 0.17264093458652496], [0.009366831742227077, 0.4311785399913788, 0.4311785399913788, 0.003013532143086195, 0.1252625435590744], [0.010545266792178154, 0.19434568285942078, 0.5244770050048828, 0.07628634572029114, 0.19434568285942078], [0.4439191222190857, 0.05850343033671379, 0.05850343033671379, 0.25961193442344666, 0.17946210503578186], [0.4400619566440582, 0.07620090991258621, 0.013186699710786343, 0.07620090991258621, 0.3943495452404022], [0.37376436591148376, 0.37376436591148376, 0.04499511420726776, 0.1591206192970276, 0.048355549573898315], [0.02021145075559616, 0.4746313691139221, 0.02021145075559616, 0.40708962082862854, 0.07785608619451523], [0.09972408413887024, 0.4320998191833496, 0.14959752559661865, 0.14959752559661865, 0.16898106038570404], [0.004776314366608858, 0.032029613852500916, 0.1873239278793335, 0.004776314366608858, 0.7710937857627869], [0.29234579205513, 0.1276620328426361, 0.024894773960113525, 0.2775487005710602, 0.2775487005710602], [0.0633988007903099, 0.32177627086639404, 0.47579944133758545, 0.1334001123905182, 0.005625355988740921], [0.4819882810115814, 0.02291356585919857, 0.0003597616159822792, 0.4819882810115814, 0.012750091031193733], [0.40070515871047974, 0.40070515871047974, 0.04172298684716225, 0.1548851579427719, 0.001981508219614625], [0.32765260338783264, 0.47744220495224, 0.007554411888122559, 0.007554411888122559, 0.17979639768600464], [0.053067587316036224, 0.028316697105765343, 0.4272560775279999, 0.028316697105765343, 0.4630429744720459], [0.1222764104604721, 0.576119065284729, 0.15365709364414215, 0.1222764104604721, 0.025671062991023064], [0.410838782787323, 0.000472042040200904, 0.15066689252853394, 0.000472042040200904, 0.43755021691322327], [0.07535627484321594, 0.00838498491793871, 0.45737984776496887, 0.0014991486677899957, 0.45737984776496887], [0.2753939628601074, 0.002408009022474289, 0.007458594627678394, 0.43934547901153564, 0.2753939628601074], [0.41160762310028076, 0.41160762310028076, 0.124616339802742, 0.04121082276105881, 0.010957549326121807], [0.24667790532112122, 0.35631269216537476, 0.03741583973169327, 0.35631269216537476, 0.0032808210235089064], [0.026315925642848015, 0.19251620769500732, 0.4291243255138397, 0.15952734649181366, 0.19251620769500732], [0.2911246716976166, 0.230721578001976, 0.2911246716976166, 0.13670365512371063, 0.050325434654951096], [0.013605207204818726, 0.013605207204818726, 0.83406001329422, 0.0030368466395884752, 0.13569276034832], [0.14207184314727783, 0.43057310581207275, 0.22199426591396332, 0.06328892707824707, 0.14207184314727783], [0.10903924703598022, 0.41632843017578125, 0.11831503361463547, 0.17815865576267242, 0.17815865576267242], [0.3756142556667328, 0.05082516372203827, 0.16531142592430115, 0.3756142556667328, 0.0326349101960659], [0.7838104963302612, 0.05291922762989998, 0.001979927998036146, 0.15931041538715363, 0.001979927998036146], [0.31628188490867615, 0.5384994745254517, 0.07016267627477646, 0.004893281031399965, 0.07016267627477646], [0.012187753804028034, 0.012187753804028034, 0.24951381981372833, 0.47223198413848877, 0.25387874245643616], [0.23792020976543427, 0.006448753643780947, 0.014540991745889187, 0.006448753643780947, 0.7346413731575012], [0.001320559298619628, 0.47568392753601074, 0.20627006888389587, 0.20627006888389587, 0.11045531928539276], [0.156326025724411, 0.24056477844715118, 0.156326025724411, 0.20422184467315674, 0.24256138503551483], [0.23452502489089966, 0.027960319072008133, 0.21121399104595184, 0.49834033846855164, 0.027960319072008133], [0.01760355941951275, 0.009001360274851322, 0.8375166058540344, 0.01760355941951275, 0.11827497184276581], [0.31197595596313477, 0.0357089638710022, 0.31197595596313477, 0.3110288977622986, 0.02931022457778454], [0.04630760848522186, 0.06910494714975357, 0.0147130461409688, 0.04630760848522186, 0.823566734790802], [7.463264046236873e-05, 0.009927540086209774, 0.3401893675327301, 0.64973384141922, 7.463264046236873e-05], [0.9583767056465149, 0.017897285521030426, 0.0053481003269553185, 0.013029715046286583, 0.0053481003269553185], [0.02467074990272522, 0.06681153178215027, 0.11403364688158035, 0.11403364688158035, 0.6804503202438354], [0.3214845657348633, 0.03124896250665188, 0.004297345876693726, 0.3214845657348633, 0.3214845657348633], [0.2826586067676544, 0.027769984677433968, 0.2826586067676544, 0.32859647274017334, 0.07831632345914841], [0.03115125745534897, 0.06760556995868683, 0.007363670505583286, 0.06760556995868683, 0.8262739777565002], [0.34869110584259033, 0.09684040397405624, 0.09385718405246735, 0.34869110584259033, 0.11192020773887634], [0.46740514039993286, 0.0015004745218902826, 0.06253980100154877, 0.46740514039993286, 0.0011494919890537858], [0.25009313225746155, 0.35710474848747253, 0.25009313225746155, 0.11053059250116348, 0.03217830881476402], [0.0821196585893631, 0.3069976568222046, 0.005259601399302483, 0.2986254394054413, 0.3069976568222046], [4.978213110007346e-05, 0.26601913571357727, 0.26601913571357727, 0.06191914528608322, 0.405992716550827], [0.0025640518870204687, 0.5937137007713318, 0.0641816109418869, 0.0641816109418869, 0.27535900473594666], [0.031179791316390038, 0.031179791316390038, 0.6223427057266235, 0.26769572496414185, 0.047602005302906036], [0.09443154186010361, 0.08999364823102951, 0.06530969589948654, 0.6602714657783508, 0.08999364823102951], [0.29738593101501465, 1.5047834494907875e-05, 0.6927419900894165, 0.00492852833122015, 0.00492852833122015], [0.6727674603462219, 0.14369425177574158, 0.14369425177574158, 0.036399513483047485, 0.00344450818374753], [0.1962629109621048, 0.6246607303619385, 0.10854943096637726, 0.03526343032717705, 0.03526343032717705], [0.1571766883134842, 0.1571766883134842, 0.5546622276306152, 0.12432336062192917, 0.006661111488938332], [0.010324275121092796, 0.04525534436106682, 0.04525534436106682, 0.5208627581596375, 0.37830230593681335], [0.02297315001487732, 0.00161500193644315, 0.88246750831604, 0.02297315001487732, 0.06997121870517731], [0.0034370655193924904, 0.03411393240094185, 0.5085230469703674, 0.03411393240094185, 0.4198121130466461], [0.03228193148970604, 0.01825832948088646, 0.14834262430667877, 0.6996872425079346, 0.10142984986305237], [0.007706258911639452, 0.1431785523891449, 0.07465072721242905, 0.08913280069828033, 0.6853317022323608], [0.048284102231264114, 0.37182724475860596, 0.20355020463466644, 0.20355020463466644, 0.17278821766376495], [0.38574427366256714, 0.38574427366256714, 0.002834873041138053, 0.015960607677698135, 0.20971591770648956], [0.04148120805621147, 0.04720284789800644, 0.3676064610481262, 0.5022282600402832, 0.04148120805621147], [0.0008118804544210434, 0.04368417337536812, 0.0008118804544210434, 0.8455944657325745, 0.10909761488437653], [0.4269949495792389, 0.13257507979869843, 0.011532440781593323, 0.4269949495792389, 0.0019025990040972829], [0.09517466276884079, 0.08354131132364273, 0.056116893887519836, 0.056116893887519836, 0.7090502381324768], [0.0031236240174621344, 0.16444143652915955, 0.4064987897872925, 0.019437329843640327, 0.4064987897872925], [0.47075095772743225, 0.0006204470992088318, 0.008106278255581856, 0.04977137967944145, 0.47075095772743225], [0.03597765043377876, 0.4647359251976013, 0.022227445617318153, 0.012323139235377312, 0.4647359251976013], [0.06811486929655075, 0.09183676540851593, 0.3578833043575287, 0.06811486929655075, 0.4140501022338867], [0.04595401510596275, 0.1177268922328949, 0.04595401510596275, 0.34522244334220886, 0.445142537355423], [0.21265819668769836, 0.21265819668769836, 0.005209754686802626, 0.013842175714671612, 0.5556316375732422], [0.026821468025445938, 2.1000994820497e-05, 0.9662411212921143, 0.0034582135267555714, 0.0034582135267555714], [0.001364953233860433, 0.8697876930236816, 6.1158948483353015e-06, 0.12747637927532196, 0.001364953233860433], [0.01095246896147728, 0.23496614396572113, 0.0056141940876841545, 0.01095246896147728, 0.7375146746635437], [0.142296701669693, 0.45584890246391296, 0.142296701669693, 7.182227273005992e-05, 0.2594859302043915], [0.0052161552011966705, 0.7655590772628784, 0.10797970741987228, 0.11602893471717834, 0.0052161552011966705], [0.1278364211320877, 0.4125170111656189, 0.012443501502275467, 0.012443501502275467, 0.43475955724716187], [0.00685186916962266, 0.010385630652308464, 0.8935611248016357, 0.00685186916962266, 0.08234953135251999], [0.019470887258648872, 0.4787520468235016, 0.4787520468235016, 0.017303651198744774, 0.005721376743167639], [0.3199267089366913, 0.010467327199876308, 0.3199267089366913, 0.0012206052197143435, 0.3484586775302887], [0.4339355230331421, 0.4551909267902374, 0.04972649738192558, 0.04972649738192558, 0.011420548893511295], [0.18645690381526947, 0.12981560826301575, 0.3336028456687927, 0.3336028456687927, 0.01652185618877411], [0.004431191831827164, 0.007894046604633331, 0.007894046604633331, 0.00017979972471948713, 0.9796008467674255], [0.052181024104356766, 0.46913886070251465, 0.00894991960376501, 0.000591326504945755, 0.46913886070251465], [0.03254009410738945, 0.1775650680065155, 0.4396274983882904, 0.1775650680065155, 0.17270232737064362], [0.3359382152557373, 0.21447151899337769, 0.25480955839157104, 0.09739036858081818, 0.09739036858081818], [0.3880899250507355, 2.7067588234785944e-05, 0.023299559950828552, 0.058426570147275925, 0.5301568508148193], [0.2237512171268463, 0.13695655763149261, 0.3159017562866211, 0.2237512171268463, 0.09963934123516083], [0.842460036277771, 0.0403766967356205, 0.0403766967356205, 0.00907732080668211, 0.06770925223827362], [0.1322329044342041, 0.2428252249956131, 0.1551111787557602, 0.1322329044342041, 0.3375977873802185], [0.32492929697036743, 0.04789741709828377, 0.32492929697036743, 0.03897971659898758, 0.2632642984390259], [0.32405486702919006, 0.12138299643993378, 0.5209078788757324, 0.025706877931952477, 0.00794741977006197], [0.3467295169830322, 0.005300326272845268, 0.3467295169830322, 0.004707908723503351, 0.2965328097343445], [0.006319972686469555, 0.041095852851867676, 0.934278666973114, 0.009152736514806747, 0.009152736514806747], [0.09712658077478409, 0.05940500274300575, 0.6175764799118042, 0.1287653148174286, 0.09712658077478409], [0.2845093905925751, 0.0890483483672142, 0.2845093905925751, 0.015111200511455536, 0.32682177424430847], [0.24189622700214386, 0.015014471486210823, 0.04255371913313866, 0.48706331849098206, 0.21347226202487946], [0.09074755758047104, 0.18498963117599487, 0.06131117045879364, 0.6296588182449341, 0.03329287841916084], [0.011241977103054523, 0.5694533586502075, 0.05418222397565842, 0.05418222397565842, 0.3109402060508728], [0.794479489326477, 0.0490499883890152, 0.028663765639066696, 0.07875679433345795, 0.0490499883890152], [0.028931787237524986, 0.028931787237524986, 0.5473044514656067, 0.00943891704082489, 0.3853929936885834], [0.9346358180046082, 0.008523454889655113, 0.04829592630267143, 2.13171515497379e-05, 0.008523454889655113], [0.1329439878463745, 0.4903359115123749, 0.37374696135520935, 0.0014866068959236145, 0.0014866068959236145], [0.26825350522994995, 0.023417454212903976, 0.3275924026966095, 0.1124831810593605, 0.26825350522994995], [0.016740797087550163, 0.12542307376861572, 0.6636667251586914, 0.09708471596240997, 0.09708471596240997], [0.5900745391845703, 0.38927337527275085, 0.0028439678717404604, 0.008904099464416504, 0.008904099464416504], [0.23572543263435364, 0.23178702592849731, 0.28542494773864746, 0.011337211355566978, 0.23572543263435364], [0.05325409024953842, 0.43573951721191406, 0.0025801672600209713, 0.07268670201301575, 0.43573951721191406], [0.08123132586479187, 0.36405646800994873, 0.14344215393066406, 0.0472135916352272, 0.36405646800994873], [0.38922202587127686, 0.06785568594932556, 0.06785568594932556, 0.036167584359645844, 0.4388989806175232], [0.025493741035461426, 0.025493741035461426, 0.21118319034576416, 0.6992374658584595, 0.038591861724853516], [0.24672304093837738, 0.26759421825408936, 0.14837037026882172, 0.16865618526935577, 0.16865618526935577], [0.014898874796926975, 0.8850662112236023, 0.03907465189695358, 0.03048013709485531, 0.03048013709485531], [0.041641637682914734, 0.03553202748298645, 0.4471626281738281, 0.02850109525024891, 0.4471626281738281], [0.12435410916805267, 0.25480830669403076, 0.14888794720172882, 0.4018575847148895, 0.07009214907884598], [0.011935444548726082, 0.011935444548726082, 0.004224452655762434, 0.9672294855117798, 0.0046752383932471275], [0.0037261240649968386, 0.6052360534667969, 0.38233518600463867, 0.0037261240649968386, 0.004976503551006317], [0.7871917486190796, 0.150055393576622, 0.004430464468896389, 0.004430464468896389, 0.05389191210269928], [0.2576135993003845, 0.28776028752326965, 0.15218622982501984, 0.04482630267739296, 0.2576135993003845], [0.3568877875804901, 0.13767029345035553, 0.1484699249267578, 8.420446829404682e-05, 0.3568877875804901], [0.377096563577652, 0.377096563577652, 0.21232104301452637, 0.03254646807909012, 0.0009394027292728424], [0.01557080913335085, 0.42548274993896484, 0.0006085744826123118, 0.42548274993896484, 0.1328551024198532], [0.33981654047966003, 0.0005146452458575368, 0.6550562977790833, 0.004097906406968832, 0.0005146452458575368], [0.43378737568855286, 0.0020030969753861427, 0.0007798479637131095, 0.0020030969753861427, 0.56142657995224], [0.1336139738559723, 0.3515644371509552, 0.0402858704328537, 0.4342498779296875, 0.0402858704328537], [0.181376114487648, 0.2360372245311737, 0.2203695923089981, 0.2203695923089981, 0.14184747636318207], [0.4026593565940857, 0.028468608856201172, 0.2764298915863037, 0.01601218804717064, 0.2764298915863037], [0.029552510008215904, 0.14544887840747833, 0.14544887840747833, 0.02862648107111454, 0.6509233117103577], [0.01943640038371086, 0.27358755469322205, 0.4155668020248413, 0.01943640038371086, 0.2719728350639343], [0.0025754275266081095, 0.0038718569558113813, 0.47781336307525635, 0.03792586922645569, 0.47781336307525635], [0.6326028108596802, 0.08722975850105286, 0.025520874187350273, 0.12732326984405518, 0.12732326984405518], [0.33578434586524963, 0.21602235734462738, 0.15410126745700836, 0.15410126745700836, 0.13999079167842865], [0.062254227697849274, 0.0506301186978817, 0.0506301186978817, 0.12274322658777237, 0.7137423157691956], [0.24836094677448273, 0.12636132538318634, 0.5538525581359863, 0.035712551325559616, 0.035712551325559616], [0.42249158024787903, 0.0015928356442600489, 0.052808601409196854, 0.4702983498573303, 0.052808601409196854], [0.2477743923664093, 0.2477743923664093, 0.21149684488773346, 0.1938396692276001, 0.09911466389894485], [0.0019695281516760588, 0.0959831178188324, 0.8995912075042725, 0.001228086999617517, 0.001228086999617517], [0.02015325054526329, 0.01512282993644476, 0.9493885040283203, 0.00021258022752590477, 0.01512282993644476], [0.03432989493012428, 0.4783828556537628, 0.06320411711931229, 0.21204158663749695, 0.21204158663749695], [2.1855115846847184e-05, 2.1855115846847184e-05, 0.44296640157699585, 0.0001503373496234417, 0.5568395853042603], [0.0006026092451065779, 0.22669538855552673, 0.3781309127807617, 0.016440195962786674, 0.3781309127807617], [0.16980287432670593, 0.16980287432670593, 0.15971039235591888, 0.003282044315710664, 0.49740180373191833], [0.08561350405216217, 0.001280877972021699, 0.03186539560556412, 0.795626699924469, 0.08561350405216217], [0.16505424678325653, 0.06863982230424881, 0.3132065236568451, 0.28804513812065125, 0.16505424678325653], [0.09588261693716049, 0.04752258583903313, 0.09588261693716049, 0.7606141567230225, 9.798421524465084e-05], [0.005506411660462618, 0.0013895700685679913, 0.051287949085235596, 0.470907986164093, 0.470907986164093], [0.2158557027578354, 0.1887706071138382, 0.2691468596458435, 0.16311340034008026, 0.16311340034008026], [0.04512014612555504, 0.017933594062924385, 0.008161204867064953, 0.008161204867064953, 0.9206238985061646], [0.013913418166339397, 0.4288082420825958, 0.03135534003376961, 0.5120096206665039, 0.013913418166339397], [0.11917553097009659, 0.508474588394165, 0.17862482368946075, 0.07454951852560043, 0.11917553097009659], [0.17963773012161255, 0.08271026611328125, 0.17963773012161255, 0.293894499540329, 0.2641197443008423], [0.16677208244800568, 0.10797329246997833, 0.009286786429584026, 0.7066810727119446, 0.009286786429584026], [0.2847934365272522, 0.3150959610939026, 0.3150959610939026, 0.016104020178318024, 0.06891060620546341], [0.010563594289124012, 0.4074280261993408, 0.050347208976745605, 0.48131388425827026, 0.050347208976745605], [9.39152596401982e-05, 0.22202563285827637, 0.7688855528831482, 0.008901017718017101, 9.39152596401982e-05], [0.11890101432800293, 0.02122052200138569, 0.8318580389022827, 0.0067999339662492275, 0.02122052200138569], [0.28903132677078247, 0.1897231787443161, 0.11683318018913269, 0.28903132677078247, 0.11538102477788925], [0.36916327476501465, 0.10860785096883774, 0.14853164553642273, 0.18684861063957214, 0.18684861063957214], [0.24924077093601227, 0.06394539773464203, 0.12737104296684265, 0.3102020025253296, 0.24924077093601227], [0.4613964259624481, 0.15312190353870392, 0.15312190353870392, 0.22863005101680756, 0.0037297019734978676], [5.922682976233773e-05, 0.9465965628623962, 5.922682976233773e-05, 0.003478521713986993, 0.049806490540504456], [0.010946151800453663, 0.20629073679447174, 0.20629073679447174, 0.44615983963012695, 0.13031251728534698], [0.48732858896255493, 0.025839170441031456, 0.025839170441031456, 0.17414215207099915, 0.2868509292602539], [0.18456555902957916, 0.18456555902957916, 0.4647889733314514, 0.12677982449531555, 0.03930005058646202], [0.06013874337077141, 0.139428973197937, 0.22140762209892273, 0.5188859701156616, 0.06013874337077141], [0.2500321865081787, 0.39972934126853943, 0.06689038127660751, 0.06689038127660751, 0.21645769476890564], [0.34104424715042114, 0.003976206760853529, 0.053837813436985016, 0.34104424715042114, 0.260097473859787], [0.007211243733763695, 0.0003931978135369718, 0.07571817189455032, 0.07571817189455032, 0.8409590721130371], [0.22002561390399933, 0.07502321898937225, 0.056793808937072754, 0.056793808937072754, 0.5913636088371277], [0.00048604572657495737, 0.03513921797275543, 0.44360923767089844, 0.44360923767089844, 0.07715621590614319], [0.1760254055261612, 0.0008117540855892003, 0.1760254055261612, 0.0946793183684349, 0.5524581074714661], [0.30812352895736694, 0.1645592451095581, 0.1803426295518875, 0.1645592451095581, 0.18241539597511292], [0.35425806045532227, 0.018991604447364807, 0.35425806045532227, 0.025446642190217972, 0.2470456212759018], [0.3966400623321533, 0.015814028680324554, 0.08096558600664139, 0.21527133882045746, 0.29130905866622925], [0.02276238054037094, 0.8440881371498108, 0.09437263756990433, 0.02276238054037094, 0.016014494001865387], [0.07799749821424484, 0.00226343865506351, 0.38178253173828125, 0.38178253173828125, 0.1561739593744278], [0.013595773838460445, 0.12802614271640778, 0.42720937728881836, 0.003959380555897951, 0.42720937728881836], [0.3241025507450104, 0.05874812230467796, 0.05874812230467796, 0.09764272719621658, 0.4607584476470947], [0.004428679123520851, 0.42961010336875916, 0.08997766673564911, 0.08997766673564911, 0.3860059082508087], [0.2471320480108261, 0.2850876748561859, 0.2471320480108261, 0.0960163101553917, 0.12463199347257614], [0.05706241354346275, 0.6260802149772644, 0.20998799800872803, 0.10017938911914825, 0.006690060719847679], [0.03039744310081005, 0.4149288237094879, 0.4149288237094879, 0.0035253630485385656, 0.13621948659420013], [0.016858579590916634, 0.004320713225752115, 0.25746074318885803, 0.25746074318885803, 0.4638991057872772], [0.2558022737503052, 0.01561274565756321, 0.36187365651130676, 0.004837682470679283, 0.36187365651130676], [0.026346644386649132, 0.8000393509864807, 0.026346644386649132, 0.09953565150499344, 0.047731705009937286], [0.04113082215189934, 0.44777578115463257, 0.3504974842071533, 0.04113082215189934, 0.11946512758731842], [0.28123030066490173, 0.2673112154006958, 0.0020072932820767164, 0.1682208925485611, 0.28123030066490173], [0.3545084297657013, 0.006843596696853638, 0.3545084297657013, 0.2750924527645111, 0.00904709193855524], [0.0152351763099432, 0.7555520534515381, 0.009509590454399586, 0.10985159128904343, 0.10985159128904343], [0.12439743429422379, 0.15889762341976166, 0.05671622231602669, 0.5010911226272583, 0.15889762341976166], [0.411174476146698, 0.10259987413883209, 0.03955252096056938, 0.411174476146698, 0.035498667508363724], [0.2681751251220703, 0.2805289030075073, 0.1678587645292282, 0.002908280584961176, 0.2805289030075073], [0.003497710218653083, 0.5921818614006042, 0.25106021761894226, 0.003497710218653083, 0.14976249635219574], [0.047535959631204605, 0.10800037533044815, 0.7837612628936768, 0.047535959631204605, 0.013166457414627075], [0.4928482174873352, 0.04052160680294037, 0.386123925447464, 0.040253110229969025, 0.040253110229969025], [0.05886061489582062, 0.6704616546630859, 0.25565412640571594, 0.007511802017688751, 0.007511802017688751], [0.0001253496593562886, 0.2001134157180786, 0.2001134157180786, 0.0400301069021225, 0.5596176981925964], [0.3071764409542084, 0.3071764409542084, 0.00432640640065074, 0.3419211804866791, 0.03939948230981827], [0.07165324687957764, 0.6472794413566589, 0.10146186500787735, 0.08508501201868057, 0.09452042728662491], [0.0005580896395258605, 0.5590986609458923, 0.35236287117004395, 0.04399016872048378, 0.04399016872048378], [0.05514747276902199, 0.19879233837127686, 0.018247300758957863, 0.19879233837127686, 0.5290205478668213], [0.0033120911102741957, 0.2812725305557251, 0.15106667578220367, 0.2830761969089508, 0.2812725305557251], [0.007554501295089722, 0.05435777083039284, 0.4637211561203003, 0.4637211561203003, 0.010645532049238682], [0.4021625220775604, 0.0009461127337999642, 0.01142529584467411, 0.01142529584467411, 0.5740407705307007], [0.009449150413274765, 0.002135643269866705, 0.05347895249724388, 0.009449150413274765, 0.9254871606826782], [0.002542514819651842, 0.780770480632782, 0.0018120218301191926, 0.21233245730400085, 0.002542514819651842], [0.0017803239170461893, 0.9181653261184692, 0.05666808784008026, 0.02160601131618023, 0.0017803239170461893], [0.6281070113182068, 0.00017740925250109285, 0.3464626967906952, 0.015940284356474876, 0.00931259524077177], [0.1268874704837799, 0.36700665950775146, 0.026737213134765625, 0.1268874704837799, 0.3524811565876007], [0.6779724359512329, 0.010117020457983017, 0.010117020457983017, 0.006846423260867596, 0.2949471175670624], [0.6014907956123352, 0.05721115320920944, 0.05721115320920944, 0.2840636074542999, 2.3400021746056154e-05], [0.40912535786628723, 0.17101292312145233, 0.02449708804488182, 0.22435177862644196, 0.17101292312145233], [0.004581476096063852, 0.020279010757803917, 0.004581476096063852, 0.039578914642333984, 0.9309792518615723], [0.0017546272138133645, 0.0017546272138133645, 0.1799389123916626, 0.07552407681941986, 0.7410277128219604], [0.21861788630485535, 0.2105070948600769, 0.19362607598304749, 0.21861788630485535, 0.15863099694252014], [0.0007801336469128728, 0.4151165187358856, 0.4151165187358856, 0.15950950980186462, 0.009477319195866585], [0.10257837921380997, 0.001411427278071642, 0.07753640413284302, 0.07753640413284302, 0.7409374117851257], [0.12317536771297455, 0.026343893259763718, 0.3371381461620331, 0.026343893259763718, 0.4869987368583679], [0.4743379056453705, 0.25837019085884094, 0.0030503408052027225, 0.25837019085884094, 0.0058713648468256], [0.3018251061439514, 0.2649967670440674, 0.04246902838349342, 0.1257122904062271, 0.2649967670440674], [0.2295670509338379, 0.30165040493011475, 0.11894787847995758, 0.2295670509338379, 0.12026755511760712], [0.738055408000946, 0.03801630064845085, 0.07395857572555542, 0.03801630064845085, 0.11195340752601624], [0.02540322206914425, 0.6985757350921631, 0.23325219750404358, 0.02540322206914425, 0.0173655916005373], [0.20556415617465973, 0.03600052371621132, 0.7412939667701721, 0.014738966710865498, 0.002402302110567689], [0.2871537506580353, 0.35506388545036316, 0.13166919350624084, 0.09444394707679749, 0.13166919350624084], [0.04665490612387657, 0.10467807948589325, 0.0023396769538521767, 0.7416492104530334, 0.10467807948589325], [0.007269102614372969, 0.0005025148275308311, 0.6044145822525024, 0.0005025148275308311, 0.38731127977371216], [0.24327903985977173, 0.42215099930763245, 0.07134393602609634, 0.24327903985977173, 0.019947029650211334], [0.0029269650112837553, 0.0029269650112837553, 0.7540612816810608, 0.23261003196239471, 0.00747478473931551], [0.35408931970596313, 0.023531746119260788, 0.017298704013228416, 0.2509908974170685, 0.35408931970596313], [0.8201969861984253, 0.03081147000193596, 0.03081147000193596, 0.010346638038754463, 0.1078333929181099], [0.2410549521446228, 0.2410549521446228, 0.3049730956554413, 0.18287499248981476, 0.03004196472465992], [0.52672278881073, 0.14223186671733856, 0.004925099201500416, 0.16306015849113464, 0.16306015849113464], [0.24084292352199554, 0.5025696158409119, 0.25638124346733093, 0.00010311438381904736, 0.00010311438381904736], [0.7546288371086121, 0.21809275448322296, 0.0013817957369610667, 0.0224556066095829, 0.0034410555381327868], [0.0636814758181572, 0.02115677483379841, 0.02115677483379841, 0.8114319443702698, 0.08257307857275009], [0.33374062180519104, 0.33374062180519104, 0.005517801735550165, 0.29510337114334106, 0.03189762309193611], [0.015377985313534737, 0.005111836362630129, 0.0016261200653389096, 0.48894202709198, 0.48894202709198], [0.036036934703588486, 0.11308716982603073, 0.423852801322937, 0.423852801322937, 0.003170314244925976], [0.06071816757321358, 0.6186373233795166, 0.13704821467399597, 0.13704821467399597, 0.04654814302921295], [0.6691398620605469, 0.0004174242203589529, 0.07205161452293396, 0.1863395720720291, 0.07205161452293396], [0.009294372983276844, 0.01981624774634838, 0.4097636640071869, 0.14966462552547455, 0.4114610254764557], [0.0007648223545402288, 0.17755791544914246, 0.0007648223545402288, 0.7931304574012756, 0.02778191864490509], [0.09129785746335983, 0.2909625172615051, 0.20415261387825012, 0.12262441962957382, 0.2909625172615051], [0.22250376641750336, 0.009936555288732052, 0.23371030390262604, 0.0001091730737243779, 0.533740222454071], [0.04342186823487282, 0.20368973910808563, 0.4735887348651886, 0.20368973910808563, 0.07560993731021881], [0.002126776846125722, 0.08302149921655655, 0.8250725269317627, 0.08302149921655655, 0.006757797673344612], [0.11619928479194641, 0.34163838624954224, 0.5347630977630615, 0.0036996235139667988, 0.0036996235139667988], [0.01829094998538494, 0.4525163173675537, 0.00038415438029915094, 0.4525163173675537, 0.07629229873418808], [0.006918493192642927, 0.014682420529425144, 0.006918493192642927, 0.0014307560632005334, 0.9700499773025513], [0.01613633520901203, 0.023108189925551414, 0.9336346387863159, 0.0064587704837322235, 0.02066214196383953], [0.2089039534330368, 0.056792329996824265, 0.07630480080842972, 0.6012066006660461, 0.056792329996824265], [0.24050600826740265, 0.4070873558521271, 0.005485827103257179, 0.10641484707593918, 0.24050600826740265], [0.02905264124274254, 0.00078041129745543, 0.3644936978816986, 0.3644936978816986, 0.24117958545684814], [0.04048452526330948, 0.4615277349948883, 0.11896577477455139, 0.11896577477455139, 0.26005613803863525], [0.0034859750885516405, 0.0034859750885516405, 0.14436449110507965, 0.8305680155754089, 0.018095580860972404], [0.12462682276964188, 0.05412302166223526, 0.6113268733024597, 0.08529651910066605, 0.12462682276964188], [0.4161864221096039, 0.010109511204063892, 0.021665308624505997, 0.13585224747657776, 0.4161864221096039], [0.794335663318634, 0.0777139663696289, 0.0777139663696289, 0.048797741532325745, 0.001438681036233902], [0.01358365174382925, 0.33967000246047974, 0.28557318449020386, 0.33967000246047974, 0.0215031486004591], [0.7322556972503662, 0.16254214942455292, 0.010588174685835838, 0.09351537376642227, 0.0010986312991008162], [0.0006221851799637079, 0.00929892435669899, 0.30790314078330994, 0.37427255511283875, 0.30790314078330994], [0.2612159550189972, 0.0369039848446846, 0.6471723318099976, 0.0369039848446846, 0.017803708091378212], [0.32302725315093994, 0.48145726323127747, 0.0009725929703563452, 0.19357028603553772, 0.0009725929703563452], [0.4019929766654968, 0.07338541001081467, 0.4019929766654968, 0.030405815690755844, 0.09222275763750076], [0.8148742318153381, 0.045874014496803284, 0.04705479368567467, 0.046098485589027405, 0.046098485589027405], [0.13015463948249817, 0.2738018035888672, 0.3864293098449707, 0.13015463948249817, 0.07945962995290756], [0.07277514785528183, 0.18643806874752045, 0.038224656134843826, 0.038224656134843826, 0.6643374562263489], [0.02566654607653618, 0.010683508589863777, 0.02566654607653618, 0.09207464754581451, 0.8459087610244751], [0.004262951202690601, 0.49270570278167725, 0.0003641174698714167, 0.009961657226085663, 0.49270570278167725], [0.008855105377733707, 0.07759467512369156, 0.5041643977165222, 0.3317911624908447, 0.07759467512369156], [0.0866863951086998, 0.41033175587654114, 0.41033175587654114, 0.043137840926647186, 0.049512263387441635], [0.01707202009856701, 0.9203392863273621, 0.00504108564928174, 0.01707202009856701, 0.04047564044594765], [0.789380669593811, 0.06562372297048569, 0.06110629066824913, 0.022782985121011734, 0.06110629066824913], [0.017729826271533966, 0.1730264574289322, 0.1730264574289322, 0.599417507648468, 0.036799732595682144], [0.05946017801761627, 0.187887042760849, 0.2413298636674881, 0.187887042760849, 0.32343581318855286], [0.05274190008640289, 0.4715765416622162, 1.6175927157746628e-05, 0.4715765416622162, 0.004088850226253271], [0.02371857315301895, 0.5986343622207642, 0.35117194056510925, 0.01323756854981184, 0.01323756854981184], [0.10571444034576416, 0.09389955550432205, 0.5966336131095886, 0.09803798049688339, 0.10571444034576416], [0.15339872241020203, 0.5145094394683838, 0.0343150720000267, 0.15339872241020203, 0.14437808096408844], [0.0012292156461626291, 0.16266892850399017, 0.40766483545303345, 0.02077215537428856, 0.40766483545303345], [0.1769990622997284, 0.2625023424625397, 0.2625023424625397, 0.24128378927707672, 0.05671245977282524], [0.0013847807422280312, 0.87639981508255, 0.006768501829355955, 0.09218766540288925, 0.023259242996573448], [0.0202933419495821, 0.5004775524139404, 0.45220398902893066, 0.006731790490448475, 0.0202933419495821], [0.13248716294765472, 0.38798409700393677, 0.23296229541301727, 0.013604171574115753, 0.23296229541301727], [0.03804907575249672, 0.684758186340332, 0.03804907575249672, 0.010384690947830677, 0.2287590503692627], [0.10528934001922607, 0.24662469327449799, 0.008144036866724491, 0.3199709355831146, 0.3199709355831146], [0.5269894003868103, 0.19698770344257355, 0.20587383210659027, 0.03507452458143234, 0.03507452458143234], [0.20529884099960327, 0.0006866799085400999, 0.003124743467196822, 0.003124743467196822, 0.7877650260925293], [0.16025573015213013, 0.00015794852515682578, 0.21124817430973053, 0.16025573015213013, 0.468082457780838], [0.07667387276887894, 0.06151517853140831, 0.7694084644317627, 0.030887333676218987, 0.06151517853140831], [0.1643066704273224, 0.1643066704273224, 0.04860079661011696, 0.1442541480064392, 0.4785316288471222], [0.004601684864610434, 0.6990153193473816, 0.004601684864610434, 0.014605097472667694, 0.2771762013435364], [0.7335830330848694, 0.001624503405764699, 0.25662899017333984, 0.001624503405764699, 0.0065389336086809635], [0.1717383861541748, 0.1717383861541748, 0.03271569311618805, 0.007874900475144386, 0.6159325838088989], [0.00022328276827465743, 0.4964134991168976, 0.4964134991168976, 0.0025582958478480577, 0.004391388967633247], [0.0023092487826943398, 0.0002943511644843966, 0.9804274439811707, 0.014659657143056393, 0.0023092487826943398], [0.6222394108772278, 0.035506732761859894, 0.05044534057378769, 0.23692543804645538, 0.054883088916540146], [0.43029507994651794, 0.43029507994651794, 0.07170268893241882, 0.020891042426228523, 0.04681612178683281], [0.41508749127388, 0.41508749127388, 0.0689196065068245, 0.019889988005161285, 0.08101531118154526], [0.3443222939968109, 0.06662621349096298, 0.3443222939968109, 0.23953339457511902, 0.00519585469737649], [0.08160971105098724, 0.08160971105098724, 0.23880931735038757, 0.4964267313480377, 0.10154451429843903], [0.0009352226043120027, 0.0678940936923027, 0.0678940936923027, 0.023833511397242546, 0.839443027973175], [0.00525242742151022, 0.3993777334690094, 0.1956394910812378, 0.0003526996006257832, 0.3993777334690094], [0.3361609876155853, 0.09669583290815353, 0.2008242905139923, 0.3012513518333435, 0.06506750732660294], [0.008386725559830666, 0.206991508603096, 0.36804550886154175, 0.36804550886154175, 0.04853079468011856], [0.2954491674900055, 0.25565198063850403, 0.0017534940270707011, 0.19149331748485565, 0.25565198063850403], [0.2580459415912628, 0.20467334985733032, 0.2580459415912628, 0.2698187530040741, 0.0094160046428442], [0.28808948397636414, 0.11997118592262268, 0.2389904260635376, 0.28808948397636414, 0.06485937535762787], [0.1986846923828125, 0.007085271179676056, 0.007085271179676056, 0.008988169953227043, 0.7781566381454468], [0.6087880730628967, 0.2057240754365921, 0.07445717602968216, 0.03657342493534088, 0.07445717602968216], [0.17834416031837463, 0.00798176508396864, 0.6201168298721313, 0.015213154256343842, 0.17834416031837463], [0.012586652301251888, 0.15501242876052856, 0.0482829213142395, 0.15501242876052856, 0.6291055679321289], [0.14890430867671967, 0.011096593923866749, 0.3895222544670105, 0.3895222544670105, 0.060954537242650986], [0.02538112923502922, 0.18881000578403473, 0.0073891691863536835, 0.7710305452346802, 0.0073891691863536835], [0.19926340878009796, 0.19926340878009796, 0.24615861475467682, 0.08519557863473892, 0.27011898159980774], [0.05824628472328186, 0.682236909866333, 0.10585770010948181, 0.05824628472328186, 0.09541276842355728], [0.06658226251602173, 0.0325787216424942, 0.06658226251602173, 0.27925652265548706, 0.5550002455711365], [0.333916574716568, 0.333916574716568, 0.1589997559785843, 0.046643584966659546, 0.12652356922626495], [0.3075525164604187, 0.0354033000767231, 0.0354033000767231, 0.17965185642242432, 0.44198909401893616], [0.375319242477417, 0.375319242477417, 0.0034206511918455362, 0.24078606069087982, 0.005154769401997328], [0.15557880699634552, 0.3592917025089264, 0.0416937917470932, 0.4017418920993805, 0.0416937917470932], [0.3528362810611725, 0.10857640206813812, 0.26734277606010437, 0.0039017426315695047, 0.26734277606010437], [0.001018985640257597, 0.24710600078105927, 0.010771017521619797, 0.001018985640257597, 0.7400850057601929], [0.004177876748144627, 0.04621116816997528, 0.4747084975242615, 0.4747084975242615, 0.00019403996702749282], [0.19093148410320282, 0.41276779770851135, 0.19093148410320282, 0.04608463868498802, 0.15928462147712708], [0.000279225263511762, 0.07616771757602692, 0.6526439189910889, 0.13545458018779755, 0.13545458018779755], [0.3404178321361542, 0.01193402148783207, 0.30619582533836365, 0.03525655344128609, 0.30619582533836365], [0.5442264080047607, 0.09003052860498428, 0.013664455153048038, 0.33841416239738464, 0.013664455153048038], [0.38607853651046753, 0.13390599191188812, 0.025153174996376038, 0.13390599191188812, 0.3209563195705414], [0.004875159822404385, 0.2279943823814392, 0.2279943823814392, 0.055880527943372726, 0.4832555055618286], [0.00031472824048250914, 0.4232695400714874, 0.550102710723877, 0.013156501576304436, 0.013156501576304436], [0.17592953145503998, 0.21685530245304108, 3.498648220556788e-05, 0.3035900890827179, 0.3035900890827179], [0.06743992865085602, 0.47290220856666565, 0.07147856056690216, 0.07147856056690216, 0.3167007267475128], [0.0012713897740468383, 0.0012713897740468383, 0.98667973279953, 0.010583740659058094, 0.00019369386427570134], [0.02502729557454586, 0.3193300664424896, 0.3293522596359253, 0.0069603221490979195, 0.3193300664424896], [0.0731378048658371, 0.0731378048658371, 0.17965511977672577, 0.6607046723365784, 0.013364610262215137], [0.0022484336514025927, 0.5040178894996643, 0.24001865088939667, 0.013696366921067238, 0.24001865088939667], [0.4367882311344147, 0.2502673268318176, 0.1838354468345642, 0.06455449014902115, 0.06455449014902115], [0.09053194522857666, 0.3890986740589142, 0.10808952152729034, 0.023181188851594925, 0.3890986740589142], [0.3574061393737793, 0.1741153746843338, 0.3574061393737793, 0.07586251199245453, 0.03520990163087845], [0.005145200993865728, 0.050994936376810074, 0.006754054222255945, 0.006754054222255945, 0.9303517937660217], [0.33934327960014343, 0.05249522253870964, 0.016146063804626465, 0.33934327960014343, 0.2526721954345703], [0.48458805680274963, 0.4482440650463104, 0.06052384898066521, 0.0033220581244677305, 0.0033220581244677305], [0.2907109260559082, 0.3330461084842682, 0.0009000596473924816, 0.042296845465898514, 0.3330461084842682], [0.03372463211417198, 0.04085405915975571, 0.7030689120292664, 0.18862777948379517, 0.03372463211417198], [0.9607152342796326, 0.009326447732746601, 0.018165087327361107, 0.008571728132665157, 0.003221494611352682], [0.21285313367843628, 0.09480476379394531, 0.2615937888622284, 0.00030406718724407256, 0.43044421076774597], [0.05775841325521469, 0.4660455286502838, 2.5275148800574243e-05, 0.4660455286502838, 0.01012522354722023], [0.22189933061599731, 0.03592648729681969, 0.004173495341092348, 0.5161013603210449, 0.22189933061599731], [0.00037900597089901567, 0.1883029192686081, 0.02551981806755066, 0.7602784037590027, 0.02551981806755066], [0.8984225392341614, 0.027521586045622826, 0.026817433536052704, 0.027521586045622826, 0.019716991111636162], [0.008403006941080093, 0.00333255622535944, 0.1477358639240265, 0.1477358639240265, 0.6927927136421204], [0.9706037640571594, 0.01231599971652031, 0.01231599971652031, 0.0010038067121058702, 0.0037604018580168486], [0.008657786063849926, 0.27579936385154724, 0.015756815671920776, 0.6333930492401123, 0.06639304012060165], [0.029736854135990143, 0.071602001786232, 0.8445162773132324, 0.029736854135990143, 0.024407994002103806], [0.4731290340423584, 0.4731290340423584, 0.008779868483543396, 0.011498886160552502, 0.033463090658187866], [0.0019748855847865343, 0.05929580703377724, 0.05929580703377724, 0.048808567225933075, 0.8306249976158142], [0.8796392679214478, 0.03565632179379463, 0.013257289305329323, 0.03579075634479523, 0.03565632179379463], [0.740540623664856, 0.04915500432252884, 0.050119757652282715, 0.11006475985050201, 0.050119757652282715], [0.157589390873909, 0.06057349219918251, 0.39353013038635254, 0.19415347278118134, 0.19415347278118134], [0.10118287801742554, 0.2052447646856308, 0.34039708971977234, 0.012778203003108501, 0.34039708971977234], [0.6407105922698975, 0.07340821623802185, 0.051103707402944565, 0.07340821623802185, 0.1613692194223404], [0.0001039844355545938, 0.0001039844355545938, 0.21769475936889648, 0.7298018336296082, 0.05229542404413223], [0.11776817589998245, 0.37829360365867615, 0.04815670847892761, 0.07748782634735107, 0.37829360365867615], [0.09354027360677719, 0.05975853651762009, 0.2640085816383362, 0.29134631156921387, 0.29134631156921387], [0.05799594148993492, 0.1969669759273529, 0.29398104548454285, 0.2255280315876007, 0.2255280315876007], [0.029150279238820076, 0.2662617564201355, 0.009029421955347061, 0.3477792739868164, 0.3477792739868164], [0.16174229979515076, 0.4020041525363922, 0.16174229979515076, 0.2744310796260834, 8.023234840948135e-05], [0.024808833375573158, 0.11743266880512238, 0.42821672558784485, 0.0013251056661829352, 0.42821672558784485], [0.004095534794032574, 0.49653786420822144, 0.49653786420822144, 0.0023160360287874937, 0.0005126666510477662], [0.07508641481399536, 0.27057158946990967, 0.3706717789173126, 0.013098576106131077, 0.27057158946990967], [0.01506671030074358, 0.0008563896990381181, 0.20444302260875702, 0.38981693983078003, 0.38981693983078003], [0.005122252739965916, 0.0004348648653831333, 0.005122252739965916, 0.9753162264823914, 0.014004461467266083], [0.25393450260162354, 0.25769734382629395, 0.2216024398803711, 0.009068429470062256, 0.25769734382629395], [0.9083006381988525, 0.024325856938958168, 0.06659393012523651, 0.0003897823626175523, 0.0003897823626175523], [0.3554895520210266, 0.3554895520210266, 0.0027406595181673765, 0.021331554278731346, 0.26494866609573364], [0.12535463273525238, 0.11707153916358948, 0.03459063544869423, 0.18092061579227448, 0.5420625805854797], [0.05303480476140976, 0.28766506910324097, 0.36887338757514954, 0.0027616750448942184, 0.28766506910324097], [0.2756503224372864, 0.22349946200847626, 0.2756503224372864, 0.2243565022945404, 0.0008433845359832048], [0.02348106913268566, 0.4616703391075134, 0.023391153663396835, 0.4616703391075134, 0.029787108302116394], [0.35877397656440735, 0.579911470413208, 0.013646417297422886, 0.03402169048786163, 0.013646417297422886], [0.4818134903907776, 0.4818134903907776, 0.0016519210767000914, 0.013228130526840687, 0.021492915228009224], [0.001011944841593504, 0.006283602677285671, 0.0012510308297351003, 0.006283602677285671, 0.9851698279380798], [0.07036639750003815, 0.25794553756713867, 0.24622192978858948, 0.21273304522037506, 0.21273304522037506], [0.005205798894166946, 0.00012979698658455163, 0.010781925171613693, 0.07360897958278656, 0.9102734923362732], [0.005400900729000568, 0.05886084586381912, 0.6421486735343933, 0.005400900729000568, 0.28818875551223755], [0.16185913980007172, 0.05903295800089836, 0.5973058938980103, 0.05903295800089836, 0.1227690801024437], [0.3064274489879608, 0.1281777173280716, 0.22011029720306396, 0.3064274489879608, 0.0388571098446846], [0.012274231761693954, 0.002092539332807064, 0.6448524594306946, 0.28259342908859253, 0.05818728357553482], [0.4183075428009033, 0.3125147223472595, 0.0570690780878067, 0.15503960847854614, 0.0570690780878067], [0.007780327461659908, 0.021165743470191956, 0.9430821537971497, 0.00257223192602396, 0.02539953589439392], [0.04996035248041153, 0.022299569100141525, 0.03895178437232971, 0.8664888143539429, 0.022299569100141525], [0.015035474672913551, 0.04541165381669998, 0.015035474672913551, 0.9034987092018127, 0.02101867087185383], [0.3584122955799103, 0.17910347878932953, 0.17910347878932953, 0.09022704511880875, 0.1931537687778473], [0.06175936758518219, 0.06175936758518219, 0.524153470993042, 0.35002705454826355, 0.0023007511626929045], [0.1168295219540596, 0.18780528008937836, 0.18780528008937836, 0.4575386941432953, 0.05002129077911377], [0.38690510392189026, 0.025349421426653862, 0.19813096523284912, 0.0027094304095953703, 0.38690510392189026], [0.042786113917827606, 0.5999078154563904, 0.1773669421672821, 0.1773669421672821, 0.0025721595156937838], [0.3070073127746582, 0.07096578925848007, 0.14867518842220306, 0.3070073127746582, 0.1663443148136139], [0.6045466065406799, 0.00420887116342783, 0.01637118309736252, 0.01637118309736252, 0.35850220918655396], [0.4727024435997009, 0.4727024435997009, 0.04826310649514198, 0.0017697642324492335, 0.004562330432236195], [0.32066187262535095, 0.631807804107666, 0.001977567095309496, 0.001977567095309496, 0.04357520118355751], [0.0010529602877795696, 0.3426709771156311, 0.37105637788772583, 0.1426098346710205, 0.1426098346710205], [0.272676020860672, 0.03913402929902077, 0.10379289090633392, 0.272676020860672, 0.3117210566997528], [0.01552518829703331, 0.12000517547130585, 0.068577341735363, 0.6560871005058289, 0.13980521261692047], [0.056233081966638565, 0.056233081966638565, 0.18855205178260803, 0.6656960844993591, 0.03328568488359451], [0.45391491055488586, 0.0024540815502405167, 0.08655385673046112, 0.45391491055488586, 0.00316222058609128], [0.10327058285474777, 0.18062026798725128, 0.18062026798725128, 0.18062026798725128, 0.35486871004104614], [0.41267114877700806, 0.0210554301738739, 0.41267114877700806, 0.016088789328932762, 0.13751351833343506], [0.20194701850414276, 0.05043753609061241, 0.050011370331048965, 0.4956570565700531, 0.20194701850414276], [0.4544566869735718, 0.49421966075897217, 0.020975198596715927, 0.015174204483628273, 0.015174204483628273], [0.00152293941937387, 0.9172167181968689, 0.07640477269887924, 0.0024278247728943825, 0.0024278247728943825], [0.0042962245643138885, 0.08911336213350296, 0.44680720567703247, 0.012975944206118584, 0.44680720567703247], [0.49267593026161194, 0.49267593026161194, 0.0005973486695438623, 0.001282188226468861, 0.012768601067364216], [0.15512239933013916, 0.14907437562942505, 0.14907437562942505, 0.2595885992050171, 0.28714022040367126], [0.2685842514038086, 0.004977588076144457, 0.2685842514038086, 0.43431031703948975, 0.02354355901479721], [0.015150537714362144, 0.0002543407608754933, 0.49144434928894043, 0.0017065120628103614, 0.49144434928894043], [0.3482281267642975, 0.036138202995061874, 0.0006268625729717314, 0.4580387473106384, 0.15696807205677032], [0.6372836232185364, 0.016189491376280785, 0.07100711762905121, 0.13775986433029175, 0.13775986433029175], [0.2827722430229187, 0.2410329133272171, 0.2410329133272171, 0.18863865733146667, 0.046523235738277435], [0.010610898956656456, 0.0069258129224181175, 0.32335448265075684, 0.0069258129224181175, 0.652182936668396], [0.17157559096813202, 0.5147014856338501, 0.17157559096813202, 0.044606078416109085, 0.09754129499197006], [0.9230390191078186, 0.001322731375694275, 0.029387855902314186, 0.011511927470564842, 0.034738462418317795], [0.6849135160446167, 0.10809385031461716, 0.10809385031461716, 0.0644211620092392, 0.034477636218070984], [0.11641588807106018, 0.11641588807106018, 0.4909522235393524, 0.05475062504410744, 0.2214653193950653], [0.008744998835027218, 0.18124155700206757, 0.009871812537312508, 0.6189000606536865, 0.18124155700206757], [0.040015168488025665, 0.013295774348080158, 0.1347954124212265, 0.040015168488025665, 0.7718784809112549], [0.08208733052015305, 0.634644627571106, 0.21846942603588104, 0.04576929286122322, 0.0190292801707983], [0.3761887848377228, 0.13411706686019897, 0.13411706686019897, 0.002893263939768076, 0.35268378257751465], [0.5472952723503113, 0.0038756965659558773, 0.07645965367555618, 0.0038756965659558773, 0.3684936761856079], [0.135283425450325, 0.14691634476184845, 0.5728580355644226, 0.009658736176788807, 0.135283425450325], [0.000163614415214397, 0.000163614415214397, 0.14450642466545105, 0.8442559242248535, 0.010910390876233578], [0.22597451508045197, 0.008919421583414078, 0.01200016587972641, 0.7411057353019714, 0.01200016587972641], [0.02680792473256588, 0.48816415667533875, 0.04099603369832039, 0.04099603369832039, 0.40303584933280945], [0.03107655607163906, 0.03107655607163906, 0.10272544622421265, 0.5860604643821716, 0.2490609735250473], [0.3581942021846771, 0.3581942021846771, 0.11143486946821213, 0.06148093566298485, 0.11069581657648087], [0.4290322959423065, 0.004463049117475748, 0.019141344353556633, 0.5282219648361206, 0.019141344353556633], [0.15847647190093994, 0.07305994629859924, 0.7513805627822876, 0.008181944489479065, 0.008901029825210571], [0.4025012254714966, 0.4025012254714966, 0.004028555005788803, 0.08098036795854568, 0.10998860001564026], [0.08924560993909836, 0.12736651301383972, 0.6518980264663696, 0.004123299848288298, 0.12736651301383972], [0.002813930157572031, 0.3044570982456207, 0.3044570982456207, 0.024009324610233307, 0.36426255106925964], [0.004372905474156141, 0.02299490198493004, 0.02299490198493004, 0.009480170905590057, 0.9401570558547974], [0.07036309689283371, 0.20851081609725952, 0.07036309689283371, 0.040242020040750504, 0.6105208992958069], [0.3180655837059021, 0.3180655837059021, 0.010537028312683105, 0.01848689652979374, 0.3348449170589447], [0.4586942493915558, 0.007383792661130428, 0.0033893899526447058, 0.4586942493915558, 0.07183825969696045], [0.04505327716469765, 0.03693605959415436, 0.28123345971107483, 0.28123345971107483, 0.35554376244544983], [0.31118446588516235, 0.1911284625530243, 0.0044283452443778515, 0.0044283452443778515, 0.4888303279876709], [0.0021274867467582226, 0.487226277589798, 0.001383960130624473, 0.487226277589798, 0.022036010399460793], [0.08113738149404526, 0.793783962726593, 0.0016047258395701647, 0.12186913192272186, 0.0016047258395701647], [0.013543469831347466, 0.6215578317642212, 0.013543469831347466, 0.031772296875715256, 0.3195829391479492], [0.12574642896652222, 0.6653989553451538, 0.12574642896652222, 0.05676472187042236, 0.026343492791056633], [0.20121218264102936, 0.037039563059806824, 0.5768017768859863, 0.037039563059806824, 0.14790689945220947], [0.33136671781539917, 0.33136671781539917, 0.03409286588430405, 0.23226624727249146, 0.07090742141008377], [0.016057755798101425, 0.2699233889579773, 0.2678806483745575, 0.1762148141860962, 0.2699233889579773], [0.002599312225356698, 0.12648499011993408, 0.3156150281429291, 0.3156150281429291, 0.23968560993671417], [0.08014039695262909, 0.37324923276901245, 0.06643828004598618, 0.10692287236452103, 0.37324923276901245], [0.02088937908411026, 0.09067466109991074, 0.7962265610694885, 0.09067466109991074, 0.001534793758764863], [0.11518459767103195, 0.11518459767103195, 0.7315766215324402, 0.012880371883511543, 0.025173842906951904], [0.4996735155582428, 0.004229490179568529, 0.015286436304450035, 0.015286436304450035, 0.46552416682243347], [0.09088412672281265, 0.0920911654829979, 0.023359425365924835, 0.09088412672281265, 0.7027812004089355], [0.368639200925827, 0.13618940114974976, 0.24440471827983856, 0.11457733809947968, 0.13618940114974976], [0.1777191311120987, 0.01692228764295578, 0.3968643844127655, 0.011629852466285229, 0.3968643844127655], [0.20007263123989105, 0.015550082549452782, 0.0031558361370116472, 0.1031491830945015, 0.6780722141265869], [0.115015909075737, 0.3592912554740906, 0.115015909075737, 0.022959215566515923, 0.38771772384643555], [0.6148223280906677, 0.004831986967474222, 0.1569925844669342, 0.003287605009973049, 0.22006550431251526], [0.02963482029736042, 0.8695239424705505, 0.03978851065039635, 0.03052634559571743, 0.03052634559571743], [0.5051292777061462, 0.2629527449607849, 0.09361197054386139, 0.06915300339460373, 0.06915300339460373], [0.08614014834165573, 0.8776183724403381, 0.011775018647313118, 0.01223326288163662, 0.01223326288163662], [0.06488384306430817, 0.7020626068115234, 0.08393238484859467, 0.08423730731010437, 0.06488384306430817], [0.49204665422439575, 0.09679622203111649, 0.14235302805900574, 0.1344020664691925, 0.1344020664691925], [0.03888009116053581, 0.03888009116053581, 0.7745802402496338, 0.07965817302465439, 0.06800135225057602], [0.16718743741512299, 0.1176186203956604, 0.3508201241493225, 0.3508201241493225, 0.013553714379668236], [0.4745940864086151, 0.4745940864086151, 0.004021335393190384, 0.04167274385690689, 0.005117788445204496], [0.30277007818222046, 0.3630610406398773, 0.02247222699224949, 0.008926546201109886, 0.30277007818222046], [0.3724665939807892, 0.5248329639434814, 0.04970300570130348, 0.0032944311387836933, 0.04970300570130348], [0.8811326026916504, 0.10044839233160019, 0.009107987396419048, 0.009107987396419048, 0.00020303548080846667], [0.04336581751704216, 0.3133375942707062, 0.004084326792508364, 0.6390644311904907, 0.0001477720943512395], [0.5534793138504028, 0.17271624505519867, 0.09995070844888687, 0.17271624505519867, 0.0011374922469258308], [0.536916196346283, 0.14586065709590912, 0.004090938251465559, 0.16727153956890106, 0.14586065709590912], [0.1229010596871376, 0.2827065587043762, 0.42229610681533813, 0.08604816347360611, 0.08604816347360611], [0.04550958424806595, 0.016236532479524612, 0.14350314438343048, 0.39737534523010254, 0.39737534523010254], [0.527763843536377, 0.3892419934272766, 0.007012154441326857, 0.007012154441326857, 0.06896982342004776], [5.413601229520282e-06, 0.47272324562072754, 0.47272324562072754, 0.00205297046341002, 0.052495066076517105], [0.35765698552131653, 0.3006573021411896, 0.031654130667448044, 0.009374275803565979, 0.3006573021411896], [0.005651373416185379, 0.0026332682464271784, 0.26619455218315125, 0.7228875160217285, 0.0026332682464271784], [0.010097982361912727, 5.437554500531405e-05, 0.11638586223125458, 0.010097982361912727, 0.8633638620376587], [0.1115996316075325, 0.0003188342961948365, 0.1115996316075325, 0.6658967733383179, 0.11058509349822998], [0.4608178734779358, 0.02861863747239113, 0.02861863747239113, 0.41853630542755127, 0.06340856105089188], [0.1011567935347557, 0.03259681910276413, 0.0011265214998275042, 0.8132720589637756, 0.05184783414006233], [0.0024246422108262777, 0.04164920747280121, 0.9095439910888672, 0.004732951987534761, 0.04164920747280121], [0.13122975826263428, 0.13122975826263428, 0.19735506176948547, 0.1773892641067505, 0.36279624700546265], [0.17403344810009003, 0.00265865633264184, 0.41078609228134155, 0.0017356942407786846, 0.41078609228134155], [0.13347388803958893, 0.04307715594768524, 0.33824262022972107, 0.44212913513183594, 0.04307715594768524], [0.014938930980861187, 0.1275191754102707, 0.004547253716737032, 0.7254754304885864, 0.1275191754102707], [0.9846696853637695, 0.0022141579538583755, 0.012208080850541592, 0.0004539988876786083, 0.0004539988876786083], [0.20873159170150757, 0.5691143274307251, 0.20873159170150757, 0.011154770851135254, 0.0022676954977214336], [0.27831923961639404, 0.27831923961639404, 0.17319247126579285, 0.2061273157596588, 0.06404174119234085], [0.6596881151199341, 0.07361960411071777, 0.07361960411071777, 0.021908162161707878, 0.17116454243659973], [0.012684499844908714, 0.9101412296295166, 0.02432149276137352, 0.04016835242509842, 0.012684499844908714], [0.08563261479139328, 0.007568548433482647, 0.08563261479139328, 0.8180957436561584, 0.003070406848564744], [5.941381914453814e-06, 0.49667850136756897, 0.49667850136756897, 0.006632470525801182, 4.622932010533987e-06], [0.06780005991458893, 0.015009737573564053, 0.45743709802627563, 0.45743709802627563, 0.002315935678780079], [0.6659263968467712, 0.13584527373313904, 0.062185779213905334, 0.13584527373313904, 0.00019731874635908753], [0.023605531081557274, 0.005499240476638079, 0.3660438060760498, 0.3660438060760498, 0.23880767822265625], [0.1191835105419159, 0.20649908483028412, 0.1157730296254158, 0.1191835105419159, 0.4393608570098877], [0.2431526780128479, 0.38920024037361145, 0.015697840601205826, 0.349637895822525, 0.0023113300558179617], [0.002622542902827263, 0.031401101499795914, 0.017257660627365112, 0.47435930371284485, 0.47435930371284485], [0.00042349231080152094, 0.6227205395698547, 0.00042349231080152094, 0.34157297015190125, 0.034859564155340195], [0.02120301127433777, 0.004632832016795874, 0.05112757906317711, 0.004632832016795874, 0.9184037446975708], [0.170277938246727, 0.5690637230873108, 0.0799587294459343, 0.170277938246727, 0.010421671904623508], [0.4662374258041382, 9.644949022913352e-05, 0.4662374258041382, 0.0664549320936203, 0.0009737067739479244], [0.05894884467124939, 0.6331908702850342, 0.010458894073963165, 0.2869424819946289, 0.010458894073963165], [0.0008559458656236529, 0.04550733044743538, 0.7612435817718506, 0.09619655460119247, 0.09619655460119247], [0.30171969532966614, 0.2815823554992676, 0.00022955484746489674, 0.30171969532966614, 0.11474865674972534], [0.24428598582744598, 0.24428598582744598, 0.4394018352031708, 0.010071661323308945, 0.061954598873853683], [0.16873376071453094, 0.003280127653852105, 0.5371279120445251, 0.12212447822093964, 0.16873376071453094], [0.15198753774166107, 0.05948324874043465, 0.5835822820663452, 0.05295940861105919, 0.15198753774166107], [0.016800859943032265, 0.8071519732475281, 0.07697749137878418, 0.016800859943032265, 0.08226882666349411], [0.0024457252584397793, 0.3942849636077881, 0.2675238847732544, 0.06822146475315094, 0.2675238847732544], [0.05740831792354584, 0.2137673944234848, 0.1984647512435913, 0.1984647512435913, 0.33189475536346436], [0.09898456186056137, 0.6164985299110413, 0.15715345740318298, 0.09898456186056137, 0.028378883376717567], [0.2102537900209427, 0.002928114263340831, 0.14866125583648682, 0.2102537900209427, 0.42790305614471436], [0.3651791512966156, 0.11352504789829254, 0.0021713704336434603, 0.3651791512966156, 0.153945192694664], [0.033576250076293945, 0.01615075021982193, 0.05339909717440605, 0.05339909717440605, 0.843474805355072], [0.5646288394927979, 0.04236830025911331, 0.03665925934910774, 0.31397533416748047, 0.04236830025911331], [0.35418686270713806, 0.0045647695660591125, 0.00019821002206299454, 0.12806154787540436, 0.5129886269569397], [0.3411045968532562, 0.016262032091617584, 0.2988419830799103, 0.3411045968532562, 0.002686765743419528], [0.7126652598381042, 0.08803518861532211, 0.19608967006206512, 0.0030520365107804537, 0.00015787195297889411], [0.03722218796610832, 0.43271830677986145, 0.43271830677986145, 0.09209902584552765, 0.005242097191512585], [0.00889358390122652, 0.6039835810661316, 0.07473421841859818, 0.00889358390122652, 0.3034951090812683], [0.08379463106393814, 0.021354632452130318, 0.8153578042984009, 0.021354632452130318, 0.058138325810432434], [0.030211109668016434, 0.026519961655139923, 0.013030861504375935, 0.8334280848503113, 0.09681001305580139], [0.36660897731781006, 0.025016551837325096, 0.07535999268293381, 0.07535999268293381, 0.4576544761657715], [0.3551032841205597, 0.025115059688687325, 0.13741381466388702, 0.3551032841205597, 0.1272645890712738], [0.00012686816626228392, 0.00012686816626228392, 0.544454038143158, 0.004502222873270512, 0.45079001784324646], [0.10924631357192993, 0.8591316938400269, 0.002390553941950202, 0.026840876787900925, 0.002390553941950202], [0.04404505714774132, 0.1614166498184204, 0.04404505714774132, 0.2163178026676178, 0.5341753959655762], [0.05398315191268921, 0.05398315191268921, 0.570397675037384, 0.0004230671329423785, 0.32121291756629944], [0.021685417741537094, 0.18545088171958923, 0.003644656389951706, 0.7855744361877441, 0.003644656389951706], [0.043121252208948135, 0.27338698506355286, 0.2076663076877594, 0.4327041506767273, 0.043121252208948135], [0.025212572887539864, 0.05696680024266243, 0.13545235991477966, 0.39118412137031555, 0.39118412137031555], [0.21246102452278137, 0.3739503026008606, 0.03881676122546196, 0.3739503026008606, 0.0008215910056605935], [0.0037933550775051117, 0.0609203577041626, 0.10274185985326767, 0.831943690776825, 0.000600686704274267], [0.0639471635222435, 0.024054547771811485, 0.030424315482378006, 0.8176268935203552, 0.0639471635222435], [0.09709050506353378, 0.06317342072725296, 0.2381056845188141, 0.09709050506353378, 0.5045399069786072], [0.10623331367969513, 0.003664683783426881, 0.42115381360054016, 0.047794416546821594, 0.42115381360054016], [0.059861477464437485, 0.7932326197624207, 8.984182932181284e-05, 0.0869545266032219, 0.059861477464437485], [0.3462800979614258, 0.3462800979614258, 0.13400909304618835, 0.12442418932914734, 0.04900652542710304], [0.0019443120108917356, 0.8228894472122192, 0.07353481650352478, 0.02809663489460945, 0.07353481650352478], [0.019183585420250893, 0.019183585420250893, 0.9175276756286621, 0.03508589416742325, 0.009019232355058193], [0.27177920937538147, 0.01403323095291853, 0.029061445966362953, 0.01403323095291853, 0.6710928678512573], [0.015444686636328697, 0.14079193770885468, 0.22846369445323944, 0.5998549461364746, 0.015444686636328697], [0.3017670810222626, 0.2568332552909851, 0.07783222198486328, 0.2857353091239929, 0.07783222198486328], [0.5418624877929688, 0.1536172777414322, 0.1536172777414322, 0.1005340963602066, 0.05036885291337967], [0.3609767258167267, 0.1511031687259674, 0.1254134178161621, 0.0015299475053325295, 0.3609767258167267], [0.07751895487308502, 0.003467283211648464, 0.00014391590957529843, 0.008111463859677315, 0.9107583165168762], [0.581066370010376, 0.10670320689678192, 0.0683949887752533, 0.10670320689678192, 0.13713225722312927], [0.05203301087021828, 0.2308933287858963, 0.22865770757198334, 0.2308933287858963, 0.25752267241477966], [0.03175516426563263, 0.03175516426563263, 0.7723899483680725, 0.15789759159088135, 0.006202202755957842], [0.23377442359924316, 0.39974814653396606, 0.23377442359924316, 0.1086556538939476, 0.024047357961535454], [0.0641075074672699, 0.0641075074672699, 0.33898910880088806, 0.32080912590026855, 0.21198679506778717], [0.33915236592292786, 0.33915236592292786, 0.04786671698093414, 0.0005242067272774875, 0.2733043432235718], [0.48876094818115234, 0.16685433685779572, 0.02659275010228157, 0.2911991477012634, 0.02659275010228157], [0.8976423740386963, 0.0953764021396637, 0.0018556200666353106, 0.002562797861173749, 0.002562797861173749], [0.6225412487983704, 0.015477144159376621, 0.3200856149196625, 0.015477144159376621, 0.026418793946504593], [0.1917220652103424, 0.36474886536598206, 0.008605909533798695, 0.2432011514902115, 0.1917220652103424], [0.001754399505443871, 0.05656587705016136, 0.010737032629549503, 0.8743768334388733, 0.05656587705016136], [0.04418008029460907, 0.015467855148017406, 0.07798157632350922, 0.22709010541439056, 0.6352803707122803], [0.005377129651606083, 0.003215877804905176, 0.08710301667451859, 0.4521520137786865, 0.4521520137786865], [0.23405249416828156, 0.18653583526611328, 0.2153843492269516, 0.18653583526611328, 0.17749157547950745], [0.1717941015958786, 0.1717941015958786, 0.5287067890167236, 0.036680713295936584, 0.09102436900138855], [0.0012040919391438365, 0.006190481595695019, 0.0352526530623436, 0.9511622190475464, 0.006190481595695019], [0.1010134220123291, 0.37032797932624817, 0.22840644419193268, 0.19923870265483856, 0.1010134220123291], [9.789690375328064e-05, 0.08861980587244034, 0.08861980587244034, 0.18834425508975983, 0.6343181729316711], [0.005551104433834553, 0.43613043427467346, 0.10246538370847702, 0.0197225920855999, 0.43613043427467346], [0.09997984766960144, 0.4880276620388031, 0.281231552362442, 0.030781060457229614, 0.09997984766960144], [0.0008804842946119606, 0.2863401770591736, 0.010183850303292274, 0.6924116611480713, 0.010183850303292274], [0.23932082951068878, 0.0719556137919426, 0.0719556137919426, 0.26943397521972656, 0.34733399748802185], [0.04203496873378754, 0.168321430683136, 0.5263096690177917, 0.09501250833272934, 0.168321430683136], [0.164798304438591, 0.164798304438591, 0.016518907621502876, 0.21904948353767395, 0.4348350465297699], [0.008128990419209003, 0.23577609658241272, 0.158628910779953, 0.36168989539146423, 0.23577609658241272], [0.2389093041419983, 0.2544263005256653, 0.2389093041419983, 0.06747686117887497, 0.20027819275856018], [0.4032197594642639, 0.17362140119075775, 0.009765909984707832, 0.010173250921070576, 0.4032197594642639], [0.41793370246887207, 0.12961715459823608, 0.41793370246887207, 0.011447915807366371, 0.023067550733685493], [0.11003727465867996, 0.24627800285816193, 0.07507246732711792, 0.49353983998298645, 0.07507246732711792], [0.01559456903487444, 0.8056390881538391, 0.1423107236623764, 0.0208610650151968, 0.01559456903487444], [0.2818489670753479, 0.35054561495780945, 2.5411425667698495e-05, 0.35054561495780945, 0.017034385353326797], [0.18515485525131226, 0.046686697751283646, 0.29868218302726746, 0.18515485525131226, 0.2843213677406311], [0.10041529685258865, 0.20913885533809662, 0.3523043096065521, 0.12900273501873016, 0.20913885533809662], [0.7493352890014648, 0.05472710356116295, 0.03109215572476387, 0.11011836677789688, 0.05472710356116295], [0.06299220025539398, 0.06299220025539398, 0.010767449624836445, 0.48153039813041687, 0.3817177712917328], [0.07493845373392105, 0.15596653521060944, 0.6640617847442627, 0.07493845373392105, 0.030094796791672707], [0.7834250330924988, 0.030823489651083946, 0.05373740941286087, 0.030823489651083946, 0.10119055211544037], [0.03992408141493797, 0.084084652364254, 0.03992408141493797, 0.5741915702819824, 0.26187562942504883], [0.03255153447389603, 0.010791498236358166, 0.31574589014053345, 0.31574589014053345, 0.3251652121543884], [0.042867179960012436, 0.26996293663978577, 0.042867179960012436, 0.0966893881559372, 0.5476133823394775], [0.29077014327049255, 0.3453548848628998, 0.01522139459848404, 0.003298724303022027, 0.3453548848628998], [0.06735782325267792, 0.06735782325267792, 0.513076901435852, 0.06582802534103394, 0.2863794267177582], [0.0006955598364584148, 0.017068691551685333, 0.9111804366111755, 0.07035975158214569, 0.0006955598364584148], [0.6532217264175415, 0.03931977599859238, 0.21209324896335602, 0.047682639211416245, 0.047682639211416245], [0.005993743427097797, 0.050452012568712234, 0.9291688799858093, 0.007192704826593399, 0.007192704826593399], [0.17238646745681763, 0.024979421868920326, 0.7921333909034729, 0.005250332411378622, 0.005250332411378622], [0.8531069755554199, 0.0026359958574175835, 0.05339302122592926, 0.04543202370405197, 0.04543202370405197], [0.34418463706970215, 0.11650819331407547, 0.25443312525749207, 0.030440855771303177, 0.25443312525749207], [0.011050154455006123, 0.7410880923271179, 0.011050154455006123, 0.13574358820915222, 0.10106804966926575], [0.48620298504829407, 0.21643340587615967, 0.12285714596509933, 0.05164925009012222, 0.12285714596509933], [0.14137929677963257, 0.24060212075710297, 0.0019941304344683886, 0.24060212075710297, 0.37542232871055603], [0.17239783704280853, 0.5273730158805847, 0.005641307216137648, 0.12219003587961197, 0.17239783704280853], [0.002482723444700241, 0.03719222545623779, 0.18638384342193604, 0.3869706094264984, 0.3869706094264984], [0.33148273825645447, 0.2558234930038452, 0.09312655031681061, 0.2558234930038452, 0.06374377757310867], [0.08102166652679443, 0.2812572717666626, 0.08102166652679443, 0.028716105967760086, 0.5279833078384399], [0.49646103382110596, 0.13821746408939362, 0.13821746408939362, 0.12397324293851852, 0.10313081741333008], [0.0016876680310815573, 0.4563261866569519, 0.03443881869316101, 0.051221199333667755, 0.4563261866569519], [0.18055428564548492, 0.009652271866798401, 0.7764565944671631, 0.009652271866798401, 0.023684481158852577], [0.15321165323257446, 0.013193613849580288, 0.2842992842197418, 0.5361018180847168, 0.013193613849580288], [0.04533090814948082, 0.1419946402311325, 0.04533090814948082, 0.47271493077278137, 0.2946285307407379], [0.20619970560073853, 0.005733054596930742, 0.5323057770729065, 0.20619970560073853, 0.0495617538690567], [0.8085318207740784, 0.0928792804479599, 0.04987437278032303, 0.007675295230001211, 0.041039299219846725], [0.05513480305671692, 0.20284458994865417, 0.20284458994865417, 0.47580328583717346, 0.06337270885705948], [0.10135873407125473, 0.43131884932518005, 0.02973339520394802, 0.006270159967243671, 0.43131884932518005], [0.0008415815536864102, 0.052326712757349014, 0.0008415815536864102, 0.057146403938531876, 0.8888436555862427], [0.0021270494908094406, 0.2044564187526703, 0.1630360186100006, 0.4259240925312042, 0.2044564187526703], [0.7118943333625793, 0.0856870487332344, 0.09418247640132904, 0.0541180856525898, 0.0541180856525898], [0.2191939502954483, 0.3553842008113861, 0.026701990514993668, 0.3553842008113861, 0.0433356948196888], [0.15799707174301147, 0.15799707174301147, 0.015895096585154533, 0.19974017143249512, 0.468370646238327], [0.17828264832496643, 0.17828264832496643, 0.3190704584121704, 0.03354012966156006, 0.2908240854740143], [0.013720358721911907, 0.039763953536748886, 6.091909381211735e-05, 6.091909381211735e-05, 0.9463938474655151], [0.14504693448543549, 0.748773455619812, 0.003978945780545473, 0.047053877264261246, 0.055146731436252594], [0.0033829249441623688, 0.14103122055530548, 0.14103122055530548, 0.3678237795829773, 0.34673094749450684], [0.2017280012369156, 0.013982792384922504, 0.2017280012369156, 0.36169299483299255, 0.22086825966835022], [0.32170015573501587, 0.062345270067453384, 0.32170015573501587, 0.2019597291946411, 0.09229468554258347], [0.048998866230249405, 0.571525514125824, 0.11706168949604034, 0.11706168949604034, 0.14535222947597504], [0.21173173189163208, 0.2782491147518158, 0.29025858640670776, 0.008028769865632057, 0.21173173189163208], [0.10624107718467712, 0.40960219502449036, 0.10624107718467712, 0.3050096333026886, 0.0729060098528862], [0.300709992647171, 0.004271519370377064, 0.004271519370377064, 0.22191877663135529, 0.4688282608985901], [0.0541689470410347, 0.0541689470410347, 0.4356054365634918, 0.391112744808197, 0.06494392454624176], [0.05675594136118889, 0.8142833113670349, 0.06286834180355072, 0.05675594136118889, 0.009336493909358978], [0.16328008472919464, 0.04030580818653107, 0.15658438205718994, 0.5995239615440369, 0.04030580818653107], [0.6942890882492065, 0.061451442539691925, 0.020124590024352074, 0.2040102630853653, 0.020124590024352074], [0.2672218382358551, 0.2948257625102997, 0.2948257625102997, 0.07879363000392914, 0.06433304399251938], [0.11660578846931458, 0.005669014062732458, 0.4330191910266876, 0.011686858721077442, 0.4330191910266876], [0.030086545273661613, 0.1369789093732834, 0.7226327061653137, 0.0015171049162745476, 0.1087847426533699], [0.11935201287269592, 0.880567729473114, 3.024155375896953e-05, 1.975939994736109e-05, 3.024155375896953e-05], [0.13566896319389343, 0.0034807673655450344, 0.0034807673655450344, 0.8554777503013611, 0.0018917520064860582], [0.022813767194747925, 0.14900211989879608, 0.6550968289375305, 0.1546405702829361, 0.01844668574631214], [0.024518879130482674, 0.03008437156677246, 0.7975101470947266, 0.11780223995447159, 0.03008437156677246], [0.0041646757163107395, 0.2587539255619049, 0.028659341856837273, 0.3542110025882721, 0.3542110025882721], [0.026556383818387985, 0.6353998780250549, 0.026556383818387985, 0.29732346534729004, 0.014163856394588947], [0.2760460078716278, 0.18187889456748962, 0.25797605514526367, 0.25797605514526367, 0.026122964918613434], [0.2141890525817871, 0.09086411446332932, 0.04037565365433693, 0.5637070536613464, 0.09086411446332932], [0.03952217474579811, 0.005285412073135376, 0.1102169007062912, 0.839690089225769, 0.005285412073135376], [0.10918528586626053, 0.3898620307445526, 0.03945307433605194, 0.352314293384552, 0.10918528586626053], [0.013878214173018932, 0.03730997070670128, 0.6664106845855713, 0.15736693143844604, 0.12503419816493988], [0.00867289025336504, 0.00516947777941823, 0.03883803263306618, 0.03883803263306618, 0.9084816575050354], [0.020911535248160362, 0.208165243268013, 0.0007539103971794248, 0.562004029750824, 0.208165243268013], [0.04041775315999985, 0.7737650275230408, 0.13888971507549286, 0.0065097385086119175, 0.04041775315999985], [0.02402988076210022, 0.07176823168992996, 0.07176823168992996, 0.153056800365448, 0.6793769001960754], [0.08825492113828659, 0.020490307360887527, 0.020490307360887527, 0.01342298835515976, 0.857341468334198], [0.17298604547977448, 0.6935105323791504, 0.0172274187207222, 0.09904862195253372, 0.0172274187207222], [0.2298290878534317, 0.2298290878534317, 0.0007816666620783508, 0.09875694662332535, 0.44080328941345215], [0.0076483311131596565, 0.019841784611344337, 0.45527246594429016, 0.0619649663567543, 0.45527246594429016], [0.014025397598743439, 0.2145415097475052, 0.07039414346218109, 0.22448845207691193, 0.47655051946640015], [0.28635913133621216, 0.10269445925951004, 0.27856016159057617, 0.10269445925951004, 0.22969180345535278], [0.10911031067371368, 0.3746013939380646, 0.05140523239970207, 0.3746013939380646, 0.09028169512748718], [0.12936186790466309, 0.3482374846935272, 0.037165507674217224, 0.13699765503406525, 0.3482374846935272], [0.0006137525197118521, 0.0061485860496759415, 0.0061485860496759415, 0.9095886945724487, 0.07750032097101212], [0.003207293339073658, 0.9315113425254822, 0.057684239000082016, 0.003207293339073658, 0.004389820154756308], [0.00517938332632184, 0.9698858857154846, 0.002669718349352479, 0.011132496409118176, 0.011132496409118176], [0.055415187031030655, 0.0007485357928089797, 0.0007485357928089797, 0.7775154709815979, 0.16557227075099945], [0.00494270259514451, 0.4408946931362152, 0.0168137326836586, 0.4408946931362152, 0.0964542105793953], [0.009997298941016197, 0.2821773886680603, 0.29920604825019836, 0.2821773886680603, 0.12644189596176147], [0.39623644948005676, 0.19713439047336578, 0.003654892323538661, 0.006737846881151199, 0.39623644948005676], [0.08957117050886154, 0.5335227251052856, 0.08957117050886154, 0.15423431992530823, 0.13310055434703827], [0.4146493971347809, 0.007407382596284151, 0.0015445091994479299, 0.16174925863742828, 0.4146493971347809], [0.43926671147346497, 0.09698899835348129, 0.2176647186279297, 0.2176647186279297, 0.02841489389538765], [0.032677266746759415, 0.4112151563167572, 0.02398347295820713, 0.4112151563167572, 0.1209089532494545], [0.1276392638683319, 0.1005178913474083, 0.1005178913474083, 0.03235789015889168, 0.6389670372009277], [0.08814743161201477, 0.018410416319966316, 0.08814743161201477, 0.29060402512550354, 0.5146907567977905], [0.0162783432751894, 0.09737008064985275, 0.09737008064985275, 0.7888143062591553, 0.00016719881386961788], [0.39133694767951965, 0.13019470870494843, 0.4155557453632355, 0.03145630657672882, 0.03145630657672882], [0.5212668180465698, 0.012760120443999767, 0.013051735237240791, 0.013051735237240791, 0.43986964225769043], [0.08836481720209122, 0.0002126792533090338, 0.8143244981765747, 0.0002126792533090338, 0.09688533842563629], [0.8731790781021118, 0.10949887335300446, 0.014564445242285728, 0.0026222090236842632, 0.00013544660760089755], [0.3615475594997406, 0.17212510108947754, 0.3615475594997406, 0.041238851845264435, 0.06354089826345444], [0.4729762673377991, 0.4729762673377991, 0.000752352993004024, 0.004490459803491831, 0.04880461096763611], [0.7731730937957764, 0.028636720031499863, 0.07095003128051758, 0.07095003128051758, 0.05629013851284981], [0.385358601808548, 0.385358601808548, 0.07691281288862228, 0.0003104984643869102, 0.15205952525138855], [0.12130288779735565, 0.7283270955085754, 0.02811785601079464, 0.0009492628159932792, 0.12130288779735565], [0.04924993962049484, 0.7178981304168701, 0.007630526553839445, 0.17597147822380066, 0.04924993962049484], [0.8990654349327087, 0.022280313074588776, 0.022280313074588776, 0.023110143840312958, 0.03326386958360672], [0.022608721628785133, 0.08629629015922546, 0.019324908033013344, 0.7854737043380737, 0.08629629015922546], [0.397266685962677, 0.3207380473613739, 0.033118393272161484, 0.21575845777988434, 0.033118393272161484], [0.07805249840021133, 0.3868488073348999, 0.06784705072641373, 0.3994045853614807, 0.06784705072641373], [0.3880472779273987, 0.16068172454833984, 0.16068172454833984, 0.038027480244636536, 0.2525617778301239], [0.28476470708847046, 0.26712939143180847, 0.19548474252223969, 0.0571364089846611, 0.19548474252223969], [0.6951048374176025, 0.19356581568717957, 0.012486198917031288, 0.08635692298412323, 0.012486198917031288], [0.11770953983068466, 0.280068039894104, 0.48268261551856995, 0.11770953983068466, 0.0018302035750821233], [0.20909783244132996, 0.013956435024738312, 0.0020232805982232094, 0.006757382769137621, 0.7681649923324585], [0.9087598919868469, 0.033603377640247345, 0.016014916822314262, 0.008018438704311848, 0.033603377640247345], [0.2527383267879486, 0.14384979009628296, 0.0910327360033989, 0.3685293197631836, 0.14384979009628296], [0.05222618952393532, 0.9001438617706299, 0.03938587009906769, 0.00412206444889307, 0.00412206444889307], [0.8319935202598572, 0.0416928306221962, 0.08380525559186935, 0.0416928306221962, 0.0008155553950928152], [0.6343939900398254, 0.1574428528547287, 0.06073969602584839, 0.08668375015258789, 0.06073969602584839], [0.023641759529709816, 0.029410215094685555, 0.024627700448036194, 0.8986785411834717, 0.023641759529709816], [0.14501217007637024, 0.16721178591251373, 0.14501217007637024, 0.5100349187850952, 0.032728951424360275], [0.7981213331222534, 0.03267970681190491, 0.09286276996135712, 0.038168080151081085, 0.038168080151081085], [0.034834183752536774, 0.10000506788492203, 0.2014494091272354, 0.034834183752536774, 0.6288772225379944], [0.3719683885574341, 0.11571379005908966, 0.02714281901717186, 0.3719683885574341, 0.113206647336483], [3.5188561014365405e-05, 0.4116746485233307, 0.4116746485233307, 0.05859679728746414, 0.11801867187023163], [0.0332537405192852, 0.6065953373908997, 0.0503242090344429, 0.0332537405192852, 0.2765730023384094], [0.03939218446612358, 0.7699446678161621, 0.050064120441675186, 0.09053487330675125, 0.050064120441675186], [0.5754838585853577, 0.06101054698228836, 0.09233061969280243, 0.06101054698228836, 0.21016444265842438], [0.9024518132209778, 0.010390272364020348, 0.06531848758459091, 0.011449192650616169, 0.010390272364020348], [0.019212868064641953, 0.10517672449350357, 0.0904747024178505, 0.0904747024178505, 0.6946609616279602], [0.1272794008255005, 0.1272794008255005, 0.056255828589200974, 0.04443167522549629, 0.6447536945343018], [0.08898256719112396, 0.12482697516679764, 0.12482697516679764, 0.17791441082954407, 0.4834490120410919], [0.30038824677467346, 0.001943238195963204, 0.512686014175415, 0.09249121695756912, 0.09249121695756912], [0.1280328929424286, 0.07711286097764969, 0.13892918825149536, 0.3279625475406647, 0.3279625475406647], [0.061995234340429306, 0.806656539440155, 0.012131021358072758, 0.1070861965417862, 0.012131021358072758], [0.14886367321014404, 0.157187819480896, 0.157187819480896, 0.06760967522859573, 0.46915096044540405], [0.00047724691103212535, 0.46970340609550476, 0.05943279340863228, 0.46970340609550476, 0.0006831052014604211], [0.0160808227956295, 0.1735856831073761, 0.0160808227956295, 0.7182131409645081, 0.07603950053453445], [0.25875410437583923, 0.304906964302063, 0.033959969878196716, 0.09747201204299927, 0.304906964302063], [0.05050229653716087, 0.8023912310600281, 0.08324975520372391, 0.05050229653716087, 0.013354361988604069], [0.0024889251217246056, 0.037642624229192734, 0.004528190940618515, 0.4776701331138611, 0.4776701331138611], [0.14812901616096497, 0.14812901616096497, 0.0050019677728414536, 0.00013959732314106077, 0.6986004114151001], [0.12110594660043716, 0.6249673366546631, 0.05193907395005226, 0.08088166266679764, 0.12110594660043716], [0.03716544061899185, 0.7218006253242493, 0.03716544061899185, 0.093307264149189, 0.11056125164031982], [0.2058347910642624, 0.4259447157382965, 0.2584960460662842, 0.054862212389707565, 0.054862212389707565], [0.1277707815170288, 0.3100903034210205, 0.03675711899995804, 0.488624632358551, 0.03675711899995804], [0.3650587797164917, 0.3650587797164917, 0.09332819283008575, 0.12265701591968536, 0.05389723926782608], [0.001379519933834672, 0.08093417435884476, 0.836709201335907, 4.287407864467241e-05, 0.08093417435884476], [0.3954333961009979, 0.018047725781798363, 0.12044578790664673, 0.07063962519168854, 0.3954333961009979], [0.4059543013572693, 0.013571854680776596, 0.15898355841636658, 0.015536008402705193, 0.4059543013572693], [0.0012971947435289621, 0.9719316363334656, 0.02297179587185383, 0.003102400340139866, 0.0006969887181185186], [0.0027763284742832184, 0.26790252327919006, 0.31466180086135864, 0.2073296755552292, 0.2073296755552292], [0.1723080724477768, 0.10869555920362473, 0.10869555920362473, 0.5977615118026733, 0.012539287097752094], [0.06063636764883995, 0.11734627187252045, 0.4697391986846924, 0.11734627187252045, 0.23493188619613647], [0.3482777178287506, 0.4742307960987091, 0.1155635416507721, 0.04099847748875618, 0.02092946134507656], [0.3268532454967499, 0.0011608853237703443, 0.17176857590675354, 0.32844871282577515, 0.17176857590675354], [0.13940587639808655, 0.07627567648887634, 0.3598663806915283, 0.3598663806915283, 0.06458571553230286], [0.6098250150680542, 0.0007160276873037219, 0.028277330100536346, 0.0007160276873037219, 0.3604655861854553], [0.243001326918602, 0.003448680741712451, 0.28131529688835144, 0.4687860310077667, 0.003448680741712451], [0.0016402427572757006, 0.015070832334458828, 0.23026920855045319, 0.7379488945007324, 0.015070832334458828], [0.7261198163032532, 0.08989084511995316, 0.08989084511995316, 0.0013149119913578033, 0.09278366714715958], [0.02040330320596695, 0.18750815093517303, 0.39591875672340393, 0.39591875672340393, 0.00025100199854932725], [0.0005744759691879153, 0.0005744759691879153, 0.007752302102744579, 0.2719499468803406, 0.7191487550735474], [0.11205156147480011, 0.15032584965229034, 0.15979540348052979, 0.11205156147480011, 0.46577557921409607], [0.035537704825401306, 0.44197115302085876, 0.020013904199004173, 0.44197115302085876, 0.06050613150000572], [0.23834344744682312, 0.021608728915452957, 0.002907556015998125, 0.49879685044288635, 0.23834344744682312], [0.0009697154746390879, 0.41043490171432495, 0.004124641418457031, 0.2922353744506836, 0.2922353744506836], [0.2071927934885025, 0.2071927934885025, 0.0908011719584465, 0.4794186055660248, 0.01539467740803957], [0.010832807049155235, 0.3436029255390167, 0.3436029255390167, 0.26381728053092957, 0.03814399242401123], [0.0015360602410510182, 0.15141130983829498, 0.6822898983955383, 0.013351498171687126, 0.15141130983829498], [0.04287080466747284, 0.19764135777950287, 0.0009745585848577321, 0.19764135777950287, 0.5608718991279602], [0.01616290770471096, 4.2022220441140234e-05, 0.05922767147421837, 0.462283730506897, 0.462283730506897], [0.05578092858195305, 0.011358763091266155, 0.010448746383190155, 0.8666306138038635, 0.05578092858195305], [0.4874008297920227, 0.008030151017010212, 0.008647183887660503, 0.008520934730768204, 0.4874008297920227], [0.902401328086853, 0.009622836485505104, 0.009622836485505104, 0.0015826454618945718, 0.07677032798528671], [0.008423374965786934, 0.022113202139735222, 0.9441379308700562, 0.0032122598495334387, 0.022113202139735222], [0.13041755557060242, 0.13041755557060242, 0.050545547157526016, 0.3088969886302948, 0.37972238659858704], [0.34493473172187805, 0.006689663510769606, 0.34493473172187805, 0.05641708895564079, 0.2470238357782364], [0.1702542006969452, 0.04176810756325722, 0.2945437729358673, 0.2945437729358673, 0.1988901048898697], [0.5162213444709778, 0.030079293996095657, 0.030079293996095657, 0.4140336513519287, 0.009586431086063385], [0.0021464210003614426, 0.44391971826553345, 0.11728867143392563, 0.11728867143392563, 0.3193565607070923], [0.6595168113708496, 0.025040097534656525, 0.025040097534656525, 0.0035640967544168234, 0.28683891892433167], [0.08420000225305557, 0.06805743277072906, 0.41915518045425415, 0.2142937183380127, 0.2142937183380127], [0.14792872965335846, 0.5601950287818909, 0.05942577123641968, 0.11622519791126251, 0.11622519791126251], [0.25011882185935974, 0.3495180308818817, 0.3996983766555786, 0.00033238777541555464, 0.00033238777541555464], [0.08177516609430313, 0.020567402243614197, 0.00682158675044775, 0.8702684640884399, 0.020567402243614197], [0.0025492471177130938, 0.38025134801864624, 0.04672202840447426, 0.1902259886264801, 0.38025134801864624], [0.9452676773071289, 0.014124429784715176, 0.018014559522271156, 0.0045787314884364605, 0.018014559522271156], [0.07069788128137589, 0.638726532459259, 0.002256833715364337, 0.2124536782503128, 0.07586509734392166], [0.005477513186633587, 0.010026714764535427, 0.9049558043479919, 0.07406245172023773, 0.005477513186633587], [0.11245252937078476, 0.00022582265955861658, 0.5237411856651306, 0.20173726975917816, 0.16184324026107788], [0.1783655285835266, 5.113678707857616e-05, 0.4398704767227173, 0.281474769115448, 0.1002381220459938], [0.28390806913375854, 0.03879719227552414, 0.28581100702285767, 0.10567277669906616, 0.28581100702285767], [0.01926397904753685, 0.024861538782715797, 0.2698230743408203, 0.024861538782715797, 0.66118985414505], [0.48872947692871094, 0.012982887215912342, 0.49728262424468994, 0.000502506154589355, 0.000502506154589355], [0.3245348632335663, 0.005469387862831354, 0.21676217019557953, 0.2266167551279068, 0.2266167551279068], [0.03405826538801193, 0.09847597777843475, 0.0001984945556614548, 0.3753100335597992, 0.49195724725723267], [0.002468363381922245, 0.5238013863563538, 0.4708872139453888, 0.00037463841727003455, 0.002468363381922245], [0.37090665102005005, 0.04752562940120697, 0.37090665102005005, 0.1005830317735672, 0.11007804423570633], [0.6333388686180115, 0.3509370982646942, 0.0012442100560292602, 0.007239906117320061, 0.007239906117320061], [0.004824089352041483, 0.0232476145029068, 0.9490281939506531, 0.011450051330029964, 0.011450051330029964], [0.48893648386001587, 0.0017030986491590738, 0.0045035723596811295, 0.48893648386001587, 0.015920357778668404], [0.1294693797826767, 0.5519234538078308, 0.016513271257281303, 0.1726245880126953, 0.1294693797826767], [0.0012900293804705143, 0.009304506704211235, 0.3232235014438629, 0.3429584801197052, 0.3232235014438629], [0.0954669862985611, 0.0954669862985611, 0.1041366383433342, 0.6824489235877991, 0.022480452433228493], [0.19619815051555634, 0.43681836128234863, 0.19619815051555634, 0.06213368847966194, 0.10865165293216705], [0.005910955835133791, 0.871430516242981, 0.03061845526099205, 0.0861290767788887, 0.005910955835133791], [0.050089575350284576, 0.050089575350284576, 0.005032655317336321, 0.04984906688332558, 0.844939112663269], [0.11635549366474152, 0.19808347523212433, 0.19808347523212433, 0.2941076159477234, 0.19336992502212524], [0.04180503264069557, 0.2650449573993683, 0.05352506786584854, 0.3745799660682678, 0.2650449573993683], [0.05433374270796776, 0.0414278507232666, 0.05433374270796776, 0.8453820943832397, 0.004522510338574648], [0.18449537456035614, 0.18449537456035614, 0.5072066187858582, 0.0359412282705307, 0.08786135911941528], [0.0024536489509046078, 0.018190184608101845, 0.010859484784305096, 0.9660430550575256, 0.0024536489509046078], [0.31387683749198914, 0.2296547144651413, 0.31387683749198914, 0.08669628947973251, 0.05589530989527702], [0.40423524379730225, 0.535102367401123, 0.014382434077560902, 0.023139961063861847, 0.023139961063861847], [0.01447977963835001, 0.06856906414031982, 0.015905704349279404, 0.8851397037506104, 0.015905704349279404], [0.5578726530075073, 0.002603223780170083, 0.07003892958164215, 0.36688196659088135, 0.002603223780170083], [0.04293525964021683, 0.8612659573554993, 0.04779422655701637, 0.04779422655701637, 0.00021034803648944944], [0.0014604920288547873, 0.0009609288536012173, 0.3453163802623749, 0.30694571137428284, 0.3453163802623749], [0.05103067681193352, 0.05103067681193352, 0.05821561813354492, 0.05103853717446327, 0.7886844873428345], [0.007391871884465218, 0.022878410294651985, 0.9602422118186951, 0.0020956231746822596, 0.007391871884465218], [0.0984908938407898, 0.35308757424354553, 0.022192183881998062, 0.4277384579181671, 0.0984908938407898], [0.006471251603215933, 0.1680826097726822, 0.41166508197784424, 0.41166508197784424, 0.0021159581374377012], [0.0011024908162653446, 0.031823355704545975, 0.0011024908162653446, 0.13915283977985382, 0.8268189430236816], [0.587188720703125, 0.007523480802774429, 0.02212001383304596, 0.004683326929807663, 0.37848442792892456], [0.11041706800460815, 0.15302029252052307, 0.005299044772982597, 0.11041706800460815, 0.6208465695381165], [0.12854687869548798, 0.09076280146837234, 0.3869993984699249, 0.3869993984699249, 0.0066914730705320835], [0.4777328670024872, 0.24782828986644745, 0.003593222703784704, 0.15829330682754517, 0.11255231499671936], [0.004142488818615675, 0.033997636288404465, 0.02656080760061741, 0.006633227225393057, 0.9286658763885498], [0.10812794417142868, 0.06830721348524094, 0.10812794417142868, 0.6869590282440186, 0.028477896004915237], [0.09612807631492615, 0.20812693238258362, 0.4840189516544342, 0.11559805274009705, 0.09612807631492615], [0.3797578513622284, 0.06452948600053787, 0.13721412420272827, 0.03874070942401886, 0.3797578513622284], [0.0249013714492321, 0.01700281724333763, 0.3223349452018738, 0.3223349452018738, 0.3134259581565857], [0.007604317273944616, 0.007604317273944616, 0.08656623959541321, 0.04600954428315163, 0.8522155284881592], [0.038840800523757935, 0.07772541046142578, 0.0010783026227727532, 0.0010783026227727532, 0.8812772035598755], [0.48363903164863586, 0.02975652366876602, 0.48363903164863586, 7.782788452459499e-05, 0.0028875740244984627], [0.0032248906791210175, 4.6086923248367384e-05, 0.04217846319079399, 4.6086923248367384e-05, 0.9545044302940369], [0.0005650679231621325, 0.009065866470336914, 0.0005650679231621325, 0.03691408038139343, 0.9528899788856506], [0.07311739772558212, 0.01945379748940468, 0.8292787075042725, 0.07311739772558212, 0.005032665096223354], [0.13070476055145264, 0.211295023560524, 0.13070476055145264, 0.043396659195423126, 0.483898788690567], [0.001228931127116084, 0.038491372019052505, 0.8906415700912476, 0.031146809458732605, 0.038491372019052505], [0.00026344688376411796, 0.3228456377983093, 0.3228456377983093, 0.01867568865418434, 0.3353695571422577], [0.0491187758743763, 0.059558574110269547, 0.4399271309375763, 0.4399271309375763, 0.011468479409813881], [0.08645061403512955, 0.4269615709781647, 0.4269615709781647, 0.022635355591773987, 0.036990873515605927], [0.04552381858229637, 0.04552381858229637, 0.2103445827960968, 0.5752868056297302, 0.12332095205783844], [0.07491503655910492, 0.350983202457428, 0.04891185089945793, 0.1742067039012909, 0.350983202457428], [0.00044427093234844506, 0.627887487411499, 0.0007754935650154948, 0.00044427093234844506, 0.370448499917984], [0.7403781414031982, 0.007357157301157713, 0.04019811376929283, 0.20470942556858063, 0.007357157301157713], [0.002780492650344968, 0.005447011906653643, 0.069546639919281, 0.4611128866672516, 0.4611128866672516], [0.07913380116224289, 0.4649854898452759, 0.0021421839483082294, 0.45159634947776794, 0.0021421839483082294], [0.025852464139461517, 0.4684600234031677, 0.013634546659886837, 0.46620044112205505, 0.025852464139461517], [0.048897456377744675, 0.10186106711626053, 0.6510589122772217, 0.10186106711626053, 0.09632143378257751], [0.05331810936331749, 0.16926231980323792, 0.16926231980323792, 0.0021870210766792297, 0.6059702634811401], [0.16922439634799957, 0.04830425605177879, 0.04830425605177879, 0.19414539635181427, 0.5400217175483704], [0.9231971502304077, 0.022611461579799652, 0.0024348765145987272, 0.029145175591111183, 0.022611461579799652], [0.20385901629924774, 0.23243318498134613, 0.3041415214538574, 0.20385901629924774, 0.05570729821920395], [0.04266340658068657, 0.49096614122390747, 0.22862675786018372, 0.22862675786018372, 0.009116925299167633], [0.10080108046531677, 0.05142230540513992, 0.20637205243110657, 0.32070228457450867, 0.32070228457450867], [0.024851547554135323, 0.3948489725589752, 0.565351128578186, 0.007474198471754789, 0.007474198471754789], [0.5502381324768066, 0.03622208535671234, 0.03617037460207939, 0.3411473035812378, 0.03622208535671234], [0.12571372091770172, 0.03137742727994919, 0.43474990129470825, 0.03137742727994919, 0.37678152322769165], [0.19718122482299805, 0.08800669759511948, 0.3180025517940521, 0.3180025517940521, 0.07880695909261703], [0.017126992344856262, 0.03642202541232109, 0.20394307374954224, 0.5385648608207703, 0.20394307374954224], [0.23751965165138245, 0.26484036445617676, 0.22540415823459625, 0.007395378313958645, 0.26484036445617676], [0.16378046572208405, 0.3121821880340576, 0.0651688352227211, 0.22943423688411713, 0.22943423688411713], [0.01916874200105667, 0.48280030488967896, 0.46390825510025024, 0.003170427167788148, 0.03095223195850849], [0.6366505026817322, 0.005780411418527365, 0.27829548716545105, 0.03205283731222153, 0.04722076654434204], [0.8268234133720398, 0.11427681148052216, 0.00584576977416873, 0.026526985689997673, 0.026526985689997673], [0.32820793986320496, 0.00010734124225564301, 0.038970645517110825, 0.30450618267059326, 0.32820793986320496], [0.5516486167907715, 0.21313568949699402, 0.007961384020745754, 0.014118621125817299, 0.21313568949699402], [0.041539501398801804, 0.18864823877811432, 0.01418795995414257, 0.37781211733818054, 0.37781211733818054], [0.0030638696625828743, 0.0030638696625828743, 0.32280051708221436, 0.4899340569972992, 0.18113762140274048], [0.42994052171707153, 0.09560082852840424, 0.42994052171707153, 0.035773344337940216, 0.008744762279093266], [0.22728857398033142, 0.08044476062059402, 0.016815682873129845, 0.08044476062059402, 0.5950062870979309], [0.1981910914182663, 0.41062358021736145, 0.16292229294776917, 0.16292229294776917, 0.06534076482057571], [0.10971051454544067, 0.4007655084133148, 0.01942063868045807, 0.23505166172981262, 0.23505166172981262], [0.24144795536994934, 0.07010810822248459, 0.15539874136447906, 0.4629370868206024, 0.07010810822248459], [0.0018939789151772857, 0.1539510041475296, 0.0438372977077961, 0.7984237670898438, 0.0018939789151772857], [0.0018766905413940549, 0.24187235534191132, 0.0002919012913480401, 0.7540823221206665, 0.0018766905413940549], [0.0323757603764534, 0.2938743829727173, 0.2938743829727173, 0.17670372128486633, 0.2031717598438263], [0.007636453956365585, 0.21298740804195404, 0.01690707542002201, 0.0771879255771637, 0.6852810978889465], [0.054705094546079636, 0.011959507130086422, 0.8290795087814331, 0.09229642897844315, 0.011959507130086422], [0.08210866898298264, 0.002572261495515704, 0.9125871658325195, 0.002572261495515704, 0.0001596997317392379], [0.08359697461128235, 0.4107024073600769, 0.08359697461128235, 0.10072018951177597, 0.32138341665267944], [0.05304320156574249, 0.8586622476577759, 0.05304320156574249, 0.03515113517642021, 0.00010027850657934323], [0.0013727244222536683, 0.4512130320072174, 0.4512130320072174, 0.011694223619997501, 0.08450702577829361], [0.028718847781419754, 0.34415626525878906, 0.1709810346364975, 0.42742496728897095, 0.028718847781419754], [0.11424084007740021, 0.2187219113111496, 0.000912486226297915, 0.2187219113111496, 0.44740283489227295], [0.11174188554286957, 0.018377523869276047, 0.018377523869276047, 0.807388186454773, 0.044114865362644196], [0.39310604333877563, 0.39310604333877563, 0.14120575785636902, 0.019245339557528496, 0.05333685874938965], [0.007070181891322136, 0.007070181891322136, 0.0022001517936587334, 0.28258612751960754, 0.701073408126831], [0.4986593425273895, 0.4986593425273895, 0.002350472379475832, 0.0001304024481214583, 0.0002004472044063732], [0.23350933194160461, 0.1341395229101181, 0.37136733531951904, 0.13049189746379852, 0.13049189746379852], [0.8206630945205688, 0.17484834790229797, 1.5706289559602737e-05, 0.004457008559256792, 1.5706289559602737e-05], [7.785529305692762e-06, 0.4423356354236603, 0.02069091796875, 0.4423356354236603, 0.09462997317314148], [0.0003769091854337603, 0.4454828202724457, 0.0003769091854337603, 0.02816087007522583, 0.5256025195121765], [0.40658512711524963, 0.010284435003995895, 0.2891882658004761, 0.2891882658004761, 0.004753925837576389], [0.009483300149440765, 0.9830227494239807, 0.00013855809811502695, 0.00013855809811502695, 0.007216895464807749], [0.6408889889717102, 0.15685251355171204, 0.15685251355171204, 0.030733976513147354, 0.014672053046524525], [0.0014304611831903458, 0.060269515961408615, 0.25040286779403687, 0.25040286779403687, 0.43749430775642395], [0.03333960846066475, 0.004484755918383598, 0.004484755918383598, 0.9465899467468262, 0.01110093668103218], [0.023146899417042732, 0.28192782402038574, 0.35391291975975037, 0.28192782402038574, 0.05908454954624176], [0.24943722784519196, 0.24943722784519196, 0.008577142842113972, 0.49208566546440125, 0.00046267674770206213], [0.33266979455947876, 0.14923059940338135, 0.33266979455947876, 0.044957857578992844, 0.14047200977802277], [0.6787379384040833, 0.03459974750876427, 0.12965290248394012, 0.027356602251529694, 0.12965290248394012], [0.02138626202940941, 0.3627893924713135, 0.3044530749320984, 0.3044530749320984, 0.006918217055499554], [0.07085269689559937, 0.008534371852874756, 0.09496453404426575, 0.03564131632447243, 0.7900070548057556], [0.6393189430236816, 0.08132564276456833, 0.02536758966743946, 0.22862030565738678, 0.02536758966743946], [0.01633707620203495, 0.005663690157234669, 0.3592464029788971, 0.2595064342021942, 0.3592464029788971], [0.10519964247941971, 0.4012417197227478, 0.0010377689031884074, 0.4012417197227478, 0.09127917140722275], [0.07353262603282928, 0.2254798412322998, 0.3340394198894501, 0.03290867805480957, 0.3340394198894501], [0.7750770449638367, 0.09253820776939392, 0.07380100339651108, 0.029291871935129166, 0.029291871935129166], [0.005325217265635729, 0.007132804952561855, 0.007132804952561855, 0.48474523425102234, 0.4956640303134918], [0.12783122062683105, 0.4440704584121704, 0.27055785059928894, 0.029709255322813988, 0.12783122062683105], [9.924067126121372e-05, 0.008999472483992577, 0.008999472483992577, 0.9041613340377808, 0.07774054259061813], [0.4451020061969757, 0.045176535844802856, 0.07019039988517761, 0.21976551413536072, 0.21976551413536072], [0.1421332210302353, 0.011125612072646618, 0.5497962236404419, 0.059883106499910355, 0.23706188797950745], [5.773606972070411e-05, 0.5811963677406311, 0.014571521431207657, 0.4041167199611664, 5.773606972070411e-05], [0.05583894997835159, 0.2996247112751007, 0.6410120725631714, 0.0017621350707486272, 0.0017621350707486272], [0.0014289668761193752, 0.11663907766342163, 0.04855203256011009, 0.4166899621486664, 0.4166899621486664], [0.23350390791893005, 0.024732550606131554, 0.23050276935100555, 0.28966841101646423, 0.22159232199192047], [0.20468895137310028, 0.11296752095222473, 0.41303375363349915, 0.11296752095222473, 0.15634220838546753], [0.024752473458647728, 0.3331355154514313, 0.2119605541229248, 0.09701592475175858, 0.3331355154514313], [0.32386988401412964, 0.1625482439994812, 0.05954460799694061, 0.32386988401412964, 0.13016732037067413], [0.0001673915539868176, 0.11031675338745117, 0.11031675338745117, 0.7675696015357971, 0.011629453860223293], [0.00015517027350142598, 0.0021586345974355936, 0.19756613671779633, 0.7999649047851562, 0.00015517027350142598], [0.05749380961060524, 0.35708537697792053, 0.35708537697792053, 0.17434489727020264, 0.05399051308631897], [0.03459303081035614, 0.49400657415390015, 0.12601111829280853, 0.310796320438385, 0.03459303081035614], [0.370016485452652, 0.370016485452652, 0.2505805194377899, 0.005018138792365789, 0.004368416033685207], [0.0016517777694389224, 0.07591459155082703, 0.00044956468627788126, 0.9203323125839233, 0.0016517777694389224], [0.03627200052142143, 0.03627200052142143, 0.583342432975769, 0.3402197062969208, 0.0038938552606850863], [0.6008312702178955, 0.17027482390403748, 0.04407896846532822, 0.014540120959281921, 0.17027482390403748], [0.028096377849578857, 0.22372345626354218, 0.3291108012199402, 0.1953459531068802, 0.22372345626354218], [0.2749529778957367, 0.2749529778957367, 0.3041341304779053, 0.00043993626604788005, 0.14551998674869537], [0.6494947075843811, 0.0009719344670884311, 0.23416857421398163, 0.04245316609740257, 0.07291162014007568], [0.2706502079963684, 0.021150624379515648, 0.059468094259500504, 0.3243655562400818, 0.3243655562400818], [0.4892705976963043, 0.0025774564128369093, 0.4892705976963043, 0.018799183890223503, 8.21413632365875e-05], [0.08113006502389908, 0.20560576021671295, 0.20560576021671295, 0.17584699392318726, 0.33181139826774597], [0.07718002051115036, 0.06158467009663582, 0.001105582807213068, 0.7829497456550598, 0.07718002051115036], [0.8429503440856934, 0.013787326402962208, 0.008683737367391586, 0.008683737367391586, 0.1258949190378189], [0.057316552847623825, 0.23275145888328552, 0.0001219481200678274, 0.35490503907203674, 0.35490503907203674], [0.27141180634498596, 0.7277526259422302, 0.0003242086968384683, 0.00018715084297582507, 0.0003242086968384683], [0.0003511529939714819, 0.006104955915361643, 0.916675329208374, 0.006104955915361643, 0.07076358795166016], [0.28926366567611694, 0.032545045018196106, 0.3350352942943573, 0.3350352942943573, 0.00812072679400444], [0.47827887535095215, 0.14637391269207, 0.11421071738004684, 0.11476247012615204, 0.14637391269207], [0.2746177911758423, 0.23509477078914642, 0.23509477078914642, 0.2540922462940216, 0.001100375666283071], [0.010828937403857708, 0.010828937403857708, 0.8341589570045471, 0.01699354127049446, 0.12718957662582397], [0.07827063649892807, 0.3273279070854187, 0.26261404156684875, 0.3273279070854187, 0.00445951335132122], [0.4880926311016083, 0.15173441171646118, 0.0004650002811104059, 0.17985394597053528, 0.17985394597053528], [0.012228415347635746, 0.8528546094894409, 0.06634684652090073, 0.045450516045093536, 0.023119602352380753], [0.0688076838850975, 0.3039425313472748, 0.3039425313472748, 0.08130638301372528, 0.24200089275836945], [0.42572447657585144, 0.02466745488345623, 0.016916433349251747, 0.42572447657585144, 0.10696719586849213], [0.0005931594059802592, 0.4800558388233185, 0.23018552362918854, 0.2885722815990448, 0.0005931594059802592], [0.05859939754009247, 0.22104279696941376, 0.3586132526397705, 0.0031313856597989798, 0.3586132526397705], [0.3157098889350891, 0.0001503664825577289, 0.029760606586933136, 0.3157098889350891, 0.33866921067237854], [0.012125913985073566, 0.015086484141647816, 0.6022103428840637, 0.012125913985073566, 0.35845133662223816], [0.8783419132232666, 0.028796736150979996, 4.517579509411007e-05, 0.06401952356100082, 0.028796736150979996], [0.05775076523423195, 0.7075510621070862, 0.1196773424744606, 0.057270027697086334, 0.05775076523423195], [0.3395494520664215, 0.19786733388900757, 0.10193011164665222, 0.3395494520664215, 0.021103637292981148], [0.11066602915525436, 0.027362160384655, 0.46904557943344116, 0.11066602915525436, 0.2822602689266205], [0.003464340465143323, 0.24727335572242737, 0.29470008611679077, 0.4152671694755554, 0.039294950664043427], [0.028995754197239876, 0.42894017696380615, 0.39816775918006897, 0.028995754197239876, 0.11490058153867722], [0.12606893479824066, 0.12606893479824066, 0.3455798029899597, 0.026887832209467888, 0.3753945231437683], [0.41631412506103516, 0.41631412506103516, 0.006304695270955563, 0.11841599643230438, 0.04265110567212105], [0.04149489104747772, 0.7146741151809692, 0.04206172749400139, 0.04149489104747772, 0.1602744162082672], [0.4234355092048645, 0.03483092039823532, 0.09120522439479828, 0.4234355092048645, 0.027092816308140755], [0.16824443638324738, 0.41423216462135315, 0.0031618676148355007, 0.0001293567765969783, 0.41423216462135315], [0.6293431520462036, 0.0015218547778204083, 0.11741818487644196, 0.006052448879927397, 0.24566440284252167], [0.838771641254425, 0.029145479202270508, 0.08844353258609772, 0.02181966044008732, 0.02181966044008732], [0.955009400844574, 0.004852618556469679, 0.0092622684314847, 0.01543781254440546, 0.01543781254440546], [0.22793905436992645, 0.10591932386159897, 0.5596152544021606, 0.10591932386159897, 0.0006070691160857677], [0.2970901131629944, 0.6951907277107239, 0.0032795043662190437, 0.0011601338628679514, 0.0032795043662190437], [0.22319410741329193, 0.03908046334981918, 0.03908046334981918, 0.041618868708610535, 0.6570261120796204], [0.2472858428955078, 0.0008017250802367926, 0.02251322753727436, 0.0008017250802367926, 0.7285974621772766], [0.0070769148878753185, 0.747545063495636, 0.1536010503768921, 0.0847000926733017, 0.0070769148878753185], [0.15934476256370544, 0.18441995978355408, 0.4800562262535095, 0.016834255307912827, 0.15934476256370544], [0.01876688376069069, 0.2719300389289856, 0.35339227318763733, 0.35339227318763733, 0.002518496010452509], [0.42071813344955444, 0.0010571517050266266, 0.008393717929720879, 0.42071813344955444, 0.14911288022994995], [0.21511629223823547, 0.2872876822948456, 0.21511629223823547, 0.01871340349316597, 0.2637662887573242], [0.2773556411266327, 0.19131746888160706, 0.19131746888160706, 0.09178187698125839, 0.2482275515794754], [0.4107726216316223, 0.12157142907381058, 0.053172554820775986, 0.00371073791757226, 0.4107726216316223], [0.30491673946380615, 0.2456074208021164, 0.30491673946380615, 0.11030112206935883, 0.034257933497428894], [0.3770010471343994, 0.006617447827011347, 0.30596888065338135, 0.004443672485649586, 0.30596888065338135], [1.979456101253163e-05, 0.8508945107460022, 0.034856293350458145, 0.07937311381101608, 0.034856293350458145], [0.3412253260612488, 0.07474742084741592, 0.5267216563224792, 0.028652753680944443, 0.028652753680944443], [0.6544920802116394, 0.02088736556470394, 0.02088736556470394, 0.23287951946258545, 0.07085360586643219], [0.05765453353524208, 0.23696377873420715, 0.059239841997623444, 0.40917810797691345, 0.23696377873420715], [0.01459304615855217, 0.8197652697563171, 0.04095282405614853, 0.11009586602449417, 0.01459304615855217], [0.005305544938892126, 0.01555042713880539, 0.01555042713880539, 0.8641844987869263, 0.09940912574529648], [0.02689363993704319, 0.8568305969238281, 0.09316791594028473, 0.011553894728422165, 0.011553894728422165], [0.10082083940505981, 0.00020273249538149685, 0.00020273249538149685, 0.49099981784820557, 0.40777388215065], [0.10374295711517334, 0.3742145299911499, 0.24534641206264496, 0.24534641206264496, 0.03134967386722565], [0.006474916823208332, 0.1306014508008957, 0.1306014508008957, 0.0337720587849617, 0.6985501646995544], [0.37258267402648926, 0.22521984577178955, 0.37258267402648926, 0.027187379077076912, 0.0024274687748402357], [0.12131498754024506, 0.4687049686908722, 0.00011142621951876208, 0.4097571074962616, 0.00011142621951876208], [0.004748841747641563, 0.7544699907302856, 0.10464271157979965, 0.004748841747641563, 0.13138960301876068], [0.2818233072757721, 0.008845728822052479, 0.07322775572538376, 0.31805160641670227, 0.31805160641670227], [0.013984890654683113, 0.16820742189884186, 0.16820742189884186, 0.3717223107814789, 0.27787795662879944], [0.10239143669605255, 0.15017518401145935, 0.5082539916038513, 0.15017518401145935, 0.08900421857833862], [0.02815663255751133, 0.0029257340356707573, 0.2542649507522583, 0.7117269039154053, 0.0029257340356707573], [0.5622109770774841, 0.0022434403654187918, 0.1769680380821228, 0.08160953968763351, 0.1769680380821228], [0.18229931592941284, 0.564293622970581, 0.00013637144002132118, 0.24525095522403717, 0.008019743487238884], [0.31233319640159607, 0.12534277141094208, 0.00019262962450738996, 0.31233319640159607, 0.24979816377162933], [0.5139389634132385, 0.23400616645812988, 0.00048159490688703954, 0.017567111179232597, 0.23400616645812988], [0.1824020892381668, 0.20829634368419647, 0.20829634368419647, 0.33687731623649597, 0.06412791460752487], [0.31941646337509155, 0.012515516020357609, 0.44435375928878784, 0.012515516020357609, 0.21119873225688934], [0.00018769674352370203, 0.025036964565515518, 0.9170451164245605, 0.025036964565515518, 0.032693251967430115], [0.01567050628364086, 0.1538633406162262, 0.02992444671690464, 0.5928921699523926, 0.20764963328838348], [0.8179548382759094, 0.01439395360648632, 0.01439395360648632, 0.1182091161608696, 0.035048093646764755], [0.01077968254685402, 0.39919620752334595, 0.39919620752334595, 0.061467722058296204, 0.1293601393699646], [0.09690219163894653, 0.09690219163894653, 0.32547271251678467, 0.42446058988571167, 0.0562623031437397], [0.018549161031842232, 0.10332106053829193, 0.10332106053829193, 0.001446436275728047, 0.7733622789382935], [0.159505695104599, 0.27339261770248413, 0.015263366512954235, 0.159505695104599, 0.39233267307281494], [0.21421146392822266, 0.0038801939226686954, 0.21421146392822266, 0.2105163037776947, 0.3571806252002716], [0.36428025364875793, 0.34138038754463196, 0.010058004409074783, 0.02299647033214569, 0.2612849175930023], [0.14407184720039368, 0.25678372383117676, 0.42670685052871704, 0.14407184720039368, 0.028365731239318848], [0.10231725871562958, 0.00018779939273372293, 0.008553542196750641, 0.008553542196750641, 0.8803877830505371], [0.08948510140180588, 0.04594309255480766, 0.08948510140180588, 0.13744162023067474, 0.6376450061798096], [0.03000464104115963, 0.5155644416809082, 0.00012259827053640038, 0.22715415060520172, 0.22715415060520172], [0.0548713319003582, 0.4698620140552521, 0.00048216868890449405, 0.004922458436340094, 0.4698620140552521], [0.016250427812337875, 0.25965631008148193, 0.18532176315784454, 0.26938575506210327, 0.26938575506210327], [0.0024701107759028673, 0.005733977071940899, 0.015444074757397175, 0.9609076976776123, 0.015444074757397175], [0.009130604565143585, 0.0027918287087231874, 0.009130604565143585, 0.9575730562210083, 0.02137388475239277], [0.022098520770668983, 0.0016613942570984364, 0.022098520770668983, 0.18023639917373657, 0.7739051580429077], [0.029189620167016983, 0.3188340961933136, 0.17377297580242157, 0.029189620167016983, 0.44901376962661743], [0.1605871617794037, 0.02429973892867565, 0.22863194346427917, 0.019355906173586845, 0.5671252608299255], [0.43108290433883667, 0.07243680208921432, 0.4598246216773987, 0.018327806144952774, 0.018327806144952774], [0.47353556752204895, 0.2076307088136673, 0.036507412791252136, 0.2076307088136673, 0.07469558715820312], [1.8950413505081087e-05, 0.7747663855552673, 1.8950413505081087e-05, 0.03361433371901512, 0.1915813833475113], [0.14713440835475922, 0.43369823694229126, 0.014056828804314137, 0.3910537362098694, 0.014056828804314137], [0.0022522255312651396, 0.5762438178062439, 0.001803360297344625, 0.012633073143661022, 0.40706750750541687], [0.8539589643478394, 0.002562692854553461, 0.0007315779221244156, 0.1420152634382248, 0.0007315779221244156], [0.026168866083025932, 0.031940214335918427, 0.009799821302294731, 0.4660455882549286, 0.4660455882549286], [0.21773052215576172, 0.228969007730484, 0.5232290029525757, 0.01503576897084713, 0.01503576897084713], [0.03277264162898064, 0.3354843556880951, 0.3354843556880951, 0.2733967900276184, 0.022861815989017487], [0.016226036474108696, 0.1663288027048111, 0.016226036474108696, 0.5758106112480164, 0.22540850937366486], [0.5262911915779114, 0.008803579024970531, 0.32522743940353394, 0.13087421655654907, 0.008803579024970531], [0.00022631578030996025, 0.0005685027572326362, 0.9991651773452759, 1.9998018615297042e-05, 1.9998018615297042e-05], [0.36417892575263977, 0.2143685519695282, 0.019408630207180977, 0.36417892575263977, 0.03786502778530121], [0.6005053520202637, 0.35184478759765625, 0.023388953879475594, 0.0008719840552657843, 0.023388953879475594], [0.0004680289712268859, 0.4057539105415344, 0.16264879703521729, 0.006641095969825983, 0.4244881272315979], [0.03351297602057457, 0.1452208310365677, 0.058862946927547455, 0.03351297602057457, 0.7288902997970581], [0.3022410273551941, 0.02859538421034813, 0.3640783131122589, 0.0028442125767469406, 0.3022410273551941], [0.2263781726360321, 0.17629709839820862, 0.007681426126509905, 0.17629709839820862, 0.41334623098373413], [0.011160377413034439, 0.48089030385017395, 0.4769706130027771, 0.011160377413034439, 0.019818369299173355], [0.3610265851020813, 0.572765588760376, 0.06333839148283005, 0.0014347269898280501, 0.0014347269898280501], [0.1279519498348236, 0.40791890025138855, 0.40791890025138855, 0.044632941484451294, 0.011577295139431953], [0.08619348704814911, 0.05795250087976456, 0.6971774697303772, 0.10072402656078339, 0.05795250087976456], [0.3722943067550659, 0.34706538915634155, 0.1271238625049591, 0.07675822079181671, 0.07675822079181671], [0.03473680093884468, 0.22645387053489685, 0.18035532534122467, 0.22645387053489685, 0.33200010657310486], [0.0003481286985334009, 0.6830693483352661, 0.06878165155649185, 0.12390043586492538, 0.12390043586492538], [0.02744327485561371, 0.7094560861587524, 0.09148713201284409, 0.09148713201284409, 0.08012635260820389], [0.46650955080986023, 0.4551837146282196, 0.05007757619023323, 0.01411457359790802, 0.01411457359790802], [0.07058846205472946, 0.26379144191741943, 0.0779080018401146, 0.29385605454444885, 0.29385605454444885], [0.5796841382980347, 0.2096880078315735, 7.457735046045855e-05, 0.10527661442756653, 0.10527661442756653], [0.8714900612831116, 0.11511049419641495, 0.007313892710953951, 0.002547899493947625, 0.0035374974831938744], [0.6775122880935669, 0.11332908272743225, 0.03159604221582413, 0.03159604221582413, 0.145966574549675], [0.024663541465997696, 0.024663541465997696, 0.11599422991275787, 0.8310537338256836, 0.003624978940933943], [0.31971922516822815, 0.31971922516822815, 0.05199737846851349, 0.0058087920770049095, 0.3027553856372833], [0.12966561317443848, 0.5202294588088989, 0.01575171947479248, 0.3186015784740448, 0.01575171947479248], [0.27781790494918823, 0.018442101776599884, 0.336457759141922, 0.336457759141922, 0.03082449547946453], [0.007080871611833572, 0.007080871611833572, 0.7314628958702087, 0.12068971246480942, 0.1336856484413147], [0.053966160863637924, 0.37949374318122864, 0.37949374318122864, 0.06702195852994919, 0.12002445012331009], [0.06450483202934265, 0.7833119034767151, 0.033288102596998215, 0.033288102596998215, 0.08560710400342941], [0.43397629261016846, 0.09083659201860428, 0.018005020916461945, 0.023205814883112907, 0.43397629261016846], [0.38115888833999634, 0.011845966801047325, 0.38115888833999634, 0.19970525801181793, 0.026130974292755127], [0.38398370146751404, 0.2869986295700073, 0.021672451868653297, 0.020346563309431076, 0.2869986295700073], [0.16747985780239105, 0.19770348072052002, 0.29992660880088806, 0.16741019487380981, 0.16747985780239105], [0.04170190170407295, 0.22950796782970428, 0.10539714246988297, 0.3938849866390228, 0.22950796782970428], [0.013790425844490528, 0.013790425844490528, 0.7934219241142273, 0.05683186650276184, 0.12216533720493317], [0.0716339573264122, 0.7477885484695435, 0.09867923706769943, 0.010264286771416664, 0.0716339573264122], [0.0020018056966364384, 0.351544052362442, 0.351544052362442, 0.22938771545886993, 0.06552234292030334], [0.09681742638349533, 0.4615253508090973, 0.010199555195868015, 0.3346402943134308, 0.09681742638349533], [0.4993413984775543, 0.04745224863290787, 0.12476424872875214, 0.16422103345394135, 0.16422103345394135], [0.1556369513273239, 0.10203175246715546, 0.6265293955802917, 0.10203175246715546, 0.01377018541097641], [0.49825724959373474, 0.12348881363868713, 0.04940419644117355, 0.20536090433597565, 0.12348881363868713], [0.14611877501010895, 0.618959903717041, 0.14611877501010895, 0.004553778562694788, 0.08424870669841766], [0.017059650272130966, 0.0843125432729721, 0.0843125432729721, 0.30925774574279785, 0.5050575733184814], [0.003751239273697138, 0.5703226923942566, 0.06336317211389542, 0.06336317211389542, 0.29919975996017456], [0.7106378078460693, 0.05344359204173088, 0.07189807295799255, 0.09212248772382736, 0.07189807295799255], [0.056587815284729004, 0.27722299098968506, 0.22620901465415955, 0.2199900895357132, 0.2199900895357132], [0.0005306468810886145, 0.34624478220939636, 0.2736303508281708, 0.34624478220939636, 0.03334944695234299], [0.13953372836112976, 0.13953372836112976, 0.0036625887732952833, 0.4385608732700348, 0.2787090539932251], [0.15127110481262207, 0.12403200566768646, 0.4724836051464081, 0.12818118929862976, 0.12403200566768646], [0.007605884224176407, 0.047983553260564804, 0.007605884224176407, 0.6017295122146606, 0.3350751996040344], [0.6828673481941223, 0.07715162634849548, 0.13225315511226654, 0.030576253309845924, 0.07715162634849548], [0.03969141095876694, 0.2096816450357437, 0.2147703766822815, 0.4961651861667633, 0.03969141095876694], [0.1941005438566208, 0.45749929547309875, 0.150549978017807, 0.1941005438566208, 0.0037496478762477636], [0.040670789778232574, 0.4518847167491913, 0.028969023376703262, 0.028969023376703262, 0.4495064914226532], [0.3111085593700409, 0.002263112924993038, 0.015588432550430298, 0.3599313199520111, 0.3111085593700409], [0.20354750752449036, 0.09559717029333115, 0.22725607454776764, 0.3780020475387573, 0.09559717029333115], [0.1319480836391449, 0.20500804483890533, 0.22659653425216675, 0.3044992685317993, 0.1319480836391449], [0.45125648379325867, 0.06033206358551979, 0.45125648379325867, 0.01290081162005663, 0.02425420843064785], [0.12340647727251053, 0.3278360366821289, 0.274126797914505, 0.0005039284005761147, 0.274126797914505], [0.47623422741889954, 0.006261652801185846, 0.40181565284729004, 0.10942676663398743, 0.006261652801185846], [0.34851139783859253, 0.600757896900177, 0.009147568605840206, 0.020791590213775635, 0.020791590213775635], [0.05310290679335594, 0.05310290679335594, 0.03750813007354736, 0.6325922012329102, 0.22369384765625], [0.9542345404624939, 0.006862953770905733, 0.0040289475582540035, 0.030844667926430702, 0.0040289475582540035], [0.006608594674617052, 0.1976085603237152, 0.13926416635513306, 0.4589100778102875, 0.1976085603237152], [0.004330688156187534, 0.14083008468151093, 0.17170460522174835, 0.511430025100708, 0.17170460522174835], [0.10673318058252335, 0.2740829288959503, 0.10300502181053162, 0.10300502181053162, 0.4131738841533661], [0.007281837519258261, 0.01297820545732975, 0.4845876097679138, 0.010564642958343029, 0.4845876097679138], [0.05105812847614288, 0.9401811957359314, 0.003928010351955891, 0.003928010351955891, 0.0009045928600244224], [0.3640371263027191, 0.016074951738119125, 0.023075655102729797, 0.5917729139328003, 0.005039354786276817], [0.000381262885639444, 0.440976619720459, 0.440976619720459, 0.0747636929154396, 0.04290186986327171], [0.04848618805408478, 0.1294480264186859, 0.1294480264186859, 0.5686991214752197, 0.12391863763332367], [0.01721557043492794, 0.11524388194084167, 0.029665343463420868, 0.7347509860992432, 0.10312430560588837], [0.02374979853630066, 0.16296344995498657, 0.31796422600746155, 0.33235904574394226, 0.16296344995498657], [0.032644663006067276, 0.00212484085932374, 0.032644663006067276, 0.9233260154724121, 0.009259731508791447], [0.32957231998443604, 0.006487146485596895, 0.16310814023017883, 0.16310814023017883, 0.3377242386341095], [0.19700445234775543, 0.6520330309867859, 0.00584303867071867, 0.00584303867071867, 0.13927645981311798], [0.4163834750652313, 0.4163834750652313, 0.022261738777160645, 0.00937651563435793, 0.13559482991695404], [0.005543702282011509, 0.00347323389723897, 0.024432657286524773, 0.005543702282011509, 0.9610066413879395], [6.232431042008102e-05, 0.6928011775016785, 0.007150258868932724, 0.29283592104911804, 0.007150258868932724], [0.060365960001945496, 6.472246604971588e-05, 0.8695011734962463, 0.060365960001945496, 0.009702206589281559], [0.026103973388671875, 0.4252608120441437, 0.24957169592380524, 0.2729595899581909, 0.026103973388671875], [0.0003957792359869927, 0.03047194518148899, 0.03047194518148899, 0.7357812523841858, 0.2028791606426239], [0.4522298276424408, 0.03599710762500763, 3.289735104772262e-05, 0.5117072463035583, 3.289735104772262e-05], [0.12038733810186386, 0.24725186824798584, 0.24725186824798584, 0.2624056339263916, 0.12270329892635345], [0.4808024764060974, 0.19848118722438812, 0.3198694884777069, 4.09041922466713e-06, 0.0008427601424045861], [0.5705013275146484, 0.027407564222812653, 0.2655152678489685, 0.027407564222812653, 0.10916828364133835], [0.2792382836341858, 0.16452959179878235, 0.2792382836341858, 0.0162959024310112, 0.2606979012489319], [0.013794451020658016, 0.013794451020658016, 0.42002731561660767, 0.5484315156936646, 0.003952242434024811], [0.5583846569061279, 0.04294121637940407, 0.04842416197061539, 0.30730876326560974, 0.04294121637940407], [0.001995144644752145, 0.5761131048202515, 0.2748042047023773, 0.001995144644752145, 0.14509239792823792], [0.008911988697946072, 0.008911988697946072, 0.18327084183692932, 0.036034002900123596, 0.7628711462020874], [0.007736461702734232, 0.21045614778995514, 0.3699314296245575, 0.21045614778995514, 0.201419860124588], [0.129943385720253, 0.2330538034439087, 0.3241358697414398, 0.18292354047298431, 0.129943385720253], [0.012082788161933422, 0.06346424669027328, 0.06346424669027328, 0.49146318435668945, 0.3695255219936371], [0.6498280763626099, 0.07525482773780823, 0.22374661266803741, 0.025585241615772247, 0.025585241615772247], [0.9047986268997192, 0.010788551531732082, 0.0194097850471735, 0.045593228191137314, 0.0194097850471735], [0.018966523930430412, 0.8030269145965576, 0.17358356714248657, 0.002211485058069229, 0.002211485058069229], [0.4130978584289551, 0.009703959338366985, 0.043192606419324875, 0.12090778350830078, 0.4130978584289551], [0.013749963603913784, 0.01929948851466179, 0.09664798527956009, 0.01929948851466179, 0.851003110408783], [0.33802688121795654, 0.00022576074115931988, 0.00022576074115931988, 0.5329664349555969, 0.12855519354343414], [0.0008879476808942854, 0.08982332050800323, 0.4410134255886078, 0.02726183831691742, 0.4410134255886078], [0.05291830003261566, 0.02577502653002739, 0.3866313099861145, 0.05291830003261566, 0.48175710439682007], [0.00026061577955260873, 0.004025154747068882, 0.39391982555389404, 0.601533830165863, 0.00026061577955260873], [0.01850150153040886, 0.8631231784820557, 0.09500695019960403, 0.004866946954280138, 0.01850150153040886], [0.005876005627214909, 0.554630696773529, 0.003570308443158865, 0.21796150505542755, 0.21796150505542755], [0.006638880353420973, 0.14593033492565155, 0.14593033492565155, 0.013478850945830345, 0.6880214810371399], [0.4039563536643982, 0.1162615641951561, 0.06281208246946335, 0.013013554736971855, 0.4039563536643982], [0.15074710547924042, 0.42236703634262085, 0.001911634928546846, 0.42236703634262085, 0.0026072547771036625], [0.2875933349132538, 0.1007736548781395, 0.30015310645103455, 0.30015310645103455, 0.011326810345053673], [0.025456825271248817, 0.8923549056053162, 0.02760719135403633, 0.02760719135403633, 0.02697388455271721], [0.15230527520179749, 0.15230527520179749, 0.009422551840543747, 0.07424381375312805, 0.6117231249809265], [0.043256860226392746, 0.9128664135932922, 0.000465176795842126, 0.043256860226392746, 0.000154700072016567], [0.01469616498798132, 0.36534008383750916, 0.23092715442180634, 0.023696525022387505, 0.36534008383750916], [0.09645815193653107, 0.005271303933113813, 0.005271303933113813, 0.8230351805686951, 0.06996407359838486], [0.08203630149364471, 0.14870496094226837, 0.18217428028583527, 0.14870496094226837, 0.4383794963359833], [0.002025157678872347, 0.05373433977365494, 0.4309921860694885, 0.05373433977365494, 0.4595140516757965], [0.28992459177970886, 0.28992459177970886, 0.023945219814777374, 0.26933929324150085, 0.12686631083488464], [0.07086435705423355, 0.18656989932060242, 0.5553725957870483, 0.07086435705423355, 0.11632876098155975], [0.3900342583656311, 0.003327490296214819, 0.003327490296214819, 0.5701613426208496, 0.03314939886331558], [0.00965422485023737, 0.023763764649629593, 0.00965422485023737, 0.0690113827586174, 0.8879165053367615], [0.09808848798274994, 0.03112003766000271, 0.4331578314304352, 0.00447582034394145, 0.4331578314304352], [0.3262339234352112, 0.001812057220377028, 0.2832591235637665, 0.2832591235637665, 0.10543575137853622], [0.2699854373931885, 0.1446530669927597, 0.5435485243797302, 0.020906485617160797, 0.020906485617160797], [0.7385360598564148, 0.11679921299219131, 0.11679921299219131, 0.027141783386468887, 0.0007237526006065309], [0.7766684293746948, 0.0006691383314318955, 0.19851447641849518, 0.023478800430893898, 0.0006691383314318955], [0.09834796190261841, 0.26086848974227905, 0.006371485535055399, 0.628040611743927, 0.006371485535055399], [0.020341115072369576, 0.3383067846298218, 0.3239973187446594, 0.062259990721940994, 0.25509485602378845], [0.30776458978652954, 0.24617987871170044, 0.03336454555392265, 0.10492637753486633, 0.30776458978652954], [0.4307272434234619, 0.4307272434234619, 0.01170459482818842, 7.129006553441286e-05, 0.12676966190338135], [0.10011054575443268, 0.07455740123987198, 0.6028642058372498, 0.07455740123987198, 0.14791041612625122], [0.0008850875892676413, 0.4591054320335388, 0.0036394973285496235, 0.07726454734802246, 0.4591054320335388], [0.39293724298477173, 0.14750228822231293, 0.05328194797039032, 0.39293724298477173, 0.01334125455468893], [0.0108364038169384, 0.0005357455229386687, 0.48381727933883667, 0.48381727933883667, 0.02099325880408287], [0.39339378476142883, 0.060831792652606964, 0.0015342680271714926, 0.15084636211395264, 0.39339378476142883], [0.00048817176138982177, 0.15410256385803223, 0.33225640654563904, 0.33225640654563904, 0.18089646100997925], [0.018731050193309784, 0.0016565665137022734, 0.7893154621124268, 0.17156581580638885, 0.018731050193309784], [0.3527997136116028, 0.23283128440380096, 0.3527997136116028, 0.0013207404408603907, 0.06024850904941559], [0.22203408181667328, 0.22203408181667328, 0.13915754854679108, 0.00900427345186472, 0.4077700078487396], [0.00481694471091032, 0.4008803069591522, 0.17424461245536804, 0.019177844747900963, 0.4008803069591522], [0.053665097802877426, 0.04682504013180733, 0.04682504013180733, 0.7825887799263, 0.07009603083133698], [0.963499903678894, 0.0043879165314137936, 0.014682759530842304, 0.0043879165314137936, 0.013041412457823753], [4.3013696995330974e-05, 0.4782206416130066, 0.4782206416130066, 0.038988374173641205, 0.004527354147285223], [0.000631630071438849, 0.0008912598714232445, 0.38547632098197937, 0.612369179725647, 0.000631630071438849], [0.052946388721466064, 0.1242838129401207, 0.1242838129401207, 0.21709980070590973, 0.4813861548900604], [0.09268777072429657, 1.5657065887353383e-05, 0.003560104640200734, 0.035582005977630615, 0.8681544065475464], [0.030103109776973724, 0.0747562050819397, 0.6054769158363342, 0.029813377186655998, 0.2598503828048706], [0.0002612204698380083, 0.40587443113327026, 0.005314767360687256, 0.40587443113327026, 0.18267516791820526], [0.13225150108337402, 0.5120983123779297, 0.11519608646631241, 0.13225150108337402, 0.10820262134075165], [0.12266671657562256, 0.06444614380598068, 0.7312760949134827, 0.040805503726005554, 0.040805503726005554], [0.5245270729064941, 0.18610799312591553, 0.017177917063236237, 0.08607906848192215, 0.18610799312591553], [0.006460064090788364, 0.983535647392273, 0.006460064090788364, 2.8826050765928812e-05, 0.003515436314046383], [0.021941939368844032, 0.09923207014799118, 0.09923207014799118, 0.7776819467544556, 0.0019119663629680872], [0.3594723641872406, 0.3594723641872406, 0.2603727877140045, 0.0009657256887294352, 0.019716789945960045], [0.27771419286727905, 0.27771419286727905, 0.07895010709762573, 0.34109362959861755, 0.024527868255972862], [0.3558764159679413, 0.06471928209066391, 0.025981606915593147, 0.19754628837108612, 0.3558764159679413], [0.4142967164516449, 0.0006973682320676744, 0.0006973682320676744, 0.5467148423194885, 0.03759368881583214], [0.39618298411369324, 0.0921880230307579, 0.39618298411369324, 0.08272231370210648, 0.03272373974323273], [0.5722095966339111, 0.15861959755420685, 0.0999084860086441, 0.06935384124517441, 0.0999084860086441], [0.9302448034286499, 0.01833684928715229, 0.011003594845533371, 0.01833684928715229, 0.022077934816479683], [0.8954516649246216, 0.024969758465886116, 0.032727718353271484, 0.032727718353271484, 0.014123179949820042], [0.07646982371807098, 0.05918635055422783, 0.3965602517127991, 0.3965602517127991, 0.07122329622507095], [0.4577791094779968, 0.051389750093221664, 0.03252875432372093, 0.4577791094779968, 0.000523299619089812], [0.9504265189170837, 0.043742015957832336, 0.00023777899332344532, 0.005355799105018377, 0.00023777899332344532], [0.006652890704572201, 0.016076574102044106, 0.016076574102044106, 0.004172191489487886, 0.9570217728614807], [0.041556332260370255, 0.35301685333251953, 0.041556332260370255, 0.0412653312087059, 0.5226052403450012], [0.1375296264886856, 0.1181170865893364, 0.47098779678344727, 0.13668273389339447, 0.13668273389339447], [0.11289858818054199, 0.026474012061953545, 0.11289858818054199, 0.38457199931144714, 0.36315682530403137], [0.3906494081020355, 0.020112447440624237, 0.23470234870910645, 0.010065434500575066, 0.344470351934433], [0.035004835575819016, 0.035004835575819016, 0.02447194792330265, 0.22786305844783783, 0.6776553988456726], [0.24492594599723816, 0.1438342034816742, 0.3443387448787689, 0.021975180134177208, 0.24492594599723816], [0.17245014011859894, 0.06736516952514648, 0.04162592813372612, 0.6511935591697693, 0.06736516952514648], [0.20295995473861694, 0.14674489200115204, 0.6123006343841553, 0.010143968276679516, 0.027850577607750893], [0.045046597719192505, 0.03553994745016098, 0.011548462323844433, 0.011548462323844433, 0.8963165879249573], [0.04525713622570038, 0.08144783228635788, 0.05644918233156204, 0.7715886831283569, 0.04525713622570038], [0.5241041779518127, 0.01587359979748726, 0.017876731231808662, 0.4242687523365021, 0.017876731231808662], [0.3176131546497345, 0.0410585030913353, 0.03652872517704964, 0.28718650341033936, 0.3176131546497345], [0.032009802758693695, 0.004508376587182283, 0.42187589406967163, 0.11973011493682861, 0.42187589406967163], [0.00546360993757844, 0.2229328602552414, 0.03047134168446064, 0.2229328602552414, 0.5181993246078491], [0.012506368570029736, 0.05839759111404419, 0.012506368570029736, 0.8080500364303589, 0.10853966325521469], [0.7823027968406677, 0.019003314897418022, 0.09415239095687866, 0.08553820848464966, 0.019003314897418022], [0.00014968763571232557, 0.00014968763571232557, 0.003717668354511261, 0.9084948301315308, 0.08748813718557358], [0.03275790438055992, 0.13213476538658142, 0.37916648387908936, 0.3238060772418976, 0.13213476538658142], [0.0040185884572565556, 0.003769193310290575, 0.16223537921905518, 0.7344599366188049, 0.09551691263914108], [0.1694006323814392, 0.008226020261645317, 0.02997714653611183, 0.5457947254180908, 0.24660147726535797], [0.06801953166723251, 0.14106246829032898, 0.5968142747879028, 0.12608422338962555, 0.06801953166723251], [0.42123275995254517, 0.09990562498569489, 0.0002975414681714028, 0.05733126401901245, 0.42123275995254517], [0.76174396276474, 0.2272026687860489, 0.002269159071147442, 0.002269159071147442, 0.006515019107609987], [0.06803997606039047, 0.5302014946937561, 0.0681334137916565, 0.2412959784269333, 0.09232919663190842], [0.22605131566524506, 0.014870076440274715, 0.02466060221195221, 0.36720895767211914, 0.36720895767211914], [0.3172469735145569, 0.003923641983419657, 0.07110197097063065, 0.07110197097063065, 0.5366255044937134], [0.02121947519481182, 0.00014715458382852376, 0.3872142732143402, 0.5899213552474976, 0.001497700228355825], [0.02021629922091961, 0.03108270652592182, 0.1755012422800064, 0.3865998685359955, 0.3865998685359955], [0.047291845083236694, 0.2302553951740265, 0.1236405298113823, 0.36855679750442505, 0.2302553951740265], [0.0031905737705528736, 0.00434627803042531, 0.17164437472820282, 0.17164437472820282, 0.6491744518280029], [0.2185973972082138, 0.40231853723526, 0.2185973972082138, 0.006940408609807491, 0.15354622900485992], [0.009297309443354607, 0.6732749342918396, 0.12356041371822357, 0.18643780052661896, 0.007429513614624739], [0.04497012123465538, 0.007880834862589836, 0.401911199092865, 0.007880834862589836, 0.5373570322990417], [0.46269527077674866, 0.13644233345985413, 0.16810975968837738, 0.06464287638664246, 0.16810975968837738], [0.14201493561267853, 0.14201493561267853, 0.6860420107841492, 0.015805434435606003, 0.014122741296887398], [0.5919029116630554, 0.08526305854320526, 0.23411379754543304, 0.08526305854320526, 0.0034571944270282984], [0.06295512616634369, 0.06295512616634369, 0.23981665074825287, 0.5173957347869873, 0.11687741428613663], [0.01987522467970848, 0.9156826138496399, 0.051796805113554, 0.006322646047919989, 0.006322646047919989], [3.940533133572899e-05, 0.9020951390266418, 0.09056666493415833, 0.0036493863444775343, 0.0036493863444775343], [0.021717118099331856, 0.021717118099331856, 0.8494314551353455, 0.0019237496890127659, 0.10521054267883301], [0.10520252585411072, 0.23800340294837952, 0.33658066391944885, 0.3199669420719147, 0.0002465204452164471], [0.06254985183477402, 0.30367231369018555, 0.00523259025067091, 0.30367231369018555, 0.3248729109764099], [0.4481295049190521, 0.16889500617980957, 0.1887572705745697, 0.16889500617980957, 0.025323163717985153], [0.0280910637229681, 0.40401020646095276, 0.1091279536485672, 0.2293853610754013, 0.2293853610754013], [0.0432799756526947, 0.47805362939834595, 0.47805362939834595, 0.00015970903041306883, 0.00045304562081582844], [0.26982760429382324, 0.009689047932624817, 0.003293670481070876, 0.26982760429382324, 0.4473620355129242], [0.18365611135959625, 0.0548039935529232, 0.4107997417449951, 0.0548039935529232, 0.29593613743782043], [0.7106918692588806, 0.0036341953091323376, 0.05035354942083359, 0.0036341953091323376, 0.23168620467185974], [0.1191675141453743, 0.1005156859755516, 0.6718376874923706, 0.1005156859755516, 0.007963522337377071], [0.5052034258842468, 0.13822640478610992, 0.1364671289920807, 0.13822640478610992, 0.08187668025493622], [0.1851576417684555, 0.00021867504983674735, 0.1801721751689911, 0.431240975856781, 0.2032104879617691], [0.005482404492795467, 0.17595380544662476, 0.17595380544662476, 0.6413983702659607, 0.001211579772643745], [0.18796508014202118, 0.5340703725814819, 0.013914033770561218, 0.013914033770561218, 0.2501364052295685], [0.0067798420786857605, 0.05897967144846916, 0.8595583438873291, 0.06790222972631454, 0.0067798420786857605], [0.2188737392425537, 0.07038068026304245, 0.2188737392425537, 0.021149972453713417, 0.4707218110561371], [0.9357052445411682, 0.02567426674067974, 0.010462391190230846, 0.0024838221725076437, 0.02567426674067974], [0.0023304815404117107, 0.1850857436656952, 0.297873318195343, 0.1850857436656952, 0.3296247720718384], [0.033917661756277084, 0.8900944590568542, 0.03630248084664345, 0.019842708483338356, 0.019842708483338356], [0.5980662107467651, 0.016536567360162735, 0.3687346875667572, 0.016536567360162735, 0.00012596651504281908], [0.011157343164086342, 0.1435888111591339, 0.28814834356307983, 0.2689571976661682, 0.28814834356307983], [0.9221823811531067, 0.06494215875864029, 0.004055256024003029, 0.004764896351844072, 0.004055256024003029], [0.4192618131637573, 0.01595419831573963, 0.016909942030906677, 0.5309641361236572, 0.016909942030906677], [0.03341628611087799, 0.9242874383926392, 0.002362533938139677, 0.002362533938139677, 0.03757121041417122], [0.032190434634685516, 0.4766368269920349, 0.4766368269920349, 0.007617393042892218, 0.006918578874319792], [0.052880629897117615, 0.052880629897117615, 0.004499361384660006, 0.39074844121932983, 0.4989909529685974], [0.32845720648765564, 0.32845720648765564, 0.3034568130970001, 0.019828680902719498, 0.019800014793872833], [0.26669999957084656, 0.01074578333646059, 0.26669999957084656, 0.44388914108276367, 0.011965149082243443], [0.027450453490018845, 0.1748369336128235, 0.05256525054574013, 0.1748369336128235, 0.5703104734420776], [0.8191975951194763, 0.009810501709580421, 0.009810501709580421, 0.04459831491112709, 0.11658304184675217], [0.0011837714118883014, 0.12909150123596191, 0.4094599783420563, 0.4094599783420563, 0.050804801285266876], [0.3847331404685974, 0.3847331404685974, 0.005993572063744068, 0.12185532599687576, 0.10268481075763702], [0.24763311445713043, 0.1420510858297348, 0.24763311445713043, 0.35290998220443726, 0.00977279245853424], [0.21020618081092834, 0.21020618081092834, 0.0039838463999331, 0.024816935881972313, 0.5507868528366089], [0.032501958310604095, 0.24984797835350037, 0.032501958310604095, 0.05671089142560959, 0.6284372210502625], [0.45744213461875916, 0.0029597997199743986, 0.0029597997199743986, 0.5320399403572083, 0.004598299972712994], [0.2040390819311142, 0.2040390819311142, 0.28176864981651306, 0.2872668206691742, 0.022886313498020172], [0.1914285123348236, 0.0016705204034224153, 0.12215802073478699, 0.12215802073478699, 0.5625849366188049], [0.8663209080696106, 0.06270774453878403, 0.006736722309142351, 0.05749785900115967, 0.006736722309142351], [2.1925505279796198e-05, 0.04149167984724045, 0.12954722344875336, 0.029870646074414253, 0.7990686297416687], [0.03310393542051315, 0.7725974321365356, 0.0073017156682908535, 0.17969514429569244, 0.0073017156682908535], [0.42916569113731384, 0.07506454735994339, 0.22618533670902252, 0.22618533670902252, 0.043399084359407425], [0.21219317615032196, 0.19683639705181122, 0.39354416728019714, 0.0005898907547816634, 0.19683639705181122], [0.02829078957438469, 0.02829078957438469, 0.7716872692108154, 0.06993765383958817, 0.10179343819618225], [0.0008961465791799128, 0.10028946399688721, 0.710676372051239, 0.18724188208580017, 0.0008961465791799128], [0.16585944592952728, 0.6478977799415588, 0.14769282937049866, 0.0037482925690710545, 0.03480161726474762], [0.028751082718372345, 0.030801182612776756, 0.4266229271888733, 0.08720181882381439, 0.4266229271888733], [0.005703209899365902, 0.05312662199139595, 0.6556733846664429, 0.23237010836601257, 0.05312662199139595], [0.3114294409751892, 0.0465095154941082, 0.006678197532892227, 0.3114294409751892, 0.3239533603191376], [0.000764181837439537, 0.31129029393196106, 0.000764181837439537, 0.5271558165550232, 0.1600254625082016], [0.39060068130493164, 0.007915831170976162, 0.007915831170976162, 0.00263113621622324, 0.5909364819526672], [0.013786441646516323, 0.6572272777557373, 0.013786441646516323, 0.24811051785945892, 0.06708928197622299], [0.3546677529811859, 0.014515673741698265, 0.6137098073959351, 0.014515673741698265, 0.0025911349803209305], [0.2819123864173889, 0.0031872678082436323, 0.35291483998298645, 0.35291483998298645, 0.009070638567209244], [0.0006648806156590581, 0.26664793491363525, 0.26664793491363525, 0.4418468773365021, 0.024192459881305695], [0.38247036933898926, 0.38247036933898926, 0.00519667798653245, 0.1202215626835823, 0.10964106023311615], [0.0023153340443968773, 0.0906260684132576, 0.0009855496464297175, 0.0906260684132576, 0.8154470324516296], [0.9291628003120422, 0.023540904745459557, 0.0012142889900133014, 0.022541170939803123, 0.023540904745459557], [0.6998887658119202, 0.29262834787368774, 0.00022253769566304982, 0.00022253769566304982, 0.007037808652967215], [0.7970617413520813, 0.00501268869265914, 0.031581755727529526, 0.10738041996955872, 0.058963365852832794], [0.45087581872940063, 0.07748442143201828, 0.00021014465892221779, 0.0205537099391222, 0.45087581872940063], [0.43178048729896545, 0.05194815993309021, 0.053963206708431244, 0.030527712777256966, 0.43178048729896545], [0.012357653118669987, 0.01345337275415659, 0.03687122091650963, 0.03687122091650963, 0.9004464745521545], [0.3618319034576416, 0.08846276998519897, 0.24279245734214783, 0.0641203373670578, 0.24279245734214783], [0.001221496262587607, 0.3668088912963867, 0.0007660523406229913, 0.31560179591178894, 0.31560179591178894], [0.0836360976099968, 0.04261407628655434, 0.47567835450172424, 0.04261407628655434, 0.3554573655128479], [0.07738329470157623, 0.3564247786998749, 0.29011070728302, 0.07738329470157623, 0.19869786500930786], [0.0011404342949390411, 0.11389873921871185, 0.4893338978290558, 0.28172826766967773, 0.11389873921871185], [0.03669226914644241, 0.005674125626683235, 0.6580607295036316, 0.03669226914644241, 0.26288068294525146], [0.06663986295461655, 0.8061638474464417, 0.06663986295461655, 0.022862736135721207, 0.03769373893737793], [0.2568981647491455, 0.22838588058948517, 0.2568981647491455, 0.25286737084388733, 0.004950428381562233], [0.27903735637664795, 0.026960646733641624, 0.2797241508960724, 0.1345537155866623, 0.2797241508960724], [0.7850309014320374, 0.022390658035874367, 0.08233124762773514, 0.027916012331843376, 0.08233124762773514], [0.33829203248023987, 0.014520657248795033, 0.015099108219146729, 0.015099108219146729, 0.6169890761375427], [0.0626300722360611, 0.01020007859915495, 0.01020007859915495, 0.11583396047353745, 0.801135778427124], [0.5601304173469543, 0.14097872376441956, 0.13722892105579376, 0.13722892105579376, 0.024433044716715813], [0.5217701196670532, 0.43993598222732544, 0.014858866110444069, 0.011717529967427254, 0.011717529967427254], [0.5326810479164124, 0.01633145660161972, 0.39689338207244873, 0.03776264563202858, 0.01633145660161972], [0.023525256663560867, 0.5719497799873352, 0.023525256663560867, 0.08019151538610458, 0.3008081614971161], [0.00829875748604536, 0.325204074382782, 0.04284382238984108, 0.29844930768013, 0.325204074382782], [0.8382580280303955, 0.0007723664748482406, 0.15724806487560272, 0.0029492233879864216, 0.0007723664748482406], [0.045518908649683, 0.4186347723007202, 0.4186347723007202, 9.749538003234193e-05, 0.11711402237415314], [0.062177810817956924, 0.11451846361160278, 0.21829578280448914, 0.11451846361160278, 0.49048948287963867], [0.08448852598667145, 0.02669614739716053, 0.852627694606781, 0.02669614739716053, 0.009491555392742157], [0.03281528502702713, 0.046312861144542694, 0.3977191150188446, 0.261576384305954, 0.261576384305954], [0.018925741314888, 0.006640682928264141, 0.9639054536819458, 0.003887431463226676, 0.006640682928264141], [0.45797815918922424, 0.04436301067471504, 0.3565486967563629, 0.04436301067471504, 0.09674707800149918], [0.03485201671719551, 0.00026970673934556544, 0.00026970673934556544, 0.0256080012768507, 0.9390006065368652], [0.08120082318782806, 0.42490875720977783, 0.08120082318782806, 0.275636225938797, 0.13705335557460785], [0.007816577330231667, 0.9679706692695618, 0.010639764368534088, 0.006786453537642956, 0.006786453537642956], [0.4287124574184418, 0.03483688458800316, 0.14715354144573212, 0.14715354144573212, 0.2421436458826065], [0.052431609481573105, 0.052431609481573105, 0.858900249004364, 0.015010458417236805, 0.021226128563284874], [0.05186087638139725, 0.46946582198143005, 0.46946582198143005, 0.008544126525521278, 0.0006633342709392309], [0.4842347204685211, 0.0013141082599759102, 0.003405197523534298, 0.02681131102144718, 0.4842347204685211], [0.45931804180145264, 0.0013002812629565597, 0.07967817038297653, 0.45931804180145264, 0.0003854175447486341], [0.015259933657944202, 0.07428982853889465, 0.029446376487612724, 0.8067140579223633, 0.07428982853889465], [0.7510056495666504, 0.07947276532649994, 0.003036935580894351, 0.08324231207370758, 0.08324231207370758], [0.0030425498262047768, 0.11053827404975891, 0.00011582413571886718, 0.7757651209831238, 0.11053827404975891], [0.43074750900268555, 0.008830660954117775, 0.10219389945268631, 0.02748049981892109, 0.43074750900268555], [0.09459319710731506, 0.11442951112985611, 0.12905730307102203, 0.09459319710731506, 0.5673267841339111], [0.4423132538795471, 0.03749861568212509, 0.010002439841628075, 0.06787243485450745, 0.4423132538795471], [0.1788325309753418, 0.3682623505592346, 0.3682623505592346, 0.0057406071573495865, 0.07890219241380692], [0.30316048860549927, 0.24146956205368042, 0.1795847862958908, 0.1795847862958908, 0.0962003692984581], [0.6307610869407654, 0.013865320943295956, 0.22173833847045898, 0.1163104921579361, 0.01732471212744713], [0.008851216174662113, 0.11831517517566681, 0.7287529110908508, 0.025765428319573402, 0.11831517517566681], [0.49658942222595215, 0.017848772928118706, 0.4600076675415039, 0.007705408614128828, 0.017848772928118706], [0.0391298271715641, 0.0391298271715641, 0.5785190463066101, 0.2567201256752014, 0.08650120347738266], [0.6202925443649292, 0.3176747262477875, 0.0006962662446312606, 0.0006962662446312606, 0.06064023822546005], [0.4886776804924011, 0.04617912694811821, 0.01000478770583868, 0.45493245124816895, 0.00020605503232218325], [0.001219110214151442, 0.000890193332452327, 0.000890193332452327, 0.3232106864452362, 0.6737898588180542], [0.46713492274284363, 0.06821824610233307, 0.001483339467085898, 0.23158174753189087, 0.23158174753189087], [0.2711801826953888, 0.1596950888633728, 0.3040439188480377, 0.10538574308156967, 0.1596950888633728], [0.4532444179058075, 0.4532444179058075, 0.0543658547103405, 0.023588605225086212, 0.015556770376861095], [0.830965518951416, 0.0058304197154939175, 0.05695127695798874, 0.05695127695798874, 0.04930146411061287], [0.008690277114510536, 0.06797993928194046, 0.40835872292518616, 0.20252957940101624, 0.3124414384365082], [0.049452412873506546, 0.8443790674209595, 0.001916271634399891, 0.001916271634399891, 0.10233598947525024], [0.5587022304534912, 0.006810437422245741, 0.006810437422245741, 0.018153095617890358, 0.4095238149166107], [0.0006161291967146099, 0.053787097334861755, 0.00087434594752267, 0.00087434594752267, 0.9438480138778687], [0.00546186463907361, 0.039442576467990875, 0.93411785364151, 0.00546186463907361, 0.015515796840190887], [0.07954083383083344, 0.3852476179599762, 0.2566894590854645, 0.021832559257745743, 0.2566894590854645], [0.2563440203666687, 0.512221097946167, 0.0037869997322559357, 0.11382392793893814, 0.11382392793893814], [0.23652896285057068, 0.03072868473827839, 0.4748726487159729, 0.23652896285057068, 0.021340731531381607], [0.019602902233600616, 0.006357652135193348, 0.3995380699634552, 0.28725066781044006, 0.28725066781044006], [0.6789051294326782, 0.11118804663419724, 0.05718696489930153, 0.13806450366973877, 0.014655381441116333], [0.5411927700042725, 0.007524287328124046, 0.1743060052394867, 0.10267087817192078, 0.1743060052394867], [0.16099107265472412, 0.20019033551216125, 0.20019033551216125, 0.1987641602754593, 0.23986412584781647], [0.08696026355028152, 0.1480792909860611, 0.6144315600395203, 0.00244967732578516, 0.1480792909860611], [0.01258687674999237, 0.47507765889167786, 0.006558131892234087, 0.030699612572789192, 0.47507765889167786], [0.0673171728849411, 0.28582528233528137, 0.5266067981719971, 0.0673171728849411, 0.05293365567922592], [0.008327098563313484, 0.43453463912010193, 0.06411648541688919, 0.43453463912010193, 0.058487165719270706], [0.08634988218545914, 0.08634988218545914, 0.07332110404968262, 0.22669994831085205, 0.5272791385650635], [0.22218309342861176, 0.022956933826208115, 0.22218309342861176, 0.12948009371757507, 0.403196781873703], [0.2981000542640686, 0.03352193906903267, 0.23577629029750824, 0.19682542979717255, 0.23577629029750824], [0.4676169157028198, 0.004539990331977606, 0.05719209089875221, 0.003034042427316308, 0.4676169157028198], [0.046423669904470444, 0.4321797490119934, 0.4321797490119934, 0.01956525817513466, 0.06965158134698868], [0.10772407799959183, 0.03474024683237076, 0.005684236064553261, 0.005684236064553261, 0.8461672067642212], [0.28050726652145386, 0.032972969114780426, 0.14259177446365356, 0.28050726652145386, 0.2634206712245941], [0.42905694246292114, 0.0004980107769370079, 0.14135228097438812, 0.42905694246292114, 3.5787081287708133e-05], [0.19536927342414856, 0.13403204083442688, 0.19536927342414856, 0.10543699562549591, 0.3697924017906189], [0.2856016755104065, 0.07274167984724045, 0.3558032512664795, 0.00025174597976729274, 0.2856016755104065], [0.3842083215713501, 0.2649010419845581, 0.07628675550222397, 0.009702748619019985, 0.2649010419845581], [0.028173139318823814, 0.8405873775482178, 0.059755317866802216, 0.059755317866802216, 0.011728843674063683], [0.028301866725087166, 0.8908854722976685, 0.03460449352860451, 0.03460449352860451, 0.011603684164583683], [0.24986085295677185, 0.029734104871749878, 0.0925692468881607, 0.5352665185928345, 0.0925692468881607], [0.35140278935432434, 0.017838018015027046, 0.003290386637672782, 0.35140278935432434, 0.27606603503227234], [0.27385395765304565, 0.27385395765304565, 0.01472023967653513, 0.43733853101730347, 0.00023328156385105103], [0.018734676763415337, 0.275863379240036, 0.018734676763415337, 0.6855379939079285, 0.0011292282724753022], [0.02173011563718319, 0.04105765372514725, 0.00451873242855072, 0.9109633564949036, 0.02173011563718319], [0.17567066848278046, 0.3181101083755493, 0.17567066848278046, 0.3203463852405548, 0.010202175937592983], [0.17224618792533875, 0.24406284093856812, 0.10060929507017136, 0.23901890218257904, 0.24406284093856812], [0.8834753036499023, 0.012868601828813553, 0.08601266890764236, 0.012868601828813553, 0.00477482657879591], [0.9970123767852783, 7.595965871587396e-05, 0.0009827418252825737, 0.0018529444932937622, 7.595965871587396e-05], [0.46864187717437744, 0.020066484808921814, 0.020066484808921814, 0.04179967939853668, 0.44942545890808105], [0.2568309009075165, 0.005613873712718487, 0.4183764159679413, 0.2568309009075165, 0.06234795227646828], [0.0003373649378772825, 0.3141781985759735, 0.36413776874542236, 0.00716853141784668, 0.3141781985759735], [0.1402084082365036, 0.4120408296585083, 0.155960813164711, 0.28045719861984253, 0.011332721449434757], [0.04590582475066185, 0.37657463550567627, 0.0004077927442267537, 0.5767040252685547, 0.0004077927442267537], [0.05454772338271141, 0.05454772338271141, 0.0026163992006331682, 0.8126310110092163, 0.07565717399120331], [0.27750784158706665, 0.574852466583252, 0.09406109899282455, 0.026789290830492973, 0.026789290830492973], [0.11773203313350677, 0.7304176092147827, 0.022028490900993347, 0.012089849449694157, 0.11773203313350677], [0.6717861294746399, 0.13166038691997528, 0.048085834830999374, 0.0168073121458292, 0.13166038691997528], [0.053287334740161896, 0.004336853977292776, 0.08215460181236267, 0.855884313583374, 0.004336853977292776], [0.11878778785467148, 0.005741278640925884, 0.3860991299152374, 0.3860991299152374, 0.1032726839184761], [0.4069964289665222, 0.0004790474195033312, 0.13365735113620758, 0.05187075957655907, 0.4069964289665222], [0.34178778529167175, 0.10390234738588333, 0.032745447009801865, 0.34178778529167175, 0.17977666854858398], [0.7012760043144226, 0.23574937880039215, 0.05427773669362068, 0.004348432645201683, 0.004348432645201683], [0.34620633721351624, 0.5932492017745972, 0.025880051776766777, 0.00878437701612711, 0.025880051776766777], [0.2830396592617035, 0.0019999367650598288, 0.0019999367650598288, 0.676567018032074, 0.03639344871044159], [0.23237794637680054, 0.3092745840549469, 0.08176614344120026, 0.3092745840549469, 0.06730669736862183], [0.013766453601419926, 0.7374638319015503, 0.013766453601419926, 0.001849967404268682, 0.23315340280532837], [0.976658046245575, 0.006673316936939955, 0.00023410179710481316, 0.006673316936939955, 0.009761160239577293], [0.2678828835487366, 0.010777132585644722, 0.2678828835487366, 0.3118068277835846, 0.1416502445936203], [0.38232317566871643, 0.001931414706632495, 0.001931414706632495, 0.5663003921508789, 0.047513559460639954], [0.0020629202481359243, 0.8366228938102722, 0.0020629202481359243, 0.11502968519926071, 0.04422155022621155], [0.1077742874622345, 0.5885346531867981, 0.1634701043367386, 0.026951825246214867, 0.11326906830072403], [0.04613235965371132, 0.04613235965371132, 0.023955589160323143, 0.8722661733627319, 0.011513588018715382], [0.052004095166921616, 0.6732448935508728, 0.006791337393224239, 0.004263704642653465, 0.2636958956718445], [0.35603445768356323, 0.0006101251346990466, 0.010157306678593159, 0.6325880289077759, 0.0006101251346990466], [0.29258474707603455, 0.05630463734269142, 0.010422390885651112, 0.29258474707603455, 0.34810349345207214], [0.31541907787323, 0.004446979612112045, 0.3226335942745209, 0.03486671671271324, 0.3226335942745209], [0.1929689347743988, 0.017869479954242706, 0.002274896949529648, 0.593917727470398, 0.1929689347743988], [0.8644058704376221, 0.04423023387789726, 0.03436490520834923, 0.03436490520834923, 0.0226341113448143], [0.15921849012374878, 0.06476981937885284, 0.05191579461097717, 0.3620479702949524, 0.3620479702949524], [0.14023227989673615, 0.0011767275864258409, 0.31667661666870117, 0.31667661666870117, 0.2252376824617386], [0.3671436011791229, 0.20748211443424225, 0.18437913060188293, 0.12049757689237595, 0.12049757689237595], [0.017054324969649315, 0.5836533308029175, 0.017054324969649315, 0.0010230924235656857, 0.3812149167060852], [0.01147437747567892, 0.38721245527267456, 0.008642391301691532, 0.2963353395462036, 0.2963353395462036], [0.12557314336299896, 0.5026611089706421, 0.23846182227134705, 0.12557314336299896, 0.007730794604867697], [0.20200002193450928, 0.5305935144424438, 0.20200002193450928, 0.06441124528646469, 0.0009951854590326548], [0.32638293504714966, 0.008236217312514782, 0.6629632115364075, 0.0012088525108993053, 0.0012088525108993053], [0.08805317431688309, 0.018507808446884155, 0.018507808446884155, 0.8327609300613403, 0.04217030480504036], [0.11450580507516861, 0.13958770036697388, 0.37195974588394165, 0.0019869962707161903, 0.37195974588394165], [0.01179176289588213, 0.0022832569666206837, 0.47438037395477295, 0.49975281953811646, 0.01179176289588213], [0.17174172401428223, 0.25600385665893555, 0.25600385665893555, 0.13847294449806213, 0.17777761816978455], [0.297860324382782, 0.2604191303253174, 0.18038316071033478, 0.0009182704379782081, 0.2604191303253174], [0.0015688716666772962, 0.0015688716666772962, 0.9913182258605957, 0.0021264557726681232, 0.00341762020252645], [0.05846187472343445, 0.06534291803836823, 0.010092702694237232, 0.4330512583255768, 0.4330512583255768], [0.02032989077270031, 0.8298904895782471, 0.12004594504833221, 0.009403801523149014, 0.02032989077270031], [0.6682160496711731, 0.08615156263113022, 0.08615156263113022, 0.15551549196243286, 0.003965388983488083], [0.2594802677631378, 0.06109754741191864, 0.2635171115398407, 0.2635171115398407, 0.15238797664642334], [0.3923461437225342, 0.14241380989551544, 1.258794145542197e-05, 0.03803979977965355, 0.4271877110004425], [0.8375008702278137, 0.0016448191599920392, 0.0375332273542881, 0.0016448191599920392, 0.12167620658874512], [0.011109542101621628, 0.37872499227523804, 0.12839274108409882, 0.011109542101621628, 0.4706631600856781], [0.0007669698097743094, 0.054165538400411606, 0.0002033226191997528, 0.14304430782794952, 0.8018198609352112], [0.4078701436519623, 0.2513611912727356, 0.021355336531996727, 0.15970668196678162, 0.15970668196678162], [0.11747615039348602, 0.08901440352201462, 0.21195657551288605, 0.40594106912612915, 0.17561180889606476], [0.32471567392349243, 0.33929458260536194, 0.32471567392349243, 0.008467521518468857, 0.0028066085651516914], [0.25518473982810974, 0.023447168990969658, 0.03319069743156433, 0.6549866795539856, 0.03319069743156433], [0.44928088784217834, 0.018177751451730728, 0.44928088784217834, 0.058180563151836395, 0.0250799972563982], [0.007198185659945011, 0.23671545088291168, 0.3761225938796997, 0.003841148689389229, 0.3761225938796997], [0.3309931755065918, 0.1680600941181183, 0.2159455418586731, 0.2159455418586731, 0.06905559450387955], [0.8440023064613342, 0.019868887960910797, 0.08906754106283188, 0.025875195860862732, 0.02118607610464096], [0.13987883925437927, 0.0005163643509149551, 0.14012745022773743, 0.0009785834699869156, 0.7184987664222717], [0.07846268266439438, 0.4925478994846344, 0.2936919331550598, 0.0676487535238266, 0.0676487535238266], [0.10571181774139404, 0.7747363448143005, 0.0007363339536823332, 0.01310370210558176, 0.10571181774139404], [0.016346057876944542, 0.14134059846401215, 0.00012451551447156817, 0.016346057876944542, 0.8258427977561951], [0.2341279536485672, 0.06362428516149521, 0.3340902626514435, 0.03406723216176033, 0.3340902626514435], [0.14555883407592773, 0.09355561435222626, 0.03662092983722687, 0.14555883407592773, 0.5787057876586914], [0.9796485304832458, 0.013614204712212086, 0.0006652009906247258, 0.003036055713891983, 0.003036055713891983], [0.2688865661621094, 0.07591404020786285, 0.07591404020786285, 0.3391175866127014, 0.2401677966117859], [0.012411531060934067, 0.4784213900566101, 0.01613081432878971, 0.014614932239055634, 0.4784213900566101], [0.040792208164930344, 0.010435536503791809, 0.6483657956123352, 0.15020324289798737, 0.15020324289798737], [0.319166898727417, 0.03433061018586159, 0.13558435440063477, 0.319166898727417, 0.19175125658512115], [0.416474848985672, 0.012640685774385929, 0.025474796071648598, 0.1289348602294922, 0.416474848985672], [0.03672335296869278, 0.029702091589570045, 0.36612579226493835, 0.5377466678619385, 0.029702091589570045], [0.7432405352592468, 0.011598092503845692, 0.11500106006860733, 0.0151592418551445, 0.11500106006860733], [0.7677879929542542, 0.0664578378200531, 0.0664578378200531, 0.016408631578087807, 0.0828876867890358], [0.3623470366001129, 0.0001021170974127017, 0.0023403712548315525, 0.0023403712548315525, 0.632870078086853], [0.026933304965496063, 0.026933304965496063, 0.4225134551525116, 0.5120621919631958, 0.011557767167687416], [0.037353236228227615, 0.04077146574854851, 0.8245320916175842, 0.04867164045572281, 0.04867164045572281], [0.5291008353233337, 0.13935421407222748, 0.13935421407222748, 0.0006384904263541102, 0.19155223667621613], [0.4845206141471863, 0.41774097084999084, 0.04216583073139191, 0.013406778685748577, 0.04216583073139191], [0.4541277587413788, 0.28989169001579285, 0.10692102462053299, 0.04213842749595642, 0.10692102462053299], [0.4661330580711365, 0.023864775896072388, 0.4661330580711365, 0.0011840672232210636, 0.04268500953912735], [0.05405545234680176, 0.002782889874652028, 0.003196530509740114, 0.003196530509740114, 0.9367685914039612], [0.14672493934631348, 0.014076570980250835, 0.7423242330551147, 0.048437152057886124, 0.048437152057886124], [0.016739748418331146, 0.2846372127532959, 0.17696025967597961, 0.2846372127532959, 0.23702558875083923], [0.1171082928776741, 0.43351566791534424, 0.29198840260505676, 0.0402793288230896, 0.1171082928776741], [0.03172395005822182, 0.023067409172654152, 0.191140815615654, 0.37703388929367065, 0.37703388929367065], [0.054063186049461365, 0.11182145029306412, 0.4162594974040985, 0.4162594974040985, 0.0015963423065841198], [0.31052854657173157, 0.018074914813041687, 0.23219919204711914, 0.12866879999637604, 0.31052854657173157], [0.0028856629505753517, 0.47759518027305603, 0.47759518027305603, 0.040390580892562866, 0.0015334193594753742], [0.1932826042175293, 0.37231120467185974, 0.0031258107628673315, 0.058969203382730484, 0.37231120467185974], [0.0013522820081561804, 0.17362971603870392, 0.011198550462722778, 0.011776723898947239, 0.8020427227020264], [0.008422757498919964, 0.439837783575058, 0.04723133146762848, 0.17221125960350037, 0.33229684829711914], [0.2325720340013504, 0.2325720340013504, 0.2019522786140442, 0.1550365537405014, 0.177867129445076], [0.021012965589761734, 0.4088030457496643, 0.4088030457496643, 0.00022026477381587029, 0.1611606627702713], [0.10445377975702286, 0.6709316968917847, 0.10445377975702286, 0.11427981406450272, 0.005880877375602722], [0.5347686409950256, 0.28271812200546265, 0.004808886907994747, 0.004808886907994747, 0.17289547622203827], [0.13203512132167816, 0.13203512132167816, 0.22426843643188477, 0.4109489917755127, 0.10071232914924622], [0.06621361523866653, 0.929020881652832, 0.0009457923006266356, 0.0009457923006266356, 0.0028739185072481632], [0.00016644166316837072, 0.2387414574623108, 0.6668383479118347, 0.04712684080004692, 0.04712684080004692], [0.333276629447937, 0.030034154653549194, 0.333276629447937, 0.0009558091987855732, 0.302456796169281], [0.10056667774915695, 0.10056667774915695, 0.42599597573280334, 0.1231674924492836, 0.24970319867134094], [0.0039978064596652985, 0.5710315108299255, 0.3022508919239044, 0.11872203648090363, 0.0039978064596652985], [0.03116171807050705, 0.1948273479938507, 0.2755425274372101, 0.2755425274372101, 0.22292588651180267], [0.01271149329841137, 0.9424329400062561, 0.004855642095208168, 0.027288412675261497, 0.01271149329841137], [0.05122233182191849, 0.2709902822971344, 0.37131017446517944, 0.2709902822971344, 0.035487014800310135], [0.08478470146656036, 0.00034718867391347885, 0.3925535976886749, 0.1297609806060791, 0.3925535976886749], [0.07168252766132355, 0.21126876771450043, 0.21126876771450043, 0.07560693472623825, 0.43017295002937317], [0.4072599709033966, 0.46012893319129944, 0.03823008015751839, 0.0561508946120739, 0.03823008015751839], [0.06431476026773453, 0.7678175568580627, 0.06431476026773453, 0.041967786848545074, 0.061585165560245514], [0.0016576776979491115, 0.033126525580883026, 0.009981424547731876, 0.9535766243934631, 0.0016576776979491115], [0.005839388817548752, 0.10721582174301147, 0.1899842619895935, 0.5897447466850281, 0.10721582174301147], [0.23799213767051697, 0.062121935188770294, 0.3045295774936676, 0.09082679450511932, 0.3045295774936676], [0.6032685041427612, 0.004098952282220125, 0.004098952282220125, 0.013204477727413177, 0.37532907724380493], [0.29372620582580566, 0.29372620582580566, 0.006221291609108448, 0.3803839087486267, 0.02594243735074997], [0.4831696152687073, 0.04052267223596573, 0.04052267223596573, 0.05069872364401817, 0.3850863575935364], [0.005047712940722704, 0.569207489490509, 0.21095900237560272, 0.003826753469184041, 0.21095900237560272], [0.01172591745853424, 0.10558436065912247, 0.4791547358036041, 0.10558436065912247, 0.2979506850242615], [0.00039450600161217153, 0.4871968626976013, 0.4871968626976013, 0.014828755520284176, 0.010383076965808868], [0.04236051067709923, 0.001031037070788443, 0.001031037070788443, 0.5509706735610962, 0.4046066701412201], [0.049173325300216675, 0.036771778017282486, 4.0367791370954365e-05, 0.8648412227630615, 0.049173325300216675], [0.08383204787969589, 0.017978642135858536, 0.7169859409332275, 0.017978642135858536, 0.16322466731071472], [0.007474723272025585, 0.851866602897644, 0.012935039587318897, 0.012935039587318897, 0.11478858441114426], [0.10717274993658066, 0.07506479322910309, 0.04422830045223236, 0.10717274993658066, 0.666361391544342], [0.471891850233078, 0.471891850233078, 0.0014149559428915381, 0.05407151207327843, 0.0007298675482161343], [0.006974813062697649, 0.021901454776525497, 0.9672304391860962, 0.0019466797821223736, 0.0019466797821223736], [0.02602706477046013, 0.3212035000324249, 0.38520169258117676, 0.24154064059257507, 0.02602706477046013], [0.07787627726793289, 0.6978486180305481, 0.1438058316707611, 0.0025930185802280903, 0.07787627726793289], [0.08192818611860275, 0.08192818611860275, 0.3675481081008911, 0.03454999998211861, 0.4340454936027527], [0.18476076424121857, 0.007763087283819914, 0.007763087283819914, 0.14529822766780853, 0.6544148921966553], [0.1540752798318863, 0.03302221745252609, 0.024246854707598686, 0.7780735492706299, 0.01058204099535942], [0.06659992784261703, 0.625178337097168, 0.12208206206560135, 0.09306980669498444, 0.09306980669498444], [0.43604323267936707, 0.04358872026205063, 0.04358872026205063, 0.0020475906785577536, 0.4747316539287567], [0.06930741667747498, 0.5065008401870728, 0.06930741667747498, 0.2987309992313385, 0.05615337938070297], [4.725715916720219e-05, 0.08518828451633453, 0.8269060254096985, 0.04392918199300766, 0.04392918199300766], [0.2484239637851715, 0.14636722207069397, 0.008167419582605362, 0.14636722207069397, 0.4506741166114807], [0.44056496024131775, 0.004088941030204296, 0.07273110002279282, 0.44056496024131775, 0.04204999655485153], [0.6264952421188354, 0.1593060940504074, 0.03815509378910065, 0.1593060940504074, 0.016737475991249084], [0.013763591647148132, 0.07881759852170944, 0.821662962436676, 0.07199227064847946, 0.013763591647148132], [0.0008947598398663104, 0.05385347455739975, 0.057848963886499405, 0.057848963886499405, 0.8295538425445557], [0.05357777327299118, 0.24414099752902985, 0.39913156628608704, 0.05900869518518448, 0.24414099752902985], [0.11765965819358826, 0.03419486805796623, 0.03419486805796623, 0.0020517681259661913, 0.8118988275527954], [0.007901514880359173, 0.21111223101615906, 0.29164376854896545, 0.24467122554779053, 0.24467122554779053], [0.0027865737210959196, 0.5013449192047119, 0.0027865737210959196, 0.4626694917678833, 0.030412491410970688], [0.6871781945228577, 0.054319534450769424, 0.018265005201101303, 0.12011861801147461, 0.12011861801147461], [0.479348748922348, 0.479348748922348, 0.01024214643985033, 0.031015118584036827, 4.517822526395321e-05], [0.032584238797426224, 0.9523523449897766, 0.005801104009151459, 0.0042982702143490314, 0.004964051302522421], [0.3783988356590271, 0.16944549977779388, 0.03923294320702553, 0.03452383354306221, 0.3783988356590271], [0.4138758182525635, 0.20793159306049347, 0.20793159306049347, 0.1533733457326889, 0.01688760705292225], [0.6772358417510986, 0.0049797892570495605, 0.01605905219912529, 0.0049797892570495605, 0.29674550890922546], [0.49035826325416565, 0.1636417657136917, 0.0001459804188925773, 0.2711714208126068, 0.0746825709939003], [0.13187777996063232, 0.09685981273651123, 0.4776908755302429, 0.19671174883842468, 0.09685981273651123], [0.30129531025886536, 0.013525898568332195, 0.30129531025886536, 0.044142697006464005, 0.3397407531738281], [0.09142478555440903, 0.04708416387438774, 0.2876409590244293, 0.2876409590244293, 0.2862091064453125], [0.02341337315738201, 0.009483779780566692, 0.917859673500061, 0.003106095129624009, 0.0461370013654232], [0.12167467921972275, 0.04263605177402496, 0.6917436718940735, 0.04263605177402496, 0.10130954533815384], [0.19520388543605804, 0.4820077419281006, 0.14443916082382202, 0.03579816222190857, 0.14255110919475555], [0.09734939783811569, 0.029883552342653275, 0.09734939783811569, 0.37279415130615234, 0.4026235342025757], [0.10222221910953522, 0.09279511868953705, 0.01884300820529461, 0.004995292983949184, 0.7811443209648132], [0.06576576828956604, 0.05940116569399834, 0.6312466263771057, 0.1841852366924286, 0.05940116569399834], [0.2599881589412689, 0.16131088137626648, 0.39588820934295654, 0.16131088137626648, 0.021501868963241577], [0.039752084761857986, 0.4634091854095459, 0.4634091854095459, 0.001523654325865209, 0.03190590441226959], [0.39009734988212585, 0.12847726047039032, 0.350493460893631, 0.0024545909836888313, 0.12847726047039032], [0.7949736714363098, 0.0695682093501091, 0.03365493193268776, 0.03365493193268776, 0.06814824044704437], [0.04896475747227669, 0.7051796317100525, 0.003067795652896166, 0.12139392644166946, 0.12139392644166946], [0.21239717304706573, 0.21239717304706573, 0.044204045087099075, 0.04755377396941185, 0.4834478497505188], [0.8054640293121338, 0.00013861205661669374, 0.02931159734725952, 0.16494713723659515, 0.00013861205661669374], [0.03726973012089729, 0.0021076244302093983, 0.4633035361766815, 0.49521148204803467, 0.0021076244302093983], [0.4665226936340332, 0.02736598253250122, 0.03939231485128403, 0.4665226936340332, 0.00019637541845440865], [0.06160235404968262, 0.6745285391807556, 0.11488637328147888, 0.034096427261829376, 0.11488637328147888], [0.7156074643135071, 0.063282810151577, 0.14933474361896515, 0.00849215779453516, 0.063282810151577], [0.007120458409190178, 0.08645715564489365, 0.30617108941078186, 0.2940801978111267, 0.30617108941078186], [0.2608213722705841, 0.05490288510918617, 0.21003253757953644, 0.05490288510918617, 0.41934025287628174], [0.13664662837982178, 0.13664662837982178, 0.1539989858865738, 0.5632640719413757, 0.00944366306066513], [0.0675898939371109, 0.32847219705581665, 0.2515437602996826, 0.32847219705581665, 0.02392195351421833], [0.03981313109397888, 0.03981313109397888, 0.10009364038705826, 0.3874886929988861, 0.4327913522720337], [0.0004416027804836631, 0.0004416027804836631, 0.9723266363143921, 0.024906912818551064, 0.0018832467030733824], [0.016145776957273483, 0.3810228407382965, 0.10706149786710739, 0.3810228407382965, 0.11474709212779999], [0.04209131747484207, 0.0552934966981411, 0.6872669458389282, 0.17325694859027863, 0.04209131747484207], [0.0035553209017962217, 0.03345489874482155, 0.002597886836156249, 0.48019593954086304, 0.48019593954086304], [0.008371361531317234, 0.0018652724102139473, 0.0227701086550951, 0.48349660634994507, 0.48349660634994507], [0.024190690368413925, 0.20525294542312622, 0.0031973880250006914, 0.5621060132980347, 0.20525294542312622], [0.04382442310452461, 0.07775940001010895, 0.07775940001010895, 0.6386308670043945, 0.16202588379383087], [0.009947018697857857, 0.006129071582108736, 0.009947018697857857, 0.8333562612533569, 0.140620619058609], [0.08669949322938919, 0.034398019313812256, 0.20037102699279785, 0.08669949322938919, 0.5918320417404175], [0.007173561956733465, 0.0014447318390011787, 0.0014447318390011787, 0.913476288318634, 0.07646068930625916], [0.006253647152334452, 0.7983874082565308, 0.19145745038986206, 0.0019507353426888585, 0.0019507353426888585], [0.3089189827442169, 0.08745844662189484, 0.29253441095352173, 0.3089189827442169, 0.002169109880924225], [0.006844009272754192, 0.19089078903198242, 0.5655062794685364, 0.04586814343929291, 0.19089078903198242], [0.42440465092658997, 0.007090425584465265, 0.09115393459796906, 0.47026047110557556, 0.007090425584465265], [0.295895516872406, 0.05579887703061104, 0.295895516872406, 0.34839585423469543, 0.004014304839074612], [0.07413308322429657, 0.8252643942832947, 2.978239172080066e-05, 0.02643955685198307, 0.07413308322429657], [0.009945722296833992, 0.21269842982292175, 0.08392610400915146, 0.21269842982292175, 0.480731338262558], [0.42682623863220215, 0.12270487844944, 0.42682623863220215, 0.020757775753736496, 0.002884865738451481], [0.8479194641113281, 0.10163342207670212, 0.04511173069477081, 0.0026676503475755453, 0.0026676503475755453], [0.02984619326889515, 0.02671223133802414, 0.08497869223356247, 0.8286166787147522, 0.02984619326889515], [0.04641279578208923, 0.0037000656593590975, 0.0037000656593590975, 0.39318862557411194, 0.5529984831809998], [0.04409708455204964, 0.251578688621521, 0.3529294431209564, 0.04409708455204964, 0.3072976768016815], [0.02317364141345024, 0.08855164796113968, 0.13957169651985168, 0.13957169651985168, 0.6091313362121582], [0.34857475757598877, 0.17600080370903015, 0.026746267452836037, 0.026746267452836037, 0.4219319522380829], [0.33557969331741333, 0.02903604879975319, 0.33557969331741333, 0.00943149346858263, 0.2903730273246765], [0.3669836223125458, 0.3669836223125458, 0.015012129209935665, 0.10933785885572433, 0.1416827291250229], [0.15690481662750244, 0.7238877415657043, 0.024667562916874886, 0.09097006916999817, 0.003569805296137929], [0.17246364057064056, 0.10791425406932831, 0.0003332280903123319, 0.35964447259902954, 0.35964447259902954], [0.01203510258346796, 0.009826858527958393, 0.3379665017127991, 0.30220505595207214, 0.3379665017127991], [0.4653400480747223, 0.01953202672302723, 0.45224252343177795, 0.02902832068502903, 0.03385695442557335], [0.36306294798851013, 0.36306294798851013, 0.04221934825181961, 0.005296729970723391, 0.22635801136493683], [0.007652467116713524, 0.044758815318346024, 0.10754720866680145, 0.8323890566825867, 0.007652467116713524], [0.018763946369290352, 0.016000594943761826, 0.564750075340271, 0.3817214071750641, 0.018763946369290352], [0.27708369493484497, 0.020934389904141426, 0.31112101674079895, 0.07973985373973846, 0.31112101674079895], [0.06245926022529602, 0.06245926022529602, 0.8141470551490784, 0.0038521599490195513, 0.057082343846559525], [0.008207126520574093, 0.21221087872982025, 0.008207126520574093, 0.08267781138420105, 0.6886970400810242], [0.11077781021595001, 0.34562987089157104, 0.3019911050796509, 0.13082340359687805, 0.11077781021595001], [0.19276957213878632, 0.4360550343990326, 0.029848411679267883, 0.029848411679267883, 0.31147852540016174], [0.45701175928115845, 0.051543332636356354, 0.45701175928115845, 0.016336821019649506, 0.018096350133419037], [0.5043349266052246, 0.018949851393699646, 0.028750283643603325, 0.4192146062850952, 0.028750283643603325], [0.4064561426639557, 0.4064561426639557, 0.06584654003381729, 0.05362194776535034, 0.06761922687292099], [0.22144852578639984, 0.631712794303894, 0.024263646453619003, 0.09831136465072632, 0.024263646453619003], [0.0368090383708477, 0.30818212032318115, 0.30818212032318115, 0.3011905550956726, 0.04563617333769798], [0.38920387625694275, 0.4484107494354248, 0.03795653581619263, 0.0622144378721714, 0.0622144378721714], [0.0199092049151659, 0.26581570506095886, 0.07932953536510468, 0.31747275590896606, 0.31747275590896606], [0.10515309125185013, 0.062482286244630814, 0.001985769020393491, 0.4151894152164459, 0.4151894152164459], [0.09041882306337357, 0.18131107091903687, 0.18131107091903687, 0.5073783993721008, 0.03958062455058098], [0.23493467271327972, 0.021731046959757805, 0.22381582856178284, 0.4977874159812927, 0.021731046959757805], [0.5003647804260254, 0.0870433822274208, 0.03314237669110298, 0.18972474336624146, 0.18972474336624146], [0.1331705003976822, 0.6009494066238403, 0.1331705003976822, 0.08742109686136246, 0.04528845474123955], [0.0038811014965176582, 0.8627590537071228, 0.08141516894102097, 0.048063598573207855, 0.0038811014965176582], [0.09887360036373138, 0.32931262254714966, 0.23562686145305634, 0.00687426095828414, 0.32931262254714966], [0.11032480746507645, 0.003047167556360364, 0.0062897396273911, 0.7700135111808777, 0.11032480746507645], [0.0009655511239543557, 0.2961128056049347, 0.3508971035480499, 0.3508971035480499, 0.001127476105466485], [0.5786553025245667, 0.14350101351737976, 4.794284177478403e-05, 4.794284177478403e-05, 0.27774778008461], [0.1674264669418335, 0.5488319396972656, 0.1674264669418335, 0.07645346969366074, 0.039861638098955154], [0.3871273994445801, 0.04039215296506882, 0.06271429359912872, 0.44705185294151306, 0.06271429359912872], [0.1136082261800766, 0.5497998595237732, 0.11381616443395615, 0.10916748642921448, 0.1136082261800766], [0.20770122110843658, 0.3716302216053009, 0.3716302216053009, 0.029289981350302696, 0.019748400896787643], [0.007654206361621618, 0.007654206361621618, 0.03400404378771782, 0.9013025164604187, 0.049385134130716324], [0.02087542787194252, 0.03054291382431984, 0.07817058265209198, 0.03054291382431984, 0.8398681282997131], [0.65134596824646, 0.1422777622938156, 0.06288608908653259, 0.0012124482309445739, 0.1422777622938156], [0.07837028056383133, 0.28694021701812744, 0.5448859333992004, 0.011433287523686886, 0.07837028056383133], [0.0038642410654574633, 0.06445904076099396, 0.8638967871665955, 0.06445904076099396, 0.0033208909444510937], [0.48176512122154236, 0.48176512122154236, 0.0005669121746905148, 0.00029716131393797696, 0.03560563921928406], [0.06647339463233948, 0.15947166085243225, 0.15947166085243225, 0.6135721206665039, 0.0010110827861353755], [0.4213736355304718, 0.4213736355304718, 0.004355508368462324, 0.0684330090880394, 0.08446423709392548], [0.07034977525472641, 0.07034977525472641, 0.762015163898468, 0.08880981057882309, 0.00847543403506279], [0.012583667412400246, 0.5484750866889954, 0.426329106092453, 2.8447320801205933e-05, 0.012583667412400246], [0.00010807544458657503, 0.0010993082541972399, 0.10154908895492554, 0.5307045578956604, 0.36653897166252136], [0.00019024881476070732, 0.18340861797332764, 0.00010547378042247146, 0.00010547378042247146, 0.816190242767334], [0.06873468309640884, 0.009120454080402851, 0.009120454080402851, 0.7384254336357117, 0.17459894716739655], [0.21842214465141296, 0.30219766497612, 0.007960814982652664, 0.28562262654304504, 0.18579678237438202], [0.013309214264154434, 0.44008588790893555, 0.44008588790893555, 0.0010725579923018813, 0.1054464727640152], [0.4007529020309448, 0.005000974051654339, 0.09172725677490234, 0.1017659604549408, 0.4007529020309448], [0.12881244719028473, 0.2231188714504242, 0.619856059551239, 0.01410631649196148, 0.01410631649196148], [0.029659973457455635, 0.5620341300964355, 0.20122066140174866, 0.005864644888788462, 0.20122066140174866], [0.00034279259853065014, 0.9469412565231323, 0.011135599575936794, 0.00034279259853065014, 0.041237469762563705], [0.001483891042880714, 0.16630224883556366, 0.1309877336025238, 0.1309877336025238, 0.570238471031189], [0.3074890375137329, 0.3074890375137329, 0.03354699909687042, 0.017153937369585037, 0.3343210220336914], [0.04851239547133446, 0.2569085657596588, 0.2569085657596588, 0.013668354600667953, 0.42400211095809937], [0.40915751457214355, 0.40374070405960083, 0.0037416003178805113, 0.15702739357948303, 0.026332875713706017], [0.3422929048538208, 0.0022721881978213787, 0.3152315616607666, 0.17010168731212616, 0.17010168731212616], [0.19960761070251465, 0.07715340703725815, 0.19960761070251465, 0.09880293905735016, 0.424828439950943], [0.006416702177375555, 0.002937664045020938, 0.011890099383890629, 0.006416702177375555, 0.9723389148712158], [0.37230080366134644, 0.10006407648324966, 0.022533416748046875, 0.13280093669891357, 0.37230080366134644], [0.2478140890598297, 0.2222922295331955, 0.1662275642156601, 0.1662275642156601, 0.19743844866752625], [0.0013180189998820424, 0.031922727823257446, 0.8795970678329468, 0.05523941293358803, 0.031922727823257446], [0.24560783803462982, 0.19564251601696014, 6.024503454682417e-05, 6.024503454682417e-05, 0.5586291551589966], [0.6427103281021118, 0.004305560607463121, 0.011614397168159485, 0.17068488895893097, 0.17068488895893097], [0.017508048564195633, 0.003062636824324727, 0.010922537185251713, 0.4842533767223358, 0.4842533767223358], [0.1782919317483902, 0.1782919317483902, 0.001753416145220399, 0.6298969388008118, 0.011765865609049797], [0.03461650386452675, 0.0057123638689517975, 0.2597597539424896, 0.03461650386452675, 0.6652948260307312], [0.10125046968460083, 0.832173764705658, 0.004320643842220306, 0.031127527356147766, 0.031127527356147766], [0.0015502717578783631, 0.07746563106775284, 0.07746563106775284, 0.03056097961962223, 0.8129574656486511], [0.29148009419441223, 0.1921454221010208, 0.15062913298606873, 0.29148009419441223, 0.07426527887582779], [0.008505322970449924, 0.309162974357605, 0.35762137174606323, 0.309162974357605, 0.015547371469438076], [0.010547778569161892, 0.0715634673833847, 0.6642140746116638, 0.19098752737045288, 0.06268709897994995], [0.00011538796388776973, 0.00011538796388776973, 0.03502372279763222, 0.9642102718353271, 0.0005352410371415317], [0.22784164547920227, 0.43248164653778076, 0.09640023112297058, 0.22784164547920227, 0.015434900298714638], [0.1853329986333847, 0.008292163722217083, 0.008292163722217083, 0.6889869570732117, 0.10909571498632431], [0.6863868236541748, 0.271146684885025, 0.015764577314257622, 0.015764577314257622, 0.010937254875898361], [0.18008723855018616, 0.5580224990844727, 0.07709286361932755, 0.004710189998149872, 0.18008723855018616], [0.0011829037684947252, 0.5033963918685913, 0.31275254487991333, 0.09133407473564148, 0.09133407473564148], [0.4059453010559082, 0.4059453010559082, 0.04377094656229019, 0.13808365166187286, 0.006254850886762142], [0.15586091578006744, 0.256165474653244, 0.256165474653244, 0.2851403057575226, 0.04666784405708313], [5.372410305426456e-05, 0.48740988969802856, 0.13673065602779388, 0.37575197219848633, 5.372410305426456e-05], [0.0011187883792445064, 0.0011187883792445064, 0.025183366611599922, 0.9612325429916382, 0.01134649757295847], [0.008759465999901295, 0.013914894312620163, 0.42575231194496155, 0.42575231194496155, 0.12582094967365265], [0.7067355513572693, 0.05109557881951332, 0.008489517495036125, 0.18258380889892578, 0.05109557881951332], [0.7094784379005432, 0.019564013928174973, 0.05216214805841446, 0.07776402682065964, 0.1410313993692398], [0.42357808351516724, 0.02800513245165348, 0.21662680804729462, 0.11516313999891281, 0.21662680804729462], [0.07505213469266891, 0.14838750660419464, 0.6266534924507141, 0.0015193959698081017, 0.14838750660419464], [0.0040143998339772224, 0.031423624604940414, 0.8829870223999023, 0.07756052911281586, 0.0040143998339772224], [0.14516466856002808, 0.06694883108139038, 0.5468478798866272, 0.06694883108139038, 0.1740897297859192], [0.05373294651508331, 0.0599934458732605, 0.05373294651508331, 0.6713496446609497, 0.16119100153446198], [0.20836420357227325, 0.20836420357227325, 0.05275534465909004, 0.048303961753845215, 0.48221221566200256], [0.10379179567098618, 0.31759241223335266, 0.0625218078494072, 0.31759241223335266, 0.1985015720129013], [0.00606541195884347, 0.2612912952899933, 0.23164792358875275, 0.23970404267311096, 0.2612912952899933], [0.10069358348846436, 0.19313515722751617, 0.5338544845581055, 0.0861583948135376, 0.0861583948135376], [0.009233049117028713, 0.0007392485276795924, 0.0007392485276795924, 0.3595254421234131, 0.6297630071640015], [0.05876591429114342, 0.05876591429114342, 0.013888467103242874, 0.8523143529891968, 0.016265366226434708], [0.4996192455291748, 0.4996192455291748, 5.281664925860241e-06, 0.000393678987165913, 0.0003625202225521207], [0.13696107268333435, 0.4018236994743347, 0.032710764557123184, 0.026680849492549896, 0.4018236994743347], [0.014328389428555965, 0.37120309472084045, 0.18280211091041565, 0.37120309472084045, 0.06046333163976669], [0.9537414312362671, 0.0035493182949721813, 0.022378452122211456, 0.014677001163363457, 0.005653864704072475], [0.451999694108963, 0.451999694108963, 0.0012014342937618494, 0.060918889939785004, 0.03388034924864769], [0.058034367859363556, 0.058034367859363556, 0.22012537717819214, 0.13733257353305817, 0.5264732837677002], [0.03743024915456772, 0.4703178405761719, 0.004955385811626911, 0.01697869785130024, 0.4703178405761719], [0.07593067735433578, 0.24795159697532654, 0.026984665542840958, 0.4011813700199127, 0.24795159697532654], [1.3355291230254807e-05, 0.0490255244076252, 0.49747490882873535, 0.4534728527069092, 1.3355291230254807e-05], [0.1271401196718216, 0.12201755493879318, 0.3731316328048706, 0.3731316328048706, 0.004579043481498957], [0.28395864367485046, 0.14198994636535645, 0.14198994636535645, 0.4308868646621704, 0.0011745800729840994], [0.056090302765369415, 0.34827467799186707, 0.03141159564256668, 0.2821117341518402, 0.2821117341518402], [0.16275033354759216, 0.06912887096405029, 0.12340059131383896, 0.16275033354759216, 0.48196983337402344], [0.08312147855758667, 0.013955298811197281, 0.6746518015861511, 0.013955298811197281, 0.21431617438793182], [0.40343260765075684, 0.40343260765075684, 0.03295518085360527, 0.13313308358192444, 0.027046583592891693], [0.1979668289422989, 0.6056370735168457, 2.418336589471437e-05, 2.418336589471437e-05, 0.1963476538658142], [0.0004444739024620503, 0.05275158956646919, 0.8749832510948181, 0.05275158956646919, 0.01906907558441162], [0.3959173560142517, 0.09487839788198471, 0.17401579022407532, 0.24031002819538116, 0.09487839788198471], [0.004674630705267191, 0.3394452631473541, 0.31522950530052185, 0.3394452631473541, 0.001205381820909679], [0.4523397386074066, 0.30795183777809143, 0.11659382283687592, 0.0065207714214921, 0.11659382283687592], [0.037029363214969635, 0.3863135874271393, 0.057201679795980453, 0.2079470455646515, 0.3115083575248718], [0.7334882020950317, 0.06975144892930984, 0.0884595736861229, 0.01984127052128315, 0.0884595736861229], [0.5917034149169922, 0.3894232511520386, 0.0009407954639755189, 0.0009407954639755189, 0.01699165813624859], [9.597664029570296e-05, 0.004090971313416958, 0.817404568195343, 0.1783124953508377, 9.597664029570296e-05], [0.19120241701602936, 0.01075994223356247, 0.5744144320487976, 0.11181160062551498, 0.11181160062551498], [0.20299601554870605, 0.217179074883461, 0.2934502363204956, 0.14318732917308807, 0.14318732917308807], [0.1500076800584793, 0.2666386365890503, 0.2666386365890503, 0.2515225410461426, 0.06519250571727753], [0.0013314337702468038, 0.03397146239876747, 0.03397146239876747, 0.02839989773929119, 0.9023256897926331], [0.025202352553606033, 0.16896690428256989, 0.16896690428256989, 0.636792004108429, 7.183218258433044e-05], [0.40293577313423157, 0.002214280189946294, 0.29506051540374756, 0.0047289226204156876, 0.29506051540374756], [0.02292109653353691, 0.12642626464366913, 0.047385137528181076, 0.12642626464366913, 0.6768412590026855], [0.10321959108114243, 0.00011816436017397791, 0.13521112501621246, 0.10321959108114243, 0.6582315564155579], [0.09253339469432831, 0.31485792994499207, 0.4751307964324951, 0.024944491684436798, 0.09253339469432831], [0.02043640799820423, 0.004639154300093651, 0.004639154300093651, 0.00685125170275569, 0.9634339809417725], [0.003174399957060814, 0.16593259572982788, 0.663488507270813, 0.001471922849304974, 0.16593259572982788], [0.001725750626064837, 0.0012150721158832312, 0.001725750626064837, 0.9872848391532898, 0.008048614487051964], [0.28413477540016174, 0.053832560777664185, 0.28413477540016174, 0.37489455938339233, 0.003003268036991358], [0.00018667118274606764, 0.04067688435316086, 0.31202465295791626, 0.13475783169269562, 0.5123540163040161], [0.450427770614624, 0.2831452488899231, 0.023291880264878273, 0.023291880264878273, 0.21984316408634186], [0.3626178205013275, 0.20795446634292603, 0.3626178205013275, 0.04722023382782936, 0.01958957128226757], [0.2800517976284027, 0.0011675682617351413, 0.43761730194091797, 0.0011115261586382985, 0.2800517976284027], [0.039936844259500504, 0.00048734413576312363, 0.19405117630958557, 0.7650372982025146, 0.00048734413576312363], [0.010229496285319328, 0.0008011235622689128, 0.47635582089424133, 0.0362577922642231, 0.47635582089424133], [0.044033631682395935, 0.016738563776016235, 0.8774530291557312, 0.044033631682395935, 0.017741143703460693], [0.10416199266910553, 0.11190260201692581, 0.34703516960144043, 0.34703516960144043, 0.08986502885818481], [0.04228648170828819, 0.042158015072345734, 0.04228648170828819, 0.8661588430404663, 0.007110097911208868], [0.0015755880158394575, 0.4956642687320709, 0.005410307087004185, 0.0016855781432241201, 0.4956642687320709], [0.005942259915173054, 0.18023718893527985, 0.4045126140117645, 0.4045126140117645, 0.004795357119292021], [0.28807225823402405, 0.46527135372161865, 0.1561581790447235, 0.011082015931606293, 0.07941620796918869], [0.2288954257965088, 0.1000252515077591, 0.1433698683977127, 0.2288954257965088, 0.2988140285015106], [0.7842691540718079, 0.04335499182343483, 0.15074515342712402, 0.010815344750881195, 0.010815344750881195], [0.1309235394001007, 0.6279875636100769, 0.1309235394001007, 0.000683950143866241, 0.10948144644498825], [0.09106732904911041, 0.8299149870872498, 0.0007462790235877037, 0.07752513140439987, 0.0007462790235877037], [0.00033826639992184937, 0.0130684869363904, 0.00042174645932391286, 0.9857497215270996, 0.00042174645932391286], [0.5351658463478088, 0.04512883350253105, 0.1507216840982437, 0.1507216840982437, 0.11826196312904358], [0.0038720788434147835, 0.8324459791183472, 0.09616218507289886, 0.06364770233631134, 0.0038720788434147835], [0.38019973039627075, 0.03716432303190231, 0.015285933390259743, 0.38019973039627075, 0.1871502697467804], [0.015780199319124222, 2.9768163585686125e-05, 2.9768163585686125e-05, 0.0792408287525177, 0.9049193859100342], [0.003168428549543023, 0.019716335460543633, 0.8818809986114502, 0.003168428549543023, 0.09206581115722656], [0.09568090736865997, 0.1952076554298401, 0.12320154160261154, 0.1952076554298401, 0.3907023072242737], [0.2148071825504303, 0.22086694836616516, 0.22086694836616516, 0.03185523673892021, 0.31160369515419006], [0.05983860790729523, 0.0363038145005703, 0.7224074006080627, 0.002350115915760398, 0.17910003662109375], [0.938267707824707, 0.028595808893442154, 0.0071077896282076836, 0.0071077896282076836, 0.01892094872891903], [0.1262398511171341, 0.5018226504325867, 0.13495995104312897, 0.1262398511171341, 0.11073767393827438], [0.3429203927516937, 0.12851518392562866, 0.12851518392562866, 0.18737809360027313, 0.21267111599445343], [0.004879730753600597, 6.338729872368276e-05, 0.9877573251724243, 6.338729872368276e-05, 0.007236120291054249], [0.04759952425956726, 0.0004927325062453747, 0.7384769916534424, 0.10671540349721909, 0.10671540349721909], [0.0008470164611935616, 0.020705046132206917, 0.48912471532821655, 0.48912471532821655, 0.00019847869407385588], [0.4214708209037781, 0.021699482575058937, 0.020763205364346504, 0.2680332660675049, 0.2680332660675049], [0.8867737054824829, 0.00010500391363166273, 0.08277590572834015, 0.03024040162563324, 0.00010500391363166273], [0.43983200192451477, 0.01066782046109438, 0.00953870452940464, 0.10012935847043991, 0.43983200192451477], [0.09507010877132416, 0.5510118007659912, 0.037134524434804916, 0.1583918035030365, 0.1583918035030365], [0.015891145914793015, 0.12074200063943863, 0.3683324158191681, 0.3683324158191681, 0.12670202553272247], [0.7509639263153076, 0.0860329195857048, 0.07680122554302216, 0.0860329195857048, 0.00016891547420527786], [0.0005271098343655467, 0.0026769940741360188, 0.9916477203369141, 0.0026769940741360188, 0.002471186686307192], [0.00012741640966851264, 3.155696322210133e-05, 0.9995747208595276, 3.155696322210133e-05, 0.00023470267478842288], [0.8823410868644714, 0.016540052369236946, 0.044989168643951416, 0.011140547692775726, 0.044989168643951416], [0.0007589664892293513, 0.42879998683929443, 0.09820973128080368, 0.04343128204345703, 0.42879998683929443], [0.7436560988426208, 0.10349953174591064, 0.1139516830444336, 0.019446328282356262, 0.019446328282356262], [0.00033197717857547104, 0.3121728003025055, 0.3121728003025055, 0.3353990912437439, 0.039923295378685], [0.7703701257705688, 0.009600420482456684, 0.2137250155210495, 0.0031522142235189676, 0.0031522142235189676], [0.126352459192276, 0.4802810549736023, 0.1955777108669281, 0.1955777108669281, 0.0022111337166279554], [0.12907420098781586, 0.3941386640071869, 0.27163732051849365, 0.12907420098781586, 0.07607567310333252], [0.020387792959809303, 0.12213459610939026, 0.3335875868797302, 0.3335875868797302, 0.19030241668224335], [0.09180713444948196, 0.09180713444948196, 0.002854934660717845, 0.7278552055358887, 0.08567558974027634], [0.0880018100142479, 0.09835302829742432, 0.023158373311161995, 0.0880018100142479, 0.7024850249290466], [0.07033724337816238, 0.0022643713746219873, 0.042461223900318146, 0.814599871635437, 0.07033724337816238], [0.04208163172006607, 0.8279590606689453, 0.07607502490282059, 0.011802551336586475, 0.04208163172006607], [0.26567813754081726, 0.26567813754081726, 0.16868682205677032, 0.13104796409606934, 0.1689089685678482], [0.48712244629859924, 0.004788965918123722, 0.01655673421919346, 0.00440931273624301, 0.48712244629859924], [0.35200557112693787, 0.3089962303638458, 0.3089962303638458, 0.020181098952889442, 0.009820854291319847], [0.00895805936306715, 0.0034963448997586966, 0.1779610961675644, 0.004646741319447756, 0.8049377202987671], [0.7840617895126343, 0.008464616723358631, 0.05132567510008812, 0.008464616723358631, 0.1476833075284958], [0.026516392827033997, 0.017013028264045715, 0.017013028264045715, 0.29889100790023804, 0.6405665278434753], [0.014588537625968456, 0.014588537625968456, 0.7524458169937134, 0.0028034280985593796, 0.21557365357875824], [0.14987708628177643, 3.5383327485760674e-05, 0.26350533962249756, 0.4367050528526306, 0.14987708628177643], [0.3358956575393677, 0.06713077425956726, 0.06713077425956726, 0.5293079018592834, 0.0005348690319806337], [0.29707008600234985, 0.29707008600234985, 0.07210082560777664, 0.33144980669021606, 0.002309168456122279], [0.02613208070397377, 0.000106632593087852, 0.973460853099823, 0.00019376736599951982, 0.000106632593087852], [0.5194959044456482, 0.08346178382635117, 0.0001520180667284876, 0.31342843174934387, 0.08346178382635117], [0.12437096238136292, 0.03962919861078262, 0.0010543661192059517, 0.4174726903438568, 0.4174726903438568], [0.358345627784729, 0.0010015742154791951, 0.0010015742154791951, 0.5842579007148743, 0.055393368005752563], [0.13014821708202362, 0.38104507327079773, 0.11832484602928162, 0.13014821708202362, 0.24033361673355103], [0.12349262833595276, 0.4896949827671051, 0.1478702574968338, 0.09107190370559692, 0.1478702574968338], [0.07969875633716583, 0.03673791512846947, 0.22694212198257446, 0.07969875633716583, 0.5769225358963013], [0.02357427403330803, 0.30641302466392517, 0.008120742626488209, 0.03578762710094452, 0.6261044144630432], [0.050566334277391434, 0.09482363611459732, 0.050566334277391434, 0.7907178401947021, 0.013325846754014492], [0.04539846256375313, 0.04960756376385689, 0.01378487329930067, 0.04960756376385689, 0.841601550579071], [0.00047780631575733423, 0.4175935685634613, 0.4175935685634613, 0.040346723049879074, 0.12398824840784073], [0.023058870807290077, 0.023058870807290077, 0.3700319230556488, 0.5550737977027893, 0.02877655439078808], [0.021707598119974136, 0.021707598119974136, 0.8836756944656372, 0.00042843588744290173, 0.0724807009100914], [0.4907980263233185, 0.004492670763283968, 0.009368021972477436, 0.4907980263233185, 0.004543210379779339], [0.03642357140779495, 0.03642357140779495, 0.20243872702121735, 0.3765856623649597, 0.34812843799591064], [0.011009757407009602, 0.454524964094162, 0.005384224001318216, 0.07455608248710632, 0.454524964094162], [0.0034188679419457912, 0.019773563370108604, 0.4819811284542084, 0.4819811284542084, 0.012845201417803764], [0.021292421966791153, 0.7498089075088501, 0.2074510008096695, 0.021292421966791153, 0.0001552551257191226], [0.3000161349773407, 0.38660159707069397, 0.0036522781010717154, 0.009713878855109215, 0.3000161349773407], [0.09846038371324539, 0.03229488804936409, 0.004337630234658718, 0.03229488804936409, 0.8326122164726257], [0.05645563080906868, 0.01869415119290352, 0.023977523669600487, 0.8768951892852783, 0.023977523669600487], [0.736292839050293, 0.03328169137239456, 0.1757661998271942, 0.03328169137239456, 0.021377550438046455], [0.1809581071138382, 0.000890274066478014, 0.5063139200210571, 0.13087958097457886, 0.1809581071138382], [0.2725536525249481, 0.3059920370578766, 0.2890948951244354, 0.04508423060178757, 0.0872751995921135], [0.03576640039682388, 0.1586102396249771, 0.1586102396249771, 0.24260863661766052, 0.40440452098846436], [0.1423293948173523, 0.05078265443444252, 0.46541425585746765, 0.19914425909519196, 0.1423293948173523], [0.06241411715745926, 0.27280718088150024, 0.4860479235649109, 0.06241411715745926, 0.11631670594215393], [0.21508996188640594, 0.004966961685568094, 0.47776922583580017, 0.21508996188640594, 0.08708388358354568], [0.2580932676792145, 0.21163922548294067, 0.21163922548294067, 0.006576246116310358, 0.31205201148986816], [0.03771448880434036, 0.03635404631495476, 0.8623768091201782, 0.03635404631495476, 0.027200721204280853], [0.47661110758781433, 0.25943678617477417, 0.25943678617477417, 0.0001108686628867872, 0.0044044130481779575], [5.685475480277091e-05, 0.06879070401191711, 5.685475480277091e-05, 0.1950666308403015, 0.7360290288925171], [0.15481729805469513, 0.21763543784618378, 0.22808150947093964, 0.22808150947093964, 0.1713842898607254], [0.0943487286567688, 0.29397502541542053, 0.29397502541542053, 0.08244460076093674, 0.2352566123008728], [0.01203247532248497, 0.8679686784744263, 0.11978215724229813, 0.00010833322448888794, 0.00010833322448888794], [0.3366115391254425, 0.17558565735816956, 0.052449360489845276, 0.3366115391254425, 0.09874188899993896], [0.0005372526356950402, 0.1999395787715912, 0.3966522216796875, 0.006218729540705681, 0.3966522216796875], [0.2907530963420868, 0.34433630108833313, 0.34433630108833313, 0.012144760228693485, 0.00842948630452156], [0.4771048426628113, 0.00369701674208045, 0.0044032311998307705, 0.4771048426628113, 0.03769003227353096], [0.17393772304058075, 0.17393772304058075, 0.06593231111764908, 0.2763161063194275, 0.30987608432769775], [0.5911635160446167, 0.008510757237672806, 0.008510757237672806, 0.3153490722179413, 0.07646587491035461], [0.40788912773132324, 0.24380367994308472, 0.03878375515341759, 0.03878375515341759, 0.27073970437049866], [0.346075177192688, 0.0021936967968940735, 0.06835462152957916, 0.0021936967968940735, 0.5811828374862671], [0.006591748911887407, 0.2770780622959137, 0.3316204249858856, 0.2770780622959137, 0.10763172060251236], [0.14744095504283905, 0.017000196501612663, 0.02158573642373085, 0.018753154203295708, 0.795219898223877], [0.003773696254938841, 0.0032375850714743137, 0.49555274844169617, 0.0018832311034202576, 0.49555274844169617], [0.30783912539482117, 0.09880118817090988, 0.0774233415722847, 0.2579681873321533, 0.2579681873321533], [0.26562392711639404, 0.26626691222190857, 0.26626691222190857, 0.045045990496873856, 0.15679623186588287], [0.4414454698562622, 0.0046615502797067165, 0.08361092209815979, 0.4414454698562622, 0.028836533427238464], [0.005412964150309563, 0.4710577726364136, 0.005412964150309563, 0.5176118016242981, 0.0005045309662818909], [0.00012808613246306777, 0.03174856677651405, 0.008433240465819836, 0.4798450469970703, 0.4798450469970703], [0.03869185596704483, 0.14499659836292267, 0.16934731602668762, 0.3406846821308136, 0.30627956986427307], [0.047728847712278366, 0.013756603002548218, 0.047728847712278366, 0.07682914286851883, 0.8139564990997314], [0.33571940660476685, 0.1252528429031372, 0.4403497874736786, 0.049339015036821365, 0.049339015036821365], [0.012247559614479542, 0.10022474080324173, 0.7182810306549072, 0.012247559614479542, 0.1569991111755371], [0.08836765587329865, 0.03397808596491814, 0.0019340220605954528, 0.8417421579360962, 0.03397808596491814], [0.26110973954200745, 0.019637471064925194, 0.3569152057170868, 0.3569152057170868, 0.005422384478151798], [0.965842068195343, 0.0008542869472876191, 0.029569579288363457, 0.0008542869472876191, 0.002879783743992448], [0.00723826652392745, 0.20030085742473602, 0.5480625629425049, 0.20030085742473602, 0.04409746825695038], [0.18686550855636597, 0.12514860928058624, 0.45459580421447754, 0.046524617820978165, 0.18686550855636597], [0.00214540702290833, 0.040672000497579575, 0.040672000497579575, 0.2580459415912628, 0.6584646701812744], [0.03518630564212799, 0.03518630564212799, 0.369110107421875, 0.08691970258951187, 0.47359761595726013], [0.002982158213853836, 0.010734915733337402, 0.06439633667469025, 0.8905364871025085, 0.03135015070438385], [0.010176386684179306, 0.864342212677002, 0.1068144366145134, 0.009333483874797821, 0.009333483874797821], [0.45124030113220215, 0.002975676441565156, 0.0005962105933576822, 0.2725938856601715, 0.2725938856601715], [0.2982599139213562, 0.2807241380214691, 0.2982599139213562, 0.012250245548784733, 0.11050578206777573], [0.013729339465498924, 0.8590352535247803, 0.08852414786815643, 0.013729339465498924, 0.024981964379549026], [0.10745052248239517, 0.10745052248239517, 0.7612841129302979, 0.018937502056360245, 0.004877329338341951], [0.4038658142089844, 0.05490824580192566, 0.11157052963972092, 0.025789525359869003, 0.4038658142089844], [0.3471289873123169, 0.1245495080947876, 0.12325482815504074, 0.3471289873123169, 0.05793760344386101], [0.09922576695680618, 0.09277376532554626, 0.09922576695680618, 0.032260727137327194, 0.6765138506889343], [0.4788690507411957, 0.38949820399284363, 0.02214927412569523, 0.02214927412569523, 0.08733412623405457], [0.971096932888031, 0.004716871306300163, 0.0010169129818677902, 0.004716871306300163, 0.01845247484743595], [0.1339784413576126, 0.07705976068973541, 0.07794524729251862, 0.5770381093025208, 0.1339784413576126], [0.41823115944862366, 0.2858467400074005, 0.006337805185467005, 0.2858467400074005, 0.0037375937681645155], [0.29996076226234436, 0.01762373372912407, 0.6553308963775635, 0.009460829198360443, 0.01762373372912407], [0.22729572653770447, 0.0016407938674092293, 0.7693213820457458, 0.0016407938674092293, 0.00010126289998879656], [0.09656597673892975, 0.06787716597318649, 0.08322102576494217, 0.3761679232120514, 0.3761679232120514], [0.08732178062200546, 0.07366970926523209, 0.08732178062200546, 0.657634973526001, 0.0940517783164978], [0.011977199465036392, 0.06468547880649567, 0.011977199465036392, 0.6609733700752258, 0.2503867745399475], [0.11292273551225662, 0.5677459836006165, 0.04337608069181442, 0.13797760009765625, 0.13797760009765625], [0.04544353857636452, 0.35935771465301514, 0.21626506745815277, 0.0195759329944849, 0.35935771465301514], [0.24423637986183167, 0.3631054162979126, 0.24423637986183167, 0.02472841367125511, 0.12369339168071747], [0.0062339468859136105, 0.003325049299746752, 0.003325049299746752, 0.16221484541893005, 0.8249011635780334], [0.03297498822212219, 0.002558227628469467, 0.002558227628469467, 0.7319212555885315, 0.22998730838298798], [0.06129864603281021, 0.4236707389354706, 0.07722947746515274, 0.4236707389354706, 0.014130325987935066], [0.12258701771497726, 0.12258701771497726, 0.5680173635482788, 0.009507184848189354, 0.17730142176151276], [0.011035366915166378, 0.9251429438591003, 0.008619699627161026, 0.011035366915166378, 0.04416652396321297], [0.0128173204138875, 0.018112389370799065, 0.6533519625663757, 0.018112389370799065, 0.297605961561203], [0.11127755045890808, 0.14276231825351715, 0.11127755045890808, 0.4333009719848633, 0.20138157904148102], [0.22020798921585083, 0.062226343899965286, 0.5152962803840637, 0.14004305005073547, 0.062226343899965286], [0.027635151520371437, 0.20353201031684875, 0.0572073794901371, 0.20353201031684875, 0.5080934166908264], [0.07401995360851288, 0.07401995360851288, 0.0031291688792407513, 0.6232385039329529, 0.22559243440628052], [0.21094857156276703, 0.0006901207962073386, 0.34748899936676025, 0.22992374002933502, 0.21094857156276703], [0.0630878359079361, 0.0630878359079361, 0.08079986274242401, 0.7588906288146973, 0.034133780747652054], [0.31768056750297546, 0.001426700851880014, 0.31768056750297546, 0.13951173424720764, 0.22370044887065887], [0.07384922355413437, 0.003309375373646617, 0.4252385199069977, 0.07236431539058685, 0.4252385199069977], [0.014101649634540081, 0.5666287541389465, 0.014101649634540081, 0.3650791049003601, 0.04008882865309715], [0.12032382935285568, 0.6366814970970154, 0.24119873344898224, 0.0012969246599823236, 0.0004989610170014203], [0.05653039366006851, 0.48030272126197815, 0.4631150960922241, 2.5879589884425513e-05, 2.5879589884425513e-05], [0.0034920312464237213, 0.06759228557348251, 0.05049126222729683, 0.8749324083328247, 0.0034920312464237213], [0.004677539225667715, 0.3209567964076996, 0.3209567964076996, 0.024306509643793106, 0.32910236716270447], [0.34463801980018616, 0.07309354096651077, 0.06815066933631897, 0.34463801980018616, 0.16947978734970093], [0.024460047483444214, 0.004065506160259247, 0.004065506160259247, 0.9110246300697327, 0.05638427287340164], [0.40581828355789185, 3.205648681614548e-05, 0.40581828355789185, 0.031844399869441986, 0.15648695826530457], [0.46696266531944275, 0.09538838267326355, 0.09538838267326355, 0.0004977845819666982, 0.34176281094551086], [0.26558879017829895, 0.33565929532051086, 0.19612200558185577, 0.0065079182386398315, 0.19612200558185577], [0.0002373711031395942, 0.27774250507354736, 0.0054824878461658955, 0.3582688271999359, 0.3582688271999359], [0.24834273755550385, 0.013373862951993942, 0.013373862951993942, 0.7035430073738098, 0.02136652171611786], [0.17471309006214142, 0.2908000946044922, 0.0184163898229599, 0.0184163898229599, 0.49765411019325256], [0.48516276478767395, 0.020069211721420288, 0.001023856340907514, 0.008581445552408695, 0.48516276478767395], [0.16793759167194366, 0.005806025117635727, 0.003836955176666379, 0.003836955176666379, 0.8185824751853943], [0.21886205673217773, 0.2241184413433075, 0.2241184413433075, 0.09653538465499878, 0.23636561632156372], [0.2937755882740021, 0.025618810206651688, 0.11559166014194489, 0.2712383270263672, 0.2937755882740021], [0.5445269346237183, 1.85549561138032e-05, 0.1735970824956894, 0.1409287303686142, 0.1409287303686142], [0.003737107617780566, 0.008853890933096409, 0.4934542179107666, 0.0005006081773899496, 0.4934542179107666], [0.03514758497476578, 0.000982167897745967, 0.924593985080719, 0.03514758497476578, 0.00412872526794672], [0.8138386011123657, 0.12722456455230713, 0.006620206404477358, 0.04569628834724426, 0.006620206404477358], [0.0012254422763362527, 0.6582352519035339, 0.12772564589977264, 0.12772564589977264, 0.08508802205324173], [0.023808516561985016, 0.014627601951360703, 0.044460996985435486, 0.9024752974510193, 0.014627601951360703], [0.7043724060058594, 0.09200562536716461, 0.08251184970140457, 0.02910451963543892, 0.09200562536716461], [0.06021737679839134, 0.059300363063812256, 0.4126231074333191, 0.05523601919412613, 0.4126231074333191], [0.09278949350118637, 0.09278949350118637, 0.8013300895690918, 0.01149003952741623, 0.0016008415259420872], [0.04850497469305992, 0.1391839236021042, 0.4016146659851074, 0.009081846103072166, 0.4016146659851074], [0.3659915030002594, 0.3659915030002594, 0.10226647555828094, 0.16464777290821075, 0.0011027585715055466], [0.6889699697494507, 0.04876618832349777, 0.04876618832349777, 0.16108472645282745, 0.05241299048066139], [0.357113242149353, 0.007578801829367876, 0.357113242149353, 0.11812061071395874, 0.16007404029369354], [0.28634798526763916, 0.19972121715545654, 0.28634798526763916, 0.09721571207046509, 0.13036707043647766], [0.10641437023878098, 0.12644222378730774, 0.5046484470367432, 0.15608058869838715, 0.10641437023878098], [0.09843156486749649, 0.007917074486613274, 0.8695189356803894, 0.016215398907661438, 0.007917074486613274], [0.4894828200340271, 0.1470237374305725, 0.19019562005996704, 0.1470237374305725, 0.026274053379893303], [0.193429097533226, 0.043726179748773575, 0.002025355352088809, 0.193429097533226, 0.5673902034759521], [0.10000776499509811, 0.01670028828084469, 0.4194257855415344, 0.23193307220935822, 0.23193307220935822], [0.38669610023498535, 0.0447932593524456, 0.17152948677539825, 0.010284985415637493, 0.38669610023498535], [0.02129124104976654, 0.5164791941642761, 0.008246657438576221, 0.008246657438576221, 0.44573619961738586], [0.2416747659444809, 0.2416747659444809, 0.408132404088974, 0.09976929426193237, 0.008748790249228477], [0.4046613276004791, 0.1303059309720993, 0.02477049082517624, 0.035600874572992325, 0.4046613276004791], [0.00019470896222628653, 2.501763083273545e-05, 0.49383458495140076, 0.49383458495140076, 0.012111189775168896], [0.32449623942375183, 0.006717962212860584, 0.006717962212860584, 0.037410665303468704, 0.6246572732925415], [0.22133126854896545, 0.5805764198303223, 0.10326797515153885, 0.04741214960813522, 0.04741214960813522], [0.0004790955863427371, 0.9554131627082825, 0.007466522511094809, 0.007466522511094809, 0.029174700379371643], [0.07331790775060654, 0.42517998814582825, 0.0036253363359719515, 0.49425140023231506, 0.0036253363359719515], [0.4621376395225525, 0.001969999400898814, 0.4621376395225525, 0.026675516739487648, 0.047079216688871384], [0.083830326795578, 0.08258980512619019, 0.3604426085948944, 0.3905474841594696, 0.08258980512619019], [0.38590148091316223, 0.04289217293262482, 0.006577872205525637, 0.5580505728721619, 0.006577872205525637], [0.2570936977863312, 0.06383299082517624, 0.00782448798418045, 0.33562442660331726, 0.33562442660331726], [0.22318744659423828, 0.016378169879317284, 0.03677268698811531, 0.36183083057403564, 0.36183083057403564], [0.25519421696662903, 0.13058793544769287, 0.43424078822135925, 0.049389101564884186, 0.13058793544769287], [0.24469225108623505, 0.01891533099114895, 0.4054805040359497, 0.16545596718788147, 0.16545596718788147], [0.05511580780148506, 0.5227198004722595, 0.05511580780148506, 0.365505576133728, 0.0015429669292643666], [0.12636516988277435, 0.038187313824892044, 0.7021255493164062, 0.00695680920034647, 0.12636516988277435], [0.35539406538009644, 0.031896673142910004, 0.35539406538009644, 0.24796529114246368, 0.009349871426820755], [0.3401854932308197, 0.3401854932308197, 0.02780241146683693, 0.023318400606513023, 0.2685081660747528], [0.0053789084777235985, 0.08185530453920364, 0.90174400806427, 0.0053789084777235985, 0.00564285134896636], [0.18511056900024414, 0.18511056900024414, 0.018553612753748894, 0.6049918532371521, 0.006233385764062405], [0.05474749952554703, 0.01735793985426426, 0.04042080044746399, 0.01735793985426426, 0.8701158165931702], [0.003652904648333788, 0.1742405891418457, 0.8090214729309082, 0.003652904648333788, 0.009432070888578892], [0.3893181085586548, 0.004647361114621162, 0.2609085440635681, 0.17256295680999756, 0.17256295680999756], [0.031713686883449554, 0.516914963722229, 0.031713686883449554, 0.21412499248981476, 0.20553264021873474], [0.010021037422120571, 0.5758990049362183, 0.3928390145301819, 0.011219956912100315, 0.010021037422120571], [0.1323593258857727, 0.3404372036457062, 0.1221490427851677, 0.05321633443236351, 0.3518381416797638], [0.6164795160293579, 0.32890093326568604, 0.02710500918328762, 0.02710500918328762, 0.0004095603071618825], [0.08197053521871567, 0.13522733747959137, 0.0004997235373593867, 0.08197053521871567, 0.7003318071365356], [0.2754904329776764, 0.06740116328001022, 0.0020769049879163504, 0.2754904329776764, 0.3795410990715027], [0.6259503960609436, 0.30564403533935547, 0.020952258259058, 0.020952258259058, 0.026501119136810303], [0.5174764394760132, 0.1728033423423767, 0.1728033423423767, 0.10558007657527924, 0.03133683651685715], [0.30453917384147644, 0.03663147613406181, 0.0018096466083079576, 0.35248059034347534, 0.30453917384147644], [0.7256582379341125, 0.08133367449045181, 0.0962805449962616, 0.013108175247907639, 0.08361934125423431], [0.0020396998152136803, 0.013906016014516354, 0.0004450450942385942, 0.9697031378746033, 0.013906016014516354], [0.378677099943161, 0.018543487414717674, 0.018543487414717674, 0.30385762453079224, 0.2803782522678375], [0.17543473839759827, 0.048167090862989426, 0.26707127690315247, 0.24225562810897827, 0.26707127690315247], [0.2720074951648712, 0.07571588456630707, 0.34744200110435486, 0.03282707929611206, 0.2720074951648712], [0.0020083836279809475, 0.4588977098464966, 0.4588977098464966, 0.0080344770103693, 0.07216174900531769], [1.0360545275034383e-05, 0.28627124428749084, 0.3468222916126251, 0.0200737863779068, 0.3468222916126251], [0.03137795254588127, 0.004742533899843693, 0.42088228464126587, 0.12211496382951736, 0.42088228464126587], [0.021586552262306213, 0.021586552262306213, 0.8995289206504822, 0.043107859790325165, 0.014190130867064], [0.009503275156021118, 0.7495263814926147, 0.11703955382108688, 0.11703955382108688, 0.0068912445567548275], [0.35047009587287903, 0.35047009587287903, 0.0061504775658249855, 0.006796863861382008, 0.2861124277114868], [0.6207685470581055, 0.05688568949699402, 0.32209348678588867, 0.0001261737197637558, 0.0001261737197637558], [0.04270181432366371, 0.0005302010104060173, 0.08921636641025543, 0.8248498439788818, 0.04270181432366371], [0.003696163883432746, 0.20824770629405975, 0.13040399551391602, 0.32882606983184814, 0.32882606983184814], [0.02483213320374489, 0.05836706981062889, 0.020642809569835663, 0.8377909660339355, 0.05836706981062889], [0.5829222798347473, 0.01838347502052784, 0.08141231536865234, 0.15864098072052002, 0.15864098072052002], [0.14952188730239868, 0.0053570508025586605, 0.5433234572410583, 0.2722663879394531, 0.029531238600611687], [0.47705113887786865, 0.008454090915620327, 0.01164398342370987, 0.01164398342370987, 0.4912068247795105], [0.008276447653770447, 0.017261188477277756, 0.008276447653770447, 0.897304892539978, 0.068881094455719], [0.0016972318990156054, 0.08591903001070023, 0.018011216074228287, 0.018011216074228287, 0.8763613700866699], [0.1236041784286499, 0.6500478982925415, 0.02358914725482464, 0.0791545882821083, 0.1236041784286499], [0.0034278726670891047, 0.21503916382789612, 0.41616496443748474, 0.15032880008220673, 0.21503916382789612], [0.006046310532838106, 0.03490574657917023, 0.014420838095247746, 0.4723135530948639, 0.4723135530948639], [0.06405229866504669, 0.1291930377483368, 0.7871741056442261, 0.009790291078388691, 0.009790291078388691], [0.45957863330841064, 0.2631932199001312, 0.2631932199001312, 0.0005286940722726285, 0.013506168499588966], [0.00015732471365481615, 0.22615225613117218, 0.00015732471365481615, 0.7554457783699036, 0.018087349832057953], [0.10874815285205841, 0.515939474105835, 0.00444368040189147, 0.23478963971138, 0.13607905805110931], [0.016979580745100975, 0.147919699549675, 0.10748955607414246, 0.3638055920600891, 0.3638055920600891], [0.10518345236778259, 0.0025152983143925667, 0.27909037470817566, 0.30660539865493774, 0.30660539865493774], [0.0002434808120597154, 0.12266850471496582, 0.3762089014053345, 0.12467032670974731, 0.3762089014053345], [0.026007764041423798, 0.8828412294387817, 0.04134875908493996, 0.008453568443655968, 0.04134875908493996], [0.23389166593551636, 0.35160914063453674, 0.05717828869819641, 0.35160914063453674, 0.005711796227842569], [0.7632437348365784, 0.07308617234230042, 0.003249671310186386, 0.003249671310186386, 0.15717080235481262], [0.2546508312225342, 0.025086812674999237, 0.26731082797050476, 0.19830070436000824, 0.2546508312225342], [0.003417862579226494, 0.02072177082300186, 0.02072177082300186, 0.08196131139993668, 0.8731772899627686], [0.020958099514245987, 0.13261644542217255, 0.029903564602136612, 0.2747114896774292, 0.5418103337287903], [0.3425275385379791, 0.137391597032547, 0.23545771837234497, 0.04916544258594513, 0.23545771837234497], [0.3006555140018463, 0.47077158093452454, 0.09847842901945114, 0.09847842901945114, 0.03161604702472687], [0.025723310187458992, 0.8845829367637634, 0.08840633928775787, 0.000643688952550292, 0.000643688952550292], [0.21567402780056, 0.21567402780056, 0.0007158943335525692, 0.33220741152763367, 0.2357286512851715], [0.645010232925415, 0.001895492896437645, 0.349483460187912, 0.0018054097890853882, 0.0018054097890853882], [0.4881012737751007, 0.002770583378151059, 0.46102944016456604, 0.04532807692885399, 0.002770583378151059], [0.06676502525806427, 0.22967112064361572, 0.6356132626533508, 0.06676502525806427, 0.0011855479096993804], [0.8147115111351013, 0.029117025434970856, 0.029117025434970856, 0.0071851215325295925, 0.11986934393644333], [0.4804134666919708, 0.0014208457432687283, 0.03533447906374931, 0.002417739015072584, 0.4804134666919708], [0.014959410764276981, 0.014049253426492214, 0.08700121939182281, 0.796988844871521, 0.08700121939182281], [0.18335869908332825, 0.008932561613619328, 0.538369357585907, 0.08598071336746216, 0.18335869908332825], [0.04140280932188034, 0.1252042055130005, 0.8214711546897888, 0.005960903596132994, 0.005960903596132994], [0.0034454658161848783, 0.2609426975250244, 0.19850686192512512, 0.5338391661643982, 0.0032658211421221495], [0.7049229145050049, 0.04703449457883835, 0.002048658672720194, 0.24394531548023224, 0.002048658672720194], [0.9237063527107239, 0.00484579848125577, 0.033103447407484055, 0.03349851444363594, 0.00484579848125577], [0.12009236216545105, 0.24728243052959442, 0.24728243052959442, 0.3695211708545685, 0.015821630135178566], [0.33343836665153503, 0.23091867566108704, 0.33343836665153503, 0.05089552700519562, 0.0513090156018734], [0.3321910798549652, 0.3160642981529236, 0.018021080642938614, 0.3160642981529236, 0.017659254372119904], [0.00014415205805562437, 0.46266230940818787, 0.03719284012913704, 0.03733835741877556, 0.46266230940818787], [0.015143021009862423, 0.024679427966475487, 0.018041085451841354, 0.024679427966475487, 0.9174569249153137], [0.0003494302509352565, 0.011310129426419735, 0.9864879250526428, 0.0009262561798095703, 0.0009262561798095703], [0.04288372024893761, 0.0051546841859817505, 0.22133739292621613, 0.11171424388885498, 0.6189099550247192], [0.6498177647590637, 0.09794022142887115, 0.06317628920078278, 0.09794022142887115, 0.09112556278705597], [0.7868968844413757, 0.01825231872498989, 0.0017530693439766765, 0.17394763231277466, 0.01915012300014496], [0.43637973070144653, 0.04353189840912819, 0.049581702798604965, 0.03412694111466408, 0.43637973070144653], [0.3240344226360321, 0.26042869687080383, 0.019410597160458565, 0.26042869687080383, 0.1356976181268692], [0.07181829959154129, 0.4238135516643524, 0.01477800402790308, 0.06577660143375397, 0.4238135516643524], [0.008019332773983479, 0.10821868479251862, 0.24938298761844635, 0.6263596415519714, 0.008019332773983479], [0.2362750619649887, 0.049956806004047394, 0.11306941509246826, 0.11306941509246826, 0.4876292645931244], [0.01622425578534603, 0.1709502786397934, 0.7876766324043274, 0.01622425578534603, 0.008924511261284351], [0.022127043455839157, 0.002752678468823433, 0.4854384660720825, 0.4854384660720825, 0.00424331845715642], [0.010153925977647305, 0.05013265460729599, 0.9255144000053406, 0.010153925977647305, 0.00404508737847209], [0.2713431119918823, 0.1799619197845459, 0.004057393409311771, 0.27329447865486145, 0.2713431119918823], [0.8694717884063721, 0.050552915781736374, 0.002517925575375557, 0.03872867301106453, 0.03872867301106453], [0.05007417872548103, 0.48867762088775635, 0.39841774106025696, 0.01275625079870224, 0.05007417872548103], [0.4247116446495056, 0.18447235226631165, 0.1447509229183197, 0.10131414979696274, 0.1447509229183197], [0.9778093695640564, 0.009534355252981186, 0.004008083138614893, 0.004640226252377033, 0.004008083138614893], [0.42232927680015564, 0.007756081409752369, 0.42232927680015564, 0.12837831676006317, 0.019207026809453964], [0.019509920850396156, 0.16928428411483765, 0.16928428411483765, 0.19329236447811127, 0.4486291706562042], [0.7432741522789001, 0.07936162501573563, 0.017113812267780304, 0.14769527316093445, 0.01255511399358511], [0.03932764381170273, 0.17484194040298462, 0.07270919531583786, 0.5382792949676514, 0.17484194040298462], [0.9093393087387085, 0.025908302515745163, 0.02772580273449421, 0.00930083729326725, 0.02772580273449421], [0.0014135331148281693, 0.49019643664360046, 0.005181008018553257, 0.013012677431106567, 0.49019643664360046], [0.11092483252286911, 0.08649720996618271, 0.10376211255788803, 0.34940794110298157, 0.34940794110298157], [0.003799138590693474, 0.0004933681339025497, 0.9086990356445312, 0.0020734085701406, 0.08493507653474808], [0.09025529772043228, 0.3179437816143036, 0.21099111437797546, 0.06286602467298508, 0.3179437816143036], [0.052273210138082504, 0.3354648947715759, 0.12067897617816925, 0.3354648947715759, 0.15611805021762848], [0.7516359686851501, 0.05533871054649353, 0.049101151525974274, 0.09482293576002121, 0.049101151525974274], [0.8932501077651978, 0.03802110627293587, 0.03802110627293587, 0.01592729054391384, 0.014780467376112938], [0.19575336575508118, 0.24478797614574432, 0.16737885773181915, 0.19575336575508118, 0.19632649421691895], [0.18695279955863953, 0.03325255215167999, 0.12809331715106964, 0.18695279955863953, 0.4647485017776489], [0.0018767241854220629, 0.40610650181770325, 0.08324885368347168, 0.40610650181770325, 0.10266145318746567], [0.35317832231521606, 0.03297372907400131, 0.44669783115386963, 0.1341763585805893, 0.03297372907400131], [0.0210756603628397, 0.3037092685699463, 0.2582603693008423, 0.20847736299037933, 0.20847736299037933], [0.2842748165130615, 0.25861823558807373, 0.00016449479153379798, 0.25861823558807373, 0.19832417368888855], [0.4610149562358856, 0.4718666672706604, 0.02549041248857975, 0.01613752357661724, 0.02549041248857975], [0.036663997918367386, 0.8787891864776611, 0.03387953341007233, 0.016787756234407425, 0.03387953341007233], [0.2488958090543747, 0.7063407897949219, 0.03802530840039253, 0.003369024256244302, 0.003369024256244302], [0.19028426706790924, 0.19028426706790924, 0.015431351028382778, 0.005675266496837139, 0.5983247756958008], [0.011893088929355145, 0.7411341071128845, 0.10878706723451614, 0.10878706723451614, 0.029398731887340546], [0.02668077126145363, 0.6898936033248901, 0.08357269316911697, 0.1731722205877304, 0.02668077126145363], [0.18542246520519257, 0.06584634631872177, 0.14355868101119995, 0.18542246520519257, 0.4197501242160797], [0.47058507800102234, 0.01800139620900154, 0.47058507800102234, 0.014298070222139359, 0.0265304334461689], [0.0007257933611981571, 0.237217515707016, 0.15228530764579773, 0.15228530764579773, 0.4574861526489258], [0.6273658871650696, 0.022162966430187225, 0.1130433902144432, 0.004923939239233732, 0.23250381648540497], [0.16280117630958557, 0.01957889460027218, 0.01957889460027218, 0.41367921233177185, 0.38436177372932434], [0.05036905035376549, 0.05036905035376549, 0.02935774065554142, 0.11023630946874619, 0.7596678137779236], [0.029462099075317383, 0.20723852515220642, 0.5374775528907776, 0.018583284690976143, 0.20723852515220642], [0.21518516540527344, 0.21518516540527344, 0.04789968580007553, 0.5003041625022888, 0.02142588049173355], [0.2209823578596115, 0.6055214405059814, 0.011460332199931145, 0.08101790398359299, 0.08101790398359299], [0.051399700343608856, 0.11056115478277206, 0.826938807964325, 0.010838075540959835, 0.0002623215550556779], [0.059441011399030685, 0.059441011399030685, 0.44560113549232483, 0.3119664192199707, 0.12355038523674011], [0.05260559171438217, 0.007132651284337044, 0.0050215162336826324, 0.05260559171438217, 0.8826346397399902], [0.2695734202861786, 0.0039131841622292995, 0.3584921061992645, 0.2695734202861786, 0.09844790399074554], [0.13034117221832275, 0.5282690525054932, 0.13034117221832275, 0.1935914009809494, 0.017457183450460434], [0.031463708728551865, 0.0023330210242420435, 0.11474713683128357, 0.031463708728551865, 0.8199924230575562], [0.2215912938117981, 0.2215912938117981, 0.016095543280243874, 0.26023566722869873, 0.280486136674881], [0.4401504099369049, 0.44932276010513306, 0.005196749232709408, 0.005196749232709408, 0.10013336688280106], [0.011912258341908455, 0.6403440833091736, 0.3039565980434418, 0.021893534809350967, 0.021893534809350967], [0.010708603076636791, 0.03739942982792854, 0.4153963625431061, 0.4153963625431061, 0.12109923362731934], [0.10256136208772659, 0.00812746025621891, 0.23706448078155518, 0.6441192030906677, 0.00812746025621891], [0.4371705949306488, 0.10039661824703217, 0.10039661824703217, 0.23072069883346558, 0.13131548464298248], [0.0002685037034098059, 0.49132609367370605, 0.016753755509853363, 0.0003255175251979381, 0.49132609367370605], [0.4080517292022705, 0.17599022388458252, 0.00013828810187987983, 0.3853960335254669, 0.030423840507864952], [0.8826702833175659, 0.009159373119473457, 0.09830473363399506, 0.009159373119473457, 0.0007062277873046696], [0.49039122462272644, 0.007961922325193882, 0.0029847759287804365, 0.00827081874012947, 0.49039122462272644], [0.34236836433410645, 0.12198366969823837, 0.09270799905061722, 0.12198366969823837, 0.3209563195705414], [0.10456441342830658, 0.10456441342830658, 0.015500001609325409, 0.04418165981769562, 0.731189489364624], [0.2988719642162323, 0.32153239846229553, 2.212320214312058e-05, 2.212320214312058e-05, 0.37955132126808167], [0.010350575670599937, 0.598147451877594, 0.007491810712963343, 0.3736596405506134, 0.010350575670599937], [0.0016972118755802512, 0.1901077777147293, 0.012859524227678776, 0.7824758887290955, 0.012859524227678776], [0.20163986086845398, 0.13064256310462952, 0.18361583352088928, 0.3534591794013977, 0.13064256310462952], [0.038011010736227036, 0.29028812050819397, 0.16383817791938782, 0.34402450919151306, 0.16383817791938782], [2.0486002540565096e-05, 0.0029189877677708864, 0.5424734354019165, 0.4545665979385376, 2.0486002540565096e-05], [0.14861297607421875, 0.14861297607421875, 0.41057130694389343, 0.08951816707849503, 0.20268456637859344], [0.13702936470508575, 0.2514979839324951, 2.2363426978699863e-05, 0.4744209051132202, 0.13702936470508575], [0.04045635461807251, 0.27224108576774597, 0.025384414941072464, 0.04045635461807251, 0.6214617490768433], [0.10651180893182755, 0.0778215155005455, 0.002030972158536315, 0.03186208754777908, 0.781773567199707], [0.5199519395828247, 0.0025258217938244343, 0.23755325376987457, 0.23755325376987457, 0.002415759488940239], [0.013189039193093777, 0.4910464882850647, 0.4910464882850647, 0.003372675273567438, 0.0013453010469675064], [0.15909871459007263, 0.2837204039096832, 0.15909871459007263, 0.3251512944698334, 0.07293090224266052], [0.21054889261722565, 0.426943838596344, 0.15109644830226898, 0.0008618943393230438, 0.21054889261722565], [0.054133057594299316, 0.8219298720359802, 0.054133057594299316, 0.007018454372882843, 0.0627855584025383], [0.3200675845146179, 0.24684730172157288, 0.09628476202487946, 0.09628476202487946, 0.24051553010940552], [0.05451097711920738, 0.003193087177351117, 0.0011141551658511162, 0.003193087177351117, 0.9379886388778687], [0.3890119194984436, 0.23411406576633453, 0.12823517620563507, 0.12040364742279053, 0.12823517620563507], [0.03464122489094734, 0.8700970411300659, 0.026759296655654907, 0.033861227333545685, 0.03464122489094734], [0.34017521142959595, 0.004342480096966028, 0.48922163248062134, 0.16191820800304413, 0.004342480096966028], [0.037688400596380234, 0.2961922287940979, 0.3272981345653534, 0.011523102410137653, 0.3272981345653534], [0.10699830949306488, 0.6030607223510742, 0.17600615322589874, 0.10699830949306488, 0.006936521735042334], [0.30215874314308167, 0.0992186963558197, 0.29929327964782715, 0.29929327964782715, 3.59453224518802e-05], [0.26221027970314026, 0.24468527734279633, 0.40298041701316833, 0.00017719363677315414, 0.08994689583778381], [0.00010123039101017639, 0.9910140633583069, 0.007980229333043098, 0.00045222329208627343, 0.00045222329208627343], [0.004289318807423115, 0.013071644119918346, 0.40747129917144775, 0.5421100854873657, 0.033057622611522675], [0.4812715947628021, 0.4812715947628021, 0.03145430237054825, 0.005925562232732773, 7.695936074014753e-05], [0.1301555037498474, 0.024893702939152718, 0.1301555037498474, 0.0019740627612918615, 0.7128211259841919], [0.19241413474082947, 0.39918580651283264, 0.4000314474105835, 0.004184280522167683, 0.004184280522167683], [0.04445157200098038, 0.08926398307085037, 0.07162071019411087, 0.7053998112678528, 0.08926398307085037], [0.1729658544063568, 0.004617789760231972, 0.401395320892334, 0.01962570659816265, 0.401395320892334], [0.2781994044780731, 0.08616907149553299, 0.19806380569934845, 0.1593683362007141, 0.2781994044780731], [0.1183965727686882, 0.8101039528846741, 0.01121679600328207, 0.01121679600328207, 0.04906584322452545], [0.4881240427494049, 0.001892139669507742, 0.018444230780005455, 0.003415510291233659, 0.4881240427494049], [0.3137502670288086, 0.27665987610816956, 0.017264099791646004, 0.07857547700405121, 0.3137502670288086], [0.019992675632238388, 0.051705192774534225, 0.019992675632238388, 0.8992677927017212, 0.009041646495461464], [0.7458285093307495, 0.005555502604693174, 0.023426227271556854, 0.005555502604693174, 0.2196342498064041], [0.15148872137069702, 0.014186769723892212, 0.4141975939273834, 0.005929260049015284, 0.4141975939273834], [0.0074919178150594234, 0.030989108607172966, 0.6493640542030334, 0.28116586804389954, 0.030989108607172966], [0.6791967153549194, 0.0468333438038826, 0.020371994003653526, 0.020371994003653526, 0.2332259714603424], [0.040042754262685776, 0.13508722186088562, 0.4495284855365753, 0.13508722186088562, 0.2402542531490326], [0.4791744351387024, 0.10202059149742126, 0.4149557948112488, 0.00018745672423392534, 0.0036617235746234655], [3.3522210287628695e-05, 0.9982110261917114, 3.3522210287628695e-05, 0.001056711538694799, 0.0006653042510151863], [0.15699554979801178, 0.14282195270061493, 0.41826918721199036, 0.14282195270061493, 0.1390913426876068], [0.37816837430000305, 0.000775251304730773, 0.23966015875339508, 0.0032278827857226133, 0.37816837430000305], [0.5941608548164368, 0.09395451843738556, 0.09395451843738556, 0.21689732372760773, 0.0010327413910999894], [0.031950417906045914, 0.04426819458603859, 0.3311423659324646, 0.29631948471069336, 0.29631948471069336], [0.23436342179775238, 0.3366789221763611, 0.23436342179775238, 0.18578451871871948, 0.008809699676930904], [0.008021324872970581, 0.0009960542665794492, 0.19558897614479065, 0.3976968228816986, 0.3976968228816986], [0.3224065601825714, 0.036496710032224655, 0.0008565863245166838, 0.3178335428237915, 0.3224065601825714], [0.021045919507741928, 0.16391880810260773, 0.16391880810260773, 0.5819147229194641, 0.0692017525434494], [0.0010028750402852893, 0.05396409332752228, 0.9008123874664307, 0.043217841535806656, 0.0010028750402852893], [0.10219558328390121, 0.014466485008597374, 0.4410804808139801, 0.0011769579723477364, 0.4410804808139801], [0.19665320217609406, 0.00559376273304224, 0.410775363445282, 0.00559376273304224, 0.3813839852809906], [0.12023135274648666, 0.12023135274648666, 0.18341286480426788, 0.5453900098800659, 0.030734404921531677], [0.09440878033638, 0.035688214004039764, 0.035688214004039764, 0.7599679231643677, 0.07424695789813995], [0.05544845759868622, 0.04576651006937027, 0.3654910624027252, 0.26664698123931885, 0.26664698123931885], [0.3919713795185089, 0.00212698127143085, 0.5667983889579773, 0.028432542458176613, 0.010670706629753113], [0.008372638374567032, 0.08119183778762817, 0.4507288336753845, 0.008977892808616161, 0.4507288336753845], [0.001146791153587401, 0.001146791153587401, 0.06383673846721649, 0.0021514170803129673, 0.9317182898521423], [0.10710050910711288, 0.10710050910711288, 0.2916783392429352, 0.4898640215396881, 0.004256576299667358], [0.2670019268989563, 0.16922983527183533, 0.5362710952758789, 0.008867344819009304, 0.01862977258861065], [0.1590116024017334, 0.07001696527004242, 0.22049391269683838, 0.47507455945014954, 0.0754028856754303], [0.0023756958544254303, 0.01643509231507778, 0.2412155717611313, 0.49875807762145996, 0.2412155717611313], [0.4890497624874115, 0.01260387897491455, 0.244700625538826, 0.00894517544656992, 0.244700625538826], [0.052343569695949554, 0.1772010624408722, 0.3102819621562958, 0.1498914510011673, 0.3102819621562958], [0.3728501498699188, 0.09938294440507889, 0.0504741445183754, 0.17695856094360352, 0.3003341555595398], [0.6693291068077087, 0.04590617120265961, 0.004543073941022158, 0.04590617120265961, 0.23431546986103058], [0.006644071079790592, 0.43675893545150757, 0.43675893545150757, 0.10991457104682922, 0.009923435747623444], [0.001356878667138517, 0.47750335931777954, 0.01573098823428154, 0.47750335931777954, 0.0279054194688797], [0.8700117468833923, 0.01225479505956173, 0.053324926644563675, 0.053324926644563675, 0.011083613149821758], [0.0651516243815422, 0.3487149775028229, 0.23494645953178406, 0.17559345066547394, 0.17559345066547394], [0.4802260994911194, 0.05566755682229996, 0.055696550756692886, 0.02949625439941883, 0.378913551568985], [0.5658836364746094, 0.01661142334342003, 0.23420333862304688, 0.01661142334342003, 0.16669021546840668], [0.02050449326634407, 0.7568628787994385, 0.08243373036384583, 0.05776512995362282, 0.08243373036384583], [0.014725355431437492, 0.6683377027511597, 0.018633225932717323, 0.28357839584350586, 0.014725355431437492], [0.03217057138681412, 0.14762695133686066, 0.14762695133686066, 0.5280651450157166, 0.1445104032754898], [0.40955519676208496, 0.07531044632196426, 0.07424099743366241, 0.07531044632196426, 0.3655828535556793], [0.11642435938119888, 0.07886597514152527, 0.12970012426376343, 0.07886597514152527, 0.5961436033248901], [0.7373270988464355, 0.0005201897583901882, 0.05025065317749977, 0.10595104843378067, 0.10595104843378067], [0.37133488059043884, 0.37133488059043884, 0.009160967543721199, 0.19320335984230042, 0.054965876042842865], [0.004589513875544071, 0.004589513875544071, 0.7369382977485657, 0.22325670719146729, 0.030625877901911736], [0.4340878129005432, 0.12083914130926132, 0.12083914130926132, 0.13091422617435455, 0.19331975281238556], [0.04030521214008331, 0.07752227783203125, 0.07752227783203125, 0.4492935836315155, 0.35535669326782227], [0.02143021859228611, 0.44026410579681396, 0.3736267387866974, 0.14324873685836792, 0.02143021859228611], [0.5661154985427856, 0.1287176012992859, 0.0025609293952584267, 0.1287176012992859, 0.17388837039470673], [0.2709556519985199, 0.12146979570388794, 0.06437642872333527, 0.5276247262954712, 0.015573377721011639], [0.06371503323316574, 0.00010554597247391939, 0.8722525238990784, 0.00021176105656195432, 0.06371503323316574], [0.27170464396476746, 0.0030084853060543537, 0.45351937413215637, 6.284019764279947e-05, 0.27170464396476746], [0.19121140241622925, 0.0011829048162326217, 0.04012099653482437, 0.04012099653482437, 0.727363646030426], [0.0026327797677367926, 0.0026327797677367926, 0.5169304609298706, 0.4723941683769226, 0.0054097846150398254], [0.14183348417282104, 0.6681309342384338, 0.14183348417282104, 0.02219258062541485, 0.02600954845547676], [0.33931753039360046, 0.18288812041282654, 0.446837455034256, 0.015297283418476582, 0.015659675002098083], [0.0009627378894947469, 0.32573172450065613, 0.010113942436873913, 0.3315958082675934, 0.3315958082675934], [0.06691506505012512, 0.737259566783905, 0.06691506505012512, 0.08688616752624512, 0.042024143040180206], [0.021596981212496758, 0.10615119338035583, 0.43591219186782837, 0.000427472114097327, 0.43591219186782837], [0.0015613925643265247, 0.00612878380343318, 0.5239490866661072, 0.00612878380343318, 0.46223199367523193], [0.293958842754364, 0.19925548136234283, 0.20666386187076569, 0.293958842754364, 0.006163045763969421], [0.39840179681777954, 0.006360355298966169, 0.19475780427455902, 0.0020781909115612507, 0.39840179681777954], [0.04698846489191055, 0.08659126609563828, 0.04698846489191055, 0.6308259963989258, 0.18860581517219543], [0.0035641700960695744, 0.0256874468177557, 0.20840147137641907, 0.5539454221725464, 0.20840147137641907], [0.00028630104498006403, 0.8976043462753296, 0.01663137972354889, 0.01663137972354889, 0.0688466802239418], [0.08027946949005127, 0.027177689597010612, 0.08027946949005127, 0.003281906945630908, 0.8089815378189087], [0.1884201467037201, 0.014941470697522163, 0.6619476675987244, 0.014941470697522163, 0.11974924057722092], [0.00422593904659152, 0.11417893320322037, 0.005850707646459341, 0.8715184926986694, 0.00422593904659152], [0.8949109315872192, 0.07694768160581589, 0.002414154354482889, 0.01870543882250786, 0.007021697703748941], [0.06113772466778755, 0.0003805450105573982, 0.228040874004364, 0.0003805450105573982, 0.7100604176521301], [0.11362741887569427, 0.05344318225979805, 0.655537486076355, 0.06376447528600693, 0.11362741887569427], [0.021450789645314217, 0.04929986968636513, 0.04929986968636513, 0.8728052377700806, 0.007144297007471323], [0.13535001873970032, 0.48224836587905884, 0.19889871776103973, 0.13535001873970032, 0.048152823001146317], [0.0029553056228905916, 0.004227026831358671, 0.03630070015788078, 0.47825849056243896, 0.47825849056243896], [0.0036738826893270016, 0.44733601808547974, 0.032026853412389755, 0.06962723284959793, 0.44733601808547974], [0.018765093758702278, 0.9245160818099976, 0.0008289635879918933, 0.05506078526377678, 0.0008289635879918933], [0.25212642550468445, 0.39882439374923706, 0.25212642550468445, 0.014422616921365261, 0.08250009268522263], [0.08514195680618286, 0.02109271101653576, 0.08514195680618286, 0.5647856593132019, 0.24383775889873505], [0.4388425946235657, 0.0520641952753067, 0.0016096550971269608, 0.4388425946235657, 0.06864093989133835], [0.3100396394729614, 0.0016591758467257023, 0.2175627201795578, 0.3100396394729614, 0.16069883108139038], [0.39795249700546265, 0.33915743231773376, 0.2613983452320099, 0.0007459037005901337, 0.0007459037005901337], [0.00795662123709917, 0.11885319650173187, 0.8521389961242676, 0.01052560843527317, 0.01052560843527317], [0.0008452374604530632, 0.004580368287861347, 0.005361631046980619, 0.9838511347770691, 0.005361631046980619], [0.03292755410075188, 0.8803712725639343, 0.040712177753448486, 0.040712177753448486, 0.005276761949062347], [0.3638138771057129, 0.2559981942176819, 0.11243762075901031, 0.11243762075901031, 0.15531274676322937], [0.10277733206748962, 0.03728089854121208, 0.15988832712173462, 0.3500267565250397, 0.3500267565250397], [0.3801925778388977, 0.2948726713657379, 0.017395522445440292, 0.012666567228734493, 0.2948726713657379], [0.018611008301377296, 0.6402530074119568, 0.20770108699798584, 0.06671741604804993, 0.06671741604804993], [0.4232330322265625, 0.010445049032568932, 0.08463774621486664, 0.08463774621486664, 0.39704641699790955], [0.19375254213809967, 0.19375254213809967, 0.11036570370197296, 0.0019127848790958524, 0.5002164244651794], [0.1770327389240265, 0.7963675856590271, 0.013245170935988426, 0.0001093906321329996, 0.013245170935988426], [0.05497214198112488, 0.4237276315689087, 0.4360404312610626, 0.030287591740489006, 0.05497214198112488], [0.03201131150126457, 0.005902545992285013, 0.42548316717147827, 0.42548316717147827, 0.11111987382173538], [0.06516598165035248, 0.8524027466773987, 0.0008005402632988989, 0.06516598165035248, 0.016464713960886], [0.009620260447263718, 0.0011352382134646177, 0.3715061545372009, 0.3715061545372009, 0.24623216688632965], [0.0036329745780676603, 0.08219797164201736, 0.7166627049446106, 0.08219797164201736, 0.11530833691358566], [0.6182553768157959, 0.024859394878149033, 0.0013652757043018937, 0.21355874836444855, 0.14196118712425232], [0.43463650345802307, 0.08708091080188751, 0.2390599250793457, 0.2390599250793457, 0.00016268700710497797], [0.06127859279513359, 0.011716384440660477, 0.8476797342300415, 0.06127859279513359, 0.018046723678708076], [0.3501521646976471, 0.3501521646976471, 0.21338830888271332, 0.08248894661664963, 0.0038184516597539186], [0.00254184496589005, 0.01093597337603569, 0.4725302755832672, 0.04146159067749977, 0.4725302755832672], [0.001017047674395144, 0.5049954056739807, 0.001017047674395144, 0.35327938199043274, 0.13969109952449799], [0.04609987512230873, 0.04609987512230873, 0.13208140432834625, 0.7695069313049316, 0.006211868487298489], [0.4764366149902344, 0.03749736770987511, 0.4764366149902344, 0.00023046383284963667, 0.009399013593792915], [0.04390467330813408, 0.10389289259910583, 0.4098961651325226, 0.03241005912423134, 0.4098961651325226], [0.23507267236709595, 0.1067652776837349, 0.03255210444331169, 0.5930578112602234, 0.03255210444331169], [0.11643843352794647, 0.2758517861366272, 0.2758517861366272, 0.3078813850879669, 0.023976581171154976], [0.21606571972370148, 0.01646321639418602, 0.26157039403915405, 0.2443302571773529, 0.26157039403915405], [0.0055209496058523655, 0.3124473989009857, 0.09735534340143204, 0.3124473989009857, 0.272228866815567], [0.46464213728904724, 0.014366460964083672, 0.005887922365218401, 0.46464213728904724, 0.05046132206916809], [0.3503970503807068, 0.07074177265167236, 0.12054286152124405, 0.3503970503807068, 0.10792127251625061], [0.039883118122816086, 0.058653831481933594, 0.058653831481933594, 0.8172211050987244, 0.025588100776076317], [0.0005454074707813561, 0.006200414150953293, 0.043602705001831055, 0.9060487747192383, 0.043602705001831055], [0.034122589975595474, 0.4483166038990021, 0.003863433375954628, 0.4483166038990021, 0.06538079679012299], [0.10220558196306229, 0.1183159202337265, 0.07330132275819778, 0.3530885875225067, 0.3530885875225067], [0.11870395392179489, 0.8217142820358276, 0.02099420502781868, 0.019293811172246933, 0.019293811172246933], [0.00027847097953781486, 0.2688060998916626, 0.3629211485385895, 0.0050731259398162365, 0.3629211485385895], [0.6283584833145142, 0.11684174835681915, 0.20649674534797668, 0.024151543155312538, 0.024151543155312538], [0.48990878462791443, 0.024494392797350883, 0.15010946989059448, 0.1792813539505005, 0.15620596706867218], [0.014810494147241116, 0.0033999828156083822, 0.46254098415374756, 0.46254098415374756, 0.05670762434601784], [0.04551088064908981, 0.0418769046664238, 0.47995173931121826, 0.4173855781555176, 0.015274879522621632], [0.0004727638734038919, 0.3736332058906555, 0.16484582424163818, 0.3736332058906555, 0.08741495013237], [0.005499526858329773, 0.19399410486221313, 0.005499526858329773, 0.025139547884464264, 0.7698672413825989], [0.9254206418991089, 2.346759538340848e-05, 2.346759538340848e-05, 4.292930680094287e-05, 0.07448938488960266], [0.17611266672611237, 0.07111817598342896, 0.1571785807609558, 0.43841201066970825, 0.1571785807609558], [0.118201844394207, 0.012114721350371838, 0.6643615365028381, 0.08712009340524673, 0.118201844394207], [0.13189804553985596, 0.07299681752920151, 0.13189804553985596, 0.29831892251968384, 0.3648882210254669], [0.06518238037824631, 0.8635345101356506, 0.020899318158626556, 0.02948448620736599, 0.020899318158626556], [0.407464861869812, 0.1799667328596115, 0.00022639318194705993, 0.407464861869812, 0.004877178464084864], [0.0355122871696949, 0.030607452616095543, 0.15089014172554016, 0.15089014172554016, 0.6320999264717102], [0.0345066636800766, 0.05865979194641113, 0.8385428786277771, 0.05865979194641113, 0.009630844928324223], [0.003639359027147293, 0.3670995533466339, 0.003639359027147293, 0.6142338514328003, 0.011387834325432777], [0.06915830820798874, 0.6467783451080322, 0.19130702316761017, 0.04085760563611984, 0.0518987663090229], [0.002196705201640725, 0.003423459827899933, 0.05347786098718643, 0.9374786019325256, 0.003423459827899933], [0.12221888452768326, 0.0591534785926342, 0.12221888452768326, 0.49666857719421387, 0.19974017143249512], [0.004868850577622652, 0.03353748470544815, 0.6697208881378174, 0.03353748470544815, 0.25833526253700256], [0.06171213835477829, 0.6229077577590942, 0.06171213835477829, 0.009592476300895214, 0.2440754920244217], [0.09689975529909134, 0.01068838033825159, 0.0010969513095915318, 0.4456574320793152, 0.4456574320793152], [0.061199866235256195, 0.06225450709462166, 0.29401013255119324, 0.5213356614112854, 0.061199866235256195], [0.10263638943433762, 0.014994735829532146, 0.014994735829532146, 0.805220901966095, 0.062153153121471405], [0.009738532826304436, 0.02196369878947735, 0.22603093087673187, 0.516235888004303, 0.22603093087673187], [0.06242957338690758, 0.009433736093342304, 0.5454069375991821, 0.3203001618385315, 0.06242957338690758], [0.01169956848025322, 0.4871811270713806, 0.4871811270713806, 0.012513456866145134, 0.001424746005795896], [0.8332624435424805, 0.0776793584227562, 0.04351482912898064, 0.04351482912898064, 0.0020285812206566334], [0.060240212827920914, 0.060240212827920914, 0.1101888045668602, 0.298551082611084, 0.4707796573638916], [0.00013559701619669795, 0.38867154717445374, 0.3714563846588135, 0.00013559701619669795, 0.23960085213184357], [0.0001189688773592934, 0.8371911644935608, 0.00222190422937274, 0.05450045317411423, 0.10596756637096405], [0.1613699048757553, 0.1613699048757553, 0.5936240553855896, 0.044760122895240784, 0.038876086473464966], [0.002783170435577631, 0.31856590509414673, 0.024412963539361954, 0.48533502221107483, 0.1689029186964035], [0.42611056566238403, 0.13407927751541138, 0.012637604027986526, 0.0010619275271892548, 0.42611056566238403], [0.3883907198905945, 0.2605219781398773, 0.05341755598783493, 0.0006994363502599299, 0.29697030782699585], [0.0037021776661276817, 0.018575403839349747, 0.4287317395210266, 0.4287317395210266, 0.12025899440050125], [0.8048235774040222, 0.009927625767886639, 0.17441892623901367, 0.009927625767886639, 0.0009021081496030092], [0.019283872097730637, 0.35800036787986755, 0.17552737891674042, 0.08918800204992294, 0.35800036787986755], [0.08633426576852798, 0.3948743939399719, 0.000641626538708806, 0.3948743939399719, 0.12327534705400467], [0.0015154527500271797, 0.41900455951690674, 0.14654327929019928, 0.41900455951690674, 0.013932096771895885], [0.029175054281949997, 0.033917613327503204, 0.8797467947006226, 0.029175054281949997, 0.027985502034425735], [0.24389061331748962, 0.0700904056429863, 0.42192384600639343, 0.0036040283739566803, 0.26049110293388367], [0.11782212555408478, 0.011304475367069244, 0.7494403719902039, 0.11782212555408478, 0.0036109364591538906], [0.027312984690070152, 0.4564386308193207, 0.41138893365859985, 0.027312984690070152, 0.07754644751548767], [0.4902030825614929, 1.3780368135485332e-05, 0.01736750639975071, 0.002212556777521968, 0.4902030825614929], [0.25186124444007874, 0.04926557093858719, 0.6399628520011902, 0.04926557093858719, 0.009644806385040283], [0.013735617510974407, 0.9338157773017883, 0.03938323259353638, 0.012960236519575119, 0.00010516316979192197], [0.3922792375087738, 0.12211242318153381, 0.009488383308053017, 0.3922792375087738, 0.0838407650589943], [0.33909669518470764, 0.08575437217950821, 0.33909669518470764, 0.21269623935222626, 0.023356014862656593], [0.0004031298740301281, 0.18741963803768158, 0.18741963803768158, 0.5854725241661072, 0.03928510099649429], [0.12064874172210693, 0.12944184243679047, 0.12064874172210693, 0.44872361421585083, 0.18053701519966125], [0.01094814483076334, 0.030630923807621002, 0.01094814483076334, 0.3326360583305359, 0.6148367524147034], [0.17187801003456116, 0.7151646018028259, 0.1117149144411087, 0.0006212808657437563, 0.0006212808657437563], [0.029874466359615326, 0.09384294599294662, 0.08228588104248047, 0.7001537680625916, 0.09384294599294662], [0.3625812530517578, 0.0808839276432991, 0.3625812530517578, 0.006509569939225912, 0.1874440312385559], [0.21325625479221344, 0.015399567782878876, 0.18378448486328125, 0.37430340051651, 0.21325625479221344], [0.05187394469976425, 0.05187394469976425, 0.5949633717536926, 0.2916167378425598, 0.009671973064541817], [0.029929809272289276, 0.1722404807806015, 0.1722404807806015, 0.014727368950843811, 0.6108619570732117], [0.37640827894210815, 0.04228217899799347, 0.16147448122501373, 0.37640827894210815, 0.04342679679393768], [0.03756279870867729, 0.24408237636089325, 0.34102341532707214, 0.13324901461601257, 0.24408237636089325], [0.005310475826263428, 0.12597830593585968, 0.8272508978843689, 0.005310475826263428, 0.03614983335137367], [0.06280212104320526, 0.0065491474233567715, 0.0018754568882286549, 0.46438664197921753, 0.46438664197921753], [0.4131251871585846, 0.04027874395251274, 0.13198134303092957, 0.0014895116910338402, 0.4131251871585846], [0.47417449951171875, 0.04038954898715019, 0.009890307672321796, 0.47417449951171875, 0.001371124293655157], [0.310085654258728, 0.09670299291610718, 0.09670299291610718, 0.4395216405391693, 0.05698676407337189], [0.17700503766536713, 0.022077608853578568, 0.17700503766536713, 0.16560064256191254, 0.45831164717674255], [0.44009876251220703, 0.1550053209066391, 0.04820084944367409, 0.17834751307964325, 0.17834751307964325], [0.034813232719898224, 0.1973201483488083, 0.034813232719898224, 0.21466690301895142, 0.5183864831924438], [0.8302361965179443, 0.007306545972824097, 0.015883734449744225, 0.13926701247692108, 0.007306545972824097], [0.26082658767700195, 0.012743141502141953, 0.7058263421058655, 0.007860755547881126, 0.012743141502141953], [0.2954060733318329, 0.3309980034828186, 0.0375204011797905, 0.005077507346868515, 0.3309980034828186], [0.06881601363420486, 0.06881601363420486, 0.1097753569483757, 0.2214386761188507, 0.5311539173126221], [0.09076091647148132, 0.24773287773132324, 0.04101201891899109, 0.09076091647148132, 0.5297332406044006], [0.30447807908058167, 0.31736692786216736, 0.00855940580368042, 0.05222872272133827, 0.31736692786216736], [0.2589486539363861, 0.005524786654859781, 0.44424968957901, 0.2857520282268524, 0.005524786654859781], [0.0005229831440374255, 0.0005729299737140536, 0.47094079852104187, 0.0005229831440374255, 0.5274403095245361], [0.11817445605993271, 0.010512561537325382, 0.030979694798588753, 0.8093536496162415, 0.030979694798588753], [0.04559716209769249, 0.010832713916897774, 0.5372593998908997, 0.36071351170539856, 0.04559716209769249], [0.006733969785273075, 0.21723687648773193, 0.4092777669429779, 0.18337567150592804, 0.18337567150592804], [0.15619578957557678, 0.04134111851453781, 0.15619578957557678, 0.5206953883171082, 0.12557193636894226], [0.2699027359485626, 0.2699027359485626, 0.15845566987991333, 0.1649368703365326, 0.1368020474910736], [0.04819686710834503, 0.04238372668623924, 0.8673056364059448, 0.04059775918722153, 0.001515933545306325], [0.9741409420967102, 0.016094975173473358, 0.003120224690064788, 0.003321927972137928, 0.003321927972137928], [0.09751299023628235, 0.3053871989250183, 0.1427236944437027, 0.14898885786533356, 0.3053871989250183], [0.14324772357940674, 0.2501055896282196, 0.07210102677345276, 0.2844400703907013, 0.2501055896282196], [0.41808056831359863, 0.4890480041503906, 0.0001855670561781153, 0.09250035136938095, 0.0001855670561781153], [0.00014811329310759902, 0.8256555795669556, 0.059493809938430786, 0.00014811329310759902, 0.11455439776182175], [0.009918761439621449, 0.12450828403234482, 0.035212937742471695, 0.4151800274848938, 0.4151800274848938], [0.020029211416840553, 0.14777489006519318, 0.14777489006519318, 0.6455198526382446, 0.03890117630362511], [0.029324166476726532, 0.4010436236858368, 0.16225357353687286, 0.029324166476726532, 0.3780544698238373], [0.08519056439399719, 0.2952500879764557, 0.07598406076431274, 0.46759122610092163, 0.07598406076431274], [0.4708848297595978, 0.23058170080184937, 0.01736343279480934, 0.05058830603957176, 0.23058170080184937], [0.41108259558677673, 0.011668907478451729, 0.41108259558677673, 0.00013815794955007732, 0.16602779924869537], [0.014869640581309795, 0.18490979075431824, 0.014869640581309795, 5.805419641546905e-05, 0.7852928638458252], [0.00014636128616984934, 0.061949461698532104, 0.6739310026168823, 0.26382672786712646, 0.00014636128616984934], [0.4409046173095703, 0.010320400819182396, 0.046236973255872726, 0.06163336709141731, 0.4409046173095703], [0.7639245390892029, 0.00045192745164968073, 0.0008229870581999421, 0.2339775711297989, 0.0008229870581999421], [0.1701778769493103, 0.0030021537095308304, 0.1701778769493103, 0.5209988355636597, 0.13564325869083405], [0.0073401243425905704, 0.5380473732948303, 0.0010384410852566361, 0.2267870306968689, 0.2267870306968689], [0.019205385819077492, 0.4793291985988617, 0.007379299495369196, 0.014756912365555763, 0.4793291985988617], [0.04350621998310089, 0.46347036957740784, 0.02510383352637291, 0.46347036957740784, 0.004449240863323212], [0.9130450487136841, 0.023775752633810043, 0.023775752633810043, 0.00978523027151823, 0.02961818501353264], [0.9758555889129639, 0.0030449279583990574, 0.00034457468427717686, 0.0030449279583990574, 0.017710039392113686], [0.029706411063671112, 0.5743913054466248, 0.2173888087272644, 0.029706411063671112, 0.14880700409412384], [0.2726227045059204, 0.022751249372959137, 0.2726227045059204, 0.04766938090324402, 0.3843339681625366], [0.3259144723415375, 0.3259144723415375, 0.011948330327868462, 0.3200885057449341, 0.016134193167090416], [0.15437480807304382, 0.30715271830558777, 0.05134733393788338, 0.24356256425380707, 0.24356256425380707], [0.12612134218215942, 0.8142733573913574, 0.020166609436273575, 0.03774062544107437, 0.0016980899963527918], [0.169801726937294, 0.5921850800514221, 0.09310685098171234, 0.09310685098171234, 0.051799476146698], [0.0017590473871678114, 0.5136013031005859, 0.2629506587982178, 0.11084450036287308, 0.11084450036287308], [0.1746947169303894, 0.08164032548666, 0.001434296602383256, 0.5675358772277832, 0.1746947169303894], [0.03679313883185387, 0.9086588621139526, 0.03679313883185387, 0.0176970474421978, 5.776932084700093e-05], [0.6820390224456787, 0.17640142142772675, 0.06506562978029251, 0.011428356170654297, 0.06506562978029251], [0.16201506555080414, 0.16201506555080414, 0.45724961161613464, 0.019656043499708176, 0.19906426966190338], [0.042595554143190384, 0.005065756384283304, 0.008252977393567562, 0.08342237770557404, 0.8606633543968201], [0.0859808549284935, 0.02360350266098976, 0.10713429749011993, 0.39164066314697266, 0.39164066314697266], [0.43749094009399414, 0.03738183528184891, 0.34638866782188416, 0.14135663211345673, 0.03738183528184891], [0.370998740196228, 0.30483153462409973, 0.30483153462409973, 0.018595200031995773, 0.0007429462275467813], [0.727624237537384, 0.0018724807305261493, 0.1318472921848297, 0.06932803243398666, 0.06932803243398666], [0.055948249995708466, 0.7578256726264954, 0.009727523662149906, 0.12055031210184097, 0.055948249995708466], [0.4477081000804901, 0.02177824266254902, 0.033634863793849945, 0.24843938648700714, 0.24843938648700714], [0.24948935210704803, 0.0388505719602108, 0.3166748285293579, 0.0388505719602108, 0.3561345934867859], [0.5179257988929749, 0.013445469550788403, 0.013445469550788403, 0.20033711194992065, 0.25484615564346313], [0.3731478154659271, 0.12484889477491379, 0.09928806871175766, 0.27786627411842346, 0.12484889477491379], [0.18451644480228424, 0.22327670454978943, 0.30688440799713135, 0.18451644480228424, 0.10080605000257492], [0.0035228582564741373, 0.006137819029390812, 0.0035228582564741373, 0.03930501267313957, 0.9475114941596985], [0.013344825245440006, 0.8416742086410522, 0.05899800732731819, 0.013344825245440006, 0.07263819128274918], [0.1798323094844818, 0.07465419918298721, 0.366538941860199, 0.012435692362487316, 0.366538941860199], [0.12766629457473755, 0.002976587973535061, 0.7050517797470093, 0.002976587973535061, 0.1613287478685379], [0.13065841794013977, 0.618698239326477, 0.01212329976260662, 0.22639666497707367, 0.01212329976260662], [0.0023841331712901592, 0.09824128448963165, 0.09824128448963165, 0.05398509278893471, 0.7471482157707214], [0.13864965736865997, 0.39207586646080017, 0.15940959751605988, 0.1712152361869812, 0.13864965736865997], [0.12333006411790848, 0.02855159342288971, 0.42401382327079773, 0.42401382327079773, 9.064711048267782e-05], [0.11665311455726624, 0.7500129342079163, 0.0015360891120508313, 0.015144847333431244, 0.11665311455726624], [0.06967318058013916, 0.10550343245267868, 0.2664792835712433, 0.4886709153652191, 0.06967318058013916], [0.4389755129814148, 0.4389755129814148, 0.00016670968034304678, 0.05716646462678909, 0.06471583247184753], [0.04695042595267296, 0.0031487413216382265, 0.8818501234054565, 0.04695042595267296, 0.021100278943777084], [0.6340590715408325, 0.026994748041033745, 0.0078946053981781, 0.0078946053981781, 0.3231569230556488], [0.45225247740745544, 0.0029556178487837315, 0.0029556178487837315, 0.1779525727033615, 0.36388373374938965], [0.030049026012420654, 0.46001529693603516, 0.04758159816265106, 0.46001529693603516, 0.0023387926630675793], [0.384322851896286, 0.384322851896286, 0.010196607559919357, 0.21382884681224823, 0.007328856736421585], [0.23325896263122559, 0.06436926126480103, 0.06436926126480103, 0.20945218205451965, 0.4285503029823303], [0.4134986102581024, 0.2846483886241913, 0.0002900903346017003, 0.2846483886241913, 0.016914576292037964], [0.16294507682323456, 0.16294507682323456, 0.1764608472585678, 0.4685836136341095, 0.029065370559692383], [0.008282387629151344, 0.4473473131656647, 0.004527640528976917, 0.5353150367736816, 0.004527640528976917], [0.03113575093448162, 0.1881800889968872, 0.1885056048631668, 0.1881800889968872, 0.40399855375289917], [0.011882342398166656, 0.011882342398166656, 1.251009598490782e-05, 0.08827807009220123, 0.8879448175430298], [0.19804225862026215, 0.007988937199115753, 0.007988937199115753, 0.6470792293548584, 0.13890059292316437], [0.11874112486839294, 0.10167184472084045, 0.11874112486839294, 0.002242923015728593, 0.6586030721664429], [0.21671679615974426, 0.001735179452225566, 0.07220558822154999, 0.21671679615974426, 0.4926256537437439], [0.3964511752128601, 0.3964511752128601, 0.017802929505705833, 0.17493180930614471, 0.014362872578203678], [0.005852590315043926, 0.5241482257843018, 0.005852590315043926, 0.006081269588321447, 0.45806533098220825], [0.9525349140167236, 0.010982099920511246, 0.0031086995732039213, 0.010982099920511246, 0.022392241284251213], [0.7271480560302734, 0.0034027076326310635, 0.13982747495174408, 0.11295528709888458, 0.016666527837514877], [0.14764203131198883, 0.005232725292444229, 0.13875560462474823, 0.7031369209289551, 0.005232725292444229], [0.5576959252357483, 0.03154293820261955, 0.03154293820261955, 0.2772682309150696, 0.10195005685091019], [8.483238343615085e-05, 0.15676794946193695, 0.15676794946193695, 0.494139164686203, 0.1922401338815689], [0.9128926396369934, 0.025325344875454903, 0.034546155482530594, 0.025325344875454903, 0.0019105680985376239], [0.3709898293018341, 0.3709898293018341, 0.24793772399425507, 0.010062620043754578, 1.9979357603006065e-05], [0.005424081813544035, 0.04024776443839073, 0.06534738093614578, 0.005424081813544035, 0.8835566639900208], [0.21009916067123413, 0.1726636290550232, 0.1726636290550232, 0.24310816824436188, 0.2014654576778412], [0.09650672227144241, 0.43251389265060425, 0.007780024781823158, 0.36669260263442993, 0.09650672227144241], [0.03794335573911667, 0.424558162689209, 0.23710240423679352, 0.26245272159576416, 0.03794335573911667], [0.4472821056842804, 0.5268334150314331, 0.0017656530253589153, 0.02235320210456848, 0.0017656530253589153], [0.07697052508592606, 0.05845598876476288, 0.7671718001365662, 0.07697052508592606, 0.02043120190501213], [0.010835709981620312, 0.5208308696746826, 0.43437182903289795, 0.02312588319182396, 0.010835709981620312], [0.015085937455296516, 0.015085937455296516, 0.24715286493301392, 0.24079477787017822, 0.4818805158138275], [0.011809089221060276, 0.8475605249404907, 0.008796494454145432, 0.1026417538523674, 0.029192158952355385], [0.7108638882637024, 0.013299854472279549, 0.00021708228450734168, 0.004535829182714224, 0.27108341455459595], [0.05547044798731804, 0.1689116507768631, 0.16151869297027588, 0.12644125521183014, 0.48765793442726135], [0.0449526309967041, 0.05719796568155289, 0.11266345530748367, 0.6643286347389221, 0.12085733562707901], [0.07828634232282639, 0.021551525220274925, 0.7520975470542908, 0.1265130639076233, 0.021551525220274925], [0.382874459028244, 0.4058379530906677, 0.021337442100048065, 0.16861270368099213, 0.021337442100048065], [0.02278956025838852, 0.00886208564043045, 0.46085265278816223, 0.04664307087659836, 0.46085265278816223], [0.39797526597976685, 0.12632128596305847, 0.04386429861187935, 0.033863797783851624, 0.39797526597976685], [0.043171949684619904, 0.034360188990831375, 0.034360188990831375, 0.30438995361328125, 0.5837177634239197], [0.7671170830726624, 0.08085310459136963, 0.04954843968153, 0.05293292924761772, 0.04954843968153], [0.0010942841181531549, 0.0010942841181531549, 0.7061063051223755, 0.2371356189250946, 0.05456952005624771], [0.27494561672210693, 0.33853816986083984, 0.33853816986083984, 0.016571911051869392, 0.031406134366989136], [0.6127544045448303, 0.1548018604516983, 0.06528394669294357, 0.06528394669294357, 0.10187581926584244], [0.2591731548309326, 0.14239370822906494, 0.010426944121718407, 0.2591731548309326, 0.3288329839706421], [0.009911097586154938, 0.0007639593677595258, 0.5008391737937927, 0.46319153904914856, 0.02529432624578476], [0.44378384947776794, 0.027905641123652458, 0.44378384947776794, 0.04963509365916252, 0.03489159792661667], [0.005732829682528973, 0.33582955598831177, 0.3310821056365967, 0.16367773711681366, 0.16367773711681366], [0.25286057591438293, 0.1813904494047165, 0.0006763479323126376, 0.5643962621688843, 0.0006763479323126376], [4.0631119190948084e-05, 0.8822738528251648, 0.005301946774125099, 0.09961238503456116, 0.012771155685186386], [0.010926173068583012, 0.010926173068583012, 0.2263469099998474, 0.7312806248664856, 0.020520159974694252], [0.002663217019289732, 0.22644227743148804, 0.5798900127410889, 0.09550227969884872, 0.09550227969884872], [7.487652328563854e-05, 7.487652328563854e-05, 0.18250803649425507, 0.5717635750770569, 0.2455786168575287], [0.07645625621080399, 0.0003137991589028388, 0.3244170844554901, 0.5223566293716431, 0.07645625621080399], [0.10810729116201401, 0.10810729116201401, 0.057428259402513504, 0.5548951029777527, 0.1714620739221573], [0.18927431106567383, 0.1170036718249321, 0.18927431106567383, 0.042601458728313446, 0.46184617280960083], [0.2577509582042694, 0.45961716771125793, 0.01214498933404684, 0.2577509582042694, 0.012735980562865734], [1.5180593436525669e-05, 0.3450544774532318, 0.3450544774532318, 0.3089353144168854, 0.0009405120508745313], [0.5779201984405518, 0.2033858746290207, 0.002842422341927886, 0.012465598061680794, 0.2033858746290207], [0.34448352456092834, 0.07328831404447556, 0.34448352456092834, 0.04489772394299507, 0.1928468942642212], [0.1679954081773758, 0.611718475818634, 0.0003070633392781019, 0.1679954081773758, 0.051983606070280075], [0.11953099071979523, 0.11953099071979523, 0.09489370137453079, 0.21087409555912018, 0.4551701843738556], [0.39879024028778076, 0.009983564727008343, 0.3638078272342682, 0.11370918154716492, 0.11370918154716492], [0.4690190553665161, 0.008400419726967812, 0.5138447284698486, 0.00033532598172314465, 0.008400419726967812], [0.21943123638629913, 0.003075001062825322, 0.38839566707611084, 0.38839566707611084, 0.0007023670477792621], [0.23772747814655304, 0.2392829954624176, 0.1595374494791031, 0.20391462743282318, 0.1595374494791031], [0.03557191416621208, 0.01879969798028469, 0.7349990010261536, 0.17505745589733124, 0.03557191416621208], [0.5113993287086487, 0.33257541060447693, 0.014466863125562668, 0.0707792118191719, 0.0707792118191719], [0.02302124910056591, 0.02302124910056591, 0.013749280013144016, 0.9156585335731506, 0.024549664929509163], [0.19003550708293915, 0.19003550708293915, 0.12057191133499146, 0.33804723620414734, 0.1613098680973053], [0.6064558029174805, 0.00010688466863939539, 0.07814069092273712, 0.004693361930549145, 0.3106032609939575], [0.00011412955063860863, 0.33658111095428467, 0.17067842185497284, 0.2463131695985794, 0.2463131695985794], [0.02453533187508583, 0.8772792220115662, 0.029863061383366585, 0.03845936805009842, 0.029863061383366585], [0.18960008025169373, 0.18960008025169373, 0.0391477569937706, 0.10172491520643234, 0.4799272418022156], [0.21839120984077454, 0.5007172226905823, 0.0004237017419654876, 0.0620766244828701, 0.21839120984077454], [0.11842522770166397, 0.03936505317687988, 0.41396358609199524, 0.01428245473653078, 0.41396358609199524], [0.31573912501335144, 0.07766611874103546, 0.14169837534427643, 0.14169837534427643, 0.32319799065589905], [0.30278557538986206, 0.30278557538986206, 0.3600177764892578, 0.0076057035475969315, 0.026805415749549866], [0.042225390672683716, 0.3617748022079468, 0.5725401043891907, 0.011729864403605461, 0.011729864403605461], [0.39742130041122437, 0.08809240162372589, 0.39742130041122437, 0.10685411840677261, 0.010210887528955936], [0.024023879319429398, 0.04612406715750694, 0.7850449681282043, 0.04612406715750694, 0.0986829549074173], [0.005926421377807856, 0.8683671355247498, 0.01066706981509924, 0.0002638506412040442, 0.11477546393871307], [0.14347614347934723, 0.2442805916070938, 0.43778812885284424, 0.14347614347934723, 0.03097892925143242], [0.5875943303108215, 0.026301246136426926, 0.05956142768263817, 4.712432928499766e-05, 0.3264959752559662], [0.4626370370388031, 0.08769914507865906, 0.021420147269964218, 0.34054455161094666, 0.08769914507865906], [0.18318599462509155, 0.25221094489097595, 0.23718450963497162, 0.1442325860261917, 0.18318599462509155], [0.1880742311477661, 0.03626049682497978, 0.3212911784648895, 0.13308294117450714, 0.3212911784648895], [0.3440890610218048, 0.41319146752357483, 0.036783214658498764, 0.045015331357717514, 0.1609208732843399], [0.12565544247627258, 0.4095717668533325, 0.00628837663680315, 0.048912663012742996, 0.4095717668533325], [0.5189690589904785, 0.4628043472766876, 0.0027060809079557657, 0.0027060809079557657, 0.012814396992325783], [0.0017285693902522326, 0.0017285693902522326, 0.011899166740477085, 0.37958618998527527, 0.6050574779510498], [0.19573141634464264, 0.03494413569569588, 0.4669239819049835, 0.10666907578706741, 0.19573141634464264], [0.023356320336461067, 0.2372402846813202, 0.023356320336461067, 0.6778396368026733, 0.03820747509598732], [0.0005347870755940676, 0.4614875018596649, 0.26618510484695435, 0.26618510484695435, 0.00560754956677556], [0.38215282559394836, 0.02746136486530304, 0.0074323490262031555, 0.5554921627044678, 0.02746136486530304], [0.020916059613227844, 0.001071165781468153, 0.020916059613227844, 0.0092336256057024, 0.947862982749939], [0.01114414818584919, 0.13620513677597046, 0.13620513677597046, 0.6984116435050964, 0.018033988773822784], [0.15605871379375458, 0.2533108592033386, 0.09115930646657944, 0.24973557889461517, 0.24973557889461517], [0.016262196004390717, 0.008917432278394699, 0.13526049256324768, 0.13526049256324768, 0.7042993307113647], [0.3306027054786682, 0.0022419714368879795, 0.5908140540122986, 0.0022419714368879795, 0.07409922778606415], [0.2944433093070984, 0.2944433093070984, 0.38949093222618103, 0.01698301173746586, 0.004639462102204561], [0.007218832615762949, 0.010053214617073536, 0.8936846852302551, 0.07898997515439987, 0.010053214617073536], [0.003171991789713502, 0.9777772426605225, 4.46012609245372e-06, 0.018978260457515717, 6.806106102885678e-05], [0.8889176249504089, 0.003961756359785795, 0.01917397603392601, 0.003961756359785795, 0.08398494869470596], [0.264739990234375, 0.033497367054224014, 0.4103630483150482, 0.026659594848752022, 0.264739990234375], [0.09707838296890259, 0.4303125739097595, 0.029356883838772774, 0.4340646266937256, 0.009187509305775166], [0.13806386291980743, 0.13806386291980743, 0.023899028077721596, 0.46407338976860046, 0.23589982092380524], [0.0047624558210372925, 0.3195176124572754, 0.2664813697338104, 0.3195176124572754, 0.0897209420800209], [0.21171632409095764, 0.21171632409095764, 0.1069566011428833, 0.40265390276908875, 0.06695684790611267], [0.011369241401553154, 0.10620614886283875, 0.10620614886283875, 0.0547860786318779, 0.7214324474334717], [0.3886944651603699, 0.008369567804038525, 0.5748799443244934, 0.019686514511704445, 0.008369567804038525], [0.4058036804199219, 0.22996215522289276, 0.20716522634029388, 0.07853443175554276, 0.07853443175554276], [0.4550560414791107, 0.032876309007406235, 0.050429653376340866, 0.4550560414791107, 0.006581936962902546], [0.11200354993343353, 0.11200354993343353, 0.24077796936035156, 0.30032145977020264, 0.23489347100257874], [0.0029328358359634876, 0.4780425727367401, 0.004683535546064377, 0.4780425727367401, 0.03629842400550842], [0.010183192789554596, 0.08864680677652359, 0.010183192789554596, 0.01728496514260769, 0.8737018704414368], [0.4794072210788727, 0.13322265446186066, 0.13322265446186066, 0.22093826532363892, 0.033209193497896194], [0.10416997224092484, 0.1527250111103058, 0.5867209434509277, 0.10416997224092484, 0.05221406742930412], [0.0735069215297699, 0.395321786403656, 0.04750097543001175, 0.0883486419916153, 0.395321786403656], [0.03812658041715622, 0.032701537013053894, 0.03812658041715622, 0.13233883678913116, 0.7587065100669861], [0.2738499343395233, 0.1254718005657196, 0.39933669567108154, 0.1254718005657196, 0.07586976140737534], [0.48752880096435547, 0.0377805158495903, 0.0008888589800335467, 0.47291290760040283, 0.0008888589800335467], [0.009680347517132759, 0.009680347517132759, 0.9628961682319641, 0.016439164057374, 0.0013040394987910986], [0.007938720285892487, 0.7182769179344177, 0.1340918242931366, 0.005600754637271166, 0.1340918242931366], [0.0763617679476738, 0.17286115884780884, 0.6742233037948608, 0.00019202727708034217, 0.0763617679476738], [0.09917928278446198, 0.5307800769805908, 0.021484654396772385, 0.3270713686943054, 0.021484654396772385], [0.34761226177215576, 0.34761226177215576, 0.18436464667320251, 0.0006598379695788026, 0.11975099891424179], [0.30165010690689087, 0.1829918622970581, 0.0016821288736537099, 0.33068400621414185, 0.1829918622970581], [0.04055456444621086, 0.04055456444621086, 0.44075965881347656, 0.47798359394073486, 0.00014772322901990265], [0.019911201670765877, 0.37964481115341187, 0.019911201670765877, 0.5787164568901062, 0.0018163161585107446], [0.3386065661907196, 0.25803250074386597, 0.3386065661907196, 0.0012364303693175316, 0.0635179802775383], [0.5453424453735352, 0.1480729728937149, 0.04295416548848152, 0.11555744707584381, 0.1480729728937149], [0.18572716414928436, 0.04894080385565758, 0.18572716414928436, 0.0001586318394402042, 0.5794463157653809], [0.20623883605003357, 0.002926951041445136, 0.2963641583919525, 0.20623883605003357, 0.2882312536239624], [0.23830659687519073, 0.2289636731147766, 0.2872049808502197, 0.23830659687519073, 0.007218129001557827], [0.07721903175115585, 0.009603645652532578, 0.009603645652532578, 0.008515307679772377, 0.8950583934783936], [0.25055915117263794, 0.09698967635631561, 0.08477616310119629, 0.48289886116981506, 0.08477616310119629], [0.23482318222522736, 0.26847171783447266, 0.23482318222522736, 0.25982779264450073, 0.0020541551057249308], [0.1185256689786911, 0.024622946977615356, 0.024622946977615356, 0.39630767703056335, 0.43592074513435364], [0.2792360186576843, 0.014029819518327713, 0.017682339996099472, 0.07095352560281754, 0.6180983781814575], [0.09736000001430511, 0.021127603948116302, 0.7405771613121033, 0.09736000001430511, 0.043575238436460495], [0.001380452187731862, 0.41581448912620544, 0.16062913835048676, 0.006361439358443022, 0.41581448912620544], [0.011611444875597954, 0.2720927894115448, 0.2720927894115448, 0.26104703545570374, 0.1831558644771576], [0.34692955017089844, 0.34692955017089844, 0.13946452736854553, 0.06767258793115616, 0.09900382906198502], [0.35844624042510986, 0.01912514679133892, 0.5834086537361145, 0.01912514679133892, 0.01989482156932354], [0.2486095279455185, 0.2486095279455185, 0.08667843043804169, 0.3420006334781647, 0.07410182803869247], [0.010365366004407406, 0.49210092425346375, 0.00012013816012768075, 0.0053127664141356945, 0.49210092425346375], [0.002890055999159813, 0.7513971924781799, 0.002890055999159813, 0.0005027035367675126, 0.24232003092765808], [0.19954712688922882, 0.2852168083190918, 0.12417511641979218, 0.007164460606873035, 0.38389652967453003], [0.013855532743036747, 0.4445805847644806, 0.06318773329257965, 0.4445805847644806, 0.033795516937971115], [0.287403404712677, 0.24958530068397522, 0.13330303132534027, 0.287403404712677, 0.042304813861846924], [0.019607434049248695, 0.4558537006378174, 0.05402269586920738, 0.4558537006378174, 0.014662452042102814], [0.19248276948928833, 0.19248276948928833, 0.021677475422620773, 0.5921134948730469, 0.0012434617383405566], [0.02441447041928768, 0.0004548517463263124, 0.8900225162506104, 0.060693711042404175, 0.02441447041928768], [0.046775151044130325, 0.0004867645329795778, 0.0519680492579937, 0.8539949655532837, 0.046775151044130325], [0.6144424676895142, 0.3772103786468506, 0.00018461041327100247, 0.007796609774231911, 0.0003660498186945915], [0.0003007691993843764, 0.0398259311914444, 0.4755856990814209, 0.00870197918266058, 0.4755856990814209], [0.07211127132177353, 0.7061465382575989, 0.016214193776249886, 0.07211127132177353, 0.13341669738292694], [0.0015985170612111688, 0.009191025979816914, 0.9089303016662598, 0.07108903676271439, 0.009191025979816914], [0.02183433808386326, 0.45918509364128113, 0.09737593680620193, 0.02183433808386326, 0.3997703194618225], [0.25444653630256653, 0.1871708631515503, 0.1871708631515503, 0.2341727763414383, 0.1370389610528946], [0.17209112644195557, 0.16260725259780884, 0.019148405641317368, 0.019148405641317368, 0.6270048022270203], [0.9278779029846191, 0.007136727683246136, 0.05606384947896004, 0.007136727683246136, 0.0017848167335614562], [0.4522503614425659, 0.0013911295682191849, 0.0011011091992259026, 0.04491066932678223, 0.5003467202186584], [0.0002478650421835482, 0.4219314157962799, 0.5335161685943604, 0.044056762009859085, 0.0002478650421835482], [0.0017260713502764702, 0.3294471800327301, 0.33147382736206055, 0.005879109725356102, 0.33147382736206055], [0.9965744018554688, 0.002443228382617235, 9.915413102135062e-05, 9.915413102135062e-05, 0.0007841422921046615], [0.16338224709033966, 0.16972939670085907, 0.04016963765025139, 0.4633364975452423, 0.16338224709033966], [0.015520388260483742, 0.2539745271205902, 0.4740517735481262, 0.0024787599686533213, 0.2539745271205902], [0.4601469039916992, 0.4601469039916992, 0.0018590603722259402, 0.062402695417404175, 0.015444423072040081], [0.35060641169548035, 0.020235929638147354, 0.5040327906608582, 0.020235929638147354, 0.10488897562026978], [0.002361447084695101, 0.06533448398113251, 0.8419867753982544, 0.06533448398113251, 0.024982836097478867], [0.002216164954006672, 0.2403046041727066, 0.6101703643798828, 0.07365444302558899, 0.07365444302558899], [0.1502852439880371, 0.6257151961326599, 0.059173282235860825, 0.014540988951921463, 0.1502852439880371], [0.7471567988395691, 0.0028242720291018486, 0.18644402921199799, 0.060750626027584076, 0.0028242720291018486], [0.0852106511592865, 0.05251309648156166, 0.0852106511592865, 0.2197447419166565, 0.5573208928108215], [0.9475598335266113, 0.02064346894621849, 0.00903414562344551, 0.002119069918990135, 0.02064346894621849], [0.7365706562995911, 0.08061113208532333, 0.013473191298544407, 0.08061113208532333, 0.08873386681079865], [0.0004250913916621357, 0.0330364853143692, 0.05882123485207558, 0.9072920083999634, 0.0004250913916621357], [0.023928195238113403, 0.019654531031847, 0.08020137250423431, 0.023928195238113403, 0.852287769317627], [0.22316983342170715, 0.16414834558963776, 0.12998631596565247, 0.2413477897644043, 0.2413477897644043], [0.32930251955986023, 0.009275962598621845, 0.23664319515228271, 0.4155023992061615, 0.009275962598621845], [0.07650065422058105, 0.02172255888581276, 0.742235004901886, 0.07650065422058105, 0.08304113149642944], [0.04549293592572212, 0.3646891117095947, 0.3646891117095947, 0.08054418116807938, 0.14458462595939636], [0.3150031268596649, 0.0005281826597638428, 0.0005738092004321516, 0.6833667159080505, 0.0005281826597638428], [0.42748376727104187, 0.03182108700275421, 0.05975371226668358, 0.053457632660865784, 0.42748376727104187], [0.16925597190856934, 0.027106789872050285, 0.002080514095723629, 0.7744499444961548, 0.027106789872050285], [0.005770834628492594, 0.005770834628492594, 0.0487971194088459, 0.4889691472053528, 0.4506920874118805], [0.003925927449017763, 0.4505096673965454, 0.2472592294216156, 0.2472592294216156, 0.05104595050215721], [0.38281333446502686, 0.0028240224346518517, 0.07187099754810333, 0.38281333446502686, 0.15967829525470734], [0.00011268271191511303, 0.04329913854598999, 0.4782716929912567, 0.4782716929912567, 4.484119199332781e-05], [0.018333178013563156, 0.45212531089782715, 0.0038069370202720165, 0.07360921055078506, 0.45212531089782715], [0.19455541670322418, 0.16252845525741577, 0.04466962069272995, 0.5535768270492554, 0.04466962069272995], [0.20673751831054688, 0.2575033903121948, 0.06213873624801636, 0.2575033903121948, 0.21611692011356354], [0.3514862060546875, 0.09842369705438614, 0.007246957626193762, 0.3514862060546875, 0.19135692715644836], [0.07198083400726318, 0.08853622525930405, 0.28863146901130676, 0.26221999526023865, 0.28863146901130676], [0.1820625364780426, 0.038188111037015915, 0.4651126563549042, 0.1820625364780426, 0.132574200630188], [0.6722474098205566, 0.16290995478630066, 5.114861050969921e-05, 0.16290995478630066, 0.0018815338844433427], [0.901418149471283, 0.03678138181567192, 0.03506956994533539, 0.013365432620048523, 0.013365432620048523], [0.04003320634365082, 0.0874023288488388, 0.2049197554588318, 0.0874023288488388, 0.580242395401001], [0.22691062092781067, 0.10596603155136108, 0.22691062092781067, 0.0012518108123913407, 0.438960999250412], [0.7012354135513306, 0.019273661077022552, 0.22463463246822357, 0.019273661077022552, 0.035582587122917175], [0.03952088952064514, 0.4629463255405426, 0.00771537097170949, 0.02687099762260914, 0.4629463255405426], [0.007803109008818865, 0.18679176270961761, 0.026619622483849525, 0.18679176270961761, 0.5919936895370483], [0.11827117204666138, 0.1718502938747406, 0.514637291431427, 0.023390939459204674, 0.1718502938747406], [0.26237788796424866, 0.17157608270645142, 0.26237788796424866, 0.3026210069656372, 0.0010471814312040806], [0.0007295379182323813, 0.3138048052787781, 0.3138048052787781, 0.26146531105041504, 0.11019556224346161], [0.8445146679878235, 0.0102122463285923, 0.019633619114756584, 0.11542719602584839, 0.0102122463285923], [0.12723350524902344, 0.3737196624279022, 0.09415984898805618, 0.31072714924812317, 0.09415984898805618], [0.6947898268699646, 0.21458300948143005, 0.027769627049565315, 0.03142877295613289, 0.03142877295613289], [0.0010510253487154841, 0.001548125990666449, 0.19203977286815643, 0.8043100237846375, 0.0010510253487154841], [0.00408521993085742, 0.4629271328449249, 0.0339052714407444, 0.03615522384643555, 0.4629271328449249], [0.12284717708826065, 0.3795645236968994, 0.10788079351186752, 0.010143043473362923, 0.3795645236968994], [0.010742519982159138, 0.010742519982159138, 0.01425707247108221, 0.8616617321968079, 0.10259605944156647], [0.23757539689540863, 0.522506058216095, 0.20911113917827606, 0.015403704717755318, 0.015403704717755318], [0.5622957348823547, 0.3406980335712433, 0.02677742950618267, 0.04345139488577843, 0.02677742950618267], [0.0027826963923871517, 0.05914336070418358, 0.0073912376537919044, 0.0027826963923871517, 0.927899956703186], [0.6799219250679016, 0.1017468273639679, 0.059218503534793854, 0.07955636829137802, 0.07955636829137802], [0.4425586462020874, 0.05748175084590912, 0.03608686476945877, 0.23193639516830444, 0.23193639516830444], [0.0028196885250508785, 0.836264431476593, 0.004673810210078955, 0.1515681892633438, 0.004673810210078955], [0.10740316659212112, 0.10740316659212112, 0.37762972712516785, 0.2381432205438614, 0.16942065954208374], [0.1004866436123848, 0.32401350140571594, 0.3609515428543091, 0.10727415233850479, 0.10727415233850479], [0.0199537742882967, 0.0199537742882967, 0.18971285223960876, 0.61043381690979, 0.15994571149349213], [0.010330062359571457, 0.10472515225410461, 0.6965668201446533, 0.010330062359571457, 0.17804783582687378], [0.12269175052642822, 0.02563408575952053, 0.12269175052642822, 0.2543024718761444, 0.47467997670173645], [0.01195536833256483, 0.3410660922527313, 0.3410660922527313, 0.017294637858867645, 0.2886177599430084], [0.2641127407550812, 0.0006799185066483915, 0.7018230557441711, 0.032704371958971024, 0.0006799185066483915], [0.44309303164482117, 0.08156000822782516, 0.44309303164482117, 0.0016576221678406, 0.030596401542425156], [0.15209950506687164, 0.007850800640881062, 0.15209950506687164, 0.6860650181770325, 0.0018851913046091795], [0.7249167561531067, 0.09420622885227203, 0.03753272071480751, 0.04913800582289696, 0.09420622885227203], [0.1678968369960785, 0.048166222870349884, 0.7225998044013977, 0.048166222870349884, 0.013170857913792133], [0.045113418251276016, 0.045113418251276016, 0.7667410373687744, 0.08702941983938217, 0.056002721190452576], [0.0003302444820292294, 0.0003302444820292294, 0.24687455594539642, 0.18207044899463654, 0.5703945159912109], [0.5809376239776611, 0.1738448590040207, 0.016296658664941788, 0.09488033503293991, 0.13404053449630737], [0.12979952991008759, 0.0484040193259716, 0.18588842451572418, 0.45001956820487976, 0.18588842451572418], [0.05114975571632385, 0.1466321498155594, 0.09221002459526062, 0.05114975571632385, 0.6588583588600159], [0.4687598645687103, 0.0011032761540263891, 0.4687598645687103, 0.0038141903933137655, 0.05756276473402977], [0.13728362321853638, 0.00017438277427572757, 0.41537365317344666, 0.03179469704627991, 0.41537365317344666], [0.07654590904712677, 0.5727123022079468, 0.17532230913639069, 0.17532230913639069, 9.708310244604945e-05], [0.2351023405790329, 0.3574192523956299, 0.031240522861480713, 0.3574192523956299, 0.018818628042936325], [0.006413365248590708, 0.00153162342030555, 0.006413365248590708, 0.08045785129070282, 0.9051836729049683], [0.0751814991235733, 0.3858610689640045, 0.02076035551726818, 0.02076035551726818, 0.49743667244911194], [0.3872089982032776, 0.5637961030006409, 0.003177404636517167, 0.003177404636517167, 0.042640071362257004], [0.020417053252458572, 0.0031629379373043776, 0.020417053252458572, 0.8277641534805298, 0.12823885679244995], [0.2890884280204773, 0.1571042686700821, 0.23650065064430237, 0.028218207880854607, 0.2890884280204773], [0.003977048210799694, 0.08752381056547165, 0.7863970398902893, 0.03457827866077423, 0.08752381056547165], [0.026077955961227417, 0.0002031410695053637, 0.646977424621582, 0.026077955961227417, 0.3006635308265686], [0.2980414032936096, 0.3303612470626831, 0.004744343459606171, 0.03649182245135307, 0.3303612470626831], [0.04611997678875923, 0.009346609935164452, 0.4956079125404358, 0.4395788609981537, 0.009346609935164452], [0.01864989474415779, 0.09153787046670914, 0.444244384765625, 0.444244384765625, 0.0013233899371698499], [0.4812358021736145, 0.006358712911605835, 0.4812358021736145, 0.013282344676554203, 0.017887400463223457], [0.002055694814771414, 0.49239587783813477, 0.010735780000686646, 0.002416771138086915, 0.49239587783813477], [0.0021097431890666485, 0.4951765835285187, 0.0006910773226991296, 0.4951765835285187, 0.006846084259450436], [0.5164867043495178, 0.020166432484984398, 0.4300328195095062, 0.020166432484984398, 0.013147570192813873], [0.3056860566139221, 0.05181858688592911, 0.06638748943805695, 0.05181858688592911, 0.5242893099784851], [0.3783721625804901, 0.3783721625804901, 0.014835644513368607, 0.14494487643241882, 0.08347514271736145], [0.13757412135601044, 0.03783513605594635, 0.26465773582458496, 0.2952753007411957, 0.26465773582458496], [0.011211308650672436, 0.3483218550682068, 0.2920265793800354, 0.0001184164866572246, 0.3483218550682068], [0.48619306087493896, 0.020047223195433617, 0.22600461542606354, 0.24770790338516235, 0.020047223195433617], [0.011487237177789211, 0.03806258365511894, 0.18447335064411163, 0.03806258365511894, 0.7279142737388611], [0.07860566675662994, 0.003387544071301818, 0.3053962290287018, 0.003387544071301818, 0.609222948551178], [0.19965316355228424, 0.5724836587905884, 0.011694742366671562, 0.19965316355228424, 0.016515178605914116], [0.3273904621601105, 0.10891539603471756, 0.2104596346616745, 0.025844017043709755, 0.3273904621601105], [0.9774600267410278, 0.0008355134050361812, 0.007253599818795919, 0.007197230588644743, 0.007253599818795919], [0.03459139168262482, 0.9098153710365295, 0.02513442374765873, 0.005324384663254023, 0.02513442374765873], [0.11125596612691879, 0.8042874336242676, 0.033860910683870316, 0.003653495339676738, 0.04694220423698425], [0.34111449122428894, 0.003183948341757059, 0.26519232988357544, 0.3367464244365692, 0.05376284942030907], [0.9068812727928162, 0.05574413016438484, 0.031698137521743774, 0.002838278654962778, 0.002838278654962778], [0.679399311542511, 0.08279003947973251, 0.15373583137989044, 0.0012848323676735163, 0.08279003947973251], [0.0583207830786705, 0.0617704913020134, 0.0617704913020134, 0.059855666011571884, 0.7582825422286987], [0.024217484518885612, 0.592201828956604, 0.007891013287007809, 0.35922443866729736, 0.016465289518237114], [0.4288361370563507, 0.4288361370563507, 0.058137644082307816, 0.0016327878693118691, 0.08255720138549805], [0.05333763733506203, 0.38109585642814636, 0.15605488419532776, 0.38109585642814636, 0.028415773063898087], [0.03426828607916832, 0.42529788613319397, 0.10135925561189651, 0.21953730285167694, 0.21953730285167694], [0.0009714851039461792, 0.01996408775448799, 0.8057820796966553, 0.01996408775448799, 0.15331824123859406], [0.15729013085365295, 0.2768877446651459, 0.000671315414365381, 0.5644795298576355, 0.000671315414365381], [0.09642279893159866, 0.7293802499771118, 0.08592230081558228, 0.08592230081558228, 0.0023523950949311256], [0.15608114004135132, 0.5429395437240601, 0.15608114004135132, 0.007016654592007399, 0.13788147270679474], [0.0998544692993164, 0.4106178879737854, 0.026408368721604347, 0.2315596342086792, 0.2315596342086792], [0.45896396040916443, 0.45896396040916443, 0.01254277303814888, 0.05341501906514168, 0.016114264726638794], [0.03509994596242905, 0.8450149297714233, 0.09337224066257477, 0.013256418518722057, 0.013256418518722057], [0.5276629328727722, 0.03453695401549339, 0.005553462542593479, 0.2161233127117157, 0.2161233127117157], [0.03300575539469719, 0.7753778100013733, 0.00033753158641047776, 0.1582731306552887, 0.03300575539469719], [0.012148130685091019, 0.24359674751758575, 0.03952309489250183, 0.35236600041389465, 0.35236600041389465], [0.03299793601036072, 0.053456105291843414, 0.45641160011291504, 0.000722767086699605, 0.45641160011291504], [0.0057773166336119175, 0.0057773166336119175, 0.3672376573085785, 0.027737952768802643, 0.5934696197509766], [0.01893622986972332, 0.01893622986972332, 0.3888198435306549, 0.3186453878879547, 0.25466224551200867], [0.0012161892373114824, 0.0012161892373114824, 0.774311363697052, 0.17184436321258545, 0.05141197517514229], [0.4587065577507019, 0.0013413450215011835, 0.2389194667339325, 0.062113191932439804, 0.2389194667339325], [0.05657457932829857, 0.26141831278800964, 0.2884724736213684, 0.10506214946508408, 0.2884724736213684], [0.48522698879241943, 0.0017033660551533103, 0.027834255248308182, 8.485495527565945e-06, 0.48522698879241943], [0.025353670120239258, 0.793580949306488, 0.02548237517476082, 0.1301005333662033, 0.02548237517476082], [0.016891317442059517, 0.010750245302915573, 0.9046676754951477, 0.05694052577018738, 0.010750245302915573], [0.733177125453949, 0.15892910957336426, 0.05026070028543472, 0.00737242354080081, 0.05026070028543472], [0.0948452576994896, 0.32412487268447876, 0.48333489894866943, 0.002849729498848319, 0.0948452576994896], [0.030985398218035698, 0.15984073281288147, 0.03918630629777908, 0.15984073281288147, 0.6101468801498413], [0.3125694990158081, 0.3125694990158081, 0.10996871441602707, 0.26195475459098816, 0.002937545534223318], [0.5169954299926758, 0.01044542621821165, 0.16471970081329346, 0.2973940074443817, 0.01044542621821165], [0.04348564147949219, 0.7572261691093445, 0.029261454939842224, 0.1265411376953125, 0.04348564147949219], [0.15924572944641113, 0.6772710084915161, 0.0012947199866175652, 0.15924572944641113, 0.0029427993576973677], [0.2027951180934906, 0.19411860406398773, 0.2027951180934906, 0.015354253351688385, 0.3849368691444397], [0.3939621150493622, 0.00766546418890357, 0.08819985389709473, 0.3939621150493622, 0.1162104606628418], [0.3991331160068512, 0.20186814665794373, 0.02008657157421112, 0.18945609033107758, 0.18945609033107758], [0.1069164127111435, 0.09678512066602707, 0.3378564417362213, 0.09678512066602707, 0.36165693402290344], [0.4840824007987976, 0.005611569620668888, 0.025787532329559326, 0.4840824007987976, 0.00043617573101073503], [0.004648699890822172, 0.4695408344268799, 0.03707568719983101, 0.019193971529603004, 0.4695408344268799], [0.0011294573778286576, 0.00992247648537159, 0.3139665126800537, 0.6650590896606445, 0.00992247648537159], [0.30972951650619507, 0.30972951650619507, 0.0008771020802669227, 0.002729540690779686, 0.376934289932251], [0.07247301936149597, 0.17777256667613983, 0.5372215509414673, 0.03476026654243469, 0.17777256667613983], [0.0481504462659359, 0.1172451600432396, 0.12885989248752594, 0.6575940251350403, 0.0481504462659359], [0.0027702327352017164, 0.8979578018188477, 0.03746228665113449, 0.024347415193915367, 0.03746228665113449], [0.03305748105049133, 0.267345666885376, 0.21924078464508057, 0.03305748105049133, 0.4472986161708832], [0.15017832815647125, 0.010154876857995987, 0.15017832815647125, 0.5981540679931641, 0.09133433550596237], [0.26182428002357483, 0.295627623796463, 0.1466560810804367, 0.00026441129739396274, 0.295627623796463], [0.16599860787391663, 0.052129343152046204, 0.10985077172517776, 0.052129343152046204, 0.6198919415473938], [0.37879762053489685, 0.37879762053489685, 0.0010296034161001444, 0.23169654607772827, 0.009678609669208527], [0.971632182598114, 0.008100580424070358, 0.016188982874155045, 0.0020391237922012806, 0.0020391237922012806], [0.7349135875701904, 0.020270150154829025, 0.020270150154829025, 0.011758582666516304, 0.21278753876686096], [0.08190248161554337, 0.08190248161554337, 0.26223644614219666, 0.5730059742927551, 0.000952547590713948], [0.0359310507774353, 0.7748202085494995, 0.021290818229317665, 0.13202694058418274, 0.0359310507774353], [0.6187247037887573, 0.01008796039968729, 0.024683788418769836, 0.17325176298618317, 0.17325176298618317], [0.022876350209116936, 0.004647320136427879, 0.3450627326965332, 0.6227662563323975, 0.004647320136427879], [0.056986648589372635, 0.10878169536590576, 0.21558846533298492, 0.49444326758384705, 0.12419990450143814], [0.9685978889465332, 0.017746148630976677, 0.005950295366346836, 0.001755330478772521, 0.005950295366346836], [9.685758413979784e-05, 0.020879680290818214, 0.9596371650695801, 9.685758413979784e-05, 0.019289379939436913], [0.26699376106262207, 0.31772518157958984, 0.26699376106262207, 0.011347400024533272, 0.13693992793560028], [0.21852731704711914, 0.003702049609273672, 0.6710703372955322, 0.10299825668334961, 0.003702049609273672], [0.007331605535000563, 0.05044296383857727, 0.14166124165058136, 0.05044296383857727, 0.7501212358474731], [0.027836525812745094, 0.03356880694627762, 0.08638753741979599, 0.8243705034255981, 0.027836525812745094], [0.21687573194503784, 0.32963231205940247, 0.11294339597225189, 0.010916242375969887, 0.32963231205940247], [0.011159799061715603, 0.00826436560600996, 0.011159799061715603, 0.8785130977630615, 0.09090295433998108], [0.31333214044570923, 0.029453039169311523, 0.3109644651412964, 0.03291824087500572, 0.31333214044570923], [0.5749667286872864, 0.07445994019508362, 0.17129583656787872, 0.007981617003679276, 0.17129583656787872], [0.0034672333858907223, 0.020707067102193832, 0.020707067102193832, 0.7652907371520996, 0.18982794880867004], [0.025563444942235947, 0.45470282435417175, 0.008942196145653725, 9.053904796019197e-05, 0.5107009410858154], [0.3668586015701294, 0.011755338869988918, 0.16251564025878906, 0.45431235432624817, 0.004558106418699026], [0.009758192114531994, 0.04389278218150139, 0.9252308011054993, 0.009758192114531994, 0.011359996162354946], [0.23022179305553436, 0.23022179305553436, 0.1305437982082367, 0.20518575608730316, 0.20382682979106903], [0.10425060242414474, 0.12535594403743744, 0.006202124059200287, 0.10425060242414474, 0.659940779209137], [0.0002613764372654259, 0.20356720685958862, 0.20356720685958862, 0.5857341885566711, 0.006870035547763109], [0.30449411273002625, 0.014553551562130451, 0.0017021577805280685, 0.6775479912757874, 0.0017021577805280685], [0.6416646838188171, 0.01222988124936819, 0.06669677048921585, 0.13970431685447693, 0.13970431685447693], [0.20975162088871002, 0.003766247071325779, 0.36447885632514954, 0.36447885632514954, 0.05752437561750412], [0.39929500222206116, 0.1421498954296112, 0.39929500222206116, 0.035410188138484955, 0.02384989522397518], [0.00033085557515732944, 0.28157421946525574, 0.33846718072891235, 0.37929683923721313, 0.00033085557515732944], [0.10024973750114441, 0.2815988063812256, 0.2815988063812256, 0.11488582193851471, 0.2216668426990509], [0.05026106536388397, 0.1178169846534729, 0.3915254473686218, 0.04887107014656067, 0.3915254473686218], [0.7684791088104248, 0.04727703332901001, 0.04727703332901001, 0.13687121868133545, 9.561560000292957e-05], [0.9966214895248413, 4.933675882057287e-05, 0.0002711348934099078, 4.933675882057287e-05, 0.0030086725018918514], [0.22699181735515594, 0.16633684933185577, 0.22699181735515594, 0.27046409249305725, 0.10921542346477509], [0.53255695104599, 0.01766340434551239, 0.01766340434551239, 0.1581849604845047, 0.2739312946796417], [0.029898639768362045, 0.001597176305949688, 0.7082188129425049, 0.25868818163871765, 0.001597176305949688], [0.5859091877937317, 0.05402263626456261, 0.12034834176301956, 0.05402263626456261, 0.1856972575187683], [0.4997017979621887, 0.049474652856588364, 0.3588486313819885, 0.042500220239162445, 0.049474652856588364], [0.014768961817026138, 0.05300895869731903, 0.4277176856994629, 0.07678671181201935, 0.4277176856994629], [2.37796066357987e-05, 0.01710672676563263, 0.42372238636016846, 0.01710672676563263, 0.5420403480529785], [0.20538392663002014, 0.004957876168191433, 0.7775100469589233, 0.007190290838479996, 0.004957876168191433], [0.1468389928340912, 0.01229162234812975, 0.7921524047851562, 0.011116379871964455, 0.03760061785578728], [0.18466021120548248, 0.07937249541282654, 0.02307758666574955, 0.3564448356628418, 0.3564448356628418], [0.0005336938775144517, 0.4228269159793854, 0.1892021745443344, 0.1892021745443344, 0.19823500514030457], [0.011727179400622845, 0.011727179400622845, 0.15857326984405518, 0.35548779368400574, 0.46248456835746765], [0.06642486900091171, 0.16697686910629272, 0.06642486900091171, 0.0002871900796890259, 0.6998862028121948], [0.007452294696122408, 0.013131163083016872, 0.6885975003242493, 0.28336670994758606, 0.007452294696122408], [0.015538210049271584, 0.14238755404949188, 0.1474069058895111, 0.1474069058895111, 0.5472604036331177], [0.04808911308646202, 0.029664304107427597, 0.6747356057167053, 0.19942183792591095, 0.04808911308646202], [0.4673004746437073, 0.4673004746437073, 0.0008777292678132653, 0.0026547047309577465, 0.06186657398939133], [0.337140828371048, 0.004013403784483671, 0.5960536599159241, 0.004013403784483671, 0.05877872183918953], [0.5833710432052612, 0.32408663630485535, 0.030865784734487534, 0.03081078641116619, 0.030865784734487534], [0.692736804485321, 0.08852489292621613, 0.036915212869644165, 0.036915212869644165, 0.1449078768491745], [0.0010081984801217914, 0.007820081897079945, 0.8966329097747803, 0.00013912891154177487, 0.09439960867166519], [0.19889822602272034, 0.16875389218330383, 0.3009912967681885, 0.16875389218330383, 0.1626027375459671], [0.03874540701508522, 0.3497023284435272, 0.24404050409793854, 0.3497023284435272, 0.017809418961405754], [0.26202449202537537, 0.6663816571235657, 0.042494550347328186, 0.014549658633768559, 0.014549658633768559], [0.04391934722661972, 0.08683636784553528, 0.6712089776992798, 0.11119890213012695, 0.08683636784553528], [0.020949939265847206, 0.023429211229085922, 0.35537463426589966, 0.35537463426589966, 0.24487163126468658], [0.002434368245303631, 0.3852788209915161, 0.07806681841611862, 0.3852788209915161, 0.14894120395183563], [0.004248455166816711, 0.000612045987509191, 0.3076101839542389, 0.6562767624855042, 0.03125256299972534], [0.6080647110939026, 0.012106431648135185, 0.1884785145521164, 0.1884785145521164, 0.0028718283865600824], [0.39293476939201355, 0.005472739692777395, 0.2647264301776886, 0.2647264301776886, 0.07213963568210602], [0.020295927301049232, 0.4629908800125122, 0.4919034242630005, 0.020295927301049232, 0.004513829946517944], [0.4238659739494324, 0.14546774327754974, 0.0015534410485997796, 0.4238659739494324, 0.00524682505056262], [0.4690217673778534, 0.0680944174528122, 0.0680944174528122, 0.29764559864997864, 0.09714387357234955], [0.01528793666511774, 4.9091086111729965e-05, 0.9810876250267029, 4.9091086111729965e-05, 0.0035262962337583303], [0.29605820775032043, 0.19339197874069214, 0.20248550176620483, 0.012006118893623352, 0.29605820775032043], [0.07662706822156906, 0.36514976620674133, 0.1443343460559845, 0.26955446600914, 0.1443343460559845], [0.22489309310913086, 0.16242511570453644, 0.5157380104064941, 0.04973980784416199, 0.04720399156212807], [0.03872337192296982, 0.03872337192296982, 0.08247332274913788, 0.5661270618438721, 0.2739528715610504], [0.485340416431427, 0.03140252083539963, 0.30939149856567383, 0.14246299862861633, 0.03140252083539963], [0.004365495406091213, 0.03928595408797264, 0.06766100972890854, 0.03928595408797264, 0.8494017124176025], [0.007838549092411995, 0.00015746598364785314, 0.4353773593902588, 0.12124934792518616, 0.4353773593902588], [0.5094917416572571, 0.0023304028436541557, 0.008945128880441189, 0.4769023358821869, 0.0023304028436541557], [0.024726880714297295, 0.04648960009217262, 0.8753976225852966, 0.05261540040373802, 0.0007705246680416167], [0.3921912908554077, 0.2427709996700287, 0.11772891879081726, 0.004537755623459816, 0.2427709996700287], [0.0878857746720314, 0.03477650135755539, 0.0878857746720314, 0.14770092070102692, 0.6417509913444519], [0.07357226312160492, 0.002878426341339946, 0.7533347606658936, 0.09664232283830643, 0.07357226312160492], [0.015915989875793457, 0.390318363904953, 0.010640417225658894, 0.1928068846464157, 0.390318363904953], [0.12281840294599533, 0.4285663962364197, 0.3242992162704468, 0.12281840294599533, 0.0014976034872233868], [0.0007587173022329807, 0.31557175517082214, 0.31557175517082214, 0.0012106647482141852, 0.36688703298568726], [0.029818208888173103, 0.40680766105651855, 0.0009884529281407595, 0.15557809174060822, 0.40680766105651855], [0.35112524032592773, 0.35112524032592773, 0.023496687412261963, 0.030205223709344864, 0.244047611951828], [0.21646621823310852, 0.625937819480896, 0.0007790987729094923, 0.1560378074645996, 0.0007790987729094923], [0.6734229326248169, 0.0009148890385404229, 0.0009148890385404229, 0.1519753485918045, 0.17277200520038605], [0.34640565514564514, 0.020173680037260056, 0.020173680037260056, 0.0009244140237569809, 0.6123225688934326], [0.0774458572268486, 0.39193323254585266, 0.16314680874347687, 0.16314680874347687, 0.2043273001909256], [0.4857926368713379, 0.4968279004096985, 0.006977988872677088, 0.005200735758990049, 0.005200735758990049], [0.28877362608909607, 0.004829804413020611, 0.00015811999037396163, 0.35311922430992126, 0.35311922430992126], [0.38255074620246887, 0.15604938566684723, 0.07696284353733063, 0.0018862624419853091, 0.38255074620246887], [0.47782212495803833, 0.26025909185409546, 0.00014909579476807266, 0.26025909185409546, 0.001510534668341279], [0.016966134309768677, 0.013523946516215801, 0.7772669792175293, 0.17527683079242706, 0.016966134309768677], [0.4186800718307495, 0.4186800718307495, 0.10405958443880081, 0.0042585814371705055, 0.05432170629501343], [1.9928080291720107e-05, 0.10663948953151703, 0.10663948953151703, 0.00031785888131707907, 0.7863832712173462], [0.007636505179107189, 0.005416510626673698, 0.5395980477333069, 0.007636505179107189, 0.43971240520477295], [0.005214017350226641, 0.9364391565322876, 0.0004489222774282098, 0.05744897946715355, 0.0004489222774282098], [0.09355802834033966, 0.10385926812887192, 0.0040250420570373535, 0.09355802834033966, 0.704999566078186], [0.12760379910469055, 0.07728541642427444, 0.07728541642427444, 0.5567776560783386, 0.16104766726493835], [0.23518946766853333, 0.001960196066647768, 0.001960196066647768, 0.7606075406074524, 0.00028255145298317075], [0.4031943380832672, 0.4031943380832672, 0.002692834474146366, 0.013075095601379871, 0.17784351110458374], [0.6827057003974915, 0.04777246341109276, 0.042452480643987656, 0.04777246341109276, 0.17929688096046448], [0.09353242069482803, 0.757003128528595, 0.09353242069482803, 0.023622261360287666, 0.03230984881520271], [0.132892444729805, 0.3528241813182831, 0.3528241813182831, 0.10869502276182175, 0.052764181047677994], [0.14235042035579681, 0.04211430624127388, 0.15958306193351746, 0.4963690936565399, 0.15958306193351746], [0.3803879916667938, 0.10366001725196838, 0.08533136546611786, 0.3803879916667938, 0.05023263394832611], [0.0961698368191719, 0.4095514714717865, 0.2993028163909912, 0.0961698368191719, 0.0988060012459755], [0.7019202709197998, 0.06213131919503212, 0.06213131919503212, 0.09900959581136703, 0.07480739802122116], [0.18462882936000824, 0.3183998465538025, 0.4244486093521118, 0.03626135364174843, 0.03626135364174843], [0.8016508221626282, 0.15525086224079132, 0.0037233075127005577, 0.0356518030166626, 0.0037233075127005577], [0.009119517169892788, 0.34027430415153503, 0.26383453607559204, 0.1229371428489685, 0.26383453607559204], [0.24665597081184387, 0.3624906837940216, 0.0007432301645167172, 0.027619371190667152, 0.3624906837940216], [0.02159922942519188, 0.14469014108181, 0.02159922942519188, 0.13843084871768951, 0.6736805438995361], [0.1306818127632141, 0.1306818127632141, 0.6822308897972107, 0.007997920736670494, 0.04840759187936783], [0.007706963922828436, 0.00014714826829731464, 0.03248369321227074, 0.00014714826829731464, 0.9595150351524353], [0.008179777301847935, 0.23762941360473633, 0.23762941360473633, 0.08978768438100815, 0.42677366733551025], [0.0002107646723743528, 0.27307218313217163, 0.13279005885124207, 0.29696348309516907, 0.29696348309516907], [0.033340245485305786, 0.006816179025918245, 0.4793410301208496, 0.0011615634430199862, 0.4793410301208496], [0.0122390016913414, 0.2340211123228073, 0.03344741091132164, 0.03344741091132164, 0.686845064163208], [0.11324389278888702, 0.11324389278888702, 0.6317682862281799, 0.08850032091140747, 0.05324355885386467], [0.0033421856351196766, 0.05233370140194893, 0.35155922174453735, 0.24120564758777618, 0.35155922174453735], [0.10928208380937576, 0.0020070665050297976, 0.3700729012489319, 0.14856502413749695, 0.3700729012489319], [0.035715654492378235, 0.9133419990539551, 0.01209817174822092, 0.01209817174822092, 0.026745960116386414], [0.8737245202064514, 0.016214026138186455, 0.018190983682870865, 0.04593522474169731, 0.04593522474169731], [0.1989239752292633, 0.11646097898483276, 0.3510153293609619, 0.21713872253894806, 0.11646097898483276], [0.31250789761543274, 0.07754678279161453, 0.033325210213661194, 0.033325210213661194, 0.5432949066162109], [0.5103421211242676, 0.12769457697868347, 0.16329163312911987, 0.03538002818822861, 0.16329163312911987], [0.2298150211572647, 0.0017331172712147236, 0.3840731680393219, 0.000305475783534348, 0.3840731680393219], [0.058733366429805756, 0.03858138620853424, 0.7237894535064697, 0.1403144747018814, 0.03858138620853424], [0.06058087944984436, 0.06058087944984436, 0.24995391070842743, 0.11244818568229675, 0.5164361596107483], [0.003960016183555126, 0.8138548135757446, 0.07320581376552582, 0.07320581376552582, 0.03577350452542305], [0.5840408802032471, 0.2969651222229004, 0.026245415210723877, 0.06650318950414658, 0.026245415210723877], [0.09328698366880417, 0.4454557001590729, 0.009112092666327953, 0.006689457688480616, 0.4454557001590729], [0.04995186999440193, 0.04995186999440193, 0.09203669428825378, 0.06982960551977158, 0.7382298707962036], [0.9644954800605774, 0.0008114793454296887, 0.0030547333881258965, 0.011473383754491806, 0.020164933055639267], [0.4241717457771301, 0.01336810551583767, 0.1550358533859253, 0.01336810551583767, 0.394056111574173], [0.025546306744217873, 0.4807012975215912, 0.008531985804438591, 0.0045190490782260895, 0.4807012975215912], [0.43043482303619385, 0.43043482303619385, 0.024452360346913338, 0.11460135132074356, 7.666189776500687e-05], [0.07407838851213455, 0.0526764802634716, 0.8159269094467163, 0.004641710314899683, 0.0526764802634716], [0.16749276220798492, 0.3721769452095032, 0.0036543323658406734, 0.3721769452095032, 0.08449897170066833], [0.0005502854473888874, 0.00797281228005886, 0.07664499431848526, 0.8381869792938232, 0.07664499431848526], [0.07215432822704315, 0.0960688591003418, 0.07215432822704315, 0.28825104236602783, 0.47137144207954407], [0.022911611944437027, 0.31024008989334106, 0.0010122102685272694, 0.6648238301277161, 0.0010122102685272694], [0.008541840128600597, 0.18542343378067017, 0.18542343378067017, 0.4992409646511078, 0.12137026339769363], [0.016870683059096336, 0.0019981844816356897, 0.016870683059096336, 0.037617042660713196, 0.9266433715820312], [0.9116654992103577, 0.0055919610895216465, 0.003344995900988579, 0.0760524794459343, 0.003344995900988579], [0.0006624683155678213, 0.4992937445640564, 0.0042268214747309685, 0.1681806594133377, 0.3276364207267761], [0.8822476863861084, 0.007839459925889969, 0.007839459925889969, 0.04750562831759453, 0.054567817598581314], [0.010621029883623123, 0.6760789155960083, 0.05215640738606453, 0.25052255392074585, 0.010621029883623123], [0.8935990929603577, 0.016323745250701904, 0.006777712609618902, 0.06697575002908707, 0.016323745250701904], [0.4731025993824005, 0.008297833614051342, 0.0377100370824337, 0.4731025993824005, 0.007786890957504511], [0.6032554507255554, 0.1225416511297226, 0.1335955411195755, 0.018065709620714188, 0.1225416511297226], [0.03024081513285637, 0.03024081513285637, 0.040326181799173355, 0.04551779106259346, 0.8536743521690369], [0.17028048634529114, 0.021586507558822632, 0.7212424278259277, 0.021586507558822632, 0.06530404090881348], [0.881704568862915, 0.022223221138119698, 0.0019961309153586626, 0.07185283303260803, 0.022223221138119698], [0.02361912466585636, 0.8521003723144531, 0.030020449310541153, 0.09158139675855637, 0.0026786495000123978], [0.015450462698936462, 0.009173978120088577, 0.000559394306037575, 0.9593657851219177, 0.015450462698936462], [0.2907104194164276, 0.3054122030735016, 0.09611225128173828, 0.01705467700958252, 0.2907104194164276], [0.01251571998000145, 0.027598323300480843, 0.0012565766228362918, 0.027598323300480843, 0.9310309886932373], [0.0005777711048722267, 0.2256489247083664, 0.2256489247083664, 0.5471680164337158, 0.000956352858338505], [0.0032828140538185835, 0.0032828140538185835, 0.021069452166557312, 0.010180828161537647, 0.9621840119361877], [0.18278926610946655, 0.18278926610946655, 0.04017309844493866, 0.07154887914657593, 0.5226995348930359], [0.047090839594602585, 0.06109273061156273, 0.020809248089790344, 0.1678565889596939, 0.7031506299972534], [0.48087629675865173, 0.008265983313322067, 0.02824760600924492, 0.0017337946919724345, 0.48087629675865173], [0.4351908266544342, 0.12619812786579132, 0.4351908266544342, 0.0026882390957325697, 0.0007319620926864445], [0.48298728466033936, 0.0008128613117150962, 0.03320038691163063, 0.48298728466033936, 1.2249784958839882e-05], [0.11766908317804337, 0.028199195861816406, 0.8259303569793701, 0.028199195861816406, 2.1984533304930665e-06], [0.18261505663394928, 0.5165615081787109, 0.03553494065999985, 0.03553494065999985, 0.22975358366966248], [0.00020822181249968708, 0.006447821855545044, 0.09700953960418701, 0.5279605388641357, 0.3683738708496094], [0.0037950139958411455, 0.22675396502017975, 0.025484107434749603, 0.5991039276123047, 0.14486292004585266], [0.10820707678794861, 0.2223651111125946, 0.11516627669334412, 0.2223651111125946, 0.3318963944911957], [0.11792971938848495, 0.3859843909740448, 0.0031662790570408106, 0.3859843909740448, 0.10693527013063431], [0.2415931224822998, 0.3279980421066284, 0.10131978243589401, 0.08749593049287796, 0.2415931224822998], [0.00011678444570861757, 0.017581485211849213, 0.00011678444570861757, 0.7976534366607666, 0.18453148007392883], [0.4208122789859772, 0.028712589293718338, 0.5342980027198792, 0.008088567294180393, 0.008088567294180393], [0.48182594776153564, 0.0008246808429248631, 0.48182594776153564, 0.03551080822944641, 1.2646974028029945e-05], [0.3777771592140198, 0.09657302498817444, 0.4214102327823639, 0.09657302498817444, 0.007666605059057474], [0.9608486294746399, 0.011153328232467175, 0.0022269785404205322, 0.011153328232467175, 0.01461788360029459], [0.4767194390296936, 0.0014143054140731692, 0.015864672139286995, 0.029282083734869957, 0.4767194390296936], [0.647968053817749, 0.002420365344733, 0.0025385951157659292, 0.0025385951157659292, 0.34453436732292175], [0.0018798231612890959, 0.0013614232884719968, 0.08049114793539047, 0.9143877625465393, 0.0018798231612890959], [0.3366044759750366, 0.3366044759750366, 0.204884871840477, 0.05268673598766327, 0.0692194253206253], [0.0022353711538016796, 0.060443416237831116, 0.16402801871299744, 0.3866465985774994, 0.3866465985774994], [0.22307293117046356, 0.22307293117046356, 0.06890682876110077, 0.34480300545692444, 0.14014433324337006], [0.0008692385163158178, 0.01244419813156128, 0.08965010941028595, 0.08965010941028595, 0.8073862791061401], [0.041848164051771164, 0.8221649527549744, 0.08296283334493637, 0.026512036100029945, 0.026512036100029945], [0.001114496961236, 0.4575638771057129, 0.4575638771057129, 0.08305314928293228, 0.0007045587990432978], [0.13001739978790283, 0.01782768778502941, 0.5124883651733398, 0.01782768778502941, 0.3218388259410858], [0.40683746337890625, 0.15794934332370758, 0.00026332272682338953, 0.40683746337890625, 0.02811240591108799], [0.39544692635536194, 0.0383034273982048, 0.0383034273982048, 0.26726505160331726, 0.2606811225414276], [0.012574904598295689, 0.061898622661828995, 0.05521135404706001, 0.05521135404706001, 0.8151037096977234], [0.07180768996477127, 0.07180768996477127, 9.954379493137822e-05, 0.7490535974502563, 0.107231505215168], [0.008216295391321182, 0.010523463599383831, 0.688442051410675, 0.28748995065689087, 0.005328238010406494], [0.0027155817952007055, 0.3425457775592804, 0.00048502188292331994, 0.31170788407325745, 0.3425457775592804], [0.0008742231293581426, 0.2872885763645172, 0.5426087379455566, 0.16835424304008484, 0.0008742231293581426], [0.30707627534866333, 0.0030848353635519743, 0.34160086512565613, 0.04116173833608627, 0.30707627534866333], [0.4041156768798828, 0.34746766090393066, 0.018810410052537918, 0.21079590916633606, 0.018810410052537918], [0.019906219094991684, 0.08492367714643478, 0.1902587115764618, 0.3524557054042816, 0.3524557054042816], [0.005876309238374233, 0.31167206168174744, 0.037387553602457047, 0.33339205384254456, 0.31167206168174744], [0.20606666803359985, 0.27065959572792053, 0.27308008074760437, 0.04412694647908211, 0.20606666803359985], [0.012286785989999771, 0.0005042416742071509, 0.012286785989999771, 0.00338873453438282, 0.9715334177017212], [0.7013117074966431, 0.0006191916763782501, 0.265200138092041, 0.0006191916763782501, 0.032249756157398224], [0.9295035600662231, 0.016121653839945793, 0.03574009984731674, 0.016121653839945793, 0.002513058017939329], [0.01186788734048605, 0.01432882435619831, 0.01432882435619831, 0.5659025311470032, 0.39357197284698486], [0.17836397886276245, 0.04222338646650314, 0.04222338646650314, 0.6113804578781128, 0.12580882012844086], [0.34005802869796753, 0.004669978283345699, 0.007459509186446667, 0.007459509186446667, 0.6403529644012451], [0.015159176662564278, 0.6112575531005859, 0.004161326214671135, 0.3300416171550751, 0.03938040882349014], [0.07959942519664764, 0.005103748291730881, 0.729334831237793, 0.07959942519664764, 0.10636256635189056], [0.00047607129090465605, 0.0004446351376827806, 0.0004446351376827806, 0.08516589552164078, 0.9134687185287476], [0.0073344712145626545, 0.4205750823020935, 0.5270251631736755, 0.037730805575847626, 0.0073344712145626545], [0.04853333905339241, 0.20870007574558258, 0.6651068329811096, 0.029126401990652084, 0.04853333905339241], [0.9424607157707214, 0.025194436311721802, 0.004049346316605806, 0.025194436311721802, 0.0031011165119707584], [0.08433964103460312, 0.7485196590423584, 0.00815424695611, 0.00815424695611, 0.15083223581314087], [0.01630021445453167, 0.6701341867446899, 0.2855638861656189, 0.01630021445453167, 0.011701465584337711], [0.1027887687087059, 0.001049581915140152, 0.2611103355884552, 0.37394100427627563, 0.2611103355884552], [0.32446202635765076, 0.004486147314310074, 0.32446202635765076, 0.344084769487381, 0.0025049869436770678], [0.061723195016384125, 0.6480916142463684, 0.04960896819829941, 0.19096729159355164, 0.04960896819829941], [0.3670211434364319, 0.21274933218955994, 0.3670211434364319, 0.0007078012567944825, 0.05250059813261032], [0.14344099164009094, 0.0012500048615038395, 0.14344099164009094, 0.6776926517486572, 0.03417531028389931], [0.03140163794159889, 0.028836242854595184, 0.44495776295661926, 0.4659680724143982, 0.028836242854595184], [0.3507976233959198, 0.3875225782394409, 0.22649343311786652, 0.01759321056306362, 0.01759321056306362], [0.001694382051937282, 0.001694382051937282, 0.2618016302585602, 0.7192390561103821, 0.015570523217320442], [0.8224466443061829, 0.008756042458117008, 0.07505564391613007, 0.018686020746827126, 0.07505564391613007], [0.0713261142373085, 0.43489113450050354, 0.05027342960238457, 0.19786779582500458, 0.2456415593624115], [0.00035021943040192127, 0.16995759308338165, 0.5355042219161987, 0.00035021943040192127, 0.2938377857208252], [0.00024403077259194106, 0.017339428886771202, 0.43796271085739136, 0.43796271085739136, 0.10649115592241287], [0.04625778645277023, 0.5932194590568542, 0.07966984808444977, 0.04625778645277023, 0.23459510505199432], [0.35434237122535706, 0.003574100788682699, 0.35434237122535706, 0.013155641965568066, 0.274585485458374], [0.052922435104846954, 0.02955484390258789, 0.06467627733945847, 0.06467627733945847, 0.7881701588630676], [0.11277850717306137, 0.36434152722358704, 0.36434152722358704, 0.05798878148198128, 0.10054969042539597], [0.025496041402220726, 0.06901119649410248, 0.8675333857536316, 0.012463301420211792, 0.025496041402220726], [0.22103339433670044, 0.22103339433670044, 0.5509225726127625, 0.0003196847974322736, 0.006690968293696642], [0.30200228095054626, 0.03221398591995239, 0.30200228095054626, 0.3636234998703003, 0.00015794856881257147], [0.6347087621688843, 0.0018255604663863778, 0.046841755509376526, 0.0018255604663863778, 0.3147982954978943], [0.1651468276977539, 0.5975295305252075, 0.002425477374345064, 0.11744910478591919, 0.11744910478591919], [0.21191421151161194, 0.11459935456514359, 0.31698209047317505, 0.11459935456514359, 0.24190500378608704], [0.03964713588356972, 0.2570905387401581, 0.03964713588356972, 0.11169014871120453, 0.551925003528595], [0.28426799178123474, 0.28426799178123474, 0.3693982660770416, 0.031987808644771576, 0.030077945441007614], [0.0012480909936130047, 0.21666373312473297, 0.21666373312473297, 0.05039643868803978, 0.5150279402732849], [0.2528761029243469, 0.2700241208076477, 0.21706795692443848, 0.2528761029243469, 0.007155719678848982], [0.00218351767398417, 0.6586736440658569, 0.13781696557998657, 0.13781696557998657, 0.06350897252559662], [0.2790544629096985, 0.3428836166858673, 0.08083921670913696, 0.12645447254180908, 0.17076821625232697], [0.010534029453992844, 0.010534029453992844, 0.03831827640533447, 0.3768186867237091, 0.5637949705123901], [0.16498920321464539, 0.028808139264583588, 0.019566502422094345, 0.3933180868625641, 0.3933180868625641], [0.015973107889294624, 0.06780126690864563, 0.035184599459171295, 0.4405204951763153, 0.4405204951763153], [0.009668460115790367, 0.2535151541233063, 0.6000524759292603, 0.12709538638591766, 0.009668460115790367], [0.3049052357673645, 0.3419824540615082, 0.3419824540615082, 0.0023201515432447195, 0.008809744380414486], [0.0038331602700054646, 0.29043689370155334, 0.015050865709781647, 0.4002421796321869, 0.29043689370155334], [0.04559699073433876, 0.7353332042694092, 0.052145443856716156, 0.0834621861577034, 0.0834621861577034], [0.3605402410030365, 0.19782474637031555, 0.06279917061328888, 0.018295656889677048, 0.3605402410030365], [0.0017198201967403293, 0.3710545301437378, 0.0004775549750775099, 0.2556934952735901, 0.3710545301437378], [0.03560255840420723, 0.11166103184223175, 0.03560255840420723, 0.7625390291213989, 0.054594751447439194], [0.03206109628081322, 0.6177698373794556, 0.24296389520168304, 0.03206109628081322, 0.07514408975839615], [0.04537612944841385, 0.5432895421981812, 0.3235207200050354, 0.042437486350536346, 0.04537612944841385], [0.5734265446662903, 0.07742678374052048, 0.08628951013088226, 0.08628951013088226, 0.17656759917736053], [0.009872146882116795, 0.009872146882116795, 0.0012174771400168538, 0.7345506548881531, 0.24448756873607635], [0.1510615199804306, 0.01611088216304779, 0.026576580479741096, 0.1510615199804306, 0.6551894545555115], [0.27157166600227356, 0.17460720241069794, 0.30299749970436096, 0.0762164369225502, 0.17460720241069794], [0.007858259603381157, 0.04374073073267937, 0.6593084931373596, 0.04374073073267937, 0.24535180628299713], [0.4885958731174469, 0.0010038797045126557, 0.004907657857984304, 0.016896681860089302, 0.4885958731174469], [0.03578567877411842, 0.367757648229599, 0.22759218513965607, 0.367757648229599, 0.0011067948071286082], [0.15998007357120514, 0.5810995101928711, 0.24732989072799683, 0.007216171361505985, 0.004374342039227486], [0.4524891674518585, 0.4524891674518585, 0.05938694253563881, 0.004059325437992811, 0.03157539293169975], [0.13180597126483917, 0.11144369095563889, 0.573133111000061, 0.0667441114783287, 0.11687310039997101], [0.02362135425209999, 0.26394835114479065, 0.2398432195186615, 0.2398432195186615, 0.23274384438991547], [0.41516804695129395, 0.05612020939588547, 0.41516804695129395, 0.050822123885154724, 0.06272156536579132], [0.015728607773780823, 0.25601527094841003, 0.015728607773780823, 0.4312414228916168, 0.2812861204147339], [0.2743634581565857, 0.2423403263092041, 0.03772576153278351, 0.2032301276922226, 0.2423403263092041], [0.47780755162239075, 0.2477288693189621, 0.010232808999717236, 0.2477288693189621, 0.016501914709806442], [0.039684172719717026, 0.0055533526465296745, 0.12933489680290222, 0.41271376609802246, 0.41271376609802246], [0.9372320175170898, 0.001794499927200377, 0.0020091955084353685, 0.05695514753460884, 0.0020091955084353685], [0.1569027453660965, 0.21410715579986572, 0.13152243196964264, 0.21410715579986572, 0.28336048126220703], [0.5017955303192139, 0.34977784752845764, 0.039837878197431564, 0.003625095123425126, 0.10496367514133453], [0.02134956419467926, 0.015317401848733425, 0.02134956419467926, 0.6097849607467651, 0.3321985602378845], [0.2980499267578125, 0.2547207772731781, 0.030201228335499763, 0.08620892465114594, 0.33081910014152527], [9.22916478884872e-06, 0.10210534930229187, 0.6797211766242981, 0.21815501153469086, 9.22916478884872e-06], [0.00546655198559165, 0.2839823365211487, 0.21443207561969757, 0.4906524121761322, 0.00546655198559165], [0.001712872995994985, 0.027852367609739304, 0.02007642760872841, 0.02007642760872841, 0.930281937122345], [0.001014025299809873, 0.001014025299809873, 0.026923857629299164, 9.767594747245312e-05, 0.9709503650665283], [0.059661123901605606, 0.11975978314876556, 0.613365113735199, 0.11975978314876556, 0.0874541774392128], [0.013099605217576027, 0.3762407898902893, 0.5432919263839722, 0.013099605217576027, 0.054268065840005875], [0.23216219246387482, 0.30172353982925415, 0.056411776691675186, 0.20485123991966248, 0.20485123991966248], [0.023509306833148003, 0.06598643213510513, 0.22991843521595, 0.6570765376091003, 0.023509306833148003], [0.019098058342933655, 0.04462606459856033, 0.45265042781829834, 0.45265042781829834, 0.03097507730126381], [0.0016414772253483534, 0.09299883246421814, 0.07475554198026657, 0.8289626836776733, 0.0016414772253483534], [0.011863473802804947, 0.00045253016287460923, 0.0025904003996402025, 0.916115939617157, 0.06897757947444916], [0.1062854751944542, 0.4216879606246948, 0.3524183928966522, 0.013322755694389343, 0.1062854751944542], [0.2510432004928589, 0.2510432004928589, 0.0922890454530716, 0.05389287322759628, 0.35173162817955017], [0.1592961549758911, 0.25473034381866455, 0.2699892222881317, 0.06125391274690628, 0.25473034381866455], [0.35491567850112915, 0.022186383605003357, 0.022186383605003357, 0.2036130428314209, 0.39709845185279846], [0.006807933561503887, 0.1408247947692871, 0.6686493158340454, 0.1408247947692871, 0.04289311543107033], [0.454382985830307, 0.0681827962398529, 0.006566325202584267, 0.016484959051012993, 0.454382985830307], [0.2795090675354004, 0.05115058273077011, 0.38943642377853394, 0.2795090675354004, 0.00039484657463617623], [0.08021850883960724, 0.33931851387023926, 0.06187312677502632, 0.06187312677502632, 0.45671671628952026], [0.032857246696949005, 0.003800639184191823, 0.9094448089599609, 0.0032852059230208397, 0.05061212182044983], [0.0020818011835217476, 0.09065809845924377, 0.09065809845924377, 0.12989670038223267, 0.6867052912712097], [0.013513519428670406, 0.008902893401682377, 0.6934678554534912, 0.013513519428670406, 0.2706022262573242], [0.7455024123191833, 0.0008243608754128218, 0.0008243608754128218, 0.1696523129940033, 0.08319652825593948], [0.14074960350990295, 0.5445284247398376, 0.15341120958328247, 0.15900753438472748, 0.0023032422177493572], [0.6736400723457336, 0.08073429763317108, 0.11217968910932541, 0.11217968910932541, 0.021266283467411995], [0.05854747071862221, 0.025317436084151268, 0.20456436276435852, 0.20456436276435852, 0.5070063471794128], [0.0018058845307677984, 0.15045033395290375, 0.8473564982414246, 0.00019362580496817827, 0.00019362580496817827], [0.138590008020401, 0.07421219348907471, 0.00028948814724572003, 0.138590008020401, 0.6483182311058044], [0.10759709030389786, 0.36983180046081543, 0.36983180046081543, 0.1494210958480835, 0.0033181572798639536], [0.0030957763083279133, 0.22468698024749756, 0.01765626296401024, 0.0030957763083279133, 0.7514652609825134], [0.47308042645454407, 0.006411267444491386, 0.028520403429865837, 0.018907571211457253, 0.47308042645454407], [0.012664400972425938, 0.027588531374931335, 0.027588531374931335, 0.0023788963444530964, 0.929779589176178], [0.5111799240112305, 0.25643831491470337, 0.0015583074418827891, 0.10382445156574249, 0.12699899077415466], [0.16572581231594086, 0.11975220590829849, 0.31960323452949524, 0.31960323452949524, 0.07531551271677017], [0.3717421889305115, 0.1888098567724228, 0.0004032314755022526, 0.2195223569869995, 0.2195223569869995], [0.09979812800884247, 0.17259985208511353, 0.5461987853050232, 0.17259985208511353, 0.00880335085093975], [0.12926462292671204, 4.028754119644873e-06, 0.29643872380256653, 0.27785390615463257, 0.29643872380256653], [0.004505848977714777, 0.11504263430833817, 0.5567425489425659, 0.3222939372062683, 0.001415026606991887], [0.5687447786331177, 0.0009592141723260283, 0.12936139106750488, 0.17157313227653503, 0.12936139106750488], [0.7693654894828796, 0.014684531837701797, 0.014684531837701797, 0.07752549648284912, 0.12373990565538406], [0.06547383219003677, 0.11288894712924957, 0.19980654120445251, 0.11288894712924957, 0.5089417695999146], [0.017419913783669472, 0.003898235969245434, 0.07714316993951797, 0.9012836813926697, 0.0002549661439843476], [0.3028923273086548, 0.31785446405410767, 0.0699760690331459, 0.3028923273086548, 0.006384852807968855], [0.015701953321695328, 0.02160472981631756, 0.9388018846511841, 0.01194570679217577, 0.01194570679217577], [0.17977802455425262, 0.12219062447547913, 0.17977802455425262, 0.4406734108924866, 0.07757999002933502], [0.38738352060317993, 0.38738352060317993, 0.011242981068789959, 0.15185464918613434, 0.06213534250855446], [0.4623739719390869, 0.001477611716836691, 0.048974521458148956, 0.024799834936857224, 0.4623739719390869], [0.07205605506896973, 0.03569294884800911, 0.40438005328178406, 0.2439354807138443, 0.2439354807138443], [0.3895842432975769, 0.04886477440595627, 0.2795950472354889, 0.0023609092459082603, 0.2795950472354889], [0.0353328138589859, 0.0901804193854332, 0.19276946783065796, 0.4889478385448456, 0.19276946783065796], [0.12494263797998428, 0.295928955078125, 0.295928955078125, 0.17958325147628784, 0.1036161556839943], [0.04206353425979614, 0.3181772828102112, 0.3129766285419464, 0.013805985450744629, 0.3129766285419464], [0.23929058015346527, 0.16707898676395416, 0.16707898676395416, 0.208806574344635, 0.21774479746818542], [0.3949083387851715, 0.3949083387851715, 0.19542427361011505, 0.006832174025475979, 0.007926910184323788], [0.22708778083324432, 0.07100723683834076, 0.1786981225013733, 0.2616034150123596, 0.2616034150123596], [0.013203141279518604, 0.3305903375148773, 0.15313167870044708, 0.013203141279518604, 0.48987171053886414], [0.5770334005355835, 0.010130845010280609, 0.010130845010280609, 0.38848721981048584, 0.014217661693692207], [0.19111251831054688, 0.030770283192396164, 0.19111251831054688, 0.3875175416469574, 0.1994870901107788], [0.7070733308792114, 0.13137173652648926, 0.07161103188991547, 0.04497191682457924, 0.04497191682457924], [0.09177255630493164, 0.5466706156730652, 0.24829833209514618, 0.09177255630493164, 0.021485893055796623], [0.18796014785766602, 0.005192078184336424, 0.4062720537185669, 0.18796014785766602, 0.21261562407016754], [0.0602184422314167, 0.9017007946968079, 0.010204820893704891, 0.01767115294933319, 0.010204820893704891], [0.16389019787311554, 0.26746508479118347, 0.04409701004624367, 0.16389019787311554, 0.36065757274627686], [0.7272297143936157, 0.003259812481701374, 5.5409724154742435e-05, 5.5409724154742435e-05, 0.26939961314201355], [0.3062814772129059, 0.3062814772129059, 0.011540316045284271, 0.33161816000938416, 0.04427862912416458], [0.00784437358379364, 0.2551358938217163, 0.14807112514972687, 0.00784437358379364, 0.5811043381690979], [0.6269397735595703, 0.18077853322029114, 0.08535843342542648, 0.08535843342542648, 0.021564863622188568], [0.0042581381276249886, 0.07771556079387665, 0.00328639498911798, 0.9114534854888916, 0.00328639498911798], [0.06533898413181305, 0.817257821559906, 0.04104665666818619, 0.011017550714313984, 0.06533898413181305], [0.3046685755252838, 0.35252898931503296, 0.00023178124683909118, 0.3046685755252838, 0.0379020981490612], [0.35348600149154663, 0.0022682109847664833, 0.14502976834774017, 0.14573004841804504, 0.35348600149154663], [0.006468213628977537, 0.006468213628977537, 0.0975537821650505, 0.10937797278165817, 0.7801318764686584], [0.004143234342336655, 0.4633156657218933, 0.06379663199186325, 0.4633156657218933, 0.005428831093013287], [0.06876321882009506, 0.19464413821697235, 0.29979702830314636, 0.13699860870838165, 0.29979702830314636], [0.24639572203159332, 0.25033944845199585, 0.0435216948390007, 0.25033944845199585, 0.20940369367599487], [0.3040187358856201, 0.008090291172266006, 0.033763591200113297, 0.008090291172266006, 0.6460371017456055], [0.21354229748249054, 0.5154364705085754, 0.042055949568748474, 0.015422934666275978, 0.21354229748249054], [0.065717913210392, 0.0012618355685845017, 0.7674949169158936, 0.007371566258370876, 0.15815375745296478], [0.016829784959554672, 0.33899667859077454, 0.2896836996078491, 0.33899667859077454, 0.015493129380047321], [0.34496045112609863, 0.03662271052598953, 0.1134529709815979, 0.03662271052598953, 0.4683411419391632], [0.058395691215991974, 0.058395691215991974, 0.5217981338500977, 0.3181432783603668, 0.043267205357551575], [0.035944581031799316, 0.8075631260871887, 0.01973547227680683, 0.01973547227680683, 0.117021344602108], [0.2693091332912445, 0.2693091332912445, 0.007341716904193163, 0.08897846192121506, 0.3650616407394409], [0.0637575164437294, 0.16883181035518646, 0.3825729787349701, 0.0022647096775472164, 0.3825729787349701], [0.05990990251302719, 0.00596198532730341, 0.4656234085559845, 0.002881296444684267, 0.4656234085559845], [0.2544626295566559, 0.4499146342277527, 0.10329373925924301, 0.09616453945636749, 0.09616453945636749], [0.05347331240773201, 0.7790772318840027, 0.030378228053450584, 0.09235644340515137, 0.04471489042043686], [0.4636455774307251, 0.0041348617523908615, 0.059916164726018906, 0.4636455774307251, 0.008657789789140224], [0.018601005896925926, 0.014134076423943043, 0.004829589277505875, 0.9576057195663452, 0.004829589277505875], [0.14808064699172974, 0.6560694575309753, 0.0717492327094078, 0.05235138535499573, 0.0717492327094078], [0.17144259810447693, 0.17144259810447693, 0.23887899518013, 0.354655921459198, 0.06357987970113754], [6.911457603564486e-05, 0.004648119211196899, 0.7744424343109131, 6.911457603564486e-05, 0.22077123820781708], [0.0419154167175293, 0.26720160245895386, 0.0006629754789173603, 0.26720160245895386, 0.4230184555053711], [0.07676675915718079, 0.07766976952552795, 0.8202659487724304, 0.012648777104914188, 0.012648777104914188], [0.060167137533426285, 0.26288846135139465, 0.26288846135139465, 0.018527138978242874, 0.3955288231372833], [0.4887368977069855, 0.0016100953798741102, 0.4887368977069855, 0.0021692521404474974, 0.01874678023159504], [0.6299981474876404, 0.00010425009531900287, 0.17845331132411957, 0.17845331132411957, 0.012990961782634258], [0.11064182966947556, 0.3175533413887024, 0.02602441795170307, 0.5197559595108032, 0.02602441795170307], [0.44969412684440613, 0.06426092982292175, 0.18108893930912018, 0.18108893930912018, 0.12386699765920639], [0.2447822540998459, 0.23332150280475616, 0.23332150280475616, 0.25727441906929016, 0.03130034729838371], [0.20470726490020752, 0.00159804942086339, 0.03381063789129257, 0.7260734438896179, 0.03381063789129257], [0.10061529278755188, 0.43166765570640564, 0.00011146446195198223, 0.035937998443841934, 0.43166765570640564], [0.37086671590805054, 0.0074560195207595825, 0.2287861555814743, 0.022024445235729218, 0.37086671590805054], [0.11294379830360413, 0.3579268455505371, 0.021365074440836906, 0.3948204517364502, 0.11294379830360413], [0.42454540729522705, 0.08176048845052719, 0.42454540729522705, 0.016296913847327232, 0.05285172909498215], [0.004172421991825104, 0.2054840475320816, 0.4887518286705017, 0.09610764682292938, 0.2054840475320816], [0.01852528378367424, 0.13747452199459076, 0.6834049820899963, 0.08029759675264359, 0.08029759675264359], [0.025008700788021088, 0.47313180565834045, 0.1797352135181427, 0.29711565375328064, 0.025008700788021088], [0.06290818005800247, 0.35221293568611145, 0.42509883642196655, 0.09687191247940063, 0.06290818005800247], [0.11934766173362732, 0.11934766173362732, 0.7103530764579773, 0.04813384637236595, 0.00281781074590981], [0.43449804186820984, 0.004762545693665743, 0.08351247757673264, 0.43449804186820984, 0.042728882282972336], [0.48917850852012634, 0.48917850852012634, 0.0136130815371871, 0.00791703537106514, 0.00011288295354461297], [0.36888736486434937, 0.18402472138404846, 0.015859713777899742, 0.4153684973716736, 0.015859713777899742], [0.4396457374095917, 0.10017328709363937, 0.017423201352357864, 0.003111967584118247, 0.4396457374095917], [0.21534670889377594, 0.36043456196784973, 0.0397910512983799, 0.0397910512983799, 0.34463661909103394], [0.7667163014411926, 0.03490552306175232, 0.024418171495199203, 0.024418171495199203, 0.14954182505607605], [0.6234786510467529, 1.3721710274694487e-05, 0.18700672686100006, 0.18700672686100006, 0.002494179643690586], [0.03484637290239334, 0.08054906129837036, 0.14918090403079987, 0.08054906129837036, 0.6548745632171631], [0.055922042578458786, 0.16031907498836517, 0.004581028129905462, 0.0017709952080622315, 0.7774068117141724], [0.18870894610881805, 0.0011122585274279118, 0.18870894610881805, 0.05963010713458061, 0.561839759349823], [0.03223931044340134, 0.08821086585521698, 0.03223931044340134, 0.14847220480442047, 0.6988383531570435], [0.767795205116272, 0.024279391393065453, 0.027891546487808228, 0.09001694619655609, 0.09001694619655609], [0.009181376546621323, 0.0014327645767480135, 0.018580757081508636, 0.48540252447128296, 0.48540252447128296], [0.06805633008480072, 0.08837149292230606, 0.08585745841264725, 0.08585745841264725, 0.6718572974205017], [0.027292709797620773, 0.034259404987096786, 0.00952001940459013, 0.46446388959884644, 0.46446388959884644], [0.346535325050354, 0.3035270869731903, 0.0009405558812431991, 0.346535325050354, 0.002461740979924798], [0.08536054193973541, 0.014347967691719532, 0.7986599802970886, 0.016270944848656654, 0.08536054193973541], [0.07133330404758453, 0.019894428551197052, 0.43924394249916077, 0.43924394249916077, 0.030284376814961433], [0.06815145909786224, 0.01343642920255661, 0.06815145909786224, 0.037517085671424866, 0.8127435445785522], [0.07198464870452881, 0.01272520050406456, 0.00041383752250112593, 0.4574381709098816, 0.4574381709098816], [0.48347240686416626, 0.0007930133142508566, 0.029083814471960068, 0.47642141580581665, 0.010229328647255898], [0.0030047555919736624, 0.06283833086490631, 0.46626394987106323, 0.001628970610909164, 0.46626394987106323], [0.03018871694803238, 0.4098397493362427, 0.29254913330078125, 0.003478818340227008, 0.26394349336624146], [0.020941004157066345, 0.08368439227342606, 0.5687310695648193, 0.30570247769355774, 0.020941004157066345], [0.18110433220863342, 0.045227330178022385, 0.08342128247022629, 0.3451235294342041, 0.3451235294342041], [0.006551035214215517, 0.0247789416462183, 0.303397536277771, 0.303397536277771, 0.3618749976158142], [0.26252487301826477, 0.26252487301826477, 0.19086377322673798, 0.28112491965293884, 0.002961565973237157], [0.275066077709198, 0.5863890051841736, 0.03787612169981003, 0.03787612169981003, 0.06279266625642776], [0.011588859371840954, 0.3195655643939972, 0.018466399982571602, 0.6319127678871155, 0.018466399982571602], [0.0011716276640072465, 0.40664297342300415, 0.5839151740074158, 0.0070985425263643265, 0.0011716276640072465], [0.021259797737002373, 0.021259797737002373, 0.06327777355909348, 0.0176786407828331, 0.8765239715576172], [0.8069078326225281, 0.002353534335270524, 0.08302735537290573, 0.08302735537290573, 0.02468390017747879], [0.029777158051729202, 0.10145370662212372, 0.022817140445113182, 0.7444982528686523, 0.10145370662212372], [0.8285514116287231, 0.002439670031890273, 0.0004231884377077222, 0.16816246509552002, 0.0004231884377077222], [0.01731136068701744, 0.07703687995672226, 0.17198197543621063, 0.6566329598426819, 0.07703687995672226], [0.5432769060134888, 0.00014852682943455875, 0.00014852682943455875, 0.0434320792555809, 0.4129939377307892], [0.22239844501018524, 0.22239844501018524, 0.005438860505819321, 0.5423855185508728, 0.007378803100436926], [0.3018789291381836, 0.00871380977332592, 0.3018789291381836, 0.024713613092899323, 0.36281469464302063], [0.00016886746743693948, 0.004064589738845825, 0.00016886746743693948, 0.9277411699295044, 0.06785646826028824], [0.3559496998786926, 0.3559496998786926, 0.19835372269153595, 0.004635446704924107, 0.08511146903038025], [0.0032746584620326757, 0.03183300420641899, 0.9604007601737976, 0.0012169111287221313, 0.0032746584620326757], [0.0659346953034401, 0.06421171128749847, 0.49111559987068176, 0.18936897814273834, 0.18936897814273834], [0.6880286931991577, 0.03722183406352997, 0.12604063749313354, 0.12604063749313354, 0.022668229416012764], [0.46091750264167786, 0.07260484993457794, 0.0008206338388845325, 0.46091750264167786, 0.00473954388871789], [0.04949568957090378, 0.24578852951526642, 0.04949568957090378, 0.6079971194267273, 0.04722299054265022], [0.07751066982746124, 0.04148886352777481, 0.6088377833366394, 0.19465205073356628, 0.07751066982746124], [0.06341743469238281, 0.003277087351307273, 0.26960036158561707, 0.06341743469238281, 0.600287675857544], [0.5638301968574524, 0.43131470680236816, 2.1739411749877036e-05, 0.0024166691582649946, 0.0024166691582649946], [0.16219300031661987, 0.09838441014289856, 0.5243749618530273, 0.09838441014289856, 0.11666325479745865], [0.004682547878473997, 0.008534073829650879, 0.004682547878473997, 0.007976140826940536, 0.9741247296333313], [0.15363474190235138, 0.670009434223175, 0.15363474190235138, 0.01196849625557661, 0.010752592235803604], [0.021984459832310677, 0.021984459832310677, 0.230193629860878, 0.15770137310028076, 0.5681360363960266], [0.8002187013626099, 0.0021924476604908705, 0.11277700215578079, 0.08261942863464355, 0.0021924476604908705], [0.22841106355190277, 0.357991486787796, 0.22841106355190277, 0.004893739707767963, 0.18029259145259857], [0.03158489614725113, 0.0037320286501199007, 0.7797912955284119, 0.15330693125724792, 0.03158489614725113], [0.8128616809844971, 0.07383716106414795, 0.002600121544674039, 0.07383716106414795, 0.03686392307281494], [0.0044848923571407795, 0.02229013293981552, 0.02229013293981552, 0.921463131904602, 0.029471680521965027], [0.5439556837081909, 0.05833388492465019, 0.0012149167014285922, 0.005423496011644602, 0.39107200503349304], [0.07100676000118256, 0.034275904297828674, 0.8056030869483948, 0.034275904297828674, 0.054838359355926514], [0.06477480381727219, 0.0012492465320974588, 0.02360043302178383, 0.0012492465320974588, 0.9091262817382812], [0.27031219005584717, 0.047775495797395706, 0.047775495797395706, 0.6283885836601257, 0.005748271010816097], [0.02393880859017372, 0.2604179382324219, 0.02500162273645401, 0.34532079100608826, 0.34532079100608826], [0.4369053542613983, 0.47425562143325806, 0.04173939302563667, 0.02354980818927288, 0.02354980818927288], [0.1023620143532753, 0.00468810647726059, 0.04052697494626045, 0.426211416721344, 0.426211416721344], [0.7120637893676758, 0.04942291975021362, 0.05104374885559082, 0.13804662227630615, 0.04942291975021362], [0.4460042119026184, 0.27520883083343506, 0.27520883083343506, 0.0007688085897825658, 0.002809239085763693], [0.4619162976741791, 0.4619162976741791, 0.06475983560085297, 0.0005509729380719364, 0.010856586508452892], [0.03373895213007927, 0.9192761182785034, 0.01103742141276598, 0.002208625664934516, 0.03373895213007927], [0.25657153129577637, 0.4658006727695465, 0.0007882602512836456, 0.27605128288269043, 0.0007882602512836456], [0.02419283241033554, 0.47594937682151794, 0.02419283241033554, 0.43862080574035645, 0.03704414516687393], [0.058627258986234665, 0.0691993236541748, 0.12072302401065826, 0.058627258986234665, 0.6928231120109558], [0.31759077310562134, 0.09720522910356522, 0.09630676358938217, 0.24444858729839325, 0.24444858729839325], [0.7370933890342712, 0.04136095568537712, 0.023270120844244957, 0.09913777559995651, 0.09913777559995651], [0.14832758903503418, 0.5191742777824402, 0.14832758903503418, 0.005029668100178242, 0.17914092540740967], [0.01153245847672224, 0.0018657405162230134, 0.9779115319252014, 0.007303150836378336, 0.0013871181290596724], [0.4496573209762573, 0.044583454728126526, 0.4607820510864258, 0.044583454728126526, 0.00039364147232845426], [0.421108603477478, 0.09580962359905243, 0.042567964643239975, 0.421108603477478, 0.019405260682106018], [0.0026206551119685173, 0.050358183681964874, 0.17221331596374512, 0.24894823133945465, 0.5258595943450928], [0.014182919636368752, 0.8114991784095764, 0.0013169958256185055, 0.17168393731117249, 0.0013169958256185055], [0.1855580359697342, 0.34665045142173767, 0.10747497528791428, 0.34665045142173767, 0.013666098937392235], [0.1974429190158844, 0.1132383644580841, 0.29967549443244934, 0.35662105679512024, 0.033022183924913406], [0.19608010351657867, 0.19608010351657867, 0.005938510410487652, 0.33812451362609863, 0.2637767791748047], [0.19667024910449982, 0.10674992948770523, 0.038987889885902405, 0.3287959396839142, 0.3287959396839142], [0.44713926315307617, 0.04158391058444977, 0.44713926315307617, 0.0067529696971178055, 0.05738455802202225], [0.09622155874967575, 0.41799700260162354, 0.41799700260162354, 0.025703489780426025, 0.04208092764019966], [0.18791413307189941, 0.5996212959289551, 0.18791413307189941, 0.0003462409076746553, 0.02420414425432682], [0.7627584338188171, 0.08422064036130905, 0.08422064036130905, 0.00032697163987904787, 0.06847333908081055], [0.3250036835670471, 0.027495475485920906, 0.027495475485920906, 0.09221649169921875, 0.5277888774871826], [0.6798153519630432, 0.05612413212656975, 0.05041709169745445, 0.05041709169745445, 0.16322626173496246], [0.07189466059207916, 0.07189466059207916, 0.37152764201164246, 0.483438640832901, 0.0012443895684555173], [0.0021542690228670835, 0.7655347585678101, 0.0021542690228670835, 0.003863021731376648, 0.22629372775554657], [0.04595574364066124, 0.8893524408340454, 0.00029579587862826884, 0.0321979857981205, 0.0321979857981205], [0.7549483180046082, 0.06290263682603836, 0.0677993893623352, 0.0677993893623352, 0.04655035212635994], [0.013182089664041996, 0.02357400394976139, 0.9270302057266235, 0.018106844276189804, 0.018106844276189804], [0.9527189135551453, 0.02138073928654194, 0.00174829107709229, 0.00174829107709229, 0.022403765469789505], [0.009457145817577839, 0.07054726034402847, 0.7892481684684753, 0.07054726034402847, 0.060200151056051254], [0.0013993388274684548, 0.40112972259521484, 0.08486868441104889, 0.08486868441104889, 0.4277336597442627], [0.13453103601932526, 0.09715279936790466, 0.3174690008163452, 0.09715279936790466, 0.3536943197250366], [0.006573278922587633, 0.27438125014305115, 0.27438125014305115, 0.3886532187461853, 0.056011002510786057], [0.08383103460073471, 0.025180527940392494, 0.025180527940392494, 0.8469487428665161, 0.0188591368496418], [0.45493242144584656, 0.45493242144584656, 0.018315322697162628, 0.011504851281642914, 0.060314953327178955], [0.0024064118042588234, 0.08900166302919388, 0.8180946111679077, 0.08900166302919388, 0.0014956149971112609], [0.15749359130859375, 0.15749359130859375, 0.2634192407131195, 0.032392989844083786, 0.3892005383968353], [0.11490411311388016, 0.02680828608572483, 0.6793051362037659, 0.11490411311388016, 0.06407838314771652], [0.048712022602558136, 0.0019733011722564697, 0.048712022602558136, 0.016870159655809402, 0.8837323784828186], [0.46994447708129883, 0.02112092263996601, 0.02112092263996601, 0.007878275588154793, 0.4799353778362274], [0.004246263764798641, 0.21593163907527924, 0.005915052257478237, 0.38695353269577026, 0.38695353269577026], [0.01229431014508009, 0.01229431014508009, 0.024377191439270973, 0.05132985860109329, 0.8997042775154114], [0.4590437114238739, 0.05143248662352562, 0.42849642038345337, 0.030513707548379898, 0.030513707548379898], [0.054439906030893326, 0.08707624673843384, 0.08707624673843384, 0.7683384418487549, 0.003069115336984396], [0.00615428714081645, 0.31951904296875, 0.00818298477679491, 0.3466246724128723, 0.31951904296875], [0.27809154987335205, 0.07454343885183334, 0.27809154987335205, 0.0058985440991818905, 0.36337488889694214], [0.9662560820579529, 0.0027239834889769554, 0.025719579309225082, 0.0026501724496483803, 0.0026501724496483803], [0.05123994126915932, 0.669197142124176, 0.05123994126915932, 0.12082413583993912, 0.10749885439872742], [0.3395330309867859, 0.2422739416360855, 0.05494067072868347, 0.3395330309867859, 0.023719308897852898], [0.0009776102378964424, 0.007079340983182192, 0.9416540265083313, 0.0009776102378964424, 0.04931143298745155], [0.0384972058236599, 0.17357859015464783, 0.5892494916915894, 0.15650075674057007, 0.04217389598488808], [0.7086694240570068, 0.0013396372087299824, 0.007640440482646227, 0.11545635014772415, 0.16689404845237732], [0.5607163310050964, 0.10723957419395447, 0.2084043323993683, 0.016400182619690895, 0.10723957419395447], [0.0027993195690214634, 0.5903342962265015, 0.2634863555431366, 0.07168998569250107, 0.07168998569250107], [0.3685678243637085, 0.13181822001934052, 0.04422910511493683, 0.3685678243637085, 0.08681702613830566], [0.20844413340091705, 0.0025816294364631176, 0.36279669404029846, 0.4201945662498474, 0.00598302623257041], [0.0048071048222482204, 0.0025930816773325205, 0.0012561341281980276, 0.0012561341281980276, 0.9900874495506287], [0.5888145565986633, 0.31274932622909546, 0.005125618074089289, 0.005125618074089289, 0.08818485587835312], [0.3077665865421295, 0.4405736029148102, 0.23795540630817413, 0.006852218881249428, 0.006852218881249428], [0.8908964395523071, 0.011080609634518623, 0.07429027557373047, 0.012652021832764149, 0.011080609634518623], [0.18019583821296692, 0.00024761399254202843, 0.40900519490242004, 0.40900519490242004, 0.0015462160808965564], [0.013797820545732975, 0.00996056105941534, 0.39322590827941895, 0.18978983163833618, 0.39322590827941895], [0.0019222849514335394, 0.08915846794843674, 0.0019222849514335394, 0.8466569185256958, 0.06034000590443611], [0.14500686526298523, 0.08280643820762634, 0.08280643820762634, 0.008653255179524422, 0.680726945400238], [0.06830054521560669, 0.09520148485898972, 0.39116695523262024, 0.05416404455900192, 0.39116695523262024], [0.3741714358329773, 0.22991672158241272, 0.017705516889691353, 0.0040349531918764114, 0.3741714358329773], [0.019931897521018982, 0.6718302965164185, 0.00892028771340847, 0.10939547419548035, 0.18992206454277039], [0.08989979326725006, 0.33360934257507324, 0.11908674240112305, 0.08989979326725006, 0.36750438809394836], [0.864554226398468, 0.0343371145427227, 0.06451971083879471, 0.0343371145427227, 0.0022517782635986805], [0.215814471244812, 0.030497560277581215, 0.0005017740186303854, 0.5373717546463013, 0.215814471244812], [0.0007748504867777228, 0.4546845555305481, 0.08949872106313705, 0.00035742478212341666, 0.4546845555305481], [0.7819837331771851, 0.026397068053483963, 0.029970018193125725, 0.05245508998632431, 0.10919403284788132], [0.04438919946551323, 0.10573246330022812, 0.0397065095603466, 0.7657827138900757, 0.04438919946551323], [0.005338238552212715, 0.6443740129470825, 0.2802058458328247, 0.0350409671664238, 0.0350409671664238], [0.014831267297267914, 0.015579155646264553, 0.014831267297267914, 0.9466069936752319, 0.008151321671903133], [0.24772968888282776, 0.2714763283729553, 0.00044133549090474844, 0.2714763283729553, 0.2088763266801834], [0.023408599197864532, 0.2089305818080902, 0.23897823691368103, 0.5283083319664001, 0.000374270835891366], [0.30033230781555176, 0.004188802093267441, 0.12860724329948425, 0.2665393650531769, 0.30033230781555176], [0.2730729579925537, 3.4268174204044044e-05, 0.015333425253629684, 0.6962258219718933, 0.015333425253629684], [0.19304467737674713, 0.4875369668006897, 0.09008987247943878, 0.03628382459282875, 0.19304467737674713], [0.0014133246149867773, 0.21047596633434296, 0.0014133246149867773, 0.009695318527519703, 0.7770021557807922], [0.2732502818107605, 0.03516769036650658, 0.06628534197807312, 0.5901289582252502, 0.03516769036650658], [0.902800977230072, 0.032824981957674026, 0.00019400683231651783, 0.06398598849773407, 0.00019400683231651783], [0.008222438395023346, 0.008222438395023346, 0.27630615234375, 0.6966762542724609, 0.010572691448032856], [0.042601510882377625, 0.003879434196278453, 0.042601510882377625, 0.8824845552444458, 0.028432922437787056], [0.25226107239723206, 0.03921251371502876, 0.2221495360136032, 0.26422733068466187, 0.2221495360136032], [0.4442623555660248, 0.4442623555660248, 0.07060141116380692, 0.02748267911374569, 0.01339123584330082], [0.19658075273036957, 0.04564793407917023, 0.018729669973254204, 0.04564793407917023, 0.6933935880661011], [0.022866077721118927, 0.022866077721118927, 0.2103915959596634, 0.3862058222293854, 0.35767045617103577], [0.0816708356142044, 0.009079101495444775, 0.889909029006958, 0.010262001305818558, 0.009079101495444775], [0.17825539410114288, 0.5317826867103577, 0.042874787002801895, 0.20421238243579865, 0.042874787002801895], [0.16741430759429932, 0.1131642684340477, 0.46325963735580444, 0.14299753308296204, 0.1131642684340477], [0.6248088479042053, 0.0363154336810112, 0.0363154336810112, 0.1482444703578949, 0.1543157696723938], [0.00249133026227355, 0.411689817905426, 0.00249133026227355, 0.027179837226867676, 0.5561476349830627], [0.09438146650791168, 0.3808434307575226, 0.3808434307575226, 0.0018826649757102132, 0.14204908907413483], [0.0976424440741539, 0.02320466749370098, 0.3756808936595917, 0.0976424440741539, 0.4058295786380768], [0.0470130518078804, 0.011395956389605999, 0.0470130518078804, 0.8805075883865356, 0.014070362783968449], [0.19775709509849548, 0.20520853996276855, 0.20520853996276855, 0.36618831753730774, 0.025637473911046982], [0.02277716062963009, 0.0363253653049469, 0.12736423313617706, 0.4067666232585907, 0.4067666232585907], [0.2324172854423523, 0.048473916947841644, 0.03819924220442772, 0.3404547870159149, 0.3404547870159149], [0.005072086583822966, 0.4149519205093384, 0.4149519205093384, 0.14993003010749817, 0.015094010159373283], [0.7881028056144714, 0.1674150675535202, 0.021710896864533424, 0.0010603509144857526, 0.021710896864533424], [0.35500895977020264, 0.007886089384555817, 0.2757505178451538, 0.006345522124320269, 0.35500895977020264], [0.017851311713457108, 0.8653154969215393, 0.05146651715040207, 0.036265481263399124, 0.029101155698299408], [0.025173677131533623, 0.0622076690196991, 0.0622076690196991, 0.24498075246810913, 0.6054301857948303], [0.9234759211540222, 0.03314896300435066, 0.00879152212291956, 0.0014346508542075753, 0.03314896300435066], [0.06083456054329872, 0.2805647552013397, 0.19981637597084045, 0.41305670142173767, 0.0457276813685894], [0.00013390506501309574, 0.7471763491630554, 0.00013390506501309574, 0.02547655627131462, 0.22707931697368622], [0.0075980545952916145, 0.25554656982421875, 0.0010954809840768576, 0.6991864442825317, 0.03657345846295357], [0.25635242462158203, 0.36731410026550293, 0.11395804584026337, 0.25635242462158203, 0.006023028399795294], [0.7374676465988159, 0.14779207110404968, 0.030187398195266724, 0.030187398195266724, 0.05436544865369797], [0.07941199839115143, 0.03420448303222656, 0.020176490768790245, 0.07941199839115143, 0.7867950201034546], [0.08984506875276566, 0.0132501982152462, 0.05146711319684982, 0.05146711319684982, 0.79397052526474], [0.04461146146059036, 0.04461146146059036, 0.07997915893793106, 0.5523402094841003, 0.2784576714038849], [0.03163762763142586, 0.1895134150981903, 3.4531487472122535e-05, 0.3894071877002716, 0.3894071877002716], [0.403436541557312, 0.004045659676194191, 0.18002420663833618, 0.4084479808807373, 0.004045659676194191], [0.4665098786354065, 0.4665098786354065, 0.016072096303105354, 0.03207539767026901, 0.018832765519618988], [0.011480715125799179, 0.4553104043006897, 0.4553104043006897, 0.018319258466362953, 0.059579234570264816], [0.07847701013088226, 0.07847701013088226, 0.22427408397197723, 0.022198326885700226, 0.596573531627655], [0.927585244178772, 0.027058949694037437, 0.0036984123289585114, 0.03795882686972618, 0.0036984123289585114], [0.013997062109410763, 0.11341529339551926, 0.11341529339551926, 0.6826068162918091, 0.07656551152467728], [0.16249245405197144, 0.04079426825046539, 0.001522210193797946, 0.39759552478790283, 0.39759552478790283], [0.3462982475757599, 0.001553559210151434, 0.013828588649630547, 0.6367660760879517, 0.001553559210151434], [0.505103588104248, 0.053674034774303436, 0.10663586854934692, 0.10663586854934692, 0.22795069217681885], [0.025865668430924416, 0.008917615748941898, 0.0017851351294666529, 0.031085634604096413, 0.9323459267616272], [0.039854392409324646, 0.0032194117084145546, 0.8818240761756897, 0.035247717052698135, 0.039854392409324646], [0.2003708779811859, 0.3742451071739197, 0.014702330343425274, 0.21031086146831512, 0.2003708779811859], [0.057783108204603195, 0.24583037197589874, 0.13388589024543762, 0.3166702687740326, 0.24583037197589874], [0.00034982225042767823, 0.02174503169953823, 0.004772144835442305, 0.9683608412742615, 0.004772144835442305], [0.05661999061703682, 0.43998482823371887, 0.4047964811325073, 0.03065173327922821, 0.06794696301221848], [0.21277901530265808, 0.36551526188850403, 0.00106346036773175, 0.36551526188850403, 0.05512700229883194], [0.4400593638420105, 0.22352199256420135, 0.15128657221794128, 0.03384549543261528, 0.15128657221794128], [0.08456075936555862, 0.5937332510948181, 0.17891527712345123, 0.08456075936555862, 0.05822988227009773], [0.0010149438166990876, 0.43638041615486145, 0.0029312523547559977, 0.43638041615486145, 0.1232929676771164], [0.14010021090507507, 0.14010021090507507, 0.03655471280217171, 0.618915319442749, 0.06432951241731644], [0.28213921189308167, 0.23866017162799835, 0.23866017162799835, 0.033271096646785736, 0.2072693556547165], [0.4703705906867981, 0.4703705906867981, 0.016629956662654877, 0.010337283834815025, 0.032291535288095474], [0.20229797065258026, 0.3723038136959076, 0.03962627053260803, 0.3723038136959076, 0.013468174263834953], [0.1804705411195755, 0.2187090963125229, 0.1804705411195755, 0.4154311716556549, 0.004918644204735756], [0.6012575030326843, 0.038383129984140396, 0.0011703241616487503, 0.1795945018529892, 0.1795945018529892], [0.007544772699475288, 0.3472197353839874, 0.22858822345733643, 0.40910249948501587, 0.007544772699475288], [0.12691396474838257, 0.5120329260826111, 0.12691396474838257, 0.0804000198841095, 0.15373915433883667], [0.02872154302895069, 0.21216124296188354, 0.7063155770301819, 0.02872154302895069, 0.024080082774162292], [0.018136944621801376, 0.01780451275408268, 0.018136944621801376, 0.014303265139460564, 0.9316183924674988], [0.030756385996937752, 0.42317652702331543, 0.42317652702331543, 0.09024880081415176, 0.03264179825782776], [0.23992036283016205, 0.23364782333374023, 0.000464899989310652, 0.292319118976593, 0.23364782333374023], [0.30425596237182617, 0.2651861310005188, 0.06489703059196472, 0.06140494719147682, 0.30425596237182617], [0.15287302434444427, 0.0007261508726514876, 0.022723399102687836, 0.15287302434444427, 0.6708043813705444], [0.27175354957580566, 0.16830100119113922, 0.20043383538722992, 0.20043383538722992, 0.15907776355743408], [0.18415826559066772, 0.4166509211063385, 0.14363540709018707, 0.11192004382610321, 0.14363540709018707], [0.059090834110975266, 0.019644755870103836, 0.4561145007610321, 0.00903540663421154, 0.4561145007610321], [2.9693119358853437e-05, 0.04584254324436188, 0.28022706508636475, 0.672882080078125, 0.0010186949511989951], [0.9372169375419617, 0.01014125719666481, 0.01014125719666481, 0.0369035080075264, 0.0055969781242311], [0.4233056902885437, 0.148006871342659, 0.4233056902885437, 0.0027697053737938404, 0.0026121705304831266], [0.023235375061631203, 0.023235375061631203, 0.05841967090964317, 0.5166639089584351, 0.3784456253051758], [0.050238143652677536, 0.027903465554118156, 0.04171501100063324, 0.050238143652677536, 0.8299051523208618], [0.043821144849061966, 0.25588923692703247, 0.35014069080352783, 8.183940735762008e-06, 0.35014069080352783], [0.000218909204704687, 0.4919915795326233, 0.0022185971029102802, 0.013579393737018108, 0.4919915795326233], [0.3475571274757385, 0.507351279258728, 0.07734991610050201, 0.06333345174789429, 0.004408234264701605], [0.10116178542375565, 0.24661481380462646, 0.24661481380462646, 0.014500149525702, 0.3911083936691284], [0.4223269820213318, 0.0016878906171768904, 0.05595000833272934, 0.09770810604095459, 0.4223269820213318], [0.00974267814308405, 0.3301333487033844, 0.12573327124118805, 0.20425736904144287, 0.3301333487033844], [0.021397320553660393, 0.08163466304540634, 0.0023257185239344835, 0.8923165202140808, 0.0023257185239344835], [0.800324022769928, 0.007739167660474777, 0.022297799587249756, 0.14734120666980743, 0.022297799587249756], [0.23328745365142822, 0.23328745365142822, 0.02022157981991768, 0.29771047830581665, 0.2154930979013443], [0.3584941327571869, 0.002144996542483568, 0.0009300283272750676, 0.2799367606639862, 0.3584941327571869], [0.10816804319620132, 0.7129306793212891, 0.06936915963888168, 0.10816804319620132, 0.001364037743769586], [0.33389046788215637, 0.01343443337827921, 0.6370460987091064, 0.01343443337827921, 0.0021945140324532986], [0.16141285002231598, 0.11389030516147614, 0.2003806084394455, 0.3629034161567688, 0.16141285002231598], [0.209425151348114, 0.209425151348114, 0.22559235990047455, 0.30887964367866516, 0.046677734702825546], [0.014467474073171616, 0.11320077627897263, 0.4695263206958771, 0.28960469365119934, 0.11320077627897263], [0.32482150197029114, 0.04953126981854439, 0.32482150197029114, 0.2884431481361389, 0.012382594868540764], [0.022058598697185516, 0.2186332643032074, 0.5058305263519287, 0.2186332643032074, 0.034844353795051575], [0.14308643341064453, 0.4043118357658386, 0.0562494657933712, 0.0562494657933712, 0.34010282158851624], [0.0006823985022492707, 0.15188349783420563, 0.6948632597923279, 0.15188349783420563, 0.0006873614620417356], [0.4391734302043915, 0.4391734302043915, 0.07977759838104248, 0.04003800451755524, 0.0018374306382611394], [0.1327173411846161, 4.317213551985333e-06, 0.7704017162322998, 0.00012486202467698604, 0.09675174206495285], [0.17813648283481598, 0.17813648283481598, 0.0732935294508934, 0.3835684359073639, 0.18686510622501373], [0.3401643633842468, 0.16872555017471313, 0.045138027518987656, 0.3401643633842468, 0.10580771416425705], [0.4580664336681366, 0.0010292575461789966, 0.07282545417547226, 0.010012494400143623, 0.4580664336681366], [0.049353085458278656, 0.049353085458278656, 0.2744886577129364, 0.6266486048698425, 0.0001565617130836472], [0.06249118968844414, 0.4644949436187744, 0.007345919031649828, 0.001172981457784772, 0.4644949436187744], [0.009026233106851578, 0.0023250419180840254, 0.8344101309776306, 0.1452123075723648, 0.009026233106851578], [0.1514049768447876, 0.5608999729156494, 0.0038052850868552923, 0.1324848085641861, 0.1514049768447876], [0.005130990874022245, 0.049646202474832535, 0.4846271574497223, 0.4109494686126709, 0.049646202474832535], [0.22970905900001526, 0.24935553967952728, 0.2543763518333435, 0.24935553967952728, 0.017203526571393013], [0.1383342146873474, 0.7775847315788269, 0.002574008656665683, 0.0789329931139946, 0.002574008656665683], [0.33200353384017944, 0.1873604953289032, 0.017315449193120003, 0.33200353384017944, 0.13131697475910187], [0.042768750339746475, 0.042768750339746475, 0.8000525832176208, 0.05541011691093445, 0.058999884873628616], [0.04088464006781578, 0.33992090821266174, 0.07729111611843109, 0.20198245346546173, 0.33992090821266174], [0.00011391049338271841, 0.12150895595550537, 0.13917911052703857, 0.6000189185142517, 0.13917911052703857], [0.10120844841003418, 0.012594552710652351, 0.008027718402445316, 0.012594552710652351, 0.8655746579170227], [0.33116090297698975, 0.33116090297698975, 0.014361581765115261, 0.2983143925666809, 0.02500222437083721], [0.0035959265660494566, 0.0035959265660494566, 0.5041913986206055, 0.03028298169374466, 0.45833373069763184], [0.06952707469463348, 0.32070228457450867, 0.28600698709487915, 0.03775670379400253, 0.28600698709487915], [0.615947425365448, 0.006315218284726143, 0.042948152869939804, 0.16739463806152344, 0.16739463806152344], [4.1877279727486894e-05, 0.008639546111226082, 0.008259250782430172, 0.9830174446105957, 4.1877279727486894e-05], [0.007452331017702818, 0.17094086110591888, 0.1344570517539978, 0.1344570517539978, 0.552692711353302], [0.01607677713036537, 0.004458783660084009, 0.004458783660084009, 0.964356005191803, 0.01064964197576046], [0.006136502139270306, 0.20593911409378052, 0.20593911409378052, 0.5150822401046753, 0.0669030249118805], [0.012968813069164753, 0.10060174018144608, 0.10060174018144608, 0.16142971813678741, 0.6243979334831238], [0.03452932462096214, 0.8714680075645447, 0.01176523882895708, 0.01176523882895708, 0.07047220319509506], [0.4201151132583618, 0.010205784812569618, 0.00044816199806518853, 0.1491159200668335, 0.4201151132583618], [0.19741757214069366, 0.10836843401193619, 0.6813001036643982, 0.006456948816776276, 0.006456948816776276], [0.001741211162880063, 0.001741211162880063, 0.0025354581885039806, 0.28011077642440796, 0.7138713598251343], [0.0010486359242349863, 0.024407869204878807, 0.9517543911933899, 0.021740498021245003, 0.0010486359242349863], [0.19739842414855957, 0.029727859422564507, 0.036239784210920334, 0.6366750001907349, 0.09995893388986588], [0.024809300899505615, 0.4264955222606659, 0.10523128509521484, 0.41865459084510803, 0.024809300899505615], [0.0019202135736122727, 0.5991482138633728, 0.24891896545886993, 0.011216194368898869, 0.13879644870758057], [0.039885733276605606, 0.8641358017921448, 0.03247564658522606, 0.03102712891995907, 0.03247564658522606], [0.45303186774253845, 0.03240620344877243, 0.45303186774253845, 0.04923984780907631, 0.012290135025978088], [0.032950349152088165, 0.3245912194252014, 0.3164087235927582, 0.009641020558774471, 0.3164087235927582], [0.02909649908542633, 0.30698221921920776, 0.5591663122177124, 0.02909649908542633, 0.07565848529338837], [0.004246271215379238, 0.004246271215379238, 0.372951477766037, 0.3308860659599304, 0.2876700162887573], [0.0025481467600911856, 0.3966902196407318, 0.06799835711717606, 0.06799835711717606, 0.46476486325263977], [0.2773386836051941, 0.03186459094285965, 0.2773386836051941, 0.1340097188949585, 0.2794483006000519], [0.017557905986905098, 0.33906519412994385, 0.33906519412994385, 0.1799715757369995, 0.12434011697769165], [0.3062545657157898, 0.023333711549639702, 0.06509282439947128, 0.2990643382072449, 0.3062545657157898], [0.013452271930873394, 0.0842021182179451, 0.3699987530708313, 0.26617342233657837, 0.26617342233657837], [0.02412198856472969, 0.28510206937789917, 0.03595159947872162, 0.3274121880531311, 0.3274121880531311], [0.000166702302522026, 0.7797994613647461, 0.00017811932775657624, 0.2196889966726303, 0.000166702302522026], [0.28441011905670166, 0.03859949856996536, 0.093143530189991, 0.29943665862083435, 0.28441011905670166], [0.1822841465473175, 0.015134952031075954, 0.29179176688194275, 0.3285049498081207, 0.1822841465473175], [0.20375467836856842, 0.20375467836856842, 0.05120651796460152, 0.4964039921760559, 0.044880203902721405], [0.18870842456817627, 0.33384379744529724, 0.33384379744529724, 0.14330759644508362, 0.0002963988808915019], [0.6026628613471985, 0.16184201836585999, 0.08980515599250793, 0.05588487535715103, 0.08980515599250793], [0.31812000274658203, 0.35618650913238525, 0.31812000274658203, 0.007110316306352615, 0.00046324037248268723], [0.06971506774425507, 0.8004066944122314, 0.02236906625330448, 0.037794098258018494, 0.06971506774425507], [0.02594684064388275, 0.48065584897994995, 0.02594684064388275, 0.35002005100250244, 0.1174304261803627], [0.004456418566405773, 0.017590653151273727, 0.1367926448583603, 0.7961452007293701, 0.04501504451036453], [0.0455671101808548, 0.0455671101808548, 0.8260840177536011, 0.08049990981817245, 0.002281819935888052], [0.02739318273961544, 0.5913398861885071, 0.25153255462646484, 0.0028419645968824625, 0.12689243257045746], [0.09998933970928192, 0.6883496046066284, 0.02332461252808571, 0.09416820853948593, 0.09416820853948593], [0.12675756216049194, 0.12675756216049194, 0.5770250558853149, 0.03804006054997444, 0.13141976296901703], [0.0015549954259768128, 0.47734734416007996, 0.004380432888865471, 0.039369869977235794, 0.47734734416007996], [0.9540687203407288, 0.004993756767362356, 0.016888916492462158, 0.007159692235291004, 0.016888916492462158], [0.8313576579093933, 0.027149787172675133, 0.018818369135260582, 0.09552441537380219, 0.027149787172675133], [0.29478034377098083, 0.29478034377098083, 0.03170332685112953, 0.11961515247821808, 0.2591208815574646], [0.2653271555900574, 0.03395478054881096, 0.06027130037546158, 0.2653271555900574, 0.375119686126709], [0.34002885222435, 0.63905930519104, 0.008043691515922546, 0.0048245093785226345, 0.008043691515922546], [0.12277914583683014, 0.10648860037326813, 0.4661787450313568, 0.050713617354631424, 0.2538398504257202], [0.06975169479846954, 0.012468192726373672, 0.7991820573806763, 0.10612990707159042, 0.012468192726373672], [0.09552396088838577, 0.3432903289794922, 0.2119690626859665, 0.0059262607246637344, 0.3432903289794922], [0.00011025690037058666, 0.0002330619900021702, 0.9972231388092041, 0.00011025690037058666, 0.002323324326425791], [0.003462868509814143, 0.03872368112206459, 0.02655523642897606, 0.90470290184021, 0.02655523642897606], [0.01751934364438057, 0.015155244618654251, 0.015155244618654251, 0.2105507254600525, 0.7416194081306458], [0.3931925594806671, 0.056491076946258545, 0.050828561186790466, 0.056491076946258545, 0.44299671053886414], [0.6116025447845459, 0.3517795205116272, 0.013651535846292973, 0.00931484717875719, 0.013651535846292973], [0.0866202637553215, 0.021322965621948242, 0.021322965621948242, 0.5216995477676392, 0.3490343391895294], [0.21799448132514954, 0.21799448132514954, 0.5012574791908264, 2.5093469957937486e-05, 0.0627284049987793], [0.012736815959215164, 0.1165960356593132, 0.005046296399086714, 0.22263021767139435, 0.6429905891418457], [0.14704200625419617, 0.025376273319125175, 0.0041088685393333435, 0.025376273319125175, 0.7980966567993164], [0.6044411659240723, 0.01490554679185152, 0.14219850301742554, 0.01490554679185152, 0.22354918718338013], [0.02347235195338726, 0.02347235195338726, 0.0293696541339159, 0.537531316280365, 0.38615429401397705], [0.7030919790267944, 0.022381648421287537, 0.022381648421287537, 0.0197332464158535, 0.2324114590883255], [0.24524462223052979, 0.2954755127429962, 0.15726026892662048, 0.00654406426474452, 0.2954755127429962], [0.0480588935315609, 0.02500816062092781, 0.752051830291748, 0.08744056522846222, 0.08744056522846222], [0.1235247477889061, 0.1235247477889061, 0.4694368839263916, 0.28262048959732056, 0.0008932194905355573], [0.30373841524124146, 0.023076308891177177, 0.35173583030700684, 0.017711039632558823, 0.30373841524124146], [0.0056493026204407215, 0.03305155783891678, 0.0056493026204407215, 0.6775389909744263, 0.27811089158058167], [0.5328246355056763, 0.3124365210533142, 0.12858979403972626, 0.013074565678834915, 0.013074565678834915], [0.3592779040336609, 0.2145634889602661, 0.3592779040336609, 0.03119090013206005, 0.03568978235125542], [0.31494536995887756, 0.37742504477500916, 0.039073243737220764, 0.13427814841270447, 0.13427814841270447], [0.34107792377471924, 0.3181114196777344, 0.02150305174291134, 0.0011962607968598604, 0.3181114196777344], [0.0024695598985999823, 0.8903321623802185, 0.034729696810245514, 0.034729696810245514, 0.037738870829343796], [0.2326490879058838, 0.005249795038253069, 0.08519726991653442, 0.6716540455818176, 0.005249795038253069], [0.0007272936054505408, 0.02865077182650566, 0.37084951996803284, 0.37084951996803284, 0.22892287373542786], [0.004965121392160654, 0.6185674071311951, 0.19295677542686462, 0.09175530821084976, 0.09175530821084976], [0.004542252980172634, 0.9318890571594238, 0.030864324420690536, 0.0018400950357317924, 0.030864324420690536], [0.03463352099061012, 0.1342654526233673, 0.20064206421375275, 0.49619340896606445, 0.1342654526233673], [0.0034138006158173084, 0.21217051148414612, 0.46570298075675964, 0.1065421849489212, 0.21217051148414612], [0.04373503848910332, 0.36286962032318115, 0.27456796169281006, 0.27456796169281006, 0.044259414076805115], [0.006896027829498053, 0.14713536202907562, 0.32896900177001953, 0.369864284992218, 0.14713536202907562], [0.42900070548057556, 0.00017770208069123328, 0.00017770208069123328, 0.33725887537002563, 0.23338495194911957], [0.009223033674061298, 0.0035103957634419203, 0.16050738096237183, 0.020361701026558876, 0.806397557258606], [0.8111209273338318, 0.02932611107826233, 0.07770070433616638, 0.004151548724621534, 0.07770070433616638], [0.018115611746907234, 0.8494147062301636, 0.03891107067465782, 0.03891107067465782, 0.054647598415613174], [0.21703805029392242, 0.2281728982925415, 0.21703805029392242, 0.011646718718111515, 0.3261043429374695], [0.00032002266380004585, 0.17760834097862244, 0.30694183707237244, 0.17760834097862244, 0.33752137422561646], [0.0846811830997467, 0.0846811830997467, 0.2376154065132141, 0.5285128355026245, 0.06450937688350677], [0.019221238791942596, 0.6288655996322632, 0.3391157388687134, 0.006398729048669338, 0.006398729048669338], [0.1703014224767685, 0.08662549406290054, 0.012357658706605434, 0.7183578014373779, 0.012357658706605434], [0.4415854513645172, 0.0602150484919548, 0.0020498766098171473, 0.4415854513645172, 0.05456414073705673], [0.14514514803886414, 0.2777171730995178, 0.4049025774002075, 0.027089940384030342, 0.14514514803886414], [0.023812033236026764, 0.05255550891160965, 0.22585779428482056, 0.22585779428482056, 0.47191691398620605], [0.007095991633832455, 0.007095991633832455, 0.5176681876182556, 0.2730942368507385, 0.19504554569721222], [0.1549931913614273, 0.724972128868103, 0.01090849470347166, 0.09821771085262299, 0.01090849470347166], [0.005919759627431631, 0.007382987067103386, 0.005530408583581448, 0.005919759627431631, 0.9752470254898071], [0.01558094471693039, 0.3693051338195801, 0.23804587125778198, 0.007762990891933441, 0.3693051338195801], [0.46329912543296814, 0.006049011368304491, 0.06359289586544037, 0.46329912543296814, 0.0037598139606416225], [0.05469413846731186, 0.4670661389827728, 0.0029827901162207127, 0.4670661389827728, 0.008190782740712166], [0.0220287274569273, 0.35217300057411194, 0.4731145203113556, 0.12382766604423523, 0.02885606326162815], [0.0355268195271492, 0.0355268195271492, 0.3720107972621918, 0.0008335046004503965, 0.5561020970344543], [0.006265486590564251, 0.0009840691927820444, 0.017689434811472893, 0.48753052949905396, 0.48753052949905396], [0.453034907579422, 0.453034907579422, 0.08915570378303528, 0.0028430556412786245, 0.0019314488163217902], [0.20560389757156372, 0.13992241024971008, 0.052106406539678574, 0.39676332473754883, 0.20560389757156372], [0.002352879848331213, 0.3841826319694519, 0.3841826319694519, 0.03612988442182541, 0.19315196573734283], [0.1327374130487442, 0.2757393717765808, 0.15905925631523132, 0.2757393717765808, 0.15672458708286285], [0.15580953657627106, 0.1225159764289856, 0.3577539622783661, 0.3577539622783661, 0.006166540551930666], [0.14432929456233978, 0.253688246011734, 0.0010579166701063514, 0.34723636507987976, 0.253688246011734], [0.22376827895641327, 0.21488985419273376, 0.09009053558111191, 0.3811608552932739, 0.09009053558111191], [0.10714174807071686, 0.433355450630188, 0.0010159800294786692, 0.025131328031420708, 0.433355450630188], [0.5544254779815674, 0.12334194779396057, 0.000984766287729144, 0.12334194779396057, 0.19790583848953247], [0.34156888723373413, 0.34156888723373413, 0.001530815614387393, 0.30437660217285156, 0.01095485221594572], [0.6025522947311401, 0.06365931034088135, 0.018136976286768913, 0.31201738119125366, 0.0036339852958917618], [0.30937322974205017, 0.01962735317647457, 0.5500569939613342, 0.06047124043107033, 0.06047124043107033], [0.4170653820037842, 0.08263762295246124, 0.38280412554740906, 0.08263762295246124, 0.03485536947846413], [0.00038956335629336536, 0.006871180608868599, 0.22932715713977814, 0.7565409541130066, 0.006871180608868599], [0.46036309003829956, 0.4685346484184265, 0.00949922762811184, 0.00949922762811184, 0.05210384726524353], [0.08235719054937363, 0.17250292003154755, 0.0618596151471138, 0.3416401445865631, 0.3416401445865631], [0.16767661273479462, 0.03181713819503784, 0.0013620903482660651, 0.39957207441329956, 0.39957207441329956], [0.2680985629558563, 0.00017997086979448795, 0.4632645845413208, 0.2680985629558563, 0.0003582485078368336], [0.22414959967136383, 0.5334393978118896, 0.0019252889323979616, 0.22414959967136383, 0.01633612811565399], [0.03858378529548645, 0.25889232754707336, 0.00911480188369751, 0.6548252701759338, 0.03858378529548645], [0.0692862793803215, 0.09948131442070007, 0.02959623374044895, 0.09948131442070007, 0.7021547555923462], [0.0698985606431961, 0.0005489799659699202, 0.18383736908435822, 0.0698985606431961, 0.6758164763450623], [0.4759410619735718, 0.004854891914874315, 0.013755002990365028, 0.4759410619735718, 0.029507961124181747], [0.0019839550368487835, 0.0019839550368487835, 0.5945038199424744, 0.12402769923210144, 0.27750054001808167], [0.002360102953389287, 0.23151174187660217, 0.7302805781364441, 0.033487532287836075, 0.002360102953389287], [0.0005751405842602253, 0.0005751405842602253, 0.25806304812431335, 0.001369246281683445, 0.7394173741340637], [0.00026894602342508733, 0.9093647599220276, 0.00026894602342508733, 0.004183821380138397, 0.08591356128454208], [0.08843400329351425, 0.3045044541358948, 0.27277445793151855, 0.061512675136327744, 0.27277445793151855], [0.028124764561653137, 0.14616408944129944, 0.45744144916534424, 0.3401448726654053, 0.028124764561653137], [0.0920630395412445, 0.6190551519393921, 0.07929874211549759, 0.16121096909046173, 0.0483720563352108], [5.6622458942001686e-05, 0.8548963665962219, 5.6622458942001686e-05, 0.03770655766129494, 0.107283815741539], [0.028591379523277283, 0.0780528336763382, 0.015430005267262459, 0.015430005267262459, 0.8624957799911499], [0.42770472168922424, 0.04769091308116913, 0.05545239523053169, 0.041447289288043976, 0.42770472168922424], [0.04385676234960556, 0.3555816411972046, 0.01477072760462761, 0.3555816411972046, 0.23020923137664795], [0.15597718954086304, 0.5725461840629578, 0.15597718954086304, 0.0810856893658638, 0.034413695335388184], [0.002231285907328129, 0.09323341399431229, 0.06460209935903549, 0.07231159508228302, 0.7676215171813965], [0.01925625652074814, 0.08497001975774765, 0.29783308506011963, 0.4526127874851227, 0.1453278660774231], [0.3524882197380066, 0.022333530709147453, 0.041466742753982544, 0.23122331500053406, 0.3524882197380066], [0.0012465681647881866, 0.9464417695999146, 0.0018362033879384398, 0.0012465681647881866, 0.04922885820269585], [0.05652103200554848, 0.14825107157230377, 0.3194364607334137, 0.3577207028865814, 0.11807067692279816], [0.021069040521979332, 0.06820717453956604, 0.021069040521979332, 0.1556759625673294, 0.7339787483215332], [0.005642633885145187, 0.005642633885145187, 0.9191721677780151, 0.06930597871541977, 0.00023651598894502968], [0.04578418284654617, 0.04094671085476875, 0.011100592091679573, 0.04094671085476875, 0.8612218499183655], [0.0007452626014128327, 0.452682763338089, 0.452682763338089, 0.052228160202503204, 0.04166105389595032], [0.036195628345012665, 0.0027846237644553185, 0.03628427907824516, 0.8885398507118225, 0.036195628345012665], [0.08404213935136795, 0.10785678774118423, 0.1861870139837265, 0.1861870139837265, 0.4357271194458008], [0.037374839186668396, 0.0012916842242702842, 0.0782071053981781, 0.8818347454071045, 0.0012916842242702842], [0.016080493107438087, 0.03632776811718941, 0.03632776811718941, 0.8867281675338745, 0.024535782635211945], [0.3629932105541229, 0.03255339711904526, 0.0010708702029660344, 0.24038931727409363, 0.3629932105541229], [0.0016798522556200624, 0.013335795141756535, 5.6797649449435994e-05, 5.6797649449435994e-05, 0.9848707318305969], [0.13731534779071808, 0.5245012044906616, 0.07136460393667221, 0.07136460393667221, 0.19545423984527588], [0.10919079184532166, 0.14939570426940918, 0.3703807592391968, 0.3703807592391968, 0.0006519876187667251], [0.13537761569023132, 0.002669508336111903, 0.5144150257110596, 0.17376892268657684, 0.17376892268657684], [0.32374367117881775, 0.6102845072746277, 0.0019736469257622957, 0.031999118626117706, 0.031999118626117706], [0.014274938963353634, 0.026354696601629257, 0.949442982673645, 0.004963720683008432, 0.004963720683008432], [0.2814159691333771, 0.025993293151259422, 0.2386287897825241, 0.006436875090003014, 0.4475250244140625], [0.0569424144923687, 0.010199623182415962, 0.03075707145035267, 0.8451585173606873, 0.0569424144923687], [0.048503413796424866, 0.0017158936243504286, 0.01280237827450037, 0.8884748220443726, 0.048503413796424866], [0.9469864964485168, 0.019982870668172836, 0.0003462756285443902, 0.016342192888259888, 0.016342192888259888], [0.07454528659582138, 0.43601271510124207, 0.23753394186496735, 0.014374097809195518, 0.23753394186496735], [0.03751775622367859, 0.3225647211074829, 0.5530237555503845, 0.04344690218567848, 0.04344690218567848], [0.2468070089817047, 0.061746902763843536, 0.413019597530365, 0.031619492918252945, 0.2468070089817047], [0.9102317094802856, 0.07021349668502808, 0.007887584157288074, 0.005833632778376341, 0.005833632778376341], [0.1383754163980484, 0.21498996019363403, 0.09374778717756271, 0.1383754163980484, 0.41451138257980347], [0.0556364469230175, 0.0027213841676712036, 0.23003017902374268, 0.0027213841676712036, 0.7088906168937683], [0.2629449665546417, 0.000839871063362807, 0.01676628179848194, 0.4565039575099945, 0.2629449665546417], [0.016823509708046913, 0.0008687347290106118, 0.016823509708046913, 0.09651412069797516, 0.8689700961112976], [0.013150692917406559, 0.3674616813659668, 0.10042838007211685, 0.3674616813659668, 0.1514975130558014], [0.008552297949790955, 0.008552297949790955, 0.8870342373847961, 0.06393736600875854, 0.0319238118827343], [0.026584776118397713, 0.2647863030433655, 0.42063066363334656, 0.023211849853396416, 0.2647863030433655], [0.13142268359661102, 0.3512849807739258, 0.3064002990722656, 0.13142268359661102, 0.07946937531232834], [0.014147268608212471, 0.05716008320450783, 0.05280608683824539, 0.09008336067199707, 0.7858031392097473], [0.20231962203979492, 0.0155722014605999, 0.2533841133117676, 0.27533990144729614, 0.2533841133117676], [0.2151859700679779, 0.10478077083826065, 0.5400935411453247, 0.0351589061319828, 0.10478077083826065], [0.35145801305770874, 0.024682486429810524, 0.35145801305770874, 0.01635754480957985, 0.2560440003871918], [0.007510718889534473, 0.007510718889534473, 0.6008592247962952, 0.34613990783691406, 0.037979453802108765], [0.001110128709115088, 0.001110128709115088, 0.3287351131439209, 0.18748106062412262, 0.4815635681152344], [0.09785185754299164, 0.13514763116836548, 0.5435760617256165, 0.0148137416690588, 0.20861069858074188], [0.09604230523109436, 0.00943340640515089, 0.05172186717391014, 0.8333689570426941, 0.00943340640515089], [0.11463408917188644, 0.07274352759122849, 0.07274352759122849, 0.005352212581783533, 0.7345266342163086], [0.16554595530033112, 0.029568195343017578, 0.324641615152359, 0.029568195343017578, 0.4506760835647583], [0.561267077922821, 0.015589755959808826, 0.39362239837646484, 0.014760387130081654, 0.014760387130081654], [0.07339301705360413, 0.18418104946613312, 0.18418104946613312, 0.2572944760322571, 0.30095040798187256], [0.580464780330658, 0.012541285715997219, 0.01579866372048855, 0.38833317160606384, 0.0028620578814297915], [0.1567874550819397, 0.46484366059303284, 0.20133961737155914, 0.08851464837789536, 0.08851464837789536], [9.158518514595926e-05, 0.7301850318908691, 0.2651766538619995, 9.158518514595926e-05, 0.004455118905752897], [0.021518688648939133, 0.46695226430892944, 0.05918968468904495, 0.021518688648939133, 0.4308207035064697], [0.0027023940347135067, 0.966586709022522, 0.0027023940347135067, 0.00017640317673794925, 0.027832066640257835], [0.13596078753471375, 0.003753258613869548, 0.08509935438632965, 0.13596078753471375, 0.6392257809638977], [0.6809691190719604, 0.0004300291766412556, 0.17982883751392365, 0.0004300291766412556, 0.1383420079946518], [0.1914486587047577, 0.055930245667696, 0.1914486587047577, 0.4378748834133148, 0.1232975497841835], [0.0065329656936228275, 0.07407654076814651, 0.09406303614377975, 0.7312644124031067, 0.09406303614377975], [0.19475148618221283, 0.04418736323714256, 0.04418736323714256, 0.5524381995201111, 0.16443555057048798], [0.004112391732633114, 0.4572478234767914, 0.09768638014793396, 0.3432669937610626, 0.09768638014793396], [0.0007819121819920838, 0.0018491919618099928, 0.017852667719125748, 0.017852667719125748, 0.9616634845733643], [0.2566196620464325, 0.19010791182518005, 0.2566196620464325, 0.1494705080986023, 0.14718224108219147], [0.007138481363654137, 0.9388419389724731, 0.00037093108403496444, 0.00037093108403496444, 0.05327773094177246], [0.6647717952728271, 0.0015168145764619112, 0.11499486118555069, 0.10114434361457825, 0.11757215112447739], [0.06320657581090927, 0.19126088917255402, 0.3128576874732971, 0.11981719732284546, 0.3128576874732971], [0.4028932750225067, 0.0765378326177597, 0.31064143776893616, 0.0765378326177597, 0.13338962197303772], [0.1607203185558319, 0.22418859601020813, 0.3039073348045349, 0.007276467047631741, 0.3039073348045349], [0.4761500656604767, 0.4761500656604767, 0.0012933388352394104, 0.02792999893426895, 0.018476534634828568], [0.047105900943279266, 0.10193147510290146, 0.6473460793495178, 0.047105900943279266, 0.15651057660579681], [0.29378607869148254, 0.0016400085296481848, 0.29378607869148254, 0.35610073804855347, 0.05468713492155075], [0.3016524314880371, 0.004375781863927841, 0.07108351588249207, 0.32123589515686035, 0.3016524314880371], [0.12272685766220093, 0.3347456753253937, 0.021631507202982903, 0.3981691300868988, 0.12272685766220093], [0.12315107882022858, 0.0326114259660244, 0.12315107882022858, 0.001304764417000115, 0.7197815775871277], [0.031635694205760956, 0.2982117533683777, 0.539273738861084, 0.10916932672262192, 0.02170943282544613], [0.09513305872678757, 0.04552825912833214, 0.7592413425445557, 0.09513305872678757, 0.004964238498359919], [0.05371863767504692, 0.05371863767504692, 0.34209463000297546, 0.33508625626564026, 0.21538181602954865], [0.002619248814880848, 0.48313114047050476, 0.0033840464893728495, 0.02773440256714821, 0.48313114047050476], [0.17515261471271515, 0.17515261471271515, 0.08544505387544632, 0.20629753172397614, 0.3579522371292114], [0.034980107098817825, 0.917715311050415, 0.03711969405412674, 0.005092448089271784, 0.005092448089271784], [0.1674828678369522, 0.19087055325508118, 0.22254666686058044, 0.21185016632080078, 0.20724979043006897], [0.5783811807632446, 0.13469386100769043, 0.005955356173217297, 0.14048480987548828, 0.14048480987548828], [0.058744318783283234, 0.058744318783283234, 0.876501739025116, 0.0058547877706587315, 0.00015491642989218235], [0.49722185730934143, 0.004709963221102953, 0.0006115736905485392, 0.49722185730934143, 0.00023473940382245928], [0.7035703659057617, 0.1369566172361374, 0.07282692939043045, 0.013819225132465363, 0.07282692939043045], [0.10962727665901184, 0.1049414575099945, 0.37268635630607605, 0.37268635630607605, 0.04005853831768036], [0.0005608444917015731, 0.04322594776749611, 0.026017814874649048, 0.0005608444917015731, 0.9296345114707947], [0.0005466369329951704, 0.07890863716602325, 0.8821364641189575, 0.012807938270270824, 0.02560029923915863], [0.3363278806209564, 0.20548951625823975, 0.09767130017280579, 0.1550217866897583, 0.20548951625823975], [0.48610687255859375, 0.02222566306591034, 0.48610687255859375, 0.001037186593748629, 0.004523501265794039], [0.13318589329719543, 0.4971659183502197, 0.13318589329719543, 0.2245100885629654, 0.011952202767133713], [0.6965726017951965, 0.2647842466831207, 0.014634355902671814, 0.014634355902671814, 0.009374503046274185], [0.2098713368177414, 0.32863879203796387, 0.0038906640838831663, 0.12896037101745605, 0.32863879203796387], [0.4975331425666809, 0.10129450261592865, 0.2754867672920227, 0.024391021579504013, 0.10129450261592865], [0.3032674789428711, 0.020813971757888794, 0.3032674789428711, 0.09483222663402557, 0.277818888425827], [0.007926435209810734, 0.008480927906930447, 0.011506824754178524, 0.9605789184570312, 0.011506824754178524], [0.6510162353515625, 0.009145578369498253, 0.0223129503428936, 1.9639619495137595e-05, 0.3175055682659149], [0.05835634469985962, 0.001714613870717585, 0.001714613870717585, 0.01396077312529087, 0.9242537021636963], [0.1356528252363205, 0.016630105674266815, 0.2921087443828583, 0.2778041660785675, 0.2778041660785675], [0.16862636804580688, 0.16862636804580688, 0.6095855832099915, 0.0006347621674649417, 0.052527014166116714], [0.004986319690942764, 0.248494952917099, 0.3672409653663635, 0.248494952917099, 0.1307828426361084], [0.14278048276901245, 0.14278048276901245, 0.10836662352085114, 0.1410760134458542, 0.46499642729759216], [0.0018700271612033248, 0.3356064260005951, 0.3356064260005951, 0.2914084494113922, 0.03550863638520241], [0.6619001030921936, 0.1201457679271698, 0.013706780038774014, 0.0841016173362732, 0.1201457679271698], [0.06389008462429047, 0.0008325688540935516, 0.04576534777879715, 0.8882467150688171, 0.001265249913558364], [0.3529135584831238, 0.13286681473255157, 0.16111618280410767, 0.0521005317568779, 0.30100294947624207], [0.022667119279503822, 0.9241547584533691, 0.010848100297152996, 0.010848100297152996, 0.031481869518756866], [0.015477176755666733, 0.8928706049919128, 0.010095699690282345, 0.07179827243089676, 0.00975820142775774], [0.13498784601688385, 0.10497681796550751, 0.1351940631866455, 0.31242063641548157, 0.31242063641548157], [0.11856120824813843, 0.4286562502384186, 0.008312864229083061, 0.4286562502384186, 0.015813462436199188], [0.0052665588445961475, 0.30566930770874023, 0.167790487408638, 0.30566930770874023, 0.21560433506965637], [0.345105916261673, 0.1311698704957962, 0.1311698704957962, 0.2756938338279724, 0.11686050891876221], [0.0762079581618309, 0.13290958106517792, 0.39534175395965576, 0.0001989508600672707, 0.39534175395965576], [0.4709235727787018, 0.00022384551994036883, 0.4709235727787018, 0.04632066935300827, 0.011608269065618515], [0.010072477161884308, 0.90859454870224, 0.02324129082262516, 0.02904585190117359, 0.02904585190117359], [0.00020672366372309625, 0.4090239703655243, 0.39913371205329895, 0.005312648601830006, 0.18632297217845917], [0.348514586687088, 0.0026164466980844736, 0.31885650753974915, 0.31885650753974915, 0.011155893094837666], [0.0014522874262183905, 0.4128991663455963, 0.0036676968447864056, 0.4128991663455963, 0.1690816730260849], [0.11494456976652145, 0.007573483977466822, 0.545114278793335, 0.324794203042984, 0.007573483977466822], [0.4312051832675934, 0.06565161049365997, 0.017471972852945328, 0.05446602404117584, 0.4312051832675934], [0.07293777167797089, 0.847883403301239, 0.009838691912591457, 0.059501443058252335, 0.009838691912591457], [0.48068809509277344, 0.02702946960926056, 0.011075536720454693, 0.0005188423674553633, 0.48068809509277344], [0.4542793929576874, 0.05826402083039284, 0.4509512186050415, 0.018252648413181305, 0.018252648413181305], [0.041599977761507034, 0.4464472830295563, 0.005172610282897949, 0.4464472830295563, 0.06033286824822426], [1.049043294187868e-05, 0.8112678527832031, 0.022157033905386925, 0.022157033905386925, 0.14440762996673584], [0.29044151306152344, 0.024477915838360786, 0.5355949401855469, 0.024477915838360786, 0.12500779330730438], [0.021257175132632256, 0.0021138275042176247, 0.3452148139476776, 0.0021138275042176247, 0.6293003559112549], [0.03154939413070679, 0.2359965443611145, 0.2359965443611145, 0.49643418192863464, 2.33439241128508e-05], [0.14192599058151245, 0.003417372237890959, 0.0008625983027741313, 0.8529314398765564, 0.0008625983027741313], [0.3788810968399048, 0.3788810968399048, 0.0002960051060654223, 0.2305632382631302, 0.011378572322428226], [0.01968184858560562, 0.523415207862854, 0.12886621057987213, 0.16401837766170502, 0.16401837766170502], [0.016361374408006668, 0.9036083221435547, 0.016361374408006668, 0.04820241034030914, 0.015466545708477497], [0.0735427662730217, 0.5356951355934143, 0.179205983877182, 0.03235011175274849, 0.179205983877182], [0.016831528395414352, 0.016945479437708855, 0.46983906626701355, 0.2481919676065445, 0.2481919676065445], [0.5701320767402649, 0.1837950050830841, 0.02442222461104393, 0.1837950050830841, 0.03785572946071625], [0.026077626273036003, 0.002977947238832712, 0.002977947238832712, 0.10984385013580322, 0.8581225872039795], [0.4572323262691498, 0.03419405594468117, 0.01835807040333748, 0.01835807040333748, 0.471857488155365], [0.9190084338188171, 0.00879791658371687, 0.03419250249862671, 0.00879791658371687, 0.029203295707702637], [0.09293557703495026, 0.09293557703495026, 0.7688999772071838, 0.03525508940219879, 0.009973770938813686], [0.23702087998390198, 0.29501622915267944, 0.03465092182159424, 0.19629105925559998, 0.23702087998390198], [0.16713829338550568, 0.31677764654159546, 0.07273552566766739, 0.12657083570957184, 0.31677764654159546], [0.015732211992144585, 0.7669211626052856, 0.18731023371219635, 0.01501823216676712, 0.01501823216676712], [0.3587851822376251, 0.2595408856868744, 0.017879357561469078, 0.18189728260040283, 0.18189728260040283], [0.01897268556058407, 0.02946970798075199, 0.6859287619590759, 0.13281448185443878, 0.13281448185443878], [0.02472865954041481, 0.06644103676080704, 0.5423665642738342, 0.0009348098537884653, 0.36552900075912476], [0.023640010505914688, 0.2140105962753296, 0.7287725806236267, 0.009936802089214325, 0.023640010505914688], [0.029682572931051254, 0.41846880316734314, 0.07360569387674332, 0.41846880316734314, 0.05977412685751915], [0.003526871558278799, 0.003526871558278799, 0.029885608702898026, 0.8791239857673645, 0.08393675833940506], [0.3946256935596466, 0.3665849268436432, 0.025540973991155624, 0.10662420094013214, 0.10662420094013214], [0.03788642957806587, 0.1393911987543106, 0.021575521677732468, 0.03788642957806587, 0.7632603049278259], [0.0183283481746912, 0.0015592817217111588, 0.8331788778305054, 0.07346673309803009, 0.07346673309803009], [0.19951017200946808, 0.3632807433605194, 0.3632807433605194, 0.011141437105834484, 0.06278690695762634], [0.0036660877522081137, 0.0036660877522081137, 0.29877403378486633, 0.16775959730148315, 0.5261341333389282], [0.5033721327781677, 0.35913175344467163, 0.030661169439554214, 0.030661169439554214, 0.07617374509572983], [0.12964923679828644, 0.12964923679828644, 0.02010631188750267, 0.6997882127761841, 0.0208070557564497], [0.07949262112379074, 0.02198706567287445, 0.0023202854208648205, 0.8951660394668579, 0.0010340166045352817], [0.2915915548801422, 0.00765311811119318, 0.5869736075401306, 0.10612861812114716, 0.00765311811119318], [0.0005407956778071821, 0.9711846113204956, 0.010523606091737747, 0.0005407956778071821, 0.017210159450769424], [0.005001177545636892, 0.3888780474662781, 0.008430417627096176, 0.20881237089633942, 0.3888780474662781], [0.3990328907966614, 0.3990328907966614, 0.08231398463249207, 0.05294068530201912, 0.06667961180210114], [0.009457534179091454, 0.0003934173146262765, 0.7027204632759094, 0.2870352268218994, 0.0003934173146262765], [0.008312530815601349, 0.912990391254425, 0.0019255545921623707, 0.008312530815601349, 0.06845899671316147], [0.3215888440608978, 0.46434295177459717, 0.06876788288354874, 0.13017676770687103, 0.015123477205634117], [0.037403278052806854, 0.006865263916552067, 0.9487350583076477, 0.00013121853407938033, 0.006865263916552067], [0.05317072197794914, 0.33803653717041016, 0.05317072197794914, 0.18129609525203705, 0.3743259310722351], [0.24400362372398376, 0.00017313729040324688, 0.029322758316993713, 0.6971777081489563, 0.029322758316993713], [0.24587127566337585, 0.46866387128829956, 0.23910963535308838, 0.03922874853014946, 0.007126455660909414], [0.12627233564853668, 0.3624092936515808, 0.02362794056534767, 0.3624092936515808, 0.1252811998128891], [0.195020854473114, 0.609431266784668, 0.195020854473114, 0.0001377276494167745, 0.000389302585972473], [0.0014521089615300298, 0.46122676134109497, 0.46122676134109497, 0.06679445505142212, 0.009299950674176216], [0.10347682237625122, 0.42700687050819397, 0.42700687050819397, 0.037526991218328476, 0.004982398822903633], [0.17672769725322723, 0.6691305041313171, 0.058446336537599564, 0.0372491329908371, 0.058446336537599564], [0.7091692686080933, 0.10194265097379684, 0.07935371994972229, 0.054767172783613205, 0.054767172783613205], [0.060579217970371246, 0.003911216743290424, 0.06665471941232681, 0.060579217970371246, 0.8082756400108337], [0.02283352054655552, 0.735213041305542, 0.10637521743774414, 0.10637521743774414, 0.029203053563833237], [0.6254599690437317, 1.4702388398291077e-05, 0.0681612640619278, 0.30634936690330505, 1.4702388398291077e-05], [0.17901931703090668, 0.0779801681637764, 0.15142439305782318, 0.15142439305782318, 0.4401516914367676], [0.003178973449394107, 0.023601453751325607, 0.003178973449394107, 0.6900016069412231, 0.280038982629776], [0.0670778900384903, 0.02442467398941517, 0.0014370454009622335, 0.4535301923751831, 0.4535301923751831], [0.003918387461453676, 0.07536465674638748, 0.07536465674638748, 0.0010509028797969222, 0.8443014621734619], [0.026150187477469444, 0.004004362039268017, 0.46779122948646545, 0.034262970089912415, 0.46779122948646545], [0.06899090856313705, 0.7095859050750732, 0.0907818078994751, 0.0907818078994751, 0.03985954448580742], [0.24359536170959473, 0.059414029121398926, 0.0010679072001948953, 0.6948547959327698, 0.0010679072001948953], [0.12806598842144012, 0.2753979563713074, 0.2753979563713074, 0.2901374399662018, 0.03100070357322693], [0.011021273210644722, 0.01562712900340557, 0.9621070027351379, 0.00022328858904074878, 0.011021273210644722], [0.011408038437366486, 0.7661807537078857, 0.012852856889367104, 0.19670552015304565, 0.012852856889367104], [0.11971955746412277, 0.11971955746412277, 0.19982348382472992, 0.004647518042474985, 0.5560898184776306], [0.5424174666404724, 0.14930076897144318, 0.09402778744697571, 0.09402778744697571, 0.12022615224123001], [0.018969904631376266, 0.2898004651069641, 0.022063998505473137, 0.12039348483085632, 0.5487721562385559], [0.06408338993787766, 0.2217487394809723, 0.2906145751476288, 0.2906145751476288, 0.1329387128353119], [0.8094670176506042, 0.004104898776859045, 0.007815944962203503, 0.004104898776859045, 0.17450720071792603], [0.02298061177134514, 0.04016001150012016, 0.005813013296574354, 0.04016001150012016, 0.8908864259719849], [0.035513896495103836, 0.03931006044149399, 0.035513896495103836, 0.05404878035187721, 0.8356134295463562], [0.00019537139451131225, 0.4002004563808441, 0.5786386728286743, 0.010482769459486008, 0.010482769459486008], [0.24968229234218597, 0.44560620188713074, 0.0038085575215518475, 0.0038085575215518475, 0.29709434509277344], [0.2535441517829895, 0.2725604474544525, 0.02896280586719513, 0.2535441517829895, 0.19138845801353455], [0.305803120136261, 0.0882340744137764, 0.006564530078321695, 0.2935951352119446, 0.305803120136261], [0.5052278637886047, 0.003157755360007286, 0.258364737033844, 0.2286016196012497, 0.004648000933229923], [0.011294043622910976, 0.7753220200538635, 0.011294043622910976, 0.0025277610402554274, 0.1995621621608734], [6.489977295132121e-06, 0.13466492295265198, 0.6098203063011169, 0.12775413691997528, 0.12775413691997528], [0.154017373919487, 0.2791104018688202, 0.2791104018688202, 0.12782375514507294, 0.1599380522966385], [0.49503618478775024, 0.2177959531545639, 0.2177959531545639, 0.016953393816947937, 0.05241855978965759], [0.01089631300419569, 0.3221755623817444, 0.1058974340558052, 0.4551332890987396, 0.1058974340558052], [0.20084360241889954, 0.053723834455013275, 0.6704901456832886, 0.03747120872139931, 0.03747120872139931], [0.29922282695770264, 0.2557683289051056, 0.31794917583465576, 0.10676059126853943, 0.02029913105070591], [0.043392110615968704, 0.0028842438478022814, 0.9102305173873901, 0.00010105923865921795, 0.043392110615968704], [0.7073110938072205, 0.08572608977556229, 0.12032396346330643, 0.0009127382654696703, 0.08572608977556229], [0.41396838426589966, 0.08952480554580688, 0.06665867567062378, 0.3631894290447235, 0.06665867567062378], [0.023450268432497978, 0.5636313557624817, 0.31564056873321533, 0.07382751256227493, 0.023450268432497978], [0.7905082702636719, 0.1706685870885849, 0.0015554247656837106, 0.018633853644132614, 0.018633853644132614], [0.3045918941497803, 0.5419378280639648, 0.12560413777828217, 0.013933094218373299, 0.013933094218373299], [0.11020190268754959, 0.8071447014808655, 0.0018249282147735357, 0.0018249282147735357, 0.07900359481573105], [0.24844004213809967, 0.3316480815410614, 0.003655543550848961, 0.08460827171802521, 0.3316480815410614], [0.06295417994260788, 0.43764984607696533, 0.06295417994260788, 0.326347291469574, 0.11009454727172852], [0.536370575428009, 0.031248439103364944, 0.21337413787841797, 0.005632666405290365, 0.21337413787841797], [0.036788616329431534, 0.21912916004657745, 0.036788616329431534, 0.002632302464917302, 0.7046614289283752], [0.041392263025045395, 0.41651594638824463, 0.26230525970458984, 0.26230525970458984, 0.017481233924627304], [0.45835980772972107, 0.08886582404375076, 0.009351789951324463, 0.35455673933029175, 0.08886582404375076], [0.19205985963344574, 0.6419336199760437, 0.07187224179506302, 0.07187224179506302, 0.022262053564190865], [0.09945143759250641, 0.025031302124261856, 0.025031302124261856, 0.4591730833053589, 0.3913128077983856], [0.25596901774406433, 0.0004195074725430459, 0.0004195074725430459, 0.5397023558616638, 0.20348961651325226], [0.26429304480552673, 0.07524021714925766, 0.28492796421051025, 0.1112457662820816, 0.26429304480552673], [0.09555119276046753, 0.29330021142959595, 0.09555119276046753, 0.2254520058631897, 0.2901454269886017], [0.0784129872918129, 0.8018075227737427, 0.057957205921411514, 0.05097540095448494, 0.01084689237177372], [0.02485254593193531, 0.1677892506122589, 0.1677892506122589, 0.6364143490791321, 0.0031545923557132483], [0.4150138199329376, 0.1642381250858307, 0.13599534332752228, 0.13599534332752228, 0.14875733852386475], [0.19437380135059357, 0.0328991636633873, 0.6889668107032776, 0.0328991636633873, 0.05086112022399902], [0.31709930300712585, 0.0415533185005188, 0.09674745053052902, 0.22750067710876465, 0.31709930300712585], [0.3991925120353699, 0.010353811085224152, 0.006999321281909943, 0.5764550566673279, 0.006999321281909943], [0.0648374855518341, 0.07941437512636185, 0.7649696469306946, 0.0648374855518341, 0.025940965861082077], [0.4647144675254822, 0.4647144675254822, 0.0006579628097824752, 0.066841259598732, 0.0030718999914824963], [0.014437936246395111, 0.05491093546152115, 0.17165346443653107, 0.17165346443653107, 0.587344229221344], [0.011820073239505291, 0.08707626909017563, 0.08119793981313705, 0.409952849149704, 0.409952849149704], [0.03192635998129845, 0.07522142678499222, 0.5908063054084778, 0.27011948823928833, 0.03192635998129845], [0.2777770757675171, 0.2777770757675171, 0.37998855113983154, 0.001394170569255948, 0.06306309998035431], [0.4042873978614807, 0.4042873978614807, 0.01089452300220728, 0.15930218994617462, 0.021228525787591934], [0.46553146839141846, 0.21864821016788483, 0.010830474086105824, 0.21864821016788483, 0.08634160459041595], [0.1291741281747818, 0.13576853275299072, 0.14460793137550354, 0.14460793137550354, 0.445841521024704], [0.061877164989709854, 0.842239499092102, 0.002436185022816062, 0.031569987535476685, 0.061877164989709854], [0.05713535472750664, 0.0022263405844569206, 0.6926161646842957, 0.05713535472750664, 0.19088679552078247], [0.04484131559729576, 0.1250787079334259, 0.1250787079334259, 0.001784709864296019, 0.7032164931297302], [0.45164817571640015, 0.45164817571640015, 0.0008526881574653089, 0.01801946945488453, 0.07783151417970657], [0.13374096155166626, 0.08416252583265305, 0.04129046946763992, 0.04129046946763992, 0.6995156407356262], [0.014282473362982273, 0.2835359573364258, 0.026163730770349503, 0.6498540639877319, 0.026163730770349503], [0.033218566328287125, 0.6465343236923218, 0.07248689234256744, 0.17527331411838531, 0.07248689234256744], [0.9373085498809814, 0.02157650515437126, 0.0010890911798924208, 0.020012883469462395, 0.020012883469462395], [0.025977805256843567, 0.0005330507410690188, 0.025977805256843567, 0.04912358522415161, 0.8983877897262573], [0.5231475234031677, 0.08987847715616226, 0.21547947824001312, 0.16575950384140015, 0.005735047627240419], [0.5963373780250549, 0.04917086660861969, 0.1546027809381485, 0.04528622701764107, 0.1546027809381485], [0.016959775239229202, 0.1784495860338211, 0.016959775239229202, 0.7013617753982544, 0.0862690880894661], [0.3859848082065582, 0.15599071979522705, 0.22022370994091034, 0.22022370994091034, 0.017577027902007103], [0.0010220498079434037, 0.33898329734802246, 0.0038451123982667923, 0.0038451123982667923, 0.6523043513298035], [0.4721592664718628, 0.043210696429014206, 0.012098796665668488, 0.1965816169977188, 0.27594971656799316], [0.8222583532333374, 0.11648301035165787, 0.04756902530789375, 0.006844811607152224, 0.006844811607152224], [0.2660565972328186, 0.5160847306251526, 0.008352713659405708, 0.008352713659405708, 0.2011532336473465], [0.5206829905509949, 0.05135301873087883, 0.05135301873087883, 0.23806309700012207, 0.1385478675365448], [0.189285546541214, 0.419673889875412, 0.005624854005873203, 0.189285546541214, 0.1961302012205124], [0.7164947390556335, 0.026545029133558273, 0.23530223965644836, 0.010828976519405842, 0.010828976519405842], [0.5732982158660889, 0.00023373136355075985, 0.0211620070040226, 0.00023373136355075985, 0.405072420835495], [0.06913372129201889, 0.053528934717178345, 0.01205233484506607, 0.06913372129201889, 0.7961512804031372], [0.01808648742735386, 0.010964371263980865, 0.03667363151907921, 0.010964371263980865, 0.923311173915863], [0.32305029034614563, 0.21208184957504272, 0.11191806942224503, 0.029899487271904945, 0.32305029034614563], [0.04183857515454292, 0.3771803081035614, 0.2008066475391388, 0.0029940700624138117, 0.3771803081035614], [0.037799641489982605, 0.1405642032623291, 0.037799641489982605, 0.31343334913253784, 0.4704033136367798], [0.20712244510650635, 0.015894673764705658, 0.015894673764705658, 0.5761542916297913, 0.18493397533893585], [0.0066708894446492195, 0.27125197649002075, 0.30272963643074036, 0.4193415939807892, 5.979284196655499e-06], [0.35089388489723206, 0.034131646156311035, 0.001103485468775034, 0.30693551898002625, 0.30693551898002625], [0.016902441158890724, 0.4403335154056549, 0.04097362235188484, 0.46081677079200745, 0.04097362235188484], [0.4093659818172455, 0.03322026506066322, 0.00564230140298605, 0.14240553975105286, 0.4093659818172455], [0.19335125386714935, 0.04799109697341919, 0.5631736516952515, 0.04799109697341919, 0.14749287068843842], [0.15496951341629028, 0.11517685651779175, 0.013407356105744839, 0.35822317004203796, 0.35822317004203796], [0.009121731854975224, 0.02147171087563038, 0.9155834913253784, 0.026911495253443718, 0.026911495253443718], [0.594901978969574, 0.05120839551091194, 0.01240469329059124, 0.01240469329059124, 0.3290802836418152], [0.010811255313456059, 0.952009916305542, 0.01811199262738228, 0.010811255313456059, 0.008255600929260254], [0.2067466825246811, 0.2389393001794815, 0.2389393001794815, 0.2838289439678192, 0.03154574707150459], [0.0003772545896936208, 0.13597261905670166, 0.2086840122938156, 0.0003772545896936208, 0.6545888185501099], [0.11680806428194046, 0.023345019668340683, 0.023345019668340683, 0.5886244177818298, 0.24787750840187073], [0.0063212099485099316, 0.043327949941158295, 0.21944470703601837, 0.5114614367485046, 0.21944470703601837], [0.0505540631711483, 0.0505540631711483, 0.27484628558158875, 0.42746254801750183, 0.19658303260803223], [0.09334475547075272, 0.8783634305000305, 0.0072320797480642796, 0.013827638700604439, 0.0072320797480642796], [0.17351184785366058, 0.5101350545883179, 0.17351184785366058, 0.13332827389240265, 0.009512991644442081], [0.14116746187210083, 0.05141326040029526, 0.5070512890815735, 0.2489546686410904, 0.05141326040029526], [0.019599121063947678, 0.19172602891921997, 0.019599121063947678, 0.6906476020812988, 0.07842808216810226], [0.44060638546943665, 0.44060638546943665, 0.08989719301462173, 0.018965598195791245, 0.009924392215907574], [0.0001496371260145679, 0.05091285705566406, 0.0007427413947880268, 0.2710455358028412, 0.67714923620224], [0.003140764543786645, 0.003140764543786645, 0.881136953830719, 0.10928795486688614, 0.003293517976999283], [0.13068197667598724, 0.3279688060283661, 0.1404087096452713, 0.3603164851665497, 0.04062401503324509], [0.26655054092407227, 0.060825470834970474, 0.327359139919281, 0.11209692806005478, 0.23316791653633118], [0.248363196849823, 0.3352622389793396, 0.016430404037237167, 0.3352622389793396, 0.06468193978071213], [0.6399339437484741, 0.1412043571472168, 0.06100797653198242, 0.0166493970900774, 0.1412043571472168], [0.49891820549964905, 0.00012325341231189668, 0.0035668350756168365, 0.0010869656689465046, 0.49630478024482727], [0.2866258919239044, 0.3366354703903198, 0.007916768081486225, 0.36090511083602905, 0.007916768081486225], [0.0039937724359333515, 0.46213841438293457, 0.14894123375415802, 0.3809327483177185, 0.0039937724359333515], [0.019214380532503128, 0.5843483209609985, 0.018007805570960045, 0.3604215979576111, 0.018007805570960045], [0.22139674425125122, 0.0300738662481308, 0.36592286825180054, 0.36592286825180054, 0.016683677211403847], [0.4144560992717743, 0.4144560992717743, 0.006405804306268692, 0.16381549835205078, 0.000866561837028712], [0.004305560607463121, 0.1852165013551712, 0.004305560607463121, 0.2997611463069916, 0.5064112544059753], [0.23050664365291595, 0.03260163962841034, 0.05418185144662857, 0.4522031843662262, 0.23050664365291595], [0.44607028365135193, 0.0020880112424492836, 0.05545107275247574, 0.44607028365135193, 0.0503203421831131], [0.1634870022535324, 0.038082562386989594, 0.038082562386989594, 0.04314815253019333, 0.7171996831893921], [0.6048206090927124, 0.15119346976280212, 0.15119346976280212, 0.07210423052310944, 0.020688185468316078], [0.003417960135266185, 0.901309072971344, 0.003417960135266185, 0.004135641269385815, 0.08771931380033493], [0.21432165801525116, 0.1457212269306183, 0.0750555694103241, 0.21432165801525116, 0.3505799472332001], [0.30019208788871765, 0.005565053783357143, 0.08831250667572021, 0.6003652811050415, 0.005565053783357143], [0.10344696044921875, 0.004174604080617428, 0.003928529564291239, 0.4442249834537506, 0.4442249834537506], [0.07101039588451385, 0.0035217676777392626, 0.8927496671676636, 0.016359109431505203, 0.016359109431505203], [0.14421655237674713, 3.788903268286958e-05, 3.788903268286958e-05, 0.018881209194660187, 0.836826503276825], [0.0019395425915718079, 0.04178723320364952, 0.7652432918548584, 0.0019395425915718079, 0.1890902817249298], [0.03526514768600464, 0.1848021298646927, 0.3312428295612335, 0.3312428295612335, 0.11744710803031921], [0.09481847286224365, 0.16526836156845093, 0.09836992621421814, 0.09481847286224365, 0.5467247366905212], [0.6586626768112183, 0.24336285889148712, 0.0006028224597685039, 0.087563656270504, 0.009807975962758064], [0.06776723265647888, 0.0010938964551314712, 0.8098931312561035, 0.05347851663827896, 0.06776723265647888], [0.011766238138079643, 0.07322151958942413, 0.05424385517835617, 0.7875468730926514, 0.07322151958942413], [0.48927831649780273, 0.004408450331538916, 0.008618852123618126, 0.008416073396801949, 0.48927831649780273], [0.28677627444267273, 0.0004512991290539503, 0.5898911356925964, 0.0004512991290539503, 0.12243001163005829], [0.30677175521850586, 0.30677175521850586, 0.00012813546345569193, 0.1908227801322937, 0.19550558924674988], [0.11528786271810532, 9.363084973301739e-05, 0.7688177824020386, 0.11528786271810532, 0.0005128788761794567], [0.10869299620389938, 0.30931293964385986, 0.10869299620389938, 0.032937947660684586, 0.4403631389141083], [0.049327194690704346, 0.01680152490735054, 0.4268846809864044, 0.049327194690704346, 0.45765936374664307], [0.10185765475034714, 0.014110657386481762, 0.7800043225288391, 0.10185765475034714, 0.0021696644835174084], [0.29133716225624084, 0.03436204791069031, 0.381355881690979, 0.29133716225624084, 0.0016077745240181684], [0.18139633536338806, 0.20274494588375092, 0.37730729579925537, 0.18139633536338806, 0.05715503916144371], [0.09016014635562897, 0.03249923139810562, 0.0695013701915741, 0.34821751713752747, 0.45962175726890564], [0.021812355145812035, 0.5680680871009827, 0.20469340682029724, 0.0007327444618567824, 0.20469340682029724], [0.12253031879663467, 0.7244144678115845, 0.01972334086894989, 0.12253031879663467, 0.010801605880260468], [0.4049278795719147, 0.04504533112049103, 0.02280759997665882, 0.504411518573761, 0.02280759997665882], [0.008085235022008419, 0.1456763744354248, 0.01609661802649498, 0.01609661802649498, 0.8140451312065125], [0.025493690744042397, 0.07108653336763382, 0.025493690744042397, 0.33743730187416077, 0.5404887199401855], [0.12967512011528015, 0.12967512011528015, 0.5560926198959351, 0.01029787864536047, 0.17425930500030518], [0.1799740046262741, 0.26313748955726624, 0.2725694477558136, 0.01174954790621996, 0.2725694477558136], [0.29068440198898315, 0.020659884437918663, 0.29242777824401855, 0.10380014777183533, 0.29242777824401855], [0.34867358207702637, 0.18562953174114227, 0.008945764973759651, 0.34867358207702637, 0.1080775335431099], [0.0994013100862503, 0.2565019130706787, 0.07761096209287643, 0.07761096209287643, 0.4888748824596405], [0.5614823698997498, 0.10100658237934113, 0.24453052878379822, 0.046490252017974854, 0.046490252017974854], [0.6749675273895264, 0.00208028475753963, 0.10391074419021606, 0.00208028475753963, 0.21696113049983978], [0.14891545474529266, 0.0859893262386322, 0.23443664610385895, 0.2653293013572693, 0.2653293013572693], [0.2980114221572876, 0.003163266694173217, 0.003781442064791918, 0.003781442064791918, 0.691262423992157], [0.028640691190958023, 0.020102793350815773, 0.8862009644508362, 0.0449528694152832, 0.020102793350815773], [0.439134806394577, 0.01829191856086254, 0.24730539321899414, 0.006199009250849485, 0.2890687882900238], [0.06588275730609894, 0.08620605617761612, 0.39215973019599915, 0.08620605617761612, 0.3695453703403473], [0.003311161184683442, 0.3699875771999359, 0.5859500765800476, 0.020375581458210945, 0.020375581458210945], [0.4776442348957062, 0.0013284501619637012, 0.5145697593688965, 0.00512907886877656, 0.0013284501619637012], [0.10235118120908737, 0.2790369987487793, 0.30161023139953613, 0.30161023139953613, 0.015391364693641663], [0.0753166675567627, 0.00478358706459403, 0.0753166675567627, 0.5415794849395752, 0.30300357937812805], [7.165099304984324e-06, 0.0014354552840813994, 0.49244943261146545, 0.0136584946885705, 0.49244943261146545], [0.034822337329387665, 0.6245837807655334, 0.07125210016965866, 0.23451943695545197, 0.034822337329387665], [0.469177782535553, 0.015002680011093616, 0.014589784666895866, 0.03205196559429169, 0.469177782535553], [0.017636563628911972, 0.0004673921503126621, 0.9670290946960449, 0.0074334223754704, 0.0074334223754704], [0.18844406306743622, 0.017269590869545937, 0.1449710875749588, 0.18844406306743622, 0.4608711898326874], [0.005659810267388821, 0.48656487464904785, 0.02103848196566105, 0.00017205292533617467, 0.48656487464904785], [0.0005264679784886539, 0.0005264679784886539, 0.005814199335873127, 0.22375380992889404, 0.7693790197372437], [0.11814412474632263, 0.7958489060401917, 0.004699085373431444, 0.04065397381782532, 0.04065397381782532], [0.04740698263049126, 0.7873432636260986, 0.1014639362692833, 0.01637882925570011, 0.04740698263049126], [0.7950373888015747, 0.15706822276115417, 0.0035635686945170164, 0.036106176674366, 0.008224639110267162], [0.000148196893860586, 0.11455117166042328, 0.3078744113445282, 0.5685426592826843, 0.008883627131581306], [0.6790201663970947, 0.028668038547039032, 0.009103268384933472, 0.1416042447090149, 0.1416042447090149], [0.032589033246040344, 0.3233816623687744, 0.312372624874115, 0.008275025524199009, 0.3233816623687744], [0.061077918857336044, 0.09892170131206512, 0.7403627634048462, 0.000715892412699759, 0.09892170131206512], [0.19827203452587128, 0.38842877745628357, 0.38842877745628357, 0.022508174180984497, 0.0023622692096978426], [0.3926197290420532, 0.1860995888710022, 0.02409820258617401, 0.3926197290420532, 0.004562717862427235], [0.3239719271659851, 0.10858938097953796, 0.10858938097953796, 0.16843995451927185, 0.29040929675102234], [0.1065010353922844, 0.006195643916726112, 0.006195643916726112, 0.4710979759693146, 0.4100096821784973], [0.22315016388893127, 0.22315016388893127, 0.2428084909915924, 0.026004645973443985, 0.28488653898239136], [0.30349409580230713, 0.008997743017971516, 0.30349409580230713, 0.09314651042222977, 0.29086756706237793], [0.02257373370230198, 0.03745856136083603, 0.03745856136083603, 0.6478474736213684, 0.2546616792678833], [0.12739743292331696, 0.016255691647529602, 0.4114440381526947, 0.4114440381526947, 0.033458806574344635], [0.10498910397291183, 0.10498910397291183, 0.4559744596481323, 0.01583845727145672, 0.31820887327194214], [0.09865609556436539, 0.4384005069732666, 0.4384005069732666, 0.01875711791217327, 0.005785711109638214], [0.43802300095558167, 0.0024867146275937557, 0.0007795366691425443, 0.43802300095558167, 0.12068773061037064], [0.12259302288293839, 0.20931628346443176, 0.26924842596054077, 0.20931628346443176, 0.18952599167823792], [0.1128518357872963, 0.24242782592773438, 0.24242782592773438, 0.2798140048980713, 0.12247846275568008], [0.00047932317829690874, 0.004438767675310373, 0.551406741142273, 0.00047932317829690874, 0.4431958794593811], [0.3636128008365631, 0.002996826311573386, 0.3636128008365631, 0.026309309527277946, 0.2434682548046112], [0.21716202795505524, 0.05962216481566429, 0.24744242429733276, 0.416151225566864, 0.05962216481566429], [0.029284410178661346, 0.053872983902692795, 0.39798498153686523, 0.12087266147136688, 0.39798498153686523], [0.007180146872997284, 0.0248391292989254, 0.2626308798789978, 0.2626308798789978, 0.4427190124988556], [0.12469862401485443, 0.02381211705505848, 0.026271820068359375, 0.8140773773193359, 0.011140109039843082], [0.008819364942610264, 0.12490088492631912, 0.011924386024475098, 0.720238983631134, 0.13411638140678406], [0.0005037383525632322, 0.07558991014957428, 0.0005037383525632322, 0.9187232255935669, 0.004679387900978327], [0.45482826232910156, 0.0001706114417174831, 0.45482826232910156, 0.08876143395900726, 0.0014113873476162553], [0.0018790732137858868, 0.008184142410755157, 0.12075961381196976, 0.43458858132362366, 0.43458858132362366], [0.41105523705482483, 0.05564909055829048, 0.23920980095863342, 0.05487611144781113, 0.23920980095863342], [0.1194084957242012, 0.03959610313177109, 0.02554342709481716, 0.02554342709481716, 0.7899085283279419], [0.05236906558275223, 0.6151552796363831, 0.16337540745735168, 0.11673116683959961, 0.05236906558275223], [0.16518695652484894, 0.3968000113964081, 0.08784288167953491, 0.18498319387435913, 0.16518695652484894], [0.04332331195473671, 0.04332331195473671, 0.0020850126165896654, 0.65934157371521, 0.2519267201423645], [0.4633449614048004, 0.006471284665167332, 0.0002896510704886168, 0.5234228372573853, 0.006471284665167332], [0.004278791137039661, 0.3260466754436493, 0.3260466754436493, 0.33453091979026794, 0.009096949361264706], [0.03996884822845459, 0.20777271687984467, 0.015041119419038296, 0.5294446349143982, 0.20777271687984467], [0.2582617998123169, 0.17661356925964355, 0.110868439078331, 0.19599443674087524, 0.2582617998123169], [0.9532515406608582, 0.009701203554868698, 0.009701203554868698, 0.021311094984412193, 0.006034867372363806], [0.05838126689195633, 0.8502744436264038, 0.028636714443564415, 0.004326237831264734, 0.05838126689195633], [0.019604897126555443, 0.5006643533706665, 0.019604897126555443, 0.40407341718673706, 0.056052446365356445], [0.0030861308332532644, 0.4573855698108673, 0.0009290827438235283, 0.08121357858181, 0.4573855698108673], [0.2998226284980774, 0.005131498444825411, 0.005131498444825411, 0.5681709051132202, 0.12174344062805176], [0.3008875250816345, 0.3008875250816345, 0.06912929564714432, 0.0664789006114006, 0.26261666417121887], [0.6821931004524231, 3.120303153991699e-05, 0.11053723096847534, 0.11053723096847534, 0.09670126438140869], [0.11092390865087509, 0.3810192346572876, 0.000691086461301893, 0.3810192346572876, 0.12634655833244324], [0.018772371113300323, 0.018772371113300323, 0.5524955987930298, 0.02397555112838745, 0.3859841227531433], [0.010092089883983135, 0.01404541451483965, 0.01404541451483965, 0.9597960710525513, 0.0020209450740367174], [0.04630207642912865, 0.024768231436610222, 0.08037599921226501, 0.08037599921226501, 0.7681776881217957], [0.004942710045725107, 0.004942710045725107, 0.09200544655323029, 0.4044457972049713, 0.49366334080696106], [0.12795595824718475, 0.18892718851566315, 0.31236401200294495, 0.31236401200294495, 0.058388851583004], [0.003946630749851465, 0.3039636015892029, 0.03864927589893341, 0.03864927589893341, 0.6147911548614502], [0.025500105693936348, 0.8257308602333069, 0.04573960229754448, 0.07752933353185654, 0.025500105693936348], [0.7730717062950134, 0.04998532682657242, 0.02477194368839264, 0.10218565911054611, 0.04998532682657242], [0.0006769400206394494, 0.04147394746541977, 0.7901101112365723, 0.16706207394599915, 0.0006769400206394494], [0.6335808634757996, 0.034321095794439316, 0.164822518825531, 0.002452931134030223, 0.164822518825531], [0.5980207324028015, 0.31800559163093567, 0.051271479576826096, 0.01635105162858963, 0.01635105162858963], [0.005938323680311441, 0.13996420800685883, 0.009812644682824612, 0.8383464813232422, 0.005938323680311441], [0.017649684101343155, 0.2923286557197571, 0.05094137042760849, 0.2923286557197571, 0.3467516601085663], [0.3775098919868469, 0.0144452303647995, 0.11774331331253052, 0.3775098919868469, 0.11279167234897614], [0.30101677775382996, 0.09974933415651321, 0.000311479700030759, 0.2979055941104889, 0.30101677775382996], [0.0030158660374581814, 0.0030158660374581814, 0.2524685561656952, 0.04831701144576073, 0.6931827068328857], [0.20012563467025757, 0.11123277246952057, 0.4458555579185486, 0.04266047850251198, 0.20012563467025757], [0.25518497824668884, 0.004181278869509697, 0.7318786382675171, 0.0045738075859844685, 0.004181278869509697], [0.006695120595395565, 0.01910454034805298, 0.40009605884552, 0.4334869086742401, 0.14061738550662994], [0.005180413834750652, 0.24050141870975494, 0.2809205651283264, 0.23289620876312256, 0.24050141870975494], [0.008009050041437149, 0.008009050041437149, 0.730563223361969, 0.011394113302230835, 0.2420245260000229], [0.06074709817767143, 0.011912073940038681, 0.016245251521468163, 0.8671295046806335, 0.04396612569689751], [0.6353611350059509, 0.016810502856969833, 0.016810502856969833, 0.3199198246002197, 0.01109802071005106], [8.912580960895866e-05, 0.004700221121311188, 0.001258314005099237, 0.49697616696357727, 0.49697616696357727], [0.47282522916793823, 0.004007278010249138, 5.4754502343712375e-05, 0.47282522916793823, 0.05028758943080902], [0.15112677216529846, 0.022338567301630974, 0.3634639084339142, 0.09960689395666122, 0.3634639084339142], [0.20170898735523224, 0.39586520195007324, 0.1822298914194107, 0.01848689280450344, 0.20170898735523224], [0.6908614039421082, 0.08370041847229004, 0.050119463354349136, 0.12519919872283936, 0.050119463354349136], [0.46312734484672546, 0.44442451000213623, 0.012284761294722557, 0.06787869334220886, 0.012284761294722557], [0.4590056240558624, 0.03505069389939308, 0.0699167475104332, 0.03505069389939308, 0.4009762108325958], [0.3226902484893799, 0.23605240881443024, 0.11400453746318817, 0.004562633577734232, 0.3226902484893799], [0.00012025119212921709, 0.2118852138519287, 0.040811263024806976, 0.5352980494499207, 0.2118852138519287], [0.04761200398206711, 0.09986363351345062, 0.09986363351345062, 0.016880597919225693, 0.7357801198959351], [0.045279212296009064, 0.9485267996788025, 0.002648774301633239, 0.002648774301633239, 0.0008965050801634789], [0.003677541622892022, 0.051963139325380325, 0.8915303349494934, 0.0008657785947434604, 0.051963139325380325], [0.3154752850532532, 0.04031974449753761, 0.02995254658162594, 0.04031974449753761, 0.5739326477050781], [0.29673394560813904, 0.0780877023935318, 0.008107841946184635, 0.3203365206718445, 0.29673394560813904], [0.004073264542967081, 0.004073264542967081, 0.6485717296600342, 0.05106562376022339, 0.29221606254577637], [0.0030896991956979036, 0.0030896991956979036, 0.23809728026390076, 0.7308176159858704, 0.024905655533075333], [0.21129831671714783, 0.02243417501449585, 0.00889232661575079, 9.620207856642082e-05, 0.7572789192199707], [0.06124329939484596, 0.6057403087615967, 0.030680859461426735, 0.15116776525974274, 0.15116776525974274], [0.8592259287834167, 0.02708963304758072, 0.059733159840106964, 0.026861583814024925, 0.02708963304758072], [0.02520565129816532, 0.4256102740764618, 0.11660831421613693, 0.006965606939047575, 0.4256102740764618], [0.7543389797210693, 0.0036254862789064646, 0.10639900714159012, 0.029237428680062294, 0.10639900714159012], [0.08332576602697372, 0.0038187424652278423, 0.007873100228607655, 0.08332576602697372, 0.8216565251350403], [0.0385972261428833, 0.3112591803073883, 0.3112591803073883, 0.3256461024284363, 0.013238322921097279], [0.08246508240699768, 0.6032891869544983, 0.06385769695043564, 0.06385769695043564, 0.18653036653995514], [0.38703590631484985, 0.0625125840306282, 0.1543063223361969, 0.011266368441283703, 0.3848787844181061], [0.5404216647148132, 0.4148329198360443, 0.016267476603388786, 0.014238941483199596, 0.014238941483199596], [0.07128673046827316, 0.09165504574775696, 0.3458687663078308, 0.14532072842121124, 0.3458687663078308], [0.578779399394989, 0.04356389120221138, 0.002836703322827816, 0.002836703322827816, 0.3719833195209503], [0.06608690321445465, 0.8112042546272278, 0.06608690321445465, 0.033785801380872726, 0.022836143150925636], [0.7953009009361267, 0.01214754581451416, 0.08422363549470901, 0.09618040174245834, 0.01214754581451416], [0.5284495949745178, 0.12538938224315643, 0.021978987380862236, 0.19879265129566193, 0.12538938224315643], [0.31493300199508667, 0.07822694629430771, 0.19043079018592834, 0.20820464193820953, 0.20820464193820953], [0.015932612121105194, 0.015932612121105194, 0.043881818652153015, 0.9095409512519836, 0.01471199095249176], [0.6521496176719666, 0.035911526530981064, 0.14464378356933594, 0.14464378356933594, 0.02265123277902603], [0.021222243085503578, 0.08142054080963135, 0.09306048601865768, 0.021222243085503578, 0.7830745577812195], [0.12460123747587204, 0.7924613952636719, 0.03913141414523125, 0.021902982145547867, 0.021902982145547867], [0.3899627923965454, 0.1711995154619217, 0.020539650693535805, 0.02833528444170952, 0.3899627923965454], [0.0011359858326613903, 0.021648524329066277, 0.021648524329066277, 0.02722506783902645, 0.928341805934906], [0.00372114940546453, 0.2067815363407135, 0.2067815363407135, 0.29156360030174255, 0.2911521792411804], [0.39787477254867554, 0.15902096033096313, 0.15902096033096313, 0.01245768740773201, 0.27162566781044006], [0.006028839852660894, 0.0011057417141273618, 0.26395848393440247, 0.7278011441230774, 0.0011057417141273618], [0.00012009788770228624, 0.8299080729484558, 0.1263151913881302, 0.04353650286793709, 0.00012009788770228624], [0.06683387607336044, 0.016314813867211342, 0.06683387607336044, 0.0008407325367443264, 0.8491767048835754], [0.3455979526042938, 0.017691761255264282, 0.19036592543125153, 0.10074642300605774, 0.3455979526042938], [0.015364023856818676, 0.6840808391571045, 0.015364023856818676, 0.15499459207057953, 0.13019660115242004], [0.48769015073776245, 0.11653443425893784, 0.18966881930828094, 0.08957214653491974, 0.11653443425893784], [0.2704381048679352, 0.1000916138291359, 0.00046146163367666304, 0.2704381048679352, 0.3585706949234009], [0.0005548985791392624, 0.21345163881778717, 0.0102201784029603, 0.0102201784029603, 0.7655531167984009], [0.17930053174495697, 0.17930053174495697, 0.07682804763317108, 0.02674238756299019, 0.5378285050392151], [0.010299649089574814, 6.577676685992628e-05, 0.9677379727363586, 0.010299649089574814, 0.01159699447453022], [0.18966902792453766, 0.05266491696238518, 0.13301530480384827, 0.43498170375823975, 0.18966902792453766], [0.05048784613609314, 0.8562972545623779, 0.05048784613609314, 0.04154554009437561, 0.0011814809404313564], [0.06260653585195541, 0.06260653585195541, 0.0020558175165206194, 4.1788076487137005e-05, 0.8726893663406372], [0.010533890686929226, 0.13843683898448944, 0.13843683898448944, 0.07995890825986862, 0.6326335072517395], [0.22110344469547272, 0.0006291598547250032, 0.057962194085121155, 0.03033246286213398, 0.6899726986885071], [0.8343032598495483, 0.0003492550749797374, 0.05911675840616226, 0.0003492550749797374, 0.10588154196739197], [0.09030061960220337, 0.0003275503986515105, 0.9026788473129272, 0.003346450859680772, 0.003346450859680772], [0.1744794249534607, 0.26305314898490906, 0.26125478744506836, 0.039957866072654724, 0.26125478744506836], [0.4811776578426361, 0.016184819862246513, 0.004250471945852041, 0.4811776578426361, 0.01720932498574257], [0.0002842034737113863, 0.0002842034737113863, 0.689688503742218, 0.001915095141157508, 0.30782800912857056], [0.0007025808445177972, 0.9426592588424683, 0.0007025808445177972, 0.04991251602768898, 0.006023081485182047], [0.0028371757362037897, 0.00430988147854805, 0.3063875436782837, 0.6821554899215698, 0.00430988147854805], [0.17392577230930328, 0.4201018214225769, 0.17392577230930328, 0.025551553815603256, 0.20649506151676178], [0.018221843987703323, 0.018221843987703323, 0.10005712509155273, 0.02253672108054161, 0.8409624695777893], [0.33333778381347656, 0.1661902666091919, 1.4773911971133202e-05, 0.33333778381347656, 0.16711938381195068], [0.16859856247901917, 0.10104324668645859, 0.4397432804107666, 0.16859856247901917, 0.12201632559299469], [0.027169244363904, 0.008032022975385189, 0.027169244363904, 0.000928781577385962, 0.936700701713562], [0.19461427628993988, 0.17302243411540985, 0.002610046649351716, 0.4567308723926544, 0.17302243411540985], [0.09135472029447556, 0.18028999865055084, 0.5353364944458008, 0.18028999865055084, 0.01272881031036377], [0.09868752956390381, 0.09868752956390381, 0.20168788731098175, 0.03896501287817955, 0.5619720220565796], [0.0618743933737278, 0.01250829640775919, 0.9120070338249207, 0.01250829640775919, 0.0011018916266039014], [0.5361678600311279, 0.2744826674461365, 0.08451943844556808, 0.020310526713728905, 0.08451943844556808], [0.39722785353660583, 0.02190195955336094, 0.4318596124649048, 0.02190195955336094, 0.1271086186170578], [0.0013731397921219468, 0.364590048789978, 0.038557130843400955, 0.5941065549850464, 0.0013731397921219468], [0.0020252084359526634, 0.51254802942276, 0.43756139278411865, 0.023932674899697304, 0.023932674899697304], [0.10235194116830826, 0.03310816362500191, 0.8076172471046448, 0.0041923485696315765, 0.05273030325770378], [0.008494329638779163, 0.009570859372615814, 0.13501988351345062, 0.8384206295013428, 0.008494329638779163], [0.02924719639122486, 0.01854509674012661, 0.8089590668678284, 0.02924719639122486, 0.11400149017572403], [0.16179335117340088, 0.14594760537147522, 0.3429786264896393, 0.006301776971668005, 0.3429786264896393], [0.45559319853782654, 0.45559319853782654, 0.05958937481045723, 0.028214970603585243, 0.0010093279415741563], [0.008402321487665176, 0.008402321487665176, 0.003907889127731323, 0.5166552662849426, 0.4626322090625763], [0.0027418204117566347, 0.023769326508045197, 0.8622121810913086, 0.0027418204117566347, 0.10853494703769684], [0.008515791036188602, 0.008515791036188602, 0.4023120105266571, 0.5573470592498779, 0.02330937050282955], [0.04583422467112541, 0.8075679540634155, 0.003986570984125137, 0.07020511478185654, 0.07240618765354156], [0.7748165130615234, 0.19611874222755432, 0.008735455572605133, 0.008735455572605133, 0.011593868024647236], [0.06138678640127182, 0.3002576529979706, 0.06138678640127182, 0.3632452189922333, 0.21372351050376892], [0.13497334718704224, 0.39622700214385986, 0.056556835770606995, 0.016015851870179176, 0.39622700214385986], [0.16235986351966858, 0.4769073724746704, 0.1478288173675537, 0.05054401606321335, 0.16235986351966858], [0.03815580904483795, 0.030529478564858437, 0.46398410201072693, 0.46398410201072693, 0.003346475772559643], [0.08521290868520737, 0.08521290868520737, 0.35715049505233765, 0.47233930230140686, 8.448043081443757e-05], [0.07929098606109619, 0.12105764448642731, 0.7108062505722046, 0.009554099291563034, 0.07929098606109619], [0.019967420026659966, 0.6652860641479492, 0.019967420026659966, 0.25116828083992004, 0.043610814958810806], [0.4254278242588043, 0.012400698848068714, 0.4254278242588043, 0.01671886257827282, 0.12002483755350113], [0.12261047959327698, 0.6186994314193726, 0.0953698605298996, 0.0953698605298996, 0.06795032322406769], [0.2504732608795166, 0.21727469563484192, 0.036080438643693924, 0.2802025377750397, 0.21596910059452057], [0.4116465449333191, 0.4116465449333191, 0.0316963829100132, 0.1262494921684265, 0.018761061131954193], [0.0005866035935468972, 0.006190371233969927, 0.06619049608707428, 0.4635162651538849, 0.4635162651538849], [0.40264230966567993, 0.19569088518619537, 0.19569088518619537, 0.08095759898424149, 0.12501834332942963], [0.4913867115974426, 0.004448919091373682, 0.005025751423090696, 0.4913867115974426, 0.007751892786473036], [0.14078493416309357, 0.4125528037548065, 0.4125528037548065, 0.027422107756137848, 0.006687307730317116], [0.009249312803149223, 0.045556966215372086, 0.8700414299964905, 0.029595373198390007, 0.045556966215372086], [0.01993744634091854, 0.2602277100086212, 0.17224286496639252, 0.01993744634091854, 0.5276545882225037], [0.019508609548211098, 0.6156790852546692, 0.16213953495025635, 0.16213953495025635, 0.04053325951099396], [0.43305322527885437, 0.07439391314983368, 0.15940263867378235, 0.15940263867378235, 0.17374758422374725], [0.021269183605909348, 0.03758849576115608, 0.1770893931388855, 0.04008791595697403, 0.7239649891853333], [0.03311005234718323, 0.4594942629337311, 0.4594942629337311, 0.04787395894527435, 2.7418165700510144e-05], [0.02460000105202198, 0.3889654576778412, 0.1970820426940918, 0.000386999046895653, 0.3889654576778412], [0.12355678528547287, 0.019535722211003304, 0.6083287596702576, 0.12502199411392212, 0.12355678528547287], [0.0013942321529611945, 0.4976603090763092, 0.0004527293785940856, 0.4976603090763092, 0.0028323691803961992], [6.4994725107681e-05, 0.017939383164048195, 0.20513445138931274, 6.4994725107681e-05, 0.7767961025238037], [0.07072341442108154, 0.0364874042570591, 0.4007349908351898, 0.4007349908351898, 0.09131915867328644], [0.34465959668159485, 0.22692547738552094, 0.21217738091945648, 0.21217738091945648, 0.00406018178910017], [0.4795534610748291, 0.02231394313275814, 0.001096302061341703, 0.4795534610748291, 0.017482886090874672], [0.04636847972869873, 0.6791875958442688, 0.08830252289772034, 0.08830252289772034, 0.09783878922462463], [0.338704913854599, 0.2138744741678238, 0.10605083405971527, 0.002664861036464572, 0.338704913854599], [0.5327216982841492, 0.20424173772335052, 0.002455557696521282, 0.20424173772335052, 0.05633923038840294], [0.012465312145650387, 0.00823827926069498, 0.3372103273868561, 0.6296207308769226, 0.012465312145650387], [0.12132205069065094, 0.02411138080060482, 0.5211522579193115, 0.12132205069065094, 0.21209226548671722], [0.039448052644729614, 0.22357036173343658, 0.010125447064638138, 0.6874081492424011, 0.039448052644729614], [0.10698174685239792, 0.6366846561431885, 0.1484142392873764, 0.10698174685239792, 0.0009375921217724681], [0.002458536997437477, 0.057076819241046906, 0.011108662001788616, 0.011108662001788616, 0.9182472229003906], [0.18206527829170227, 0.2418704777956009, 0.19076475501060486, 0.2418704777956009, 0.14342902600765228], [0.18260769546031952, 0.6723016500473022, 0.13088588416576385, 0.007102403324097395, 0.007102403324097395], [0.33373767137527466, 0.0017639190191403031, 0.0012814922956749797, 0.0017639190191403031, 0.6614530086517334], [0.011102299205958843, 0.8695794939994812, 0.009337636642158031, 0.07338637858629227, 0.036594223231077194], [0.018702469766139984, 0.5392055511474609, 0.0016384943155571818, 0.0016384943155571818, 0.43881499767303467], [0.004575507249683142, 0.004575507249683142, 0.8715141415596008, 0.10741348564624786, 0.011921311728656292], [0.02033562771975994, 0.4202856421470642, 0.019433142617344856, 0.4202856421470642, 0.11965994536876678], [0.021736813709139824, 0.21138989925384521, 0.0846620500087738, 0.470821350812912, 0.21138989925384521], [0.029995400458574295, 0.00200314330868423, 0.7890957593917847, 0.00200314330868423, 0.17690259218215942], [0.35598528385162354, 0.5800891518592834, 0.0127475680783391, 0.0127475680783391, 0.03843039274215698], [0.4576857388019562, 0.04903912544250488, 0.0019843652844429016, 0.033605046570301056, 0.4576857388019562], [0.11283674836158752, 0.0011312876595184207, 0.11283674836158752, 0.04843265935778618, 0.7247626781463623], [0.03902420774102211, 0.03902420774102211, 0.037984397262334824, 0.15529228746891022, 0.7286749482154846], [0.28470179438591003, 0.014730310067534447, 0.13485045731067657, 0.13485045731067657, 0.4308669865131378], [0.08302953839302063, 0.061540644615888596, 0.7850522994995117, 0.008836880326271057, 0.061540644615888596], [0.39562520384788513, 0.39562520384788513, 0.0023763864301145077, 0.04656185582280159, 0.159811332821846], [0.39183297753334045, 0.15198524296283722, 0.015983596444129944, 0.39183297753334045, 0.0483652800321579], [0.5560784339904785, 0.1961626261472702, 0.08318736404180527, 0.08228577673435211, 0.08228577673435211], [0.46273377537727356, 0.46273377537727356, 0.017976706847548485, 0.003430322278290987, 0.053125541657209396], [0.149873286485672, 0.6126088500022888, 0.149873286485672, 0.004605759866535664, 0.08303883671760559], [0.27445146441459656, 0.3679680824279785, 0.27445146441459656, 0.08305744081735611, 7.150812598410994e-05], [0.38436567783355713, 0.03750469908118248, 0.056848686188459396, 0.38436567783355713, 0.13691525161266327], [0.020061418414115906, 0.06149083003401756, 0.7785021066665649, 0.1198842003941536, 0.020061418414115906], [0.40963223576545715, 0.0004955959157086909, 0.1801053285598755, 0.0001346777571598068, 0.40963223576545715], [0.6003040671348572, 0.18225590884685516, 0.02793029136955738, 0.18225590884685516, 0.0072537800297141075], [0.4216042757034302, 0.0466470904648304, 0.13858449459075928, 0.12091857939958572, 0.2722455859184265], [0.02776765450835228, 0.0008974327938631177, 0.4086558520793915, 0.4086558520793915, 0.15402312576770782], [0.48038116097450256, 0.0023504053242504597, 0.0023504053242504597, 0.2894519865512848, 0.2254660427570343], [0.31809934973716736, 0.01825130358338356, 0.5883399844169617, 0.05705804377794266, 0.01825130358338356], [0.015100362710654736, 0.00016764839529059827, 0.11718472093343735, 0.0630938783288002, 0.804453432559967], [0.0427081398665905, 0.07005473971366882, 0.208608478307724, 0.3393142819404602, 0.3393142819404602], [0.1078442633152008, 0.16265907883644104, 0.07228895276784897, 0.4945485591888428, 0.16265907883644104], [0.04233900085091591, 0.4686276316642761, 0.4492287039756775, 0.019902318716049194, 0.019902318716049194], [0.5504423379898071, 0.16903887689113617, 0.16903887689113617, 0.11024169623851776, 0.0012382252607494593], [0.48772019147872925, 0.004496801178902388, 0.01992349699139595, 0.0001393267884850502, 0.48772019147872925], [0.00170794571749866, 0.014175387099385262, 0.00623804097995162, 0.7894607782363892, 0.18841782212257385], [0.3524993658065796, 0.3524993658065796, 0.2568424940109253, 0.03693550452589989, 0.0012232641456648707], [0.5347967743873596, 0.0007288972265087068, 0.35302063822746277, 0.11072475463151932, 0.0007288972265087068], [0.0028879407327622175, 0.06098273769021034, 0.7022791504859924, 0.06098273769021034, 0.17286747694015503], [0.21465791761875153, 0.5386921167373657, 0.008771519176661968, 0.02322050929069519, 0.21465791761875153], [0.32149797677993774, 0.2920736074447632, 0.020247289910912514, 0.32149797677993774, 0.04468318819999695], [0.11683861911296844, 0.7639809846878052, 0.11683861911296844, 0.0019890840630978346, 0.0003527299559209496], [0.15689809620380402, 0.06731095165014267, 0.15689809620380402, 0.2926260828971863, 0.3262667953968048], [0.445644348859787, 0.036431968212127686, 0.07163172215223312, 0.0006475638947449625, 0.445644348859787], [0.00020773262076545507, 0.2563926577568054, 0.39918819069862366, 0.08781871944665909, 0.2563926577568054], [0.002608671085909009, 0.006527672987431288, 0.24438656866550446, 0.002608671085909009, 0.7438684105873108], [0.4174891710281372, 0.03704875707626343, 0.0668005421757698, 0.41186097264289856, 0.0668005421757698], [0.025943290442228317, 0.03783319890499115, 0.025988927111029625, 0.27303287386894226, 0.637201726436615], [0.17678049206733704, 0.2981974184513092, 0.1583334058523178, 0.277994304895401, 0.08869434148073196], [0.38312169909477234, 0.38312169909477234, 0.11525874584913254, 0.09867927432060242, 0.019818579778075218], [0.0008248889935202897, 0.9563734531402588, 0.0024206910748034716, 0.03796028718352318, 0.0024206910748034716], [0.0055962069891393185, 0.46610918641090393, 0.026904433965682983, 0.46610918641090393, 0.035281047224998474], [0.037992365658283234, 0.0462215356528759, 0.006483654957264662, 0.9028187394142151, 0.006483654957264662], [0.18848268687725067, 0.5232431292533875, 0.18848268687725067, 0.026784857735037804, 0.07300662994384766], [0.08094573765993118, 0.348586767911911, 0.348586767911911, 0.21748097240924835, 0.004399708937853575], [0.00213996646925807, 0.6933214068412781, 0.00213996646925807, 0.11986381560564041, 0.18253487348556519], [0.074529267847538, 0.8293417692184448, 0.074529267847538, 0.0027397761587053537, 0.018859894946217537], [0.45218759775161743, 0.45218759775161743, 0.06517907232046127, 0.02296537160873413, 0.00748039223253727], [0.5645778775215149, 0.2636403739452362, 0.08347441256046295, 0.004832896403968334, 0.08347441256046295], [0.00024421975831501186, 0.10154583305120468, 0.05649934336543083, 0.10154583305120468, 0.7401646971702576], [0.3771734833717346, 0.4338622987270355, 0.08625385165214539, 0.08625385165214539, 0.016456494107842445], [0.6697561144828796, 0.011746259406208992, 0.011746259406208992, 0.2805011570453644, 0.026250282302498817], [0.15997546911239624, 0.15997546911239624, 1.3359054719330743e-05, 0.059936314821243286, 0.6200993061065674], [0.04151824861764908, 0.8296032547950745, 0.04151824861764908, 0.03562602028250694, 0.05173414200544357], [0.08556840568780899, 0.05679052323102951, 0.05679052323102951, 0.05341893061995506, 0.7474315762519836], [0.3830564022064209, 0.23378007113933563, 3.724810085259378e-05, 6.988050154177472e-05, 0.3830564022064209], [0.031427089124917984, 0.906550943851471, 0.031427089124917984, 0.0006968976813368499, 0.02989795245230198], [0.5380653738975525, 0.19826677441596985, 0.054776545614004135, 0.15411467850208282, 0.054776545614004135], [0.028666967526078224, 0.018122538924217224, 0.018122538924217224, 0.9288759231567383, 0.006212078034877777], [0.03005979396402836, 0.15347008407115936, 0.00032875945908017457, 0.15347008407115936, 0.6626712083816528], [0.34369009733200073, 0.01920207217335701, 0.34369009733200073, 0.0023747191298753023, 0.2910429537296295], [0.0017435918562114239, 0.08337602764368057, 0.09461826086044312, 0.09461826086044312, 0.7256439328193665], [0.2731170654296875, 0.2731170654296875, 0.04161740839481354, 0.00738664623349905, 0.40476182103157043], [0.4486629366874695, 0.4486629366874695, 0.012131000868976116, 0.017873484641313553, 0.07266969233751297], [0.39601218700408936, 0.10116918385028839, 0.0001586882135597989, 0.2513299882411957, 0.2513299882411957], [0.006815203931182623, 0.43956318497657776, 0.43956318497657776, 0.02342878468334675, 0.09062965959310532], [0.0029069806914776564, 0.4705338180065155, 0.0030934272799640894, 0.46077558398246765, 0.06269022822380066], [0.1799687296152115, 0.3341813087463379, 0.3341813087463379, 0.15155768394470215, 0.00011094444926129654], [0.4582524597644806, 0.4582524597644806, 0.0003030722727999091, 0.06970500200986862, 0.013486994430422783], [0.5386673212051392, 0.45947328209877014, 0.00017528932949062437, 0.00017528932949062437, 0.00150878238491714], [0.18014557659626007, 0.21648527681827545, 0.21648527681827545, 0.38273248076438904, 0.004151404369622469], [0.007059901021420956, 0.2542029917240143, 0.3588859438896179, 0.3588859438896179, 0.020965218544006348], [0.21320384740829468, 0.37418946623802185, 0.009072310291230679, 0.19033056497573853, 0.21320384740829468], [0.108281709253788, 0.27662280201911926, 0.5064294338226318, 0.108281709253788, 0.0003843042650260031], [0.05392028018832207, 0.0001760942250257358, 0.0001760942250257358, 0.47466370463371277, 0.47106388211250305], [0.8161529898643494, 0.008439327590167522, 0.14942875504493713, 0.008439327590167522, 0.01753964275121689], [0.02394188567996025, 0.0024575097486376762, 0.9705815315246582, 0.0015095295384526253, 0.0015095295384526253], [0.06139025464653969, 0.012269973754882812, 0.025343919172883034, 0.875652015209198, 0.025343919172883034], [0.3769356310367584, 0.11740271002054214, 0.05333181843161583, 0.3769356310367584, 0.07539422065019608], [0.5477015972137451, 0.09494888037443161, 0.04776345193386078, 0.09494888037443161, 0.21463719010353088], [0.8807565569877625, 0.00010358447616454214, 0.10175208002328873, 0.00010358447616454214, 0.017284220084547997], [0.11520889401435852, 0.3686111271381378, 0.3686111271381378, 0.019221065565943718, 0.12834781408309937], [0.0013244615402072668, 0.002152381930500269, 0.0013244615402072668, 0.00033257942413911223, 0.9948660135269165], [0.17981615662574768, 0.00041570173925720155, 0.05513044074177742, 0.5848215222358704, 0.17981615662574768], [0.002491511171683669, 0.4484280049800873, 0.08860605210065842, 0.012046408839523792, 0.4484280049800873], [0.061531681567430496, 0.4428877830505371, 0.052654772996902466, 0.4428877830505371, 3.795879092649557e-05], [0.1950867772102356, 0.5204117894172668, 0.09291695803403854, 0.09291695803403854, 0.09866754710674286], [0.052949901670217514, 0.16422028839588165, 0.16422028839588165, 0.027430763468146324, 0.591178834438324], [0.12012482434511185, 0.33510148525238037, 0.20364239811897278, 0.33510148525238037, 0.006029819138348103], [0.12252280861139297, 0.12252280861139297, 0.2536410093307495, 0.5004040002822876, 0.0009093557018786669], [0.3858832120895386, 0.001124102738685906, 0.03168458864092827, 0.2906540632247925, 0.2906540632247925], [0.0775989219546318, 0.38167399168014526, 0.11748205125331879, 0.3456462025642395, 0.0775989219546318], [0.0009647784172557294, 0.05106944963335991, 0.7142616510391235, 0.05106944963335991, 0.18263471126556396], [0.3005244731903076, 0.10480666905641556, 0.3005244731903076, 0.0018441571155562997, 0.29230016469955444], [0.083518847823143, 0.0018229910638183355, 0.5019615292549133, 0.3291777968406677, 0.083518847823143], [0.01047853659838438, 0.004667097702622414, 0.01047853659838438, 0.17563587427139282, 0.7987399101257324], [0.008964271284639835, 0.11758173257112503, 0.008964271284639835, 0.8606361150741577, 0.003853547852486372], [0.06274710595607758, 0.06274710595607758, 0.5441133975982666, 0.27620774507522583, 0.0541846826672554], [0.19956551492214203, 0.4863698184490204, 0.00027691206196323037, 0.31351086497306824, 0.00027691206196323037], [0.023522457107901573, 0.15753969550132751, 0.017889924347400665, 0.40052399039268494, 0.40052399039268494], [0.12492493540048599, 0.6459408402442932, 0.12492493540048599, 0.08669420331716537, 0.01751512475311756], [0.014748970977962017, 0.008078779093921185, 0.13822323083877563, 0.13822323083877563, 0.7007257342338562], [0.4985646903514862, 0.11725471168756485, 0.0076684365049004555, 0.11725471168756485, 0.25925755500793457], [0.0299344751983881, 0.06427250057458878, 0.4158251881599426, 0.4158251881599426, 0.07414260506629944], [0.32940593361854553, 0.13336999714374542, 0.39455801248550415, 0.13336999714374542, 0.009296013042330742], [0.16222894191741943, 0.443366140127182, 0.2562020421028137, 0.06910143047571182, 0.06910143047571182], [0.10825709998607635, 0.30353766679763794, 0.3049418330192566, 0.14163169264793396, 0.14163169264793396], [0.3440420925617218, 0.024184446781873703, 0.3440420925617218, 0.18867896497249603, 0.09905239939689636], [0.5865943431854248, 0.03824825584888458, 0.009512984193861485, 0.3561314046382904, 0.009512984193861485], [0.31528741121292114, 0.007182485423982143, 0.07802420109510422, 0.2842184901237488, 0.31528741121292114], [0.03261585906147957, 0.1563720554113388, 0.39425766468048096, 0.39425766468048096, 0.02249675616621971], [0.3645058572292328, 0.2844375669956207, 0.021517498418688774, 0.2844375669956207, 0.04510144889354706], [0.047022901475429535, 3.561245102901012e-05, 0.839842677116394, 0.10942613333463669, 0.0036726342514157295], [0.5968307852745056, 0.09646899253129959, 0.011467975564301014, 0.005811771843582392, 0.2894205152988434], [0.0018702164525166154, 0.06290038675069809, 0.047741711139678955, 0.0010089321294799447, 0.8864787220954895], [0.01749149151146412, 0.35637298226356506, 0.3365134596824646, 0.22144657373428345, 0.06817552447319031], [0.05575079098343849, 0.0054705278016626835, 0.9269446134567261, 0.0054705278016626835, 0.006363428197801113], [0.03947979584336281, 0.010721968486905098, 0.9270714521408081, 0.010721968486905098, 0.012004904448986053], [0.4510713517665863, 0.07531741261482239, 0.4510713517665863, 0.00402654567733407, 0.018513333052396774], [0.8399803042411804, 0.14794816076755524, 0.005801493767648935, 0.005801493767648935, 0.00046850088983774185], [0.07422871887683868, 0.013275518082082272, 0.13516026735305786, 0.6421752572059631, 0.13516026735305786], [0.00994686409831047, 0.8702558875083923, 0.00994686409831047, 0.03615573048591614, 0.0736946389079094], [0.12088838219642639, 0.36908459663391113, 0.027924230322241783, 0.11301816254854202, 0.36908459663391113], [0.08402853459119797, 0.5881738662719727, 0.14825701713562012, 0.03128352761268616, 0.14825701713562012], [0.004405321553349495, 0.13420574367046356, 0.29731667041778564, 0.5138352513313293, 0.0502370186150074], [0.0025995434261858463, 0.002142895944416523, 0.5492461323738098, 0.443868488073349, 0.002142895944416523], [0.2166367769241333, 0.26135820150375366, 0.26135820150375366, 0.21875198185443878, 0.041894830763339996], [0.9193734526634216, 0.03393501415848732, 0.005861485842615366, 0.005861485842615366, 0.034968528896570206], [0.007199973799288273, 0.5592243075370789, 0.007199973799288273, 0.35995110869407654, 0.0664246454834938], [0.043756622821092606, 0.0008084173896349967, 0.03919263184070587, 0.8860762715339661, 0.030166171491146088], [0.05469052121043205, 0.05514078214764595, 0.0061421748250722885, 0.0061421748250722885, 0.8778844475746155], [0.0005651251995004714, 0.0005651251995004714, 0.011482978239655495, 0.2564350962638855, 0.7309516072273254], [0.08988086134195328, 0.1928619146347046, 0.6234286427497864, 0.08988086134195328, 0.003947641234844923], [0.03575631231069565, 0.23969797790050507, 0.03575631231069565, 0.09505434334278107, 0.5937350988388062], [8.561473805457354e-05, 0.8698787689208984, 0.00344451772980392, 0.12650549411773682, 8.561473805457354e-05], [0.04506434500217438, 0.07709068059921265, 0.4340139627456665, 0.4340139627456665, 0.009817041456699371], [0.1834850013256073, 0.09411290287971497, 0.013115384615957737, 0.6151738166809082, 0.09411290287971497], [0.15275838971138, 0.512814998626709, 0.011938625946640968, 0.15275838971138, 0.16972965002059937], [0.051236748695373535, 0.2131505012512207, 0.04572189599275589, 0.47674036026000977, 0.2131505012512207], [0.014675515703856945, 0.09657228738069534, 0.4433247148990631, 0.4433247148990631, 0.002102686557918787], [0.010477211326360703, 0.4454166293144226, 0.4454166293144226, 0.036563511937856674, 0.0621260404586792], [0.7782874703407288, 0.0005348068661987782, 0.22059878706932068, 0.00028947702958248556, 0.00028947702958248556], [0.028039902448654175, 0.09823114424943924, 0.8720719814300537, 0.0015198388136923313, 0.00013703701552003622], [0.3114151358604431, 0.6416444778442383, 0.019956860691308975, 0.0070267245173454285, 0.019956860691308975], [0.2929338216781616, 0.23915714025497437, 0.2285282462835312, 0.23915714025497437, 0.0002236418513348326], [0.0728442445397377, 0.0025316374376416206, 0.0019485651282593608, 0.0025316374376416206, 0.9201439023017883], [0.04407287761569023, 0.8830328583717346, 0.00371429231017828, 0.05376601591706276, 0.015413984656333923], [0.14345119893550873, 0.5720366835594177, 0.14345119893550873, 0.08387519419193268, 0.05718577653169632], [0.01932055875658989, 0.013601512648165226, 0.406065970659256, 0.2805060148239136, 0.2805060148239136], [0.08682654798030853, 0.0970989242196083, 0.0970989242196083, 0.005259128287434578, 0.713716447353363], [0.17480607330799103, 0.10666104406118393, 0.3339925706386566, 0.3339925706386566, 0.050547726452350616], [0.06267363578081131, 0.0013679694384336472, 0.07706332206726074, 0.7129440307617188, 0.1459510177373886], [0.4038352370262146, 0.066127710044384, 0.040514178574085236, 0.2447614073753357, 0.2447614073753357], [0.5947707891464233, 0.04705273360013962, 0.16971567273139954, 0.16971567273139954, 0.01874510757625103], [0.06967046856880188, 0.7744998335838318, 0.055728740990161896, 0.06967046856880188, 0.030430471524596214], [0.07941988110542297, 0.19155696034431458, 0.19155696034431458, 0.22813700139522552, 0.30932924151420593], [0.03321168199181557, 0.03542202711105347, 0.6421452760696411, 0.03542202711105347, 0.2537989914417267], [0.1824418008327484, 0.017002711072564125, 0.06342979520559311, 0.06454773247241974, 0.6725779175758362], [0.12698423862457275, 0.1822194755077362, 0.1822194755077362, 0.08422348648309708, 0.42435333132743835], [0.0021982607431709766, 0.07956504821777344, 0.761410117149353, 0.06898526102304459, 0.08784127980470657], [0.37652716040611267, 0.37652716040611267, 0.1503494679927826, 0.032172802835702896, 0.06442344933748245], [0.07552961260080338, 0.1773384064435959, 0.03883401304483414, 0.6327683925628662, 0.07552961260080338], [0.4523743689060211, 0.01898050867021084, 0.4523743689060211, 0.07120391726493835, 0.005066710524260998], [0.0038414057344198227, 0.0038414057344198227, 0.9272472858428955, 0.0031198954675346613, 0.061949990689754486], [0.8391352891921997, 0.07755077630281448, 0.04993034526705742, 0.012503555975854397, 0.02088000997900963], [0.06407486647367477, 0.03713638335466385, 0.1398085653781891, 0.7218438386917114, 0.03713638335466385], [0.0001891808060463518, 0.04154171422123909, 0.6503550410270691, 0.30772489309310913, 0.0001891808060463518], [0.12353111803531647, 0.12353111803531647, 0.08196387439966202, 0.0023030880838632584, 0.6686708331108093], [0.021418998017907143, 0.34999340772628784, 0.08002676069736481, 0.19856742024421692, 0.34999340772628784], [0.10677169263362885, 0.10677169263362885, 0.03209655359387398, 0.6825376749038696, 0.0718224048614502], [0.10540549457073212, 0.25076648592948914, 0.0013336132979020476, 0.6300747990608215, 0.012419608421623707], [0.0008516930392943323, 0.07552781701087952, 0.9036539793014526, 0.01911473460495472, 0.0008516930392943323], [0.057583287358284, 0.6501557230949402, 0.2284695953130722, 0.057583287358284, 0.006208119448274374], [0.030109696090221405, 0.24425047636032104, 0.030109696090221405, 0.4554843008518219, 0.24004586040973663], [0.02359885536134243, 0.44877681136131287, 0.030469369143247604, 0.24857744574546814, 0.24857744574546814], [0.03328872099518776, 0.020185567438602448, 0.5461061000823975, 0.03328872099518776, 0.3671308755874634], [0.06276726722717285, 0.37853917479515076, 0.37853917479515076, 0.14175012707710266, 0.03840429335832596], [0.0004715965478681028, 0.6409554481506348, 0.15801134705543518, 0.04255019873380661, 0.15801134705543518], [0.010071461088955402, 0.03966638445854187, 0.06376241892576218, 0.06376241892576218, 0.8227372765541077], [0.3221314251422882, 0.23244577646255493, 0.07297612726688385, 0.050315242260694504, 0.3221314251422882], [0.25022727251052856, 0.0020606385078281164, 0.43429988622665405, 0.06318496912717819, 0.25022727251052856], [0.4772094488143921, 0.4772094488143921, 0.009812209755182266, 0.008932824246585369, 0.026836106553673744], [0.15652674436569214, 0.4852789044380188, 0.003364634234458208, 0.15652674436569214, 0.1983030140399933], [0.5499763488769531, 0.05556711554527283, 0.05556711554527283, 0.3057984411716461, 0.03309090808033943], [0.3765474557876587, 0.016911467537283897, 0.4120410084724426, 0.1775885820388794, 0.016911467537283897], [0.009359522722661495, 0.4872913658618927, 0.08572206646203995, 0.3319050669670105, 0.08572206646203995], [0.0010203707497566938, 0.7296216487884521, 0.20956382155418396, 0.029897114261984825, 0.029897114261984825], [0.00011180467845406383, 0.028830546885728836, 0.0026267212815582752, 0.9658041596412659, 0.0026267212815582752], [0.12856872379779816, 0.00021346310677472502, 0.12856872379779816, 0.6310379505157471, 0.11161108314990997], [0.12490168958902359, 0.37535569071769714, 0.03595302626490593, 0.08843392878770828, 0.37535569071769714], [0.047769613564014435, 0.23716072738170624, 0.2817465662956238, 0.047769613564014435, 0.3855535089969635], [0.01812584698200226, 0.5003623962402344, 0.0002524587034713477, 0.2406296283006668, 0.2406296283006668], [0.5782935619354248, 0.2859738767147064, 0.06358800083398819, 0.06358800083398819, 0.008556491695344448], [0.13605700433254242, 0.001405010698363185, 0.031156102195382118, 0.13605700433254242, 0.6953248977661133], [0.2293996661901474, 0.21390704810619354, 0.04177847504615784, 0.21390704810619354, 0.30100783705711365], [0.42010021209716797, 0.42010021209716797, 0.1365032196044922, 0.022716782987117767, 0.0005795630277134478], [0.07409543544054031, 0.5668203830718994, 0.04898430407047272, 0.26111558079719543, 0.04898430407047272], [0.17225101590156555, 0.15736834704875946, 0.20044344663619995, 0.2694937288761139, 0.20044344663619995], [0.16878505051136017, 0.02135843224823475, 0.5264596343040466, 0.16878505051136017, 0.11461180448532104], [0.006165235303342342, 0.005689422599971294, 0.7487869262695312, 0.23575571179389954, 0.0036027610767632723], [0.9213194251060486, 1.4400661711988505e-05, 0.0564282089471817, 0.022205078974366188, 3.297218063380569e-05], [0.9137222170829773, 0.025760861113667488, 0.025760861113667488, 0.00020551671332214028, 0.03455051779747009], [0.27860864996910095, 0.006235141307115555, 0.11312044411897659, 0.3010178804397583, 0.3010178804397583], [0.13205525279045105, 0.1013813391327858, 0.29597675800323486, 0.33853134512901306, 0.13205525279045105], [0.11348943412303925, 0.10554807633161545, 0.25443360209465027, 0.07676513493061066, 0.4497637152671814], [0.01561746932566166, 0.03434467315673828, 0.03434467315673828, 0.9081035256385803, 0.007589611690491438], [0.041729435324668884, 0.5604205131530762, 0.015427254140377045, 0.36699554324150085, 0.015427254140377045], [0.3139415383338928, 0.02064463682472706, 0.29122984409332275, 0.29122984409332275, 0.08295413851737976], [0.3669893145561218, 0.04556265473365784, 0.3669893145561218, 0.00023994008370209485, 0.2202187329530716], [0.3908914625644684, 0.09080826491117477, 0.11469205468893051, 0.012716798111796379, 0.3908914625644684], [0.12871256470680237, 0.2126048356294632, 0.32913902401924133, 0.32913902401924133, 0.00040453410474583507], [0.8228161931037903, 0.027306275442242622, 0.010141883976757526, 0.010141883976757526, 0.12959381937980652], [0.763339638710022, 0.11032923310995102, 0.005747564136981964, 0.11032923310995102, 0.0102543318644166], [0.9047702550888062, 0.041930265724658966, 0.0011036493815481663, 0.0011036493815481663, 0.05109216645359993], [0.007237981539219618, 0.923637330532074, 0.029420895501971245, 0.03246575593948364, 0.007237981539219618], [0.055005352944135666, 0.003629020880907774, 0.8709463477134705, 0.01541395764797926, 0.055005352944135666], [0.3162473440170288, 0.6279248595237732, 0.026689870283007622, 0.0024480721913278103, 0.026689870283007622], [0.22789834439754486, 0.0005967086763121188, 0.7223595976829529, 0.04854865372180939, 0.0005967086763121188], [0.11791742593050003, 0.6797768473625183, 0.013210783712565899, 0.07117751985788345, 0.11791742593050003], [0.8521506190299988, 0.11724796146154404, 0.022995486855506897, 0.00469998549669981, 0.0029058733489364386], [0.0007772671524435282, 0.0007772671524435282, 0.7974759936332703, 0.18490587174892426, 0.016063595190644264], [0.4342592656612396, 0.03238983452320099, 0.4342592656612396, 0.05561880022287369, 0.04347280040383339], [0.016219722107052803, 0.259012907743454, 0.2131655067205429, 0.25580093264579773, 0.25580093264579773], [0.0035115405917167664, 0.49386435747146606, 0.008597357198596, 0.00016231872723437846, 0.49386435747146606], [0.26880574226379395, 0.05575721710920334, 0.009272311814129353, 0.01793072000145912, 0.6482340097427368], [0.0027010939083993435, 0.8219712376594543, 0.15396712720394135, 0.0027010939083993435, 0.018659383058547974], [0.026134632527828217, 0.13639551401138306, 0.055808935314416885, 0.13639551401138306, 0.6452654004096985], [0.0642942562699318, 0.2096475064754486, 0.2096475064754486, 0.030909886583685875, 0.4855007827281952], [0.01346294954419136, 0.018135199323296547, 0.018135199323296547, 0.18354827165603638, 0.7667184472084045], [0.3744398355484009, 0.46749135851860046, 0.07185041159391403, 0.07185041159391403, 0.014367983676493168], [0.056297414004802704, 0.12362805753946304, 0.7057768106460571, 0.058000288903713226, 0.056297414004802704], [0.14239566028118134, 0.07088194042444229, 0.4791637063026428, 0.16516299545764923, 0.14239566028118134], [0.4130744934082031, 0.08871665596961975, 0.041510794311761856, 0.4151872992515564, 0.041510794311761856], [0.7190916538238525, 0.19332098960876465, 0.0810151994228363, 0.0032860864885151386, 0.0032860864885151386], [0.005758571904152632, 0.5225508213043213, 0.36549797654151917, 0.1004340648651123, 0.005758571904152632], [0.0019596442580223083, 0.3441632091999054, 0.3441632091999054, 0.30840274691581726, 0.0013111562002450228], [0.030766041949391365, 0.030766041949391365, 0.2217346727848053, 0.6694118976593018, 0.04732133075594902], [0.034759771078825, 0.5096491575241089, 0.024704504758119583, 0.034759771078825, 0.3961268365383148], [0.045513905584812164, 0.21904884278774261, 0.34920433163642883, 0.21904884278774261, 0.1671840399503708], [0.1975298970937729, 0.03724728524684906, 0.4897391200065613, 0.07795380055904388, 0.1975298970937729], [0.08800705522298813, 0.0073546781204640865, 0.022120889276266098, 0.8751627206802368, 0.0073546781204640865], [0.02900887280702591, 0.29047730565071106, 0.01404707133769989, 0.29047730565071106, 0.3759894073009491], [0.7466980218887329, 0.14120349287986755, 0.040148235857486725, 0.035975124686956406, 0.035975124686956406], [0.04238523170351982, 0.02067027986049652, 0.7026718258857727, 0.1918874830007553, 0.04238523170351982], [0.004846715368330479, 0.029116451740264893, 0.4431849718093872, 0.2614259123802185, 0.2614259123802185], [0.16825467348098755, 0.35044705867767334, 0.11718618869781494, 0.013664985075592995, 0.35044705867767334], [0.351751446723938, 0.02955709956586361, 0.351751446723938, 0.002973248716443777, 0.26396676898002625], [0.017119795083999634, 0.2790899872779846, 0.1626046746969223, 0.26209554076194763, 0.2790899872779846], [0.2608431279659271, 0.3183467984199524, 0.013098197989165783, 0.05970439687371254, 0.3480075001716614], [0.09724251180887222, 0.7087070345878601, 0.09724251180887222, 0.0244564488530159, 0.07235144078731537], [0.009897846728563309, 0.009897846728563309, 0.21109092235565186, 0.7669169902801514, 0.002196315210312605], [0.00588210066780448, 0.00588210066780448, 0.6920168995857239, 0.2246738225221634, 0.07154510170221329], [0.333962619304657, 0.333962619304657, 0.007908879779279232, 0.10572641342878342, 0.2184394896030426], [0.050447069108486176, 0.5682775378227234, 0.15481208264827728, 0.17601622641086578, 0.050447069108486176], [0.38987302780151367, 0.0360548160970211, 0.016043828800320625, 0.38987302780151367, 0.1681552529335022], [0.0003031764936167747, 0.14501643180847168, 0.6633503437042236, 0.09566498547792435, 0.09566498547792435], [0.4744366705417633, 0.0187610425055027, 0.010507087223231792, 0.02185850590467453, 0.4744366705417633], [0.0001846315135480836, 0.0014146619942039251, 0.5968211889266968, 0.39907991886138916, 0.0024995654821395874], [0.004727340769022703, 0.025843191891908646, 0.004727340769022703, 0.0549386665225029, 0.909763514995575], [0.47452878952026367, 0.03874018043279648, 0.47452878952026367, 0.00044984478154219687, 0.011752420105040073], [0.0033215326257050037, 0.07486773282289505, 0.4416038691997528, 0.03860295191407204, 0.4416038691997528], [0.8606315851211548, 0.028326477855443954, 0.08018365502357483, 0.015429132618010044, 0.015429132618010044], [0.11065729707479477, 0.5708218216896057, 0.20648673176765442, 0.0013768880162388086, 0.11065729707479477], [0.2589850425720215, 0.19886818528175354, 0.2654821574687958, 0.01767955720424652, 0.2589850425720215], [0.17293010652065277, 0.02583596110343933, 0.01592201180756092, 0.17293010652065277, 0.6123818159103394], [0.571519672870636, 0.17581422626972198, 0.06732482463121414, 0.17581422626972198, 0.009527121670544147], [0.24672918021678925, 0.22621506452560425, 0.01332137268036604, 0.2920299768447876, 0.22170443832874298], [0.5094595551490784, 0.02501624822616577, 0.4335833787918091, 0.0069245933555066586, 0.02501624822616577], [0.005897941067814827, 0.22575058043003082, 0.2289014309644699, 0.2697250247001648, 0.2697250247001648], [0.25322797894477844, 0.18738138675689697, 0.25322797894477844, 0.07226549088954926, 0.2338971495628357], [0.06355400383472443, 0.37643691897392273, 0.003401680151000619, 0.4930533766746521, 0.06355400383472443], [0.5129587650299072, 0.010874947533011436, 0.23728610575199127, 0.010874947533011436, 0.22800523042678833], [0.0744607001543045, 0.06274328380823135, 0.03619930520653725, 0.4132983684539795, 0.4132983684539795], [0.033208344131708145, 0.3400881588459015, 0.5603957176208496, 0.03315390273928642, 0.03315390273928642], [0.013437507674098015, 0.0904286578297615, 0.03401397168636322, 0.013437507674098015, 0.8486824035644531], [0.0007384361233562231, 0.20480498671531677, 0.022856516763567924, 0.20480498671531677, 0.5667950510978699], [0.11171163618564606, 0.062336601316928864, 0.3506799340248108, 0.23763594031333923, 0.23763594031333923], [1.5528645235463046e-05, 0.043534617871046066, 1.5528645235463046e-05, 0.784525990486145, 0.17190834879875183], [0.7233754396438599, 0.000641967577394098, 0.15286476910114288, 0.12247584015130997, 0.000641967577394098], [0.8359039425849915, 0.10440056771039963, 0.03721126541495323, 0.01124210748821497, 0.01124210748821497], [0.3687039017677307, 0.13691891729831696, 0.11166192591190338, 0.27105334401130676, 0.11166192591190338], [0.1264936625957489, 0.07210933417081833, 0.3869398832321167, 0.027517197653651237, 0.3869398832321167], [0.10161048173904419, 0.004096090793609619, 0.004096090793609619, 0.0186210498213768, 0.8715763688087463], [0.05016108974814415, 0.16082151234149933, 0.5811640024185181, 0.04703196510672569, 0.16082151234149933], [0.04427535459399223, 0.1074269562959671, 0.31953155994415283, 0.4844907820224762, 0.04427535459399223], [0.0026797070167958736, 0.7232115864753723, 0.0026797070167958736, 0.2612571716308594, 0.010171793401241302], [0.6645609736442566, 0.014762582257390022, 0.2743506133556366, 0.014762582257390022, 0.031563159078359604], [0.3305507302284241, 0.09396588057279587, 1.8552666006144136e-05, 0.3305507302284241, 0.24491411447525024], [0.20777153968811035, 0.0022007436491549015, 0.3705839216709137, 0.3705839216709137, 0.04885988309979439], [0.11026348173618317, 0.33190032839775085, 0.08666934818029404, 0.11026348173618317, 0.36090341210365295], [0.00850617978721857, 2.386725100222975e-05, 0.0014536607777699828, 0.4950081408023834, 0.4950081408023834], [0.40776708722114563, 0.013147708028554916, 0.40776708722114563, 0.07450097799301147, 0.09681719541549683], [0.7338242530822754, 0.008532972075045109, 0.12478277087211609, 0.12478277087211609, 0.008077125996351242], [0.04726773127913475, 0.055309925228357315, 0.8417280912399292, 0.055309925228357315, 0.0003843872691504657], [0.31973475217819214, 0.18149065971374512, 0.015027105808258057, 0.31973475217819214, 0.16401275992393494], [0.059208497405052185, 0.011820496059954166, 0.059208497405052185, 0.30536264181137085, 0.5643998384475708], [0.470044881105423, 0.015491871163249016, 0.470044881105423, 0.018455637618899345, 0.025962775573134422], [0.0063614509999752045, 0.07076409459114075, 0.0063614509999752045, 0.0943698063492775, 0.8221431970596313], [0.18841566145420074, 0.11345560848712921, 0.3351800739765167, 0.3351800739765167, 0.02776857279241085], [0.30065038800239563, 0.30065038800239563, 0.03324924409389496, 0.003120394190773368, 0.3623295724391937], [0.31183570623397827, 0.034661609679460526, 0.31183570623397827, 0.00712768966332078, 0.3345393240451813], [0.015053312294185162, 0.1635676920413971, 0.22251521050930023, 0.015053312294185162, 0.5838104486465454], [0.21526341140270233, 0.041731394827365875, 0.023341104388237, 0.023341104388237, 0.6963229775428772], [0.11463187634944916, 0.5366498231887817, 0.09709170460700989, 0.11463187634944916, 0.13699471950531006], [0.714874804019928, 0.12525025010108948, 0.014941487461328506, 0.13378112018108368, 0.011152345687150955], [0.052464768290519714, 0.052464768290519714, 0.2473747581243515, 0.49420297145843506, 0.1534927636384964], [0.04159180074930191, 0.9033665060997009, 0.004447526298463345, 0.007900049909949303, 0.04269413277506828], [0.08256348222494125, 0.22094984352588654, 0.3464655876159668, 0.3464655876159668, 0.003555482253432274], [0.6428192853927612, 0.1802375465631485, 0.07970627397298813, 0.01753060705959797, 0.07970627397298813], [0.022150259464979172, 0.12267980724573135, 0.06842004507780075, 0.3933749496936798, 0.3933749496936798], [0.8194329738616943, 0.05444873124361038, 0.05444873124361038, 0.07057678699493408, 0.0010928252013400197], [0.026473889127373695, 0.6550408601760864, 0.00277967331930995, 0.31292593479156494, 0.00277967331930995], [0.2890995442867279, 0.0033337343484163284, 0.4015001356601715, 0.30273282527923584, 0.0033337343484163284], [0.22759394347667694, 0.020346079021692276, 0.6431472301483154, 0.002762493211776018, 0.10615020245313644], [0.06412997096776962, 0.14977537095546722, 0.14977537095546722, 0.02952621504664421, 0.6067931056022644], [0.042902495712041855, 0.13711999356746674, 0.00213366886600852, 0.00213366886600852, 0.815710186958313], [0.0014474112540483475, 0.05523780360817909, 0.05523780360817909, 0.606923520565033, 0.28115347027778625], [0.10792730748653412, 0.7596462965011597, 0.0005672118859365582, 0.13129191100597382, 0.0005672118859365582], [0.10679749399423599, 0.14794661104679108, 0.46570301055908203, 0.17275545001029968, 0.10679749399423599], [0.20923399925231934, 0.008779812604188919, 0.20923399925231934, 0.16501981019973755, 0.40773239731788635], [0.24989590048789978, 0.012223406694829464, 0.3224117159843445, 0.3224117159843445, 0.09305728226900101], [0.35443824529647827, 0.41836056113243103, 0.015667077153921127, 0.008097188547253609, 0.203436940908432], [0.033256009221076965, 0.3526706397533417, 0.1394582837820053, 0.3526706397533417, 0.12194447964429855], [0.30666837096214294, 0.21744684875011444, 0.018560238182544708, 0.15065619349479675, 0.30666837096214294], [0.06247371435165405, 0.053628481924533844, 0.43673935532569885, 0.43673935532569885, 0.010419130325317383], [0.11950402706861496, 0.04668509215116501, 0.7710589170455933, 0.016066929325461388, 0.04668509215116501], [0.03580238297581673, 0.000802678638137877, 0.8612853288650513, 0.03580238297581673, 0.06630725413560867], [0.08446287363767624, 0.1244446411728859, 0.6400628089904785, 0.06656685471534729, 0.08446287363767624], [0.09470003098249435, 0.6433256268501282, 0.016029398888349533, 0.09470003098249435, 0.1512448936700821], [0.04508572444319725, 0.1559121161699295, 0.010734481737017632, 0.04508572444319725, 0.7431818842887878], [0.24246132373809814, 4.7325964260380715e-05, 0.3750894069671631, 0.007312532979995012, 0.3750894069671631], [0.005532537121325731, 0.2524569034576416, 0.45513856410980225, 0.28133949637413025, 0.005532537121325731], [0.26580682396888733, 0.26580682396888733, 0.3517571985721588, 0.11490362882614136, 0.0017255280399695039], [0.14131653308868408, 0.3163668215274811, 0.1973581463098526, 0.3163668215274811, 0.02859165333211422], [0.9032664895057678, 0.040635861456394196, 0.04157250374555588, 0.00726249860599637, 0.00726249860599637], [0.3533962666988373, 0.3931940495967865, 0.10604768991470337, 0.09175147116184235, 0.055610548704862595], [0.007078951224684715, 0.4765738546848297, 0.006361502688378096, 0.5029066801071167, 0.007078951224684715], [0.2003020942211151, 0.6757994294166565, 0.00017554379883222282, 0.06186150014400482, 0.06186150014400482], [0.03221113979816437, 0.008983476087450981, 0.008983476087450981, 0.9407314658164978, 0.009090419858694077], [0.029355932027101517, 0.008606861345469952, 0.029355932027101517, 0.4898659884929657, 0.4428153932094574], [0.03328508511185646, 0.03328508511185646, 0.24192318320274353, 0.22407706081867218, 0.46742963790893555], [0.33505168557167053, 0.06420011073350906, 0.034054093062877655, 0.034054093062877655, 0.5326399803161621], [0.08044074475765228, 0.6797946691513062, 0.08044074475765228, 0.08099833130836487, 0.07832548767328262], [0.19833387434482574, 0.3668678402900696, 0.019489482045173645, 0.3668678402900696, 0.04844089597463608], [0.8152772188186646, 0.030617929995059967, 0.0017237885622307658, 0.0017237885622307658, 0.15065722167491913], [0.3383573293685913, 0.031629953533411026, 0.2191108912229538, 0.2054508626461029, 0.2054508626461029], [0.04592423513531685, 0.005264187231659889, 0.04592423513531685, 0.5882530212402344, 0.3146343231201172], [0.08279871940612793, 0.19229601323604584, 0.6414391398429871, 0.008926105685532093, 0.07454002648591995], [0.012063156813383102, 0.462092787027359, 7.839545287424698e-05, 0.462092787027359, 0.06367281079292297], [0.01505709532648325, 0.02986367978155613, 0.024193502962589264, 0.9066922664642334, 0.024193502962589264], [0.2991604804992676, 0.638473391532898, 0.030903229489922523, 0.030903229489922523, 0.0005597450071945786], [0.5003712177276611, 0.12234248220920563, 0.37695661187171936, 0.00016486483218614012, 0.00016486483218614012], [0.003082417882978916, 0.9015493988990784, 0.03037063218653202, 0.003082417882978916, 0.06191513314843178], [0.6162247657775879, 0.06712684780359268, 0.31471681594848633, 0.000965807877946645, 0.000965807877946645], [0.005333227105438709, 0.5274902582168579, 0.23352687060832977, 0.00012273313768673688, 0.23352687060832977], [0.03286091983318329, 0.004457566421478987, 0.03286091983318329, 0.10261793434619904, 0.8272026777267456], [0.7808271646499634, 0.002358892234042287, 0.17128419876098633, 0.002358892234042287, 0.04317091032862663], [0.015852155163884163, 0.2073347568511963, 0.1213870421051979, 0.2073347568511963, 0.4480912983417511], [0.6524941921234131, 0.049746718257665634, 0.049746718257665634, 0.029070425778627396, 0.21894197165966034], [0.3492814898490906, 0.12296693027019501, 0.3492814898490906, 0.031393494457006454, 0.14707662165164948], [0.04958360642194748, 0.36708176136016846, 0.36708176136016846, 0.08807741850614548, 0.12817537784576416], [0.039711449295282364, 0.003575271228328347, 0.003575271228328347, 0.8907493352890015, 0.062388643622398376], [0.47102242708206177, 0.23699945211410522, 0.23699945211410522, 0.009044336155056953, 0.045934394001960754], [0.29801464080810547, 0.13146622478961945, 0.3980771005153656, 0.13146622478961945, 0.040975842624902725], [0.39500412344932556, 0.39500412344932556, 0.13782645761966705, 0.05101782828569412, 0.021147502586245537], [0.7584931254386902, 0.05765042081475258, 0.0827450379729271, 0.04346097260713577, 0.05765042081475258], [0.5162370204925537, 0.05548937991261482, 0.001960532274097204, 0.4243524968624115, 0.001960532274097204], [0.1126939132809639, 0.3365992307662964, 0.3365992307662964, 0.030411358922719955, 0.18369628489017487], [0.28020596504211426, 0.41857558488845825, 0.004177831578999758, 0.28020596504211426, 0.01683463528752327], [0.2675561308860779, 0.001253955066204071, 0.001253955066204071, 0.36343055963516235, 0.36650538444519043], [0.1666421741247177, 0.012868894264101982, 0.31624603271484375, 0.3376007080078125, 0.1666421741247177], [0.8022775650024414, 0.14772982895374298, 0.007218511775135994, 0.007218511775135994, 0.03555550426244736], [0.02479100227355957, 0.02479100227355957, 0.10091938823461533, 0.5194269418716431, 0.33007168769836426], [0.006433428265154362, 0.006433428265154362, 0.35223355889320374, 0.0005914955982007086, 0.6343080997467041], [0.017931370064616203, 0.372383713722229, 0.02224046364426613, 0.215060755610466, 0.372383713722229], [0.01069041807204485, 0.5513296127319336, 0.18956294655799866, 0.18956294655799866, 0.0588541254401207], [0.3233483135700226, 0.13399969041347504, 0.2155831754207611, 0.0037205202970653772, 0.3233483135700226], [0.3261038661003113, 0.0007859391043893993, 0.33578959107398987, 0.0015310693997889757, 0.33578959107398987], [0.6429353952407837, 0.13033252954483032, 0.007730603218078613, 0.08866889774799347, 0.13033252954483032], [0.1608242243528366, 0.1608242243528366, 0.3440329432487488, 0.11712111532688141, 0.21719752252101898], [0.013599290512502193, 0.3129521906375885, 0.3129521906375885, 0.3595573604106903, 0.0009389226324856281], [0.36831730604171753, 0.00740980077534914, 0.3021451234817505, 0.3021451234817505, 0.019982675090432167], [0.39667806029319763, 0.005102998111397028, 0.39667806029319763, 0.049483925104141235, 0.15205693244934082], [0.9447683691978455, 0.027528362348675728, 0.0008642035536468029, 0.013419512659311295, 0.013419512659311295], [0.04515538737177849, 0.003119455883279443, 0.946402370929718, 0.003119455883279443, 0.0022032922133803368], [0.004214193671941757, 0.942931056022644, 0.004214193671941757, 0.013782735913991928, 0.03485772758722305], [0.4234648644924164, 0.11164861917495728, 0.11164861917495728, 0.04737473279237747, 0.3058631122112274], [0.7116738557815552, 0.011781509034335613, 0.2659654915332794, 0.007084413897246122, 0.0034947143867611885], [0.14636707305908203, 0.3835393190383911, 0.07882729917764664, 0.3835393190383911, 0.007727029267698526], [0.1693228781223297, 0.030808279290795326, 0.35260504484176636, 0.35260504484176636, 0.09465880692005157], [0.5686722993850708, 0.06601226329803467, 0.27630147337913513, 0.023001695051789284, 0.06601226329803467], [0.4240037798881531, 0.2329559028148651, 0.1225292906165123, 0.1225292906165123, 0.09798172116279602], [0.38839536905288696, 0.0007710657082498074, 0.38839536905288696, 0.025385452434420586, 0.1970527023077011], [0.005308166611939669, 0.0026311834808439016, 0.6109318733215332, 0.004245026968419552, 0.37688374519348145], [0.1998603790998459, 0.09028691798448563, 0.21754659712314606, 0.4020191431045532, 0.09028691798448563], [0.4187220335006714, 0.0039941114373505116, 0.4187220335006714, 0.027568556368350983, 0.13099323213100433], [0.03759448602795601, 0.46321213245391846, 0.024180972948670387, 0.46321213245391846, 0.011800223961472511], [0.04260044917464256, 0.04260044917464256, 0.4201813042163849, 0.3080870509147644, 0.1865307241678238], [0.0009444572497159243, 0.4080283045768738, 0.0006333062774501741, 0.18236561119556427, 0.4080283045768738], [0.13379433751106262, 0.17396147549152374, 0.13379433751106262, 0.020547689869999886, 0.5379021763801575], [0.05040204897522926, 0.008324062451720238, 0.8794726729393005, 0.030900612473487854, 0.030900612473487854], [0.00037831379449926317, 0.8171162009239197, 0.00037831379449926317, 9.294252231484279e-05, 0.1820342242717743], [0.008753878064453602, 0.02458326332271099, 0.008753878064453602, 0.90670245885849, 0.05120646208524704], [0.5173047184944153, 0.014538172632455826, 0.186849445104599, 0.09445817023515701, 0.186849445104599], [0.003503956599161029, 0.046114660799503326, 0.012196256779134274, 0.46909257769584656, 0.46909257769584656], [0.3545416593551636, 0.006916180718690157, 0.3434835970401764, 0.006916180718690157, 0.2881423532962799], [0.02459835633635521, 0.11634986102581024, 0.4189393222332001, 0.02459835633635521, 0.4155140817165375], [0.0093892402946949, 0.05164873227477074, 0.056070633232593536, 0.5873955488204956, 0.29549574851989746], [0.030842281877994537, 0.030842281877994537, 0.869625985622406, 0.06565959006547928, 0.0030298526398837566], [0.013388789258897305, 0.27030467987060547, 0.013388789258897305, 0.05840926989912987, 0.6445084810256958], [0.734620988368988, 0.010699834674596786, 0.11029239743947983, 0.07219337671995163, 0.07219337671995163], [0.0024449394550174475, 0.00954312551766634, 0.9497194886207581, 0.03584754467010498, 0.0024449394550174475], [0.3752325177192688, 0.13992640376091003, 0.3752325177192688, 0.055785343050956726, 0.05382324382662773], [2.466043588356115e-05, 0.024362558498978615, 0.7557214498519897, 0.21986666321754456, 2.466043588356115e-05], [0.0781659334897995, 0.7258421778678894, 0.001786976819857955, 0.09710245579481125, 0.09710245579481125], [0.1967942863702774, 0.2448091208934784, 0.2448091208934784, 0.15555590391159058, 0.15803155303001404], [0.48320624232292175, 0.01362505741417408, 0.48320624232292175, 0.01964488998055458, 0.00031764202867634594], [0.2310534417629242, 0.09890634566545486, 0.1413050889968872, 0.1413050889968872, 0.3874300420284271], [0.14646540582180023, 0.038975052535533905, 0.7691253423690796, 0.038975052535533905, 0.0064592063426971436], [0.9665665626525879, 0.014189436100423336, 0.0028107475955039263, 0.002243809401988983, 0.014189436100423336], [0.7063830494880676, 0.07216999679803848, 0.004091443028301001, 0.07216999679803848, 0.1451854407787323], [0.6302611231803894, 0.0029204559978097677, 0.035280968993902206, 0.29625651240348816, 0.035280968993902206], [0.48889392614364624, 0.017233798280358315, 0.01535121537744999, 0.017233798280358315, 0.4612872898578644], [0.4217696189880371, 0.07003264874219894, 0.0062475684098899364, 0.4217696189880371, 0.0801805779337883], [0.00202712113969028, 0.2935968339443207, 0.40187597274780273, 0.2935968339443207, 0.008903191424906254], [0.03207791969180107, 0.0021421601995825768, 0.02477196604013443, 0.4705039858818054, 0.4705039858818054], [0.05546385794878006, 0.05546385794878006, 0.8161095380783081, 0.008897397667169571, 0.06406538933515549], [0.17402859032154083, 0.38584837317466736, 0.002895305398851633, 0.4359387159347534, 0.001288999104872346], [0.17729634046554565, 0.3776390850543976, 0.16807396709918976, 0.17729634046554565, 0.09969422966241837], [0.24668236076831818, 0.01418042741715908, 0.49216893315315247, 0.24668236076831818, 0.00028586055850610137], [0.7331845760345459, 0.004393610637634993, 0.0015167673118412495, 0.2565114498138428, 0.004393610637634993], [0.026896657422184944, 0.45419999957084656, 0.007609466090798378, 0.0012460388243198395, 0.5100477933883667], [0.014361914247274399, 0.14658445119857788, 0.6212787628173828, 0.14658445119857788, 0.07119046151638031], [0.7122352719306946, 0.040951356291770935, 0.15858784317970276, 0.040951356291770935, 0.0472741462290287], [0.0456857793033123, 0.3554978370666504, 0.23941928148269653, 0.3554978370666504, 0.0038992224726825953], [0.2425299733877182, 0.27478596568107605, 0.0501830093562603, 0.18997104465961456, 0.2425299733877182], [0.028300823643803596, 0.9335563778877258, 0.0005896876682527363, 0.03696335107088089, 0.0005896876682527363], [0.2075648009777069, 0.3045017123222351, 0.1579807698726654, 0.025450939312577248, 0.3045017123222351], [0.11413858085870743, 0.3105151355266571, 0.14040666818618774, 0.3105151355266571, 0.12442448735237122], [0.567366898059845, 0.05474543571472168, 0.2609500288963318, 0.0621921569108963, 0.05474543571472168], [0.045666735619306564, 0.006128209643065929, 0.13387054204940796, 0.7686677575111389, 0.045666735619306564], [0.14285577833652496, 0.00012934643018525094, 0.00012934643018525094, 0.13157020509243011, 0.725315272808075], [0.3959471583366394, 0.069249726831913, 0.13913339376449585, 0.069249726831913, 0.3264199495315552], [0.01739603653550148, 0.10251909494400024, 0.5636168122291565, 0.01739603653550148, 0.2990720272064209], [0.0018587481463328004, 0.0018587481463328004, 0.2234150618314743, 0.7594418525695801, 0.01342562586069107], [0.03449972718954086, 0.000337858684360981, 0.000337858684360981, 0.7978858351707458, 0.16693872213363647], [0.5845651626586914, 0.0007768876967020333, 0.16855692863464355, 0.16855692863464355, 0.07754411548376083], [0.4121454358100891, 0.0001911957806441933, 0.4121454358100891, 0.09091723710298538, 0.08460073173046112], [0.2841324806213379, 0.1053515374660492, 0.12961190938949585, 0.2841324806213379, 0.19677163660526276], [0.6498585939407349, 0.2014005184173584, 0.06796648353338242, 0.06796648353338242, 0.012807906605303288], [0.0956031084060669, 0.13887275755405426, 0.6009856462478638, 0.025665687397122383, 0.13887275755405426], [0.0035255178809165955, 2.8153537641628645e-05, 0.26250478625297546, 0.7339133620262146, 2.8153537641628645e-05], [0.08333765715360641, 0.7748317122459412, 0.13958607614040375, 0.0011222523171454668, 0.0011222523171454668], [0.08374469727277756, 0.3702314794063568, 0.23406440019607544, 0.1539185494184494, 0.15804089605808258], [0.01586325094103813, 0.6280331015586853, 0.043593768030405045, 0.15625494718551636, 0.15625494718551636], [0.00010597174696158618, 0.48951029777526855, 0.007656078785657883, 0.48951029777526855, 0.013217286206781864], [0.923376739025116, 0.023450909182429314, 0.0003998061001766473, 0.023450909182429314, 0.029321715235710144], [0.4815559387207031, 0.4815559387207031, 0.034789055585861206, 0.0003704593691509217, 0.0017285981448367238], [0.6986850500106812, 0.2220764458179474, 0.018359219655394554, 0.04252004623413086, 0.018359219655394554], [0.2631753087043762, 0.5619668364524841, 0.08702543377876282, 0.08702543377876282, 0.0008069818140938878], [0.37754422426223755, 0.07584689557552338, 0.10451046377420425, 0.06455426663160324, 0.37754422426223755], [0.026512566953897476, 0.018890932202339172, 0.47334447503089905, 0.0079075051471591, 0.47334447503089905], [0.1927139312028885, 0.13112422823905945, 0.3152053654193878, 0.010736211203038692, 0.35022029280662537], [0.0008317493484355509, 0.09436851739883423, 0.5566770434379578, 0.0008317493484355509, 0.347290962934494], [0.10745057463645935, 0.32882049679756165, 0.022426731884479523, 0.2124817669391632, 0.32882049679756165], [0.2523133158683777, 0.5102731585502625, 0.04394917190074921, 0.14951518177986145, 0.04394917190074921], [0.2080342173576355, 0.46749261021614075, 0.15282277762889862, 0.01882763020694256, 0.15282277762889862], [0.011686854995787144, 0.0033164487686008215, 0.0002626146306283772, 0.9814175963401794, 0.0033164487686008215], [0.007730009965598583, 0.8041113615036011, 0.011124730110168457, 0.007730009965598583, 0.16930383443832397], [0.443025678396225, 0.13742776215076447, 0.003359274473041296, 0.13742776215076447, 0.27875959873199463], [0.144057035446167, 0.7844613790512085, 0.0039933230727910995, 0.0004666862660087645, 0.06702163815498352], [0.22985413670539856, 0.150438129901886, 0.22985413670539856, 0.0006436227122321725, 0.3892100751399994], [0.20068255066871643, 0.20068255066871643, 0.5124103426933289, 0.021600516512989998, 0.06462398916482925], [0.3890294134616852, 0.005164149217307568, 0.3890294134616852, 0.004048963077366352, 0.21272806823253632], [0.9173733592033386, 0.07910040020942688, 0.0011367836268618703, 0.0011367836268618703, 0.0012526402715593576], [6.074384873500094e-05, 0.05760131776332855, 0.05760131776332855, 0.05972947180271149, 0.8250071406364441], [0.1602228432893753, 0.6517855525016785, 0.0025512692518532276, 0.1602228432893753, 0.025217559188604355], [0.05915695056319237, 0.40979471802711487, 0.12102552503347397, 0.20501141250133514, 0.20501141250133514], [0.009808220900595188, 0.022195270285010338, 0.8389143943786621, 0.10688689351081848, 0.022195270285010338], [0.01782091334462166, 0.32411736249923706, 0.02848249301314354, 0.02848249301314354, 0.6010966300964355], [0.47091227769851685, 0.25330716371536255, 0.25330716371536255, 0.013861540704965591, 0.00861186720430851], [0.11932971328496933, 0.00253624957986176, 0.005955670028924942, 0.8662226796150208, 0.005955670028924942], [0.0034988196566700935, 0.9085973501205444, 0.0250100065022707, 0.03144688159227371, 0.03144688159227371], [0.6153759956359863, 0.000643767649307847, 0.0069623119197785854, 0.37637415528297424, 0.000643767649307847], [0.046979524195194244, 0.012948615476489067, 0.5181027054786682, 0.21098458766937256, 0.21098458766937256], [0.4063695967197418, 0.19878935813903809, 0.004202240612357855, 0.14631545543670654, 0.24432337284088135], [0.026337245479226112, 0.04204104095697403, 0.4376230537891388, 0.4376230537891388, 0.05637558177113533], [0.40921878814697266, 0.1637018918991089, 0.008508995175361633, 0.40921878814697266, 0.00935148261487484], [0.3882136642932892, 0.026188423857092857, 0.03141428530216217, 0.5227692723274231, 0.03141428530216217], [0.11505547165870667, 0.005362211726605892, 0.34718096256256104, 0.41734591126441956, 0.11505547165870667], [0.00033775647170841694, 0.04503830149769783, 0.004981687758117914, 0.9493045210838318, 0.00033775647170841694], [0.4324766993522644, 0.11702589690685272, 0.010505978949368, 0.11702589690685272, 0.322965532541275], [0.025035763159394264, 0.03439134731888771, 0.049829866737127304, 0.44537150859832764, 0.44537150859832764], [0.0001402912603225559, 0.10654756426811218, 0.013161655515432358, 0.880010187625885, 0.0001402912603225559], [0.03031006082892418, 0.19447576999664307, 0.7581411600112915, 0.00853651762008667, 0.00853651762008667], [0.4312798082828522, 0.021033816039562225, 0.00011366100807208568, 0.4312798082828522, 0.11629294604063034], [0.023081347346305847, 0.5061419606208801, 0.005349127110093832, 0.023081347346305847, 0.4423462152481079], [0.02895405888557434, 0.02895405888557434, 0.00023155729286372662, 0.5542492270469666, 0.38761112093925476], [2.7429168767412193e-05, 0.4837579131126404, 0.4837579131126404, 0.021158309653401375, 0.011298492550849915], [0.020961109548807144, 0.39116033911705017, 0.19392985105514526, 0.39116033911705017, 0.002788378158584237], [0.22881656885147095, 0.22881656885147095, 0.08877566456794739, 0.049845706671476364, 0.4037454426288605], [0.3063421845436096, 0.37038853764533997, 0.007545775268226862, 0.3063421845436096, 0.00938127376139164], [0.5485985279083252, 0.21073561906814575, 0.14239852130413055, 0.049133654683828354, 0.049133654683828354], [0.002363706473261118, 0.04929494857788086, 0.629001259803772, 0.005179754924029112, 0.3141603171825409], [0.32718023657798767, 0.06197263300418854, 0.544031023979187, 0.06197263300418854, 0.004843513481318951], [0.1525266319513321, 0.8086400628089905, 0.01594041846692562, 0.017903057858347893, 0.0049898698925971985], [0.0010714721865952015, 0.004283743444830179, 0.07365323603153229, 0.9167078137397766, 0.004283743444830179], [0.4821360409259796, 0.4821360409259796, 0.0037757905665785074, 0.004649431444704533, 0.027302728965878487], [0.05285221338272095, 0.3746972382068634, 0.1975337415933609, 0.00021965187625028193, 0.3746972382068634], [0.0014692882541567087, 0.26694414019584656, 0.4637962579727173, 0.26694414019584656, 0.0008461727993562818], [0.7300774455070496, 0.1845603734254837, 0.021119004115462303, 0.043124157935380936, 0.021119004115462303], [0.002008704701438546, 0.002937780460342765, 0.7099323868751526, 0.27833691239356995, 0.006784278433769941], [0.2702084183692932, 0.31226274371147156, 0.31226274371147156, 0.10506585240364075, 0.00020012973982375115], [0.07000984996557236, 0.4063778817653656, 0.07276399433612823, 0.04447048902511597, 0.4063778817653656], [0.2587646245956421, 0.5262747406959534, 0.0063241892494261265, 0.19232410192489624, 0.01631237380206585], [0.5965454578399658, 0.0036457569804042578, 0.14596407115459442, 0.14596407115459442, 0.1078806146979332], [0.2816389799118042, 0.1736205816268921, 0.0004020031192339957, 0.1736205816268921, 0.3707177937030792], [0.35216963291168213, 0.00016172941832337528, 0.20889590680599213, 0.21938636898994446, 0.21938636898994446], [0.1152694895863533, 0.40299761295318604, 0.40299761295318604, 0.07832380384206772, 0.00041145755676552653], [0.026069600135087967, 0.17702864110469818, 0.17837464809417725, 0.17702864110469818, 0.4414985179901123], [0.7112549543380737, 0.11858772486448288, 0.08376984298229218, 0.002617661375552416, 0.08376984298229218], [0.25967252254486084, 0.033840276300907135, 0.25967252254486084, 0.39571303129196167, 0.05110162869095802], [0.3071878254413605, 0.01690659485757351, 0.037599410861730576, 0.3191531002521515, 0.3191531002521515], [0.025802841410040855, 0.09149803221225739, 0.0015589013928547502, 0.09149803221225739, 0.7896422147750854], [0.11935273557901382, 0.1110747903585434, 0.36476394534111023, 0.36476394534111023, 0.04004459083080292], [0.031048720702528954, 0.024070950224995613, 0.015245075337588787, 0.9143901467323303, 0.015245075337588787], [0.0628163143992424, 0.4002332091331482, 0.1343095302581787, 0.002407777588814497, 0.4002332091331482], [0.4789905250072479, 0.24767014384269714, 0.023846112191677094, 0.24767014384269714, 0.0018230995628982782], [0.0009181027999147773, 0.07519318163394928, 0.0009181027999147773, 0.8850950002670288, 0.03787560760974884], [0.020165080204606056, 0.23630845546722412, 0.1841256469488144, 0.5392357707023621, 0.020165080204606056], [0.22630612552165985, 0.014548239298164845, 0.2648448646068573, 0.26799464225769043, 0.22630612552165985], [0.011004593223333359, 0.35816797614097595, 0.0973207950592041, 0.26675328612327576, 0.26675328612327576], [0.45344415307044983, 0.03201671317219734, 0.45344415307044983, 0.029527448117733, 0.03156760334968567], [0.03003230318427086, 0.4910503923892975, 0.21205677092075348, 0.21205677092075348, 0.05480371415615082], [0.1922946721315384, 0.1922946721315384, 0.05066552758216858, 0.2683057188987732, 0.29643940925598145], [0.09215175360441208, 0.002779345028102398, 0.002779345028102398, 0.3768846392631531, 0.5254048705101013], [0.7648040056228638, 0.014330718666315079, 0.011731026694178581, 0.014330718666315079, 0.19480349123477936], [0.35464006662368774, 0.028942201286554337, 0.19298583269119263, 0.35464006662368774, 0.06879182904958725], [0.5482496023178101, 0.41971805691719055, 0.013858035206794739, 0.00431621540337801, 0.013858035206794739], [0.002031848533079028, 0.354343444108963, 0.25415071845054626, 0.354343444108963, 0.03513054549694061], [0.46506866812705994, 0.0611216239631176, 0.008131430484354496, 0.46506866812705994, 0.0006096845609135926], [0.307638019323349, 0.1113443598151207, 0.003150765085592866, 0.1113443598151207, 0.46652260422706604], [0.0001332644751528278, 0.0001332644751528278, 0.007406787946820259, 0.5016240477561951, 0.4907025694847107], [0.0012216002214699984, 0.17241817712783813, 0.0057619293220341206, 0.5727125406265259, 0.24788573384284973], [0.07116398960351944, 0.002402008045464754, 0.04555152729153633, 0.5282505750656128, 0.35263189673423767], [0.4878614544868469, 0.023447321727871895, 0.026030289009213448, 0.4392136335372925, 0.023447321727871895], [0.00037465000059455633, 0.8127217292785645, 0.07583686709403992, 0.1036452203989029, 0.007421575952321291], [0.004245859105139971, 0.052603889256715775, 0.004245859105139971, 0.6992071866989136, 0.23969727754592896], [0.48071011900901794, 0.03268221765756607, 0.00027079309802502394, 0.48071011900901794, 0.005626779515296221], [0.10548339039087296, 0.12087148427963257, 0.10548339039087296, 0.6556427478790283, 0.01251895260065794], [0.2307686060667038, 0.38428613543510437, 0.00010323944297851995, 0.38428613543510437, 0.0005558544071391225], [0.12969167530536652, 0.6540133357048035, 0.03503737971186638, 0.12969167530536652, 0.051565881818532944], [0.4037648141384125, 0.4037648141384125, 0.021849697455763817, 0.11610402911901474, 0.05451672151684761], [0.001395908067934215, 0.006986116524785757, 0.031236151233315468, 0.9533957839012146, 0.006986116524785757], [0.07597817480564117, 0.53544020652771, 0.07597817480564117, 0.29767847061157227, 0.01492501050233841], [0.481329083442688, 0.0036553489044308662, 0.481329083442688, 0.013324976898729801, 0.02036144956946373], [0.32095351815223694, 0.642038881778717, 0.014468086883425713, 0.00807145144790411, 0.014468086883425713], [0.07716649770736694, 0.04011078178882599, 0.07716649770736694, 0.7881357669830322, 0.017420561984181404], [0.006152758374810219, 0.8792146444320679, 0.004009299911558628, 0.10447052121162415, 0.006152758374810219], [0.06169533729553223, 0.4494864344596863, 0.3919925093650818, 0.04841285198926926, 0.04841285198926926], [0.10056087374687195, 0.00022081656788941473, 0.00022081656788941473, 0.8312080502510071, 0.06778945028781891], [0.7570953965187073, 0.021237598732113838, 0.041633933782577515, 0.158795565366745, 0.021237598732113838], [0.003167285118252039, 0.8991506695747375, 0.09078165888786316, 0.003167285118252039, 0.0037331704515963793], [0.00966272596269846, 0.9322755336761475, 0.01711146906018257, 0.01711146906018257, 0.023838762193918228], [0.05837033689022064, 0.3598576784133911, 0.5687519907951355, 0.00016368756769225, 0.012856356799602509], [0.2574082612991333, 0.28597578406333923, 0.01009095273911953, 0.28597578406333923, 0.160549134016037], [0.30469632148742676, 0.33862921595573425, 0.33862921595573425, 0.008965888991951942, 0.00907942559570074], [0.07907899469137192, 0.874197244644165, 0.006553337909281254, 0.006553337909281254, 0.033617082983255386], [0.04398718476295471, 0.8096374273300171, 0.028212590143084526, 0.059081435203552246, 0.059081435203552246], [0.00014590556384064257, 0.01455767173320055, 0.002093137474730611, 0.9811100959777832, 0.002093137474730611], [0.9453354477882385, 0.02263432927429676, 0.0012420376297086477, 0.008153948932886124, 0.02263432927429676], [0.04089095816016197, 0.14244186878204346, 0.0009951931424438953, 0.14244186878204346, 0.6732301712036133], [0.0023636482656002045, 0.4716486930847168, 0.2594497799873352, 0.007088074926286936, 0.2594497799873352], [0.1339675337076187, 0.018351996317505836, 0.7096322178840637, 0.018351996317505836, 0.11969629675149918], [0.0009553950512781739, 0.04861683025956154, 0.012093916535377502, 0.04635598510503769, 0.8919779062271118], [0.02288883365690708, 0.08186214417219162, 0.40202274918556213, 0.24661314487457275, 0.24661314487457275], [0.30308324098587036, 0.002476529451087117, 0.5474048852920532, 0.12825852632522583, 0.018776746466755867], [0.012507661245763302, 0.012507661245763302, 0.06696086376905441, 0.03616136685013771, 0.8718624711036682], [0.12456892430782318, 0.6393147110939026, 0.12456892430782318, 0.0043301512487232685, 0.10721732676029205], [2.6167414034716785e-05, 2.6167414034716785e-05, 0.2571622431278229, 0.3476168215274811, 0.3951685428619385], [0.06950115412473679, 0.006644942332059145, 0.06950115412473679, 0.8450170755386353, 0.009335662238299847], [0.07550736516714096, 0.31723400950431824, 0.5612043142318726, 0.023027164861559868, 0.023027164861559868], [0.0037915329448878765, 0.0037915329448878765, 0.9450540542602539, 0.03982049599289894, 0.007542377337813377], [0.04785560071468353, 0.04785560071468353, 0.44197118282318115, 0.074510857462883, 0.3878066837787628], [0.9561704993247986, 0.006006021052598953, 0.0014615963445976377, 0.03490021824836731, 0.0014615963445976377], [0.031945593655109406, 0.031945593655109406, 0.42581290006637573, 0.12273356318473816, 0.3875623345375061], [0.14538875222206116, 0.12577427923679352, 0.6002443432807922, 0.06429629772901535, 0.06429629772901535], [0.21006084978580475, 0.21006084978580475, 0.12923352420330048, 0.008360251784324646, 0.4422845244407654], [0.5308747887611389, 0.35130149126052856, 0.028686203062534332, 0.06045127287507057, 0.028686203062534332], [0.026625653728842735, 0.023258384317159653, 0.45864561200141907, 0.45864561200141907, 0.03282471373677254], [0.03303799778223038, 0.010559749789536, 0.8132809400558472, 0.07156065851449966, 0.07156065851449966], [0.10233376175165176, 0.7205885648727417, 0.10233376175165176, 0.04378090053796768, 0.030962983146309853], [0.41939079761505127, 0.11217200756072998, 0.41939079761505127, 0.027721339836716652, 0.02132496051490307], [0.1768113672733307, 0.05340728536248207, 0.3030875325202942, 0.3030875325202942, 0.16360630095005035], [0.9526722431182861, 0.002645341446623206, 0.04196956753730774, 0.002645341446623206, 6.749366002622992e-05], [0.01140607614070177, 0.005410891026258469, 0.005410891026258469, 0.17693263292312622, 0.8008394837379456], [0.07803823798894882, 0.62667316198349, 0.15485146641731262, 0.13416342437267303, 0.006273733917623758], [0.5064969062805176, 3.760050458367914e-05, 3.760050458367914e-05, 0.4794062376022339, 0.014021691866219044], [0.0010338949505239725, 0.44708263874053955, 0.030205819755792618, 0.07459498941898346, 0.44708263874053955], [0.06528632342815399, 0.5886644721031189, 0.24203826487064362, 0.07834415882825851, 0.0256667397916317], [0.10380910336971283, 0.10865394026041031, 0.5867639183998108, 0.10380910336971283, 0.09696396440267563], [0.23782917857170105, 0.06065629795193672, 0.6180340051651001, 0.041740257292985916, 0.041740257292985916], [0.25522515177726746, 0.18157604336738586, 0.0588783398270607, 0.25522515177726746, 0.24909529089927673], [0.008313184604048729, 0.008313184604048729, 0.21616457402706146, 0.5262260437011719, 0.2409830242395401], [0.06114301458001137, 0.0010207173181697726, 0.0008924170979298651, 0.06114301458001137, 0.8758007884025574], [0.13175305724143982, 0.34878212213516235, 0.00943752657622099, 0.00641472777351737, 0.5036125779151917], [0.00046581655624322593, 0.9637255072593689, 0.030505700036883354, 0.00046581655624322593, 0.004837173502892256], [0.043937087059020996, 0.18947529792785645, 0.018111668527126312, 0.3742380142211914, 0.3742380142211914], [0.07059022039175034, 0.3445305824279785, 0.023276500403881073, 0.01804247871041298, 0.5435601472854614], [0.842379093170166, 0.0010436183074489236, 0.014281055890023708, 0.014281055890023708, 0.1280151754617691], [0.028334572911262512, 0.026913927868008614, 0.9158557653427124, 0.028334572911262512, 0.0005611286032944918], [0.0005631992244161665, 0.016998646780848503, 0.5436958074569702, 0.0005631992244161665, 0.4381791353225708], [0.1147821769118309, 0.3518284261226654, 0.3518284261226654, 0.018736237660050392, 0.16282470524311066], [0.22781525552272797, 0.261618435382843, 0.261618435382843, 0.16382764279842377, 0.08512025326490402], [0.5006011128425598, 0.09439774602651596, 0.02666686289012432, 0.35166749358177185, 0.02666686289012432], [0.15909595787525177, 0.15909595787525177, 0.048373930156230927, 0.05230748653411865, 0.5811266899108887], [0.1627018004655838, 0.1627018004655838, 0.3926169276237488, 0.06492844223976135, 0.21705104410648346], [0.472871333360672, 0.06897923350334167, 0.11311369389295578, 0.32227039337158203, 0.022765351459383965], [0.00040476227877661586, 0.020963827148079872, 0.6969905495643616, 0.25249752402305603, 0.029143301770091057], [0.03747411072254181, 0.07569322735071182, 0.8093709349632263, 0.0017685105558484793, 0.07569322735071182], [0.3197667598724365, 0.05398515611886978, 0.5640152096748352, 0.05398515611886978, 0.008247720077633858], [0.2956047058105469, 0.04239017888903618, 0.03626318648457527, 0.6207013726234436, 0.005040530581027269], [0.014586147852241993, 0.08168449252843857, 0.41406282782554626, 0.07560374587774277, 0.41406282782554626], [0.08457260578870773, 1.0508219929761253e-05, 0.016994668170809746, 0.898411750793457, 1.0508219929761253e-05], [0.0736149400472641, 0.1511402279138565, 0.30566325783729553, 0.0736149400472641, 0.39596661925315857], [0.14270058274269104, 0.21946673095226288, 0.001912332372739911, 0.4932198226451874, 0.14270058274269104], [5.014078851672821e-06, 0.05361940339207649, 0.14004255831241608, 0.4031665027141571, 0.4031665027141571], [0.19596856832504272, 0.031776063144207, 0.13703623414039612, 0.1548205316066742, 0.4803985357284546], [0.292277991771698, 0.0845024511218071, 0.292277991771698, 0.1562274694442749, 0.1747141182422638], [0.38189902901649475, 0.06971368193626404, 0.4875480830669403, 0.024648819118738174, 0.036190424114465714], [0.3217163383960724, 0.02615584433078766, 0.021466068923473358, 0.3089453876018524, 0.3217163383960724], [0.050555791705846786, 0.3387836515903473, 0.0845036506652832, 0.18737323582172394, 0.3387836515903473], [0.11848851293325424, 0.11848851293325424, 0.36224424839019775, 0.009498469531536102, 0.3912801742553711], [0.18028685450553894, 0.18028685450553894, 0.002948187757283449, 0.6341435313224792, 0.0023346052039414644], [0.02771715633571148, 0.7780929803848267, 0.19397711753845215, 0.00010635390208335593, 0.00010635390208335593], [0.37976470589637756, 0.047924380749464035, 0.0004139043448958546, 0.5714830756187439, 0.0004139043448958546], [0.003914779517799616, 0.018581315875053406, 0.4802280366420746, 0.4802280366420746, 0.01704779453575611], [0.4480314254760742, 0.07093315571546555, 0.00023909081937745214, 0.3832401931285858, 0.09755612164735794], [0.26469936966896057, 0.26469936966896057, 0.4221939146518707, 0.03220830857753754, 0.016199085861444473], [0.13721206784248352, 0.00668043689802289, 0.8381047248840332, 0.00668043689802289, 0.011322331614792347], [0.008439893834292889, 0.8864198923110962, 0.09651027619838715, 0.0001900950155686587, 0.008439893834292889], [0.0035376111045479774, 0.2597815990447998, 0.3500005006790161, 0.036679770797491074, 0.3500005006790161], [0.012384749948978424, 0.17930001020431519, 0.6836388111114502, 0.062338221818208694, 0.062338221818208694], [0.39399316906929016, 0.00013050886627752334, 0.39399316906929016, 0.17734546959400177, 0.03453764319419861], [0.2574000656604767, 0.035691551864147186, 0.2574000656604767, 0.44810184836387634, 0.0014064257265999913], [0.7041478753089905, 0.0006903911125846207, 0.05447354540228844, 0.0006903911125846207, 0.2399977594614029], [0.004448972176760435, 0.16176964342594147, 0.6449431777000427, 0.16176964342594147, 0.027068497613072395], [0.37347763776779175, 0.37347763776779175, 0.08462943881750107, 0.1287194937467575, 0.039695847779512405], [0.8961784243583679, 0.01004444994032383, 0.044270116835832596, 0.01004444994032383, 0.039462585002183914], [0.4895632266998291, 0.34946727752685547, 0.15219610929489136, 0.004386723507195711, 0.004386723507195711], [0.2319018840789795, 0.04079706221818924, 0.49532756209373474, 7.161944085964933e-05, 0.2319018840789795], [0.0268886536359787, 0.07901818305253983, 0.08832014352083206, 0.07901818305253983, 0.7267547845840454], [0.11424168944358826, 0.004815169610083103, 0.24231359362602234, 0.6338143944740295, 0.004815169610083103], [0.13390058279037476, 0.02257818728685379, 0.024416811764240265, 0.7946876287460327, 0.024416811764240265], [0.1918266862630844, 0.21337123215198517, 0.22463692724704742, 0.1918266862630844, 0.17833854258060455], [0.5828260779380798, 0.05972602590918541, 0.14047300815582275, 0.14047300815582275, 0.07650181651115417], [0.4309402108192444, 0.007170028984546661, 0.00025282424758188426, 0.13069669902324677, 0.4309402108192444], [0.577078640460968, 0.056223493069410324, 0.17556434869766235, 0.17556434869766235, 0.015569157898426056], [0.3335174024105072, 0.17954649031162262, 0.07861914485692978, 0.32969775795936584, 0.07861914485692978], [0.06590481847524643, 0.06590481847524643, 0.37916940450668335, 0.030770771205425262, 0.4582501947879791], [0.7221542596817017, 0.013425665907561779, 0.03273938223719597, 0.19894124567508698, 0.03273938223719597], [0.03660308197140694, 0.3354856073856354, 0.0194033682346344, 0.5891045331954956, 0.0194033682346344], [0.22312714159488678, 0.005570689681917429, 0.6611038446426392, 0.05509912222623825, 0.05509912222623825], [0.08402242511510849, 0.08402242511510849, 0.059590764343738556, 0.7520254254341125, 0.020338986068964005], [0.2233443558216095, 0.35761091113090515, 0.19254130125045776, 0.2233443558216095, 0.003159020096063614], [0.07345680147409439, 0.016663692891597748, 0.43647220730781555, 0.2411375194787979, 0.23226980865001678], [0.5354868769645691, 0.06874597072601318, 0.010270419530570507, 0.014240489341318607, 0.3712562620639801], [0.6520034670829773, 0.0012402319116517901, 0.07420787215232849, 0.07420787215232849, 0.19834059476852417], [0.2609899640083313, 0.09887760877609253, 0.3194631040096283, 0.05967932194471359, 0.2609899640083313], [0.27810046076774597, 0.012441745027899742, 0.31437957286834717, 0.11697781831026077, 0.27810046076774597], [0.41766899824142456, 0.010566221550107002, 0.0119099710136652, 0.5492885112762451, 0.010566221550107002], [0.001748640788719058, 0.9241245985031128, 0.001748640788719058, 0.0001613094937056303, 0.07221680879592896], [0.6014707684516907, 0.146483913064003, 0.062043771147727966, 0.043517615646123886, 0.146483913064003], [0.43823713064193726, 0.15490110218524933, 0.15761834383010864, 0.2475031018257141, 0.0017403794918209314], [0.5804261565208435, 6.685048720100895e-05, 0.41394802927970886, 6.685048720100895e-05, 0.005492147523909807], [0.03255684673786163, 0.03255684673786163, 0.3861373960971832, 0.0008583521121181548, 0.5478906035423279], [0.3306617736816406, 0.3130606710910797, 0.3130606710910797, 0.026979101821780205, 0.016237782314419746], [0.21577996015548706, 0.4054284393787384, 0.21577996015548706, 0.01516798697412014, 0.147843599319458], [0.1734512895345688, 0.16089880466461182, 0.16089880466461182, 0.03541504591703415, 0.46933603286743164], [0.028319697827100754, 0.005288212560117245, 0.005288212560117245, 0.8339389562606812, 0.12716493010520935], [0.475345253944397, 0.002918851561844349, 0.002670430578291416, 0.475345253944397, 0.04372026026248932], [0.026129717007279396, 0.3264808654785156, 0.13701051473617554, 0.026129717007279396, 0.48424914479255676], [0.48619544506073, 0.12634457647800446, 0.1771005541086197, 0.1771005541086197, 0.03325889632105827], [0.010379012674093246, 0.09855479001998901, 0.3233925700187683, 0.24428105354309082, 0.3233925700187683], [0.004883787594735622, 0.17238469421863556, 0.4034777879714966, 0.015775948762893677, 0.4034777879714966], [0.059548716992139816, 0.0012550951214507222, 0.4632137715816498, 0.012768691405653954, 0.4632137715816498], [0.00038169126491993666, 0.4531477093696594, 0.2721695601940155, 0.002131455345079303, 0.2721695601940155], [0.0026737258303910494, 0.008825534023344517, 0.491807222366333, 0.004886337090283632, 0.491807222366333], [0.37930387258529663, 0.08038289844989777, 0.37930387258529663, 0.12456415593624115, 0.036445148289203644], [0.1524244099855423, 0.18189992010593414, 0.0521731823682785, 0.18189992010593414, 0.4316026270389557], [0.05340863764286041, 9.10905800992623e-05, 0.3354853689670563, 0.30550745129585266, 0.30550745129585266], [0.4989110827445984, 0.45949220657348633, 0.0028415992856025696, 0.0028415992856025696, 0.03591349720954895], [0.3046884834766388, 0.19689781963825226, 0.1036963239312172, 0.3046884834766388, 0.09002889692783356], [0.01976124569773674, 0.01976124569773674, 0.3371639847755432, 0.02059299685060978, 0.6027204990386963], [0.38413888216018677, 0.38413888216018677, 0.11512330174446106, 0.00595374871045351, 0.1106451228260994], [0.0003494391276035458, 0.38155239820480347, 0.09118025749921799, 0.5265684127807617, 0.0003494391276035458], [0.012751578353345394, 0.06687095761299133, 0.17742584645748138, 0.06687095761299133, 0.6760806441307068], [0.23209404945373535, 0.38010331988334656, 0.0027863704599440098, 0.004912885371595621, 0.38010331988334656], [0.11995527893304825, 0.6052826046943665, 0.15012772381305695, 0.11995527893304825, 0.0046790833584964275], [0.38133829832077026, 0.13265091180801392, 0.04006180539727211, 0.38133829832077026, 0.06461074203252792], [0.1965327262878418, 7.2796996391844e-05, 0.7809115648269653, 0.01745474524796009, 0.005028253886848688], [0.007518792524933815, 0.004435283597558737, 0.9367435574531555, 0.04378347098827362, 0.007518792524933815], [0.0009525272180326283, 0.31489992141723633, 0.34204381704330444, 0.31489992141723633, 0.02720382809638977], [0.10738413780927658, 0.40561556816101074, 0.12063565850257874, 0.24572893977165222, 0.12063565850257874], [0.05403713881969452, 0.05403713881969452, 0.0013744478346779943, 0.890285074710846, 0.00026615781825967133], [0.02228374034166336, 0.4736385643482208, 0.0930238887667656, 0.33216848969459534, 0.0788852721452713], [0.5487364530563354, 0.030666159465909004, 0.3820286691188812, 0.007902504876255989, 0.030666159465909004], [0.21580834686756134, 0.44885316491127014, 0.04417763650417328, 0.16445092856884003, 0.12670987844467163], [0.3380085229873657, 0.0013095198664814234, 0.3380085229873657, 0.22325122356414795, 0.09942217916250229], [0.09552134573459625, 0.4451534152030945, 0.014092067256569862, 7.977131463121623e-05, 0.4451534152030945], [0.016219856217503548, 0.017956193536520004, 0.8636523485183716, 0.08421538770198822, 0.017956193536520004], [0.868166983127594, 0.00039455376099795103, 0.014984429813921452, 0.11605945974588394, 0.00039455376099795103], [0.29422733187675476, 0.33053261041641235, 0.07674716413021088, 0.07674716413021088, 0.22174575924873352], [0.2950785160064697, 0.2950785160064697, 0.08772188425064087, 0.305179238319397, 0.016941916197538376], [0.9826650619506836, 0.006835226435214281, 0.00016998499631881714, 0.010159691795706749, 0.00016998499631881714], [0.015467560850083828, 0.37199172377586365, 0.37199172377586365, 0.22600585222244263, 0.014543168246746063], [0.12401396036148071, 0.12401396036148071, 0.022862570360302925, 0.03523049131035805, 0.6938790082931519], [0.35521769523620605, 0.35521769523620605, 0.17792002856731415, 0.06557308882474899, 0.04607144743204117], [0.14425529539585114, 0.3087960481643677, 0.19365552067756653, 0.14425529539585114, 0.20903778076171875], [0.19447851181030273, 0.0006294907652772963, 0.19447851181030273, 0.12780214846134186, 0.4826112687587738], [0.21391057968139648, 0.21391057968139648, 0.2787744402885437, 0.07344556599855423, 0.21995878219604492], [0.7625431418418884, 0.08032908290624619, 0.09661655128002167, 0.03354748338460922, 0.026963792741298676], [0.039590343832969666, 0.18589885532855988, 0.2663673162460327, 0.32224464416503906, 0.18589885532855988], [0.29100167751312256, 0.02447986789047718, 0.008084693923592567, 6.658759957645088e-05, 0.6763672232627869], [0.12527264654636383, 0.2060752660036087, 0.16449324786663055, 0.33966559171676636, 0.16449324786663055], [0.4544717073440552, 0.2917940318584442, 0.12620937824249268, 0.0013155114138498902, 0.12620937824249268], [0.07745871692895889, 0.8117597699165344, 0.005132238380610943, 0.052824635058641434, 0.052824635058641434], [0.013935424387454987, 0.10941244661808014, 0.45642709732055664, 0.013935424387454987, 0.406289666891098], [0.17471563816070557, 0.34789347648620605, 0.16430069506168365, 0.15654508769512177, 0.15654508769512177], [0.008657080121338367, 0.3646409511566162, 0.008657080121338367, 0.15280814468860626, 0.4652367830276489], [0.1270144134759903, 0.6991204023361206, 0.07062971591949463, 0.032605789601802826, 0.07062971591949463], [0.04025759920477867, 0.46535393595695496, 0.015910236164927483, 0.46535393595695496, 0.013124316930770874], [0.03856736794114113, 0.03856736794114113, 0.4796251952648163, 0.14431320130825043, 0.29892683029174805], [0.43108507990837097, 0.0020308238454163074, 0.009493499994277954, 0.43108507990837097, 0.126305490732193], [0.429747074842453, 0.004069935530424118, 0.004069935530424118, 0.2258501946926117, 0.3362628221511841], [0.1723703294992447, 0.14180172979831696, 0.019054993987083435, 0.5249712467193604, 0.14180172979831696], [0.031986385583877563, 0.6788649559020996, 0.031986385583877563, 0.2562653124332428, 0.0008969776681624353], [0.002499764785170555, 0.002499764785170555, 0.9684066772460938, 0.01125303003937006, 0.015340715646743774], [0.04961932450532913, 0.09205000847578049, 0.006760234013199806, 0.42578524351119995, 0.42578524351119995], [0.33209025859832764, 0.33209025859832764, 0.007037336938083172, 0.1593128889799118, 0.1694691777229309], [0.02858654595911503, 0.00032788122189231217, 0.04544377326965332, 0.880198061466217, 0.04544377326965332], [0.45099833607673645, 0.18996556103229523, 0.0009434398380108178, 0.0009434398380108178, 0.35714924335479736], [0.006659962236881256, 0.9883346557617188, 0.00014921242836862803, 0.004706953186541796, 0.00014921242836862803], [0.1125161200761795, 0.34842008352279663, 0.34842008352279663, 0.15001927316188812, 0.040624458342790604], [0.24499736726284027, 0.1421985924243927, 0.4333183765411377, 0.1421985924243927, 0.037287019193172455], [0.07239272445440292, 0.15954150259494781, 0.005664212629199028, 0.7567374110221863, 0.005664212629199028], [0.40022915601730347, 0.1738969087600708, 0.40022915601730347, 0.025280024856328964, 0.0003647345583885908], [0.08436431735754013, 0.0002871747419703752, 0.08436431735754013, 0.5306824445724487, 0.30030179023742676], [0.00860248040407896, 0.3662174940109253, 0.01986519806087017, 0.30265742540359497, 0.30265742540359497], [0.4070259928703308, 0.17664141952991486, 0.4070259928703308, 0.003997796680778265, 0.005308766383677721], [0.340253084897995, 0.2725018858909607, 0.2725018858909607, 0.09144814312458038, 0.023295026272535324], [0.034359972923994064, 0.1204281598329544, 0.1204281598329544, 0.3363770544528961, 0.3884066939353943], [0.43301376700401306, 0.0003856864932458848, 0.5631241202354431, 0.0030906973406672478, 0.0003856864932458848], [0.007655867841094732, 0.014064399525523186, 0.007655867841094732, 0.29450276494026184, 0.6761211156845093], [0.0587371289730072, 0.0587371289730072, 0.570763885974884, 0.020501907914876938, 0.29125985503196716], [0.06697798520326614, 0.1339193880558014, 0.5763349533081055, 0.06697798520326614, 0.15578965842723846], [3.1997798942029476e-05, 0.0060648065991699696, 0.046918097883462906, 0.6760414838790894, 0.27094361186027527], [0.013797903433442116, 0.023008160293102264, 0.05813530460000038, 0.8912608027458191, 0.013797903433442116], [0.029310787096619606, 0.24377916753292084, 0.24377916753292084, 0.029128586873412132, 0.454002320766449], [0.001918324618600309, 0.011390595696866512, 0.04763629287481308, 0.001918324618600309, 0.9371364116668701], [0.01455739326775074, 0.0003214888274669647, 0.7159102559089661, 0.13460543751716614, 0.13460543751716614], [0.014536218717694283, 0.3609369695186615, 0.24726255238056183, 0.3609369695186615, 0.01632729358971119], [0.013949466869235039, 0.21295608580112457, 0.21295608580112457, 0.5593465566635132, 0.0007917851326055825], [0.441291481256485, 0.02273263968527317, 0.02273263968527317, 0.0033560108859091997, 0.5098872184753418], [0.04896538704633713, 0.2574051022529602, 0.04896538704633713, 0.0558486245572567, 0.5888153910636902], [0.05893028527498245, 0.17986150085926056, 0.013513166457414627, 0.688764750957489, 0.05893028527498245], [0.00795180257409811, 0.00795180257409811, 0.021622810512781143, 0.43216538429260254, 0.5303082466125488], [0.11548614501953125, 0.06762051582336426, 0.0031392432283610106, 0.06762051582336426, 0.74613356590271], [0.4229375720024109, 0.1533571034669876, 0.0005339127965271473, 0.4229375720024109, 0.0002338239282835275], [0.017208699136972427, 0.3815532624721527, 0.017208699136972427, 0.30395790934562683, 0.2800714373588562], [0.08484571427106857, 0.8345199823379517, 0.039400313049554825, 0.0018337416695430875, 0.039400313049554825], [0.002121818019077182, 0.9156870245933533, 0.05443638563156128, 0.025632888078689575, 0.002121818019077182], [0.013807856477797031, 0.013807856477797031, 0.17042748630046844, 0.14710618555545807, 0.6548506021499634], [0.0021852506324648857, 0.5174888372421265, 0.001967332325875759, 0.35219311714172363, 0.12616543471813202], [0.0012311283499002457, 0.06408300995826721, 0.5811611413955688, 0.0009771467885002494, 0.35254761576652527], [0.2713676691055298, 0.02348450943827629, 0.32683542370796204, 0.32683542370796204, 0.05147698521614075], [0.05194180831313133, 0.00046993381693027914, 0.025656940415501595, 0.025656940415501595, 0.8962744474411011], [0.4123183488845825, 0.0005645133787766099, 0.17401152849197388, 0.0007872558780945837, 0.4123183488845825], [0.4751092493534088, 0.04153384640812874, 0.4142017066478729, 0.027621397748589516, 0.04153384640812874], [0.0815124437212944, 0.0044457511976361275, 0.864578127861023, 0.024731889367103577, 0.024731889367103577], [0.4231974482536316, 7.31945110601373e-05, 0.18573163449764252, 0.38978052139282227, 0.001217189827002585], [0.03985554724931717, 0.2567194998264313, 0.01570448838174343, 0.4310010075569153, 0.2567194998264313], [0.0004582334659062326, 0.3086768686771393, 0.3086768686771393, 0.025481227785348892, 0.35670676827430725], [0.5980167388916016, 0.01384121086448431, 0.17120863497257233, 0.2030922770500183, 0.01384121086448431], [0.4789949059486389, 0.0013311879010871053, 0.15733277797698975, 0.18117058277130127, 0.18117058277130127], [0.013746345415711403, 0.10337706655263901, 0.762048602104187, 0.01745094358921051, 0.10337706655263901], [0.6248841881752014, 0.1922733187675476, 0.10717467218637466, 0.03783388063311577, 0.03783388063311577], [0.005971348378807306, 0.3442031741142273, 0.07500044256448746, 0.3442031741142273, 0.23062185943126678], [0.018768709152936935, 0.4023553133010864, 0.5671806931495667, 0.005847645457834005, 0.005847645457834005], [0.9390943646430969, 0.05139261856675148, 0.0024432772770524025, 0.0024432772770524025, 0.00462635513395071], [0.1861354410648346, 0.09802144765853882, 0.1861354410648346, 0.2613092362880707, 0.26839837431907654], [0.664650559425354, 0.08044338971376419, 0.016009898856282234, 0.08044338971376419, 0.15845273435115814], [0.019715573638677597, 0.0287781935185194, 0.09945356845855713, 0.0287781935185194, 0.823274552822113], [0.4118155539035797, 0.10180985927581787, 0.022061415016651154, 0.10180985927581787, 0.3625032901763916], [0.7265544533729553, 0.0001950742007466033, 0.0001950742007466033, 0.15899793803691864, 0.11405745893716812], [0.06825250387191772, 0.07920585572719574, 0.06228087469935417, 0.7279799580574036, 0.06228087469935417], [0.8479725122451782, 0.0010282889707013965, 0.10169155895709991, 0.0010282889707013965, 0.048279307782649994], [0.056196026504039764, 0.5970255732536316, 0.2583519220352173, 0.056196026504039764, 0.03223042190074921], [0.011535253375768661, 0.6843137741088867, 0.09687874466180801, 0.10363610088825226, 0.10363610088825226], [0.12886786460876465, 0.1752685308456421, 0.4369528293609619, 0.13936224579811096, 0.11954858899116516], [0.22539381682872772, 0.04913519322872162, 0.03418640047311783, 0.6570981740951538, 0.03418640047311783], [0.03417060524225235, 0.4309428632259369, 0.4309428632259369, 0.10336713492870331, 0.0005766154499724507], [0.2974631190299988, 0.09906582534313202, 0.030210815370082855, 0.1729370355606079, 0.40032318234443665], [0.00017735816072672606, 0.6225560903549194, 0.02369336597621441, 0.35339581966400146, 0.00017735816072672606], [0.08505620062351227, 0.40165045857429504, 0.15391990542411804, 0.27431720495224, 0.08505620062351227], [0.060124050825834274, 0.11332469433546066, 0.11332469433546066, 0.33305782079696655, 0.38016876578330994], [0.18523666262626648, 0.25363701581954956, 0.25363701581954956, 0.05040375143289566, 0.2570855915546417], [0.0017620610306039453, 0.6850383877754211, 0.01998233050107956, 0.005024656653404236, 0.28819260001182556], [0.5425953269004822, 0.10708493739366531, 0.07708241045475006, 0.10708493739366531, 0.16615238785743713], [0.007309795822948217, 0.020298801362514496, 0.3678050637245178, 0.5842875242233276, 0.020298801362514496], [0.7696467041969299, 0.07045740634202957, 0.04037776589393616, 0.07914042472839355, 0.04037776589393616], [0.0008229485247284174, 0.002999377204105258, 0.17379534244537354, 0.6485869884490967, 0.17379534244537354], [0.05256669968366623, 0.4088481068611145, 0.26706546545028687, 0.26706546545028687, 0.0044542946852743626], [0.31180477142333984, 0.17145036160945892, 0.0005458132945932448, 0.2580995261669159, 0.2580995261669159], [0.00043338644900359213, 0.3937288224697113, 0.10233919322490692, 0.4011594355106354, 0.10233919322490692], [0.38752856850624084, 0.0006046403432264924, 0.38752856850624084, 0.017035482451319695, 0.20730271935462952], [0.2702461779117584, 0.004359585233032703, 0.4449542760848999, 0.010193738155066967, 0.2702461779117584], [0.2979956865310669, 0.2979956865310669, 0.26306039094924927, 0.1368727833032608, 0.004075468517839909], [0.32931163907051086, 0.008674860000610352, 0.49617695808410645, 0.15716157853603363, 0.008674860000610352], [0.11714570224285126, 0.1473560333251953, 0.6822394728660583, 0.026629382744431496, 0.026629382744431496], [0.22903548181056976, 0.07282891124486923, 0.3416658341884613, 0.014803980477154255, 0.3416658341884613], [0.28741326928138733, 0.3751148581504822, 0.28741326928138733, 0.03778853267431259, 0.012270059436559677], [0.012882242910563946, 0.22306664288043976, 0.012882242910563946, 0.0739516019821167, 0.6772172451019287], [0.012292113155126572, 0.36059609055519104, 0.008135205134749413, 0.6108413934707642, 0.008135205134749413], [0.0047101774252951145, 0.0002603255270514637, 0.042587313801050186, 0.952181875705719, 0.0002603255270514637], [0.4248441159725189, 0.27567869424819946, 0.00041247456101700664, 0.023386076092720032, 0.27567869424819946], [0.050076164305210114, 0.0019580074585974216, 0.897585391998291, 0.050076164305210114, 0.0003042712633032352], [0.0008328795083798468, 0.061480872333049774, 0.795743465423584, 0.07097139954566956, 0.07097139954566956], [0.15869727730751038, 0.29066330194473267, 0.29066330194473267, 0.1453256607055664, 0.11465045809745789], [0.015850543975830078, 0.07003451138734818, 0.015850543975830078, 0.03364429622888565, 0.8646200895309448], [0.04446820914745331, 0.013054383918642998, 0.003355992492288351, 0.8946531414985657, 0.04446820914745331], [0.016589434817433357, 0.060830920934677124, 0.0014894730411469936, 0.060830920934677124, 0.8602592349052429], [0.06711849570274353, 0.10067373514175415, 0.76502925157547, 0.06711849570274353, 6.0072117776144296e-05], [0.4436851143836975, 0.28530290722846985, 0.014328822493553162, 0.2423543632030487, 0.014328822493553162], [0.09427376836538315, 0.010029951110482216, 0.06730154901742935, 0.010029951110482216, 0.8183647990226746], [0.43217894434928894, 0.06519415229558945, 0.04084770753979683, 0.43217894434928894, 0.029600253328680992], [0.7911658883094788, 0.08098707348108292, 0.062317855656147, 0.062317855656147, 0.0032113452907651663], [0.0116457873955369, 0.09561008960008621, 0.023358743637800217, 0.0116457873955369, 0.8577395677566528], [0.3295148015022278, 0.1448267549276352, 0.004038230516016483, 0.3767935037612915, 0.1448267549276352], [0.7468128204345703, 0.09074989706277847, 0.08029858767986298, 0.001840155920945108, 0.08029858767986298], [0.017706573009490967, 0.1474463939666748, 0.38159623742103577, 0.07165452092885971, 0.38159623742103577], [0.7134697437286377, 0.23729358613491058, 0.04920259118080139, 1.6991589291137643e-05, 1.6991589291137643e-05], [0.014356556348502636, 0.02015889622271061, 0.7707298398017883, 0.09737733751535416, 0.09737733751535416], [0.22238945960998535, 0.22238945960998535, 0.08200802654027939, 2.7815052817459218e-05, 0.4731852412223816], [0.009918028488755226, 0.6602806448936462, 0.005755577702075243, 0.25657889246940613, 0.0674668699502945], [0.11510846763849258, 0.03417070582509041, 0.8053018450737, 0.022709475830197334, 0.022709475830197334], [0.13590413331985474, 0.04495793953537941, 0.4037153124809265, 0.011707277968525887, 0.4037153124809265], [0.00883428193628788, 0.14884069561958313, 0.14884069561958313, 0.6929236054420471, 0.0005606622435152531], [0.5599724650382996, 0.0648607388138771, 0.34284672141075134, 0.0074346414767205715, 0.024885445833206177], [0.0007522977539338171, 0.4590284824371338, 0.07005561143159866, 0.4590284824371338, 0.011135072447359562], [0.043730977922677994, 0.2365543097257614, 0.251726895570755, 0.23399391770362854, 0.23399391770362854], [0.005851891823112965, 0.20242197811603546, 0.06118224933743477, 0.20242197811603546, 0.528121829032898], [0.0016126491827890277, 0.011060941033065319, 0.9068021178245544, 0.011060941033065319, 0.06946335732936859], [0.7147665619850159, 0.1117059513926506, 0.10596577078104019, 0.053054794669151306, 0.014506977051496506], [0.27042633295059204, 0.3061944544315338, 0.10416653752326965, 0.013018230907619, 0.3061944544315338], [0.0010505488608032465, 0.2659774124622345, 0.3534054160118103, 0.11358913779258728, 0.2659774124622345], [0.4275203347206116, 0.033354002982378006, 0.08810760825872421, 0.02349773980677128, 0.4275203347206116], [0.3339847922325134, 0.3339847922325134, 0.007873138412833214, 0.12673315405845642, 0.19742414355278015], [0.06383158266544342, 0.21346740424633026, 0.46021220088005066, 0.049021415412425995, 0.21346740424633026], [0.0074260844849050045, 0.6650297045707703, 0.0074260844849050045, 0.2902645766735077, 0.029853546991944313], [0.13767161965370178, 0.16609546542167664, 0.13103702664375305, 0.13103702664375305, 0.43415889143943787], [0.0053532905876636505, 0.7261632084846497, 0.0002539531560614705, 0.005717623513191938, 0.2625119090080261], [0.23981738090515137, 0.041877686977386475, 0.6316734552383423, 0.041877686977386475, 0.04475383087992668], [0.16916781663894653, 0.003761741565540433, 0.10457795858383179, 0.3612461984157562, 0.3612461984157562], [0.06639494746923447, 0.011094912886619568, 0.009701799601316452, 0.06639494746923447, 0.8464134335517883], [0.006915017496794462, 0.006915017496794462, 0.866378903388977, 0.0036943259183317423, 0.11609664559364319], [0.2983695864677429, 0.25850945711135864, 0.2983695864677429, 0.009312953799962997, 0.13543839752674103], [0.005589045584201813, 0.9065603613853455, 0.0009942905744537711, 0.08586202561855316, 0.0009942905744537711], [0.008200369775295258, 0.3737608790397644, 0.572336733341217, 0.037501659244298935, 0.008200369775295258], [0.06645940989255905, 0.2802721858024597, 0.2833544909954071, 0.0896417424082756, 0.2802721858024597], [0.7299086451530457, 0.09498659521341324, 0.09498659521341324, 0.04455249011516571, 0.035565681755542755], [0.04269548878073692, 0.001562420860864222, 0.448893666267395, 0.448893666267395, 0.05795479193329811], [0.332784503698349, 0.023890456184744835, 0.3101569712162018, 0.0003835814422927797, 0.332784503698349], [0.15360328555107117, 0.1088888868689537, 0.015438736416399479, 0.1088888868689537, 0.6131802201271057], [0.8252192139625549, 0.01002465933561325, 0.01002465933561325, 0.026620417833328247, 0.12811103463172913], [2.9966111469548196e-05, 0.2095920890569687, 0.014110464602708817, 0.6025428175926208, 0.1737246960401535], [0.32578378915786743, 0.0016398654552176595, 0.6449390649795532, 0.02599741518497467, 0.0016398654552176595], [0.527701199054718, 0.19579948484897614, 0.19579948484897614, 0.03953741863369942, 0.04116243124008179], [0.028079833835363388, 0.8315313458442688, 3.700265006045811e-05, 0.14031480252742767, 3.700265006045811e-05], [0.5588102340698242, 0.03784143179655075, 0.2404281049966812, 0.12507876753807068, 0.03784143179655075], [0.18000617623329163, 0.40231239795684814, 0.006962629966437817, 0.40231239795684814, 0.008406334556639194], [0.036230843514204025, 0.6353306770324707, 0.004581750370562077, 0.16192834079265594, 0.16192834079265594], [0.020352352410554886, 0.020352352410554886, 0.14842838048934937, 0.8078980445861816, 0.0029688640497624874], [0.02215706557035446, 0.4187195301055908, 0.4187195301055908, 0.0335480272769928, 0.10685578733682632], [0.6327060461044312, 0.06505737453699112, 0.02755267359316349, 0.2471311390399933, 0.02755267359316349], [0.056100744754076004, 0.007085274439305067, 0.007561825681477785, 0.056100744754076004, 0.8731513619422913], [0.01678081788122654, 0.01678081788122654, 0.8034209609031677, 0.10082250833511353, 0.06219484657049179], [0.9830465912818909, 0.012137974612414837, 1.2318546396272723e-05, 1.2318546396272723e-05, 0.004790739621967077], [0.2111833244562149, 0.5601022243499756, 0.002426784485578537, 0.015104345977306366, 0.2111833244562149], [0.4563290774822235, 0.02905130200088024, 0.0005776862963102758, 0.4563290774822235, 0.05771297961473465], [0.027936900034546852, 0.6582683324813843, 0.21979869902133942, 0.06605923175811768, 0.027936900034546852], [0.05250240117311478, 0.06454106420278549, 0.00886057410389185, 0.10438960045576096, 0.7697063088417053], [0.21257655322551727, 0.21257655322551727, 0.5745118856430054, 0.00026683491887524724, 6.818620022386312e-05], [0.007290693465620279, 0.001447488204576075, 0.007290693465620279, 0.2292119562625885, 0.7547591328620911], [0.03278230130672455, 0.0002830790472216904, 0.0002830790472216904, 0.39479511976242065, 0.5718564391136169], [2.9434995667543262e-05, 0.009979577735066414, 0.6861729025840759, 0.15190903842449188, 0.15190903842449188], [0.014936531893908978, 0.013266126625239849, 0.43283379077911377, 0.43283379077911377, 0.10612980276346207], [0.14096291363239288, 0.48848679661750793, 0.2277916669845581, 0.14096291363239288, 0.0017956779338419437], [7.279549754457548e-05, 0.49159514904022217, 0.0026104794815182686, 0.49159514904022217, 0.014126426540315151], [0.39425423741340637, 0.012818275019526482, 0.11765806376934052, 0.39425423741340637, 0.0810152217745781], [0.240740567445755, 0.21304038166999817, 0.07143662869930267, 0.23404183983802795, 0.240740567445755], [0.003094299230724573, 0.00600497517734766, 0.38926270604133606, 0.38926270604133606, 0.21237534284591675], [0.002572864294052124, 0.002572864294052124, 0.053147658705711365, 0.7779932618141174, 0.16371335089206696], [0.05275128781795502, 0.1746276319026947, 0.6803151369094849, 0.0395546555519104, 0.05275128781795502], [0.5366853475570679, 0.08591261506080627, 0.08591261506080627, 0.014795636758208275, 0.2766937017440796], [0.19718113541603088, 0.07666037976741791, 0.2585790753364563, 0.07666037976741791, 0.3909189999103546], [0.09861414134502411, 0.4510097801685333, 0.07895268499851227, 0.01788265071809292, 0.3535407781600952], [0.0023025257978588343, 0.4916210174560547, 0.006430048029869795, 0.008025389164686203, 0.4916210174560547], [0.7283024787902832, 0.057294368743896484, 0.10649481415748596, 0.10649481415748596, 0.0014136031968519092], [0.3023759126663208, 0.09497980028390884, 0.09497980028390884, 0.020299332216382027, 0.48736509680747986], [0.9252468347549438, 0.0029763360507786274, 0.03501032665371895, 0.001756112091243267, 0.03501032665371895], [0.003897272516041994, 0.17215535044670105, 0.005416849162429571, 0.003897272516041994, 0.814633309841156], [0.04349850118160248, 0.37634721398353577, 0.011586123146116734, 0.19222095608711243, 0.37634721398353577], [0.0022168506402522326, 0.07321927696466446, 0.0610508993268013, 0.07321927696466446, 0.7902936339378357], [0.037558723241090775, 0.02717769145965576, 0.3744053244590759, 0.3744053244590759, 0.1864529550075531], [0.7504647970199585, 0.0005085250013507903, 0.02918843738734722, 0.19064979255199432, 0.02918843738734722], [0.896635115146637, 0.009054984897375107, 0.009729897603392601, 0.04228996858000755, 0.04228996858000755], [0.006426454521715641, 0.1419987827539444, 0.1419987827539444, 0.3845962584018707, 0.3249797224998474], [0.0003567370877135545, 0.0003567370877135545, 0.7389618754386902, 0.2462790310382843, 0.01404565665870905], [0.08439525216817856, 0.03466513007879257, 0.4034999907016754, 0.4034999907016754, 0.07393962889909744], [0.02912706322968006, 0.3275166153907776, 0.03276347741484642, 0.3052964210510254, 0.3052964210510254], [0.2916392683982849, 0.2888675928115845, 0.12197140604257584, 0.2888675928115845, 0.008654102683067322], [0.015135138295590878, 0.2394409328699112, 0.44652214646339417, 0.2394409328699112, 0.05946081504225731], [0.042677734047174454, 0.030509741976857185, 0.3794337213039398, 0.3794337213039398, 0.16794510185718536], [0.0699293240904808, 0.20037074387073517, 0.1629934161901474, 0.2833532392978668, 0.2833532392978668], [0.11775314062833786, 0.10233248025178909, 0.38792818784713745, 0.00405804393813014, 0.38792818784713745], [0.010923599824309349, 0.45043331384658813, 0.1807214319705963, 0.34699806571006775, 0.010923599824309349], [0.4129005968570709, 0.024268480017781258, 0.1432052105665207, 0.006725176703184843, 0.4129005968570709], [0.9881497621536255, 0.0007756338454782963, 0.005232745781540871, 0.005232745781540871, 0.0006091184914112091], [0.007483376190066338, 0.007483376190066338, 0.2806342840194702, 0.2074560523033142, 0.4969429671764374], [0.08630414307117462, 0.08025611191987991, 0.08630414307117462, 0.35499513149261475, 0.3921404480934143], [0.010755645111203194, 0.23856200277805328, 0.04674419388175011, 0.6931824684143066, 0.010755645111203194], [0.0799747109413147, 0.11756636202335358, 0.003129314398393035, 0.003129314398393035, 0.7962002158164978], [0.0008790213614702225, 0.3151097595691681, 0.6190031170845032, 0.0641290470957756, 0.0008790213614702225], [0.102308489382267, 0.3192639648914337, 0.102308489382267, 0.4685029983520508, 0.007616082672029734], [0.5118070244789124, 0.3972867727279663, 0.029181526973843575, 0.03254321217536926, 0.029181526973843575], [0.014860492199659348, 0.47304055094718933, 0.47304055094718933, 0.03733411058783531, 0.0017242360627278686], [0.07978199422359467, 0.8317481279373169, 0.03426286205649376, 0.03426286205649376, 0.019944148138165474], [0.7359442710876465, 0.020983537659049034, 0.19270402193069458, 0.025184087455272675, 0.025184087455272675], [0.13966727256774902, 0.10332902520895004, 0.13966727256774902, 0.4865586459636688, 0.13077771663665771], [0.020800281316041946, 0.02059752307832241, 0.020800281316041946, 0.021799422800540924, 0.9160023927688599], [0.0319964624941349, 0.006453309208154678, 0.3611673414707184, 0.5683864951133728, 0.0319964624941349], [0.0269918292760849, 0.01147719006985426, 0.4400895833969116, 0.4400895833969116, 0.0813518613576889], [0.06058673560619354, 0.011527413502335548, 0.011527413502335548, 0.8842893838882446, 0.032069046050310135], [0.8147436380386353, 0.04664425924420357, 0.06175221502780914, 0.06175221502780914, 0.015107653103768826], [0.006546972319483757, 0.07117469608783722, 0.006546972319483757, 0.8812015652656555, 0.034529831260442734], [0.4167250990867615, 0.4167250990867615, 0.07389629632234573, 0.08855780214071274, 0.0040956889279186726], [0.4841998219490051, 0.002088014967739582, 0.0004641464911401272, 0.029048152267932892, 0.4841998219490051], [0.7410451769828796, 0.04477819800376892, 0.10319250822067261, 0.05549207329750061, 0.05549207329750061], [0.36701127886772156, 0.0014135463861748576, 0.11655030399560928, 0.36701127886772156, 0.14801354706287384], [0.4545688331127167, 0.12034455686807632, 0.013807456009089947, 0.0019301181891933084, 0.4093490540981293], [0.44638752937316895, 0.03209666907787323, 0.18049341440200806, 0.03209666907787323, 0.3089257776737213], [0.08306705206632614, 0.1227153018116951, 0.3550501763820648, 0.08306705206632614, 0.3561004400253296], [0.635223925113678, 0.3372429311275482, 0.013506488874554634, 0.007013346534222364, 0.007013346534222364], [0.031578268855810165, 0.031578268855810165, 0.19917070865631104, 0.1651017963886261, 0.5725709199905396], [0.313757985830307, 0.0017784186638891697, 0.1745956540107727, 0.33527225255966187, 0.1745956540107727], [0.34920641779899597, 0.024130523204803467, 0.34920641779899597, 0.2572377324104309, 0.020218918099999428], [0.0005794583703391254, 0.15504325926303864, 0.01642567664384842, 0.0005794583703391254, 0.8273720741271973], [0.16758398711681366, 0.3725230395793915, 0.02354719303548336, 0.21817292273044586, 0.21817292273044586], [0.05423054099082947, 0.14991386234760284, 0.47071805596351624, 0.16256879270076752, 0.16256879270076752], [0.1133635863661766, 0.4177466332912445, 0.18323460221290588, 0.2853885889053345, 0.0002665620995685458], [0.0026279583107680082, 0.0008800728828646243, 0.4396757185459137, 0.4396757185459137, 0.1171405240893364], [5.6613635024405085e-06, 0.007537576835602522, 0.5053291916847229, 5.6613635024405085e-06, 0.4871218800544739], [0.13034527003765106, 0.42838630080223083, 0.006712780334055424, 0.42838630080223083, 0.006169397383928299], [0.4350031614303589, 0.07648582756519318, 0.20885971188545227, 0.07079154253005981, 0.20885971188545227], [0.02190786600112915, 0.01601298712193966, 0.1712528020143509, 0.6195735931396484, 0.1712528020143509], [0.049701906740665436, 0.20294636487960815, 0.014751347713172436, 0.71784907579422, 0.014751347713172436], [0.4891834557056427, 0.016242194920778275, 0.005383358336985111, 0.4891834557056427, 7.607729003211716e-06], [0.019084684550762177, 0.28663474321365356, 0.28663474321365356, 0.40748485922813416, 0.0001609913888387382], [0.0033435754012316465, 0.08794716000556946, 0.2822112441062927, 0.6231544613838196, 0.0033435754012316465], [0.48414140939712524, 0.017310967668890953, 0.0010251272469758987, 0.013381019234657288, 0.48414140939712524], [0.09961459040641785, 0.7876782417297363, 0.004513910971581936, 0.09961459040641785, 0.008578703738749027], [0.28771913051605225, 0.32052087783813477, 0.28771913051605225, 0.09243505448102951, 0.011605806648731232], [0.6392785906791687, 0.0038411784917116165, 0.02299938164651394, 0.0038411784917116165, 0.3300396203994751], [0.028034711256623268, 0.030369563028216362, 0.45496952533721924, 0.03165670484304428, 0.45496952533721924], [0.011503406800329685, 0.028089849278330803, 0.36168283224105835, 0.5706340670585632, 0.028089849278330803], [0.004244897980242968, 0.446595162153244, 0.0983273833990097, 0.446595162153244, 0.004237316083163023], [0.049015581607818604, 0.45577478408813477, 0.049015581607818604, 0.056546106934547424, 0.3896479308605194], [0.036834899336099625, 0.004699687007814646, 0.9013422727584839, 0.05242343619465828, 0.004699687007814646], [0.009011449292302132, 0.023795580491423607, 0.7364743947982788, 0.20410208404064178, 0.02661648951470852], [0.08624973148107529, 0.3930271863937378, 0.056069497019052505, 0.07162638753652573, 0.3930271863937378], [0.6066861152648926, 0.15284110605716705, 0.14244718849658966, 0.003598160343244672, 0.09442747384309769], [0.027390187606215477, 0.0068496414460241795, 0.027390187606215477, 0.06826996058225632, 0.8701000213623047], [0.4167315661907196, 0.015415871515870094, 0.053926754742860794, 0.044995203614234924, 0.46893057227134705], [0.002127022948116064, 0.0053536673076450825, 0.4902523458003998, 0.012014588341116905, 0.4902523458003998], [0.47536444664001465, 0.09120313823223114, 0.4302947521209717, 0.0015687812119722366, 0.0015687812119722366], [0.27244335412979126, 0.22278065979480743, 0.27244335412979126, 0.08364655077457428, 0.14868612587451935], [0.284338116645813, 0.34852421283721924, 0.010860058479011059, 0.34852421283721924, 0.007753385230898857], [0.05841294676065445, 0.03500858321785927, 0.13024310767650604, 0.6460922360420227, 0.13024310767650604], [0.3272134065628052, 0.0726061537861824, 0.12467435002326965, 0.4028998911380768, 0.0726061537861824], [0.15929043292999268, 0.20559488236904144, 0.32512110471725464, 0.10439873486757278, 0.20559488236904144], [0.856472909450531, 0.03832198306918144, 0.03832198306918144, 0.06271252781152725, 0.004170609638094902], [0.061770960688591, 0.03429881110787392, 0.8547570705413818, 0.03429881110787392, 0.0148743512108922], [0.4912216067314148, 0.0004935570177622139, 0.004988372791558504, 0.012074883095920086, 0.4912216067314148], [0.4742881953716278, 0.47061464190483093, 0.0018283954123035073, 0.02663440629839897, 0.02663440629839897], [0.0049681211821734905, 0.01209032442420721, 0.9424223899841309, 0.0049681211821734905, 0.03555111214518547], [0.9396169781684875, 3.824959640041925e-05, 0.008162279613316059, 0.052144382148981094, 3.824959640041925e-05], [0.0024199876934289932, 0.656192421913147, 0.28139984607696533, 0.057567741721868515, 0.0024199876934289932], [0.7173029184341431, 0.17621353268623352, 0.06545711308717728, 0.020513251423835754, 0.020513251423835754], [0.8049901127815247, 0.01593632809817791, 0.012029978446662426, 0.15501348674297333, 0.012029978446662426], [0.19698961079120636, 0.10379994660615921, 0.46622979640960693, 0.035991087555885315, 0.19698961079120636], [0.016788780689239502, 0.2637876570224762, 0.007531406823545694, 0.2637876570224762, 0.44810453057289124], [0.8578724265098572, 0.09088155627250671, 0.028389669954776764, 0.01142813079059124, 0.01142813079059124], [0.00027705953107215464, 0.0009994582505896688, 0.006261840928345919, 0.2423076331615448, 0.7501540184020996], [0.0222338680177927, 0.19790539145469666, 0.0011159047717228532, 0.7565109729766846, 0.0222338680177927], [0.320794939994812, 0.004718554671853781, 0.320794939994812, 0.352736234664917, 0.0009553182753734291], [0.0510999858379364, 0.44230398535728455, 0.25278714299201965, 0.1269044578075409, 0.1269044578075409], [0.17469976842403412, 0.005705772899091244, 0.3484097421169281, 0.3484097421169281, 0.12277493625879288], [0.923704206943512, 0.0013329796493053436, 0.06051718071103096, 0.007222787011414766, 0.007222787011414766], [0.1033855453133583, 0.0132003678008914, 0.07287567108869553, 0.07287567108869553, 0.737662672996521], [0.46843695640563965, 0.022607112303376198, 0.46843695640563965, 0.02542230673134327, 0.01509664673358202], [0.08971536159515381, 0.8164985179901123, 0.041695643216371536, 0.041695643216371536, 0.010394854471087456], [0.1698039025068283, 0.049899954348802567, 0.049899954348802567, 0.24207893013954163, 0.4883173108100891], [0.0257120244204998, 0.34413713216781616, 0.2712932229042053, 0.2712932229042053, 0.08756434172391891], [0.548724353313446, 0.15549980103969574, 0.08620689809322357, 0.05406912416219711, 0.15549980103969574], [0.1256578117609024, 0.1928398460149765, 0.13109813630580902, 0.41930603981018066, 0.13109813630580902], [0.2511126697063446, 0.004666684661060572, 0.26758795976638794, 0.46162790060043335, 0.015004846267402172], [0.23972195386886597, 0.021776825189590454, 0.22809343039989471, 0.22809343039989471, 0.28231433033943176], [0.23490506410598755, 0.00011669452214846388, 0.23490506410598755, 0.21462684869766235, 0.31544628739356995], [0.007159223314374685, 0.19533798098564148, 0.25648343563079834, 0.19533798098564148, 0.34568139910697937], [0.129184752702713, 0.14802104234695435, 0.04630770906805992, 0.010749829933047295, 0.6657366752624512], [0.5785276889801025, 0.34863755106925964, 0.0026934274937957525, 0.0026934274937957525, 0.06744790822267532], [0.4621107280254364, 0.00265103648416698, 0.0697350800037384, 0.003392464015632868, 0.4621107280254364], [0.008561603724956512, 0.8727394938468933, 0.10934804379940033, 0.0007892642170190811, 0.008561603724956512], [0.5155349969863892, 0.002449585124850273, 0.439471960067749, 0.002449585124850273, 0.04009384661912918], [0.06966284662485123, 0.461908221244812, 0.0036833910271525383, 0.461908221244812, 0.0028372870292514563], [0.03388188034296036, 0.11110632866621017, 0.3070600926876068, 0.3070600926876068, 0.24089157581329346], [0.002047445625066757, 0.002047445625066757, 0.9719330072402954, 0.021300045773386955, 0.00267203850671649], [0.09492574632167816, 0.047089122235774994, 0.19383525848388672, 0.047089122235774994, 0.6170607805252075], [0.053717758506536484, 0.4540283977985382, 0.053717758506536484, 0.4376004636287689, 0.0009356377995572984], [0.04670625552535057, 0.3389742374420166, 0.1907162070274353, 0.08462904393672943, 0.3389742374420166], [0.4689677953720093, 0.03732086718082428, 0.0062351468950510025, 0.01850842870771885, 0.4689677953720093], [0.3558282256126404, 0.02900606207549572, 0.13566860556602478, 0.3558282256126404, 0.1236688494682312], [0.12041393667459488, 0.0076683335937559605, 0.4118506610393524, 0.4118506610393524, 0.048216406255960464], [0.3958441913127899, 0.12494734674692154, 0.07540465891361237, 0.3958441913127899, 0.007959610782563686], [0.1005343571305275, 0.03719564527273178, 0.7581306099891663, 0.003605042351409793, 0.1005343571305275], [0.1805437207221985, 0.14796186983585358, 0.5053080916404724, 0.08309316635131836, 0.08309316635131836], [0.004860579967498779, 0.03752764314413071, 0.012733875773847103, 0.9321439862251282, 0.012733875773847103], [0.028590574860572815, 0.06987173855304718, 0.028590574860572815, 0.11706293374300003, 0.7558841705322266], [0.18292967975139618, 0.6246050596237183, 0.008084789849817753, 0.18292967975139618, 0.0014508651802316308], [0.03388277813792229, 0.013957158662378788, 0.7343201637268066, 0.013957158662378788, 0.20388275384902954], [0.37938544154167175, 0.45538192987442017, 0.05815313011407852, 0.05353974178433418, 0.05353974178433418], [0.029904425144195557, 0.04095752164721489, 0.015981297940015793, 0.4565783441066742, 0.4565783441066742], [0.0025359177961945534, 0.00201658857986331, 0.9699729084968567, 0.02345805987715721, 0.00201658857986331], [0.06257195770740509, 0.2561172842979431, 0.07343209534883499, 0.2553516626358032, 0.352526992559433], [0.2538071572780609, 0.2538071572780609, 0.00579068111255765, 0.0015941353049129248, 0.485000878572464], [0.11866310238838196, 0.6825007796287537, 0.05989844352006912, 0.020274631679058075, 0.11866310238838196], [0.355669230222702, 0.2294422686100006, 0.024510115385055542, 0.3685530424118042, 0.021825270727276802], [0.02372761256992817, 0.014697382226586342, 0.8453558087348938, 0.092491514980793, 0.02372761256992817], [0.1703478842973709, 0.03908044472336769, 0.04913969710469246, 0.37071600556373596, 0.37071600556373596], [0.4099627733230591, 0.16630396246910095, 0.17100554704666138, 0.17100554704666138, 0.08172214776277542], [0.006790436804294586, 0.3712421953678131, 0.007476778235286474, 0.2432483732700348, 0.3712421953678131], [0.05337277799844742, 0.04293964058160782, 0.5630500316619873, 0.04293964058160782, 0.29769793152809143], [0.34752440452575684, 0.006769724190235138, 0.6330410838127136, 0.006769724190235138, 0.005895031616091728], [0.0704527199268341, 0.3176996111869812, 0.25088903307914734, 0.285221129655838, 0.07573746889829636], [0.12665215134620667, 0.2903546690940857, 0.31791186332702637, 0.2608698308467865, 0.0042114551179111], [0.023346178233623505, 0.5513646006584167, 0.061056140810251236, 0.3031769096851349, 0.061056140810251236], [0.1580076962709427, 0.3748188614845276, 0.002222353359684348, 0.002222353359684348, 0.4627287685871124], [0.0050116293132305145, 0.012248454615473747, 0.15065327286720276, 0.681433379650116, 0.15065327286720276], [0.01067686453461647, 0.0915844738483429, 0.7908950448036194, 0.053421784192323685, 0.053421784192323685], [0.003451570635661483, 0.003451570635661483, 0.3508974611759186, 0.0410332977771759, 0.6011660695075989], [0.12204089015722275, 0.0004845104122068733, 0.12204089015722275, 0.7535901069641113, 0.0018436486134305596], [0.76053386926651, 0.045232873409986496, 0.045232873409986496, 0.1417558342218399, 0.00724455900490284], [0.08538636565208435, 0.4294077754020691, 0.05433374270796776, 0.0014643752947449684, 0.4294077754020691], [0.37432873249053955, 0.015721147879958153, 0.5291018486022949, 0.0404241643846035, 0.0404241643846035], [0.0023528807796537876, 0.07156609743833542, 0.4217684864997864, 0.0023528807796537876, 0.5019596219062805], [0.010509396903216839, 0.047619909048080444, 0.014814718626439571, 0.8794360160827637, 0.047619909048080444], [0.4906049072742462, 0.0858549177646637, 0.04557599127292633, 0.06621728092432022, 0.31174686551094055], [0.031645022332668304, 0.2846754193305969, 0.37903690338134766, 0.0069905961863696575, 0.29765206575393677], [0.003670016536489129, 0.032301221042871475, 0.9027913212776184, 0.057567380368709564, 0.003670016536489129], [0.18679866194725037, 0.035180479288101196, 0.5702217221260071, 0.0210004560649395, 0.18679866194725037], [0.19408060610294342, 0.2506925165653229, 0.2506925165653229, 0.21263757348060608, 0.09189670532941818], [0.1139204278588295, 0.05465630441904068, 0.24113687872886658, 0.5356300473213196, 0.05465630441904068], [0.3135049045085907, 0.31252768635749817, 0.013885000720620155, 0.3135049045085907, 0.04657752066850662], [1.2985383364139125e-05, 0.3220505714416504, 0.23635326325893402, 1.2985383364139125e-05, 0.4415701925754547], [0.13226625323295593, 0.13226625323295593, 0.20500995218753815, 0.19280734658241272, 0.3376501798629761], [0.09222176671028137, 0.006553701125085354, 0.7598564028739929, 0.04914642870426178, 0.09222176671028137], [0.280830979347229, 0.004832040052860975, 0.280830979347229, 0.20593397319316864, 0.2275719791650772], [0.3464224934577942, 0.01716816984117031, 0.20420436561107635, 0.22800055146217346, 0.20420436561107635], [0.005275878589600325, 0.09662434458732605, 0.09811986237764359, 0.7018600106239319, 0.09811986237764359], [0.03558143973350525, 0.3224554657936096, 0.23260414600372314, 0.08690351992845535, 0.3224554657936096], [0.11918235570192337, 0.34065499901771545, 0.36953890323638916, 0.11918235570192337, 0.05144142732024193], [0.8218926787376404, 0.00996700581163168, 0.00996700581163168, 0.10617810487747192, 0.051995132118463516], [0.8022109270095825, 0.10178197920322418, 0.001214347081258893, 0.08407273888587952, 0.010720005258917809], [0.17933419346809387, 0.14623984694480896, 0.17933419346809387, 0.3583970367908478, 0.1366948038339615], [0.005753916222602129, 0.2913096845149994, 0.4287538230419159, 0.2691061198711395, 0.005076433066278696], [0.7161473631858826, 0.005277463234961033, 0.005277463234961033, 0.21184130012989044, 0.06145644187927246], [0.6207690834999084, 0.12391915172338486, 0.012886283919215202, 0.11850633472204208, 0.12391915172338486], [0.06296424567699432, 0.16232547163963318, 0.4140751361846924, 0.18031756579875946, 0.18031756579875946], [0.23350302875041962, 0.01171351782977581, 0.7496961951255798, 0.0025436473079025745, 0.0025436473079025745], [0.08302808552980423, 0.08302808552980423, 0.028112249448895454, 0.009290479123592377, 0.796541154384613], [0.5731838345527649, 0.13552391529083252, 0.2194860726594925, 0.03590308874845505, 0.03590308874845505], [0.0021981154568493366, 0.0023055479396134615, 0.7078389525413513, 0.038529813289642334, 0.2491275817155838], [0.0001107931966544129, 0.48369207978248596, 0.032428011298179626, 7.702458970015869e-05, 0.48369207978248596], [0.0748317688703537, 0.3858723044395447, 0.16210204362869263, 0.3023621141910553, 0.0748317688703537], [0.44209638237953186, 0.08292252570390701, 0.3277025520801544, 0.08292252570390701, 0.06435605883598328], [0.42330455780029297, 0.019323814660310745, 0.27725422382354736, 0.27725422382354736, 0.002863155445083976], [0.23113150894641876, 0.17667697370052338, 0.048513054847717285, 0.17667697370052338, 0.36700156331062317], [0.9050918817520142, 0.09146475046873093, 0.00016480250633321702, 0.003113859798759222, 0.00016480250633321702], [0.10741613805294037, 0.07179540395736694, 0.2940773367881775, 0.10741613805294037, 0.4192950129508972], [0.3410005569458008, 0.04818076267838478, 0.1704317033290863, 0.09938636422157288, 0.3410005569458008], [0.4631432890892029, 0.01083943247795105, 0.4771043062210083, 0.038073547184467316, 0.01083943247795105], [0.36645185947418213, 0.04163739085197449, 0.0007205623551271856, 0.5904695987701416, 0.0007205623551271856], [0.03590526431798935, 0.6799704432487488, 0.210840106010437, 0.03664204105734825, 0.03664204105734825], [0.15230053663253784, 0.012998996302485466, 0.054757263511419296, 0.3899715542793274, 0.3899715542793274], [0.008277812972664833, 0.09269468486309052, 0.8976466655731201, 0.0006903906469233334, 0.0006903906469233334], [0.007563520222902298, 0.08806870877742767, 0.02152552641928196, 0.8613166809082031, 0.02152552641928196], [0.5209378600120544, 9.753300219017547e-06, 0.4276413321495056, 0.020953617990016937, 0.030457405373454094], [0.4184504747390747, 0.03235135227441788, 0.08333726227283478, 0.047410476952791214, 0.4184504747390747], [0.715363621711731, 0.08031611144542694, 0.030146244913339615, 0.1440277099609375, 0.030146244913339615], [0.2840416729450226, 0.016271652653813362, 0.13341917097568512, 0.13341917097568512, 0.4328483045101166], [0.721204400062561, 0.07152578979730606, 0.012538008391857147, 0.12320604920387268, 0.07152578979730606], [0.051149848848581314, 0.004460855387151241, 0.4260789752006531, 0.09223130345344543, 0.4260789752006531], [0.2928541302680969, 0.3054690659046173, 0.22288960218429565, 0.08939360082149506, 0.08939360082149506], [0.06735367327928543, 0.0892210528254509, 0.6384052634239197, 0.1157989427447319, 0.0892210528254509], [0.14324702322483063, 0.0013908559922128916, 0.14324702322483063, 0.5116983652114868, 0.20041674375534058], [0.4517965614795685, 0.10957223922014236, 0.10419860482215881, 0.2248602956533432, 0.10957223922014236], [0.12507779896259308, 0.41709932684898376, 0.04252488911151886, 0.04252488911151886, 0.37277308106422424], [0.010463687591254711, 0.9532503485679626, 0.011913306079804897, 0.013908997178077698, 0.010463687591254711], [0.21213428676128387, 0.0020857867784798145, 0.39282527565956116, 0.0001293675013585016, 0.39282527565956116], [0.515171229839325, 0.0481586791574955, 0.4190613031387329, 0.008804382756352425, 0.008804382756352425], [0.1686602085828781, 0.12256187200546265, 0.571164071559906, 0.01505198609083891, 0.12256187200546265], [0.010627406649291515, 0.010627406649291515, 0.47003185749053955, 0.1770264059305191, 0.33168691396713257], [0.447390079498291, 0.03178159147500992, 0.447390079498291, 0.0734071210026741, 3.117111191386357e-05], [0.0481087788939476, 0.04906044900417328, 0.04906044900417328, 0.7451260685920715, 0.10864425450563431], [0.0225733183324337, 0.8308380842208862, 0.0225733183324337, 0.09928345680236816, 0.024731753394007683], [0.7115693092346191, 0.05975653603672981, 0.07746455818414688, 0.0737450048327446, 0.07746455818414688], [0.05758131295442581, 0.0006485021440312266, 0.0006485021440312266, 0.210813507437706, 0.7303081154823303], [0.033749908208847046, 0.8705770373344421, 0.033749908208847046, 0.011717396788299084, 0.05020572990179062], [1.2088163202861324e-05, 0.0017316683661192656, 0.26729950308799744, 0.26729950308799744, 0.4636572301387787], [1.098071788874222e-05, 0.0018113558180630207, 0.0102866031229496, 0.0018113558180630207, 0.986079752445221], [0.959815263748169, 0.004767161328345537, 0.025764022022485733, 0.00027908317861147225, 0.00937444344162941], [0.18795570731163025, 0.18795570731163025, 0.2554284930229187, 0.21744005382061005, 0.15122002363204956], [0.19494900107383728, 0.5263704061508179, 0.08094437420368195, 0.002787223318591714, 0.19494900107383728], [0.029566340148448944, 0.0981023833155632, 0.029566340148448944, 0.840584933757782, 0.002180013805627823], [0.07969284802675247, 0.21149170398712158, 0.3256867825984955, 0.07969284802675247, 0.3034357726573944], [0.011132195591926575, 0.47442692518234253, 0.011132195591926575, 0.03579764813184738, 0.46751105785369873], [0.06596150994300842, 0.25217941403388977, 0.00035765639040619135, 0.4293219745159149, 0.25217941403388977], [0.20092102885246277, 0.11064004898071289, 0.015468183904886246, 0.6575025320053101, 0.015468183904886246], [0.07848601788282394, 0.027493715286254883, 0.44850048422813416, 0.4180260896682739, 0.027493715286254883], [0.39688581228256226, 0.024088162928819656, 0.1373370885848999, 0.39688581228256226, 0.04480312764644623], [0.2987739145755768, 0.2987739145755768, 0.029634926468133926, 0.0003826182219199836, 0.3724346458911896], [0.050581008195877075, 0.8468277454376221, 0.0020947656594216824, 0.04991554468870163, 0.050581008195877075], [0.7506890892982483, 0.0035612068604677916, 0.0005084050935693085, 0.24473291635513306, 0.0005084050935693085], [0.044733770191669464, 0.3346794545650482, 0.02078600600361824, 0.26512131094932556, 0.3346794545650482], [0.9418994188308716, 0.001134447637014091, 0.020515253767371178, 0.035316452383995056, 0.001134447637014091], [6.95552589604631e-05, 0.45001548528671265, 6.95552589604631e-05, 0.5476977825164795, 0.0021476028487086296], [0.50021892786026, 0.17351645231246948, 0.17351645231246948, 0.1035577654838562, 0.04919039458036423], [0.04402521625161171, 0.020375467836856842, 0.3315286636352539, 0.3315286636352539, 0.27254197001457214], [0.021738437935709953, 0.2329658567905426, 0.05623809993267059, 0.6673191785812378, 0.021738437935709953], [0.4524858891963959, 0.0077306670136749744, 0.025357043370604515, 0.4524858891963959, 0.0619405172765255], [0.013834628276526928, 0.10263272374868393, 0.3373992145061493, 0.3373992145061493, 0.20873425900936127], [0.01125156320631504, 0.3445388376712799, 0.005835977382957935, 0.29383474588394165, 0.3445388376712799], [0.5553744435310364, 0.11686675250530243, 0.1573992520570755, 0.1573992520570755, 0.012960323132574558], [0.7101908326148987, 0.1137705072760582, 0.008429466746747494, 0.1137705072760582, 0.05383864790201187], [0.4758869707584381, 0.008897591382265091, 0.03430686518549919, 0.005021595861762762, 0.4758869707584381], [0.003099992638453841, 0.0006411293288692832, 0.18373827636241913, 0.8118795156478882, 0.0006411293288692832], [0.30162206292152405, 0.0282451044768095, 0.08230458945035934, 0.4565635919570923, 0.1312645971775055], [0.3801831901073456, 0.05055759847164154, 0.04930055886507034, 0.13977551460266113, 0.3801831901073456], [0.056077487766742706, 0.06035444512963295, 0.34584882855415344, 0.06035444512963295, 0.47736477851867676], [0.33265653252601624, 0.33265653252601624, 0.04699401184916496, 0.26534634828567505, 0.022346574813127518], [0.14978720247745514, 0.006803632248193026, 0.5739108920097351, 0.14978720247745514, 0.1197110116481781], [0.31496724486351013, 0.07361753284931183, 0.195150688290596, 0.22111381590366364, 0.195150688290596], [0.4258485436439514, 0.4258485436439514, 0.0013730900827795267, 0.1083957627415657, 0.038534015417099], [0.04769207909703255, 0.11622779071331024, 0.008386594243347645, 0.31155118346214294, 0.5161423683166504], [0.277351051568985, 0.3570620119571686, 0.08022843301296234, 0.007951751351356506, 0.2774067521095276], [0.08143190294504166, 0.06080673262476921, 0.33225563168525696, 0.08143190294504166, 0.4440738260746002], [0.34267017245292664, 0.34267017245292664, 0.02168424427509308, 0.256700724363327, 0.036274682730436325], [0.03446948528289795, 0.8194220066070557, 0.0005363409291021526, 0.0005363409291021526, 0.1450357884168625], [0.12229614704847336, 0.12876150012016296, 0.11153875291347504, 0.11153875291347504, 0.5258647799491882], [0.02466154657304287, 0.004822747781872749, 0.32854393124580383, 0.6173102259635925, 0.02466154657304287], [0.04332609474658966, 0.056695789098739624, 0.3936787545681, 0.056695789098739624, 0.4496035575866699], [0.26108333468437195, 0.07457331568002701, 0.3606862723827362, 0.26108333468437195, 0.04257375746965408], [0.04463551938533783, 0.10992050915956497, 0.5558545589447021, 0.1223401203751564, 0.16724926233291626], [0.0038933181203901768, 0.035362374037504196, 0.012733392417430878, 0.47400549054145813, 0.47400549054145813], [0.01878643035888672, 0.011479398235678673, 0.010716223157942295, 0.9483017325401306, 0.010716223157942295], [0.19837291538715363, 0.005122273229062557, 0.19837291538715363, 0.23372882604599, 0.3644030690193176], [0.5714721083641052, 0.19441920518875122, 0.19441920518875122, 0.013599430210888386, 0.02609005570411682], [0.03796711191534996, 0.3559386730194092, 0.17415238916873932, 0.2577894628047943, 0.17415238916873932], [0.2067095935344696, 0.059331655502319336, 0.2099028378725052, 0.2067095935344696, 0.3173462748527527], [0.1370227038860321, 0.32950305938720703, 0.012055783532559872, 0.2607092261314392, 0.2607092261314392], [0.02001051977276802, 0.002770606428384781, 0.48832038044929504, 0.0005780260544270277, 0.48832038044929504], [0.27248430252075195, 0.2946765124797821, 0.1350257396697998, 0.0031369507778435946, 0.2946765124797821], [0.32660016417503357, 0.18408474326133728, 0.32660016417503357, 0.13336727023124695, 0.02934761717915535], [0.1305617094039917, 0.2831100821495056, 0.1674099713563919, 0.13580824434757233, 0.2831100821495056], [0.17663386464118958, 0.7575147151947021, 0.017617885023355484, 0.03061564266681671, 0.017617885023355484], [0.023108959197998047, 0.19008387625217438, 0.759023904800415, 0.023108959197998047, 0.0046743107959628105], [0.004489866551011801, 0.46567654609680176, 0.018829936161637306, 0.46567654609680176, 0.04532710835337639], [0.43663641810417175, 0.02133338898420334, 0.22862300276756287, 0.15670356154441833, 0.15670356154441833], [0.41374948620796204, 0.07168072462081909, 0.037620510905981064, 0.06319975852966309, 0.41374948620796204], [0.8690807223320007, 0.0377206951379776, 0.0377206951379776, 0.02808985859155655, 0.02738790586590767], [0.3506968915462494, 0.3506968915462494, 0.020902413874864578, 0.10490571707487106, 0.17279814183712006], [0.07382810115814209, 0.017549287527799606, 0.5763192772865295, 0.31475409865379333, 0.017549287527799606], [0.6720676422119141, 0.09265969693660736, 0.13046422600746155, 0.09265969693660736, 0.012148706242442131], [0.02319893054664135, 0.9469013810157776, 0.005683710798621178, 0.01853225938975811, 0.005683710798621178], [0.4114370346069336, 0.010271616280078888, 0.028676070272922516, 0.5209392309188843, 0.028676070272922516], [0.027046648785471916, 0.20646394789218903, 0.15093936026096344, 0.1447231024503708, 0.47082701325416565], [0.13061422109603882, 0.41823554039001465, 0.016874179244041443, 0.016040494665503502, 0.41823554039001465], [0.0015046432381495833, 4.232664650771767e-05, 0.5096024870872498, 0.0015046432381495833, 0.4873458445072174], [0.03998799994587898, 0.7866252064704895, 0.13293685019016266, 0.020224981009960175, 0.020224981009960175], [0.43301481008529663, 0.1720278114080429, 0.1870436817407608, 0.0208700243383646, 0.1870436817407608], [0.01058322936296463, 0.0016518846387043595, 0.016568217426538467, 0.4855983257293701, 0.4855983257293701], [0.49592751264572144, 0.09893587976694107, 0.0023803033400326967, 0.20137812197208405, 0.20137812197208405], [0.06524599343538284, 0.21369053423404694, 0.06524599343538284, 0.6395198702812195, 0.0162975937128067], [0.17132991552352905, 0.4487929046154022, 0.0031055386643856764, 0.18838584423065186, 0.18838584423065186], [0.053369827568531036, 0.45783326029777527, 0.001524873310700059, 0.02943878248333931, 0.45783326029777527], [0.2011944055557251, 0.0492679737508297, 0.6725261211395264, 0.038505762815475464, 0.038505762815475464], [0.006064200308173895, 0.3494844436645508, 0.024296129122376442, 0.005546252708882093, 0.6146090030670166], [0.07359324395656586, 0.4483785331249237, 0.009841122664511204, 0.07359324395656586, 0.3945937752723694], [0.3640221953392029, 0.03898444026708603, 0.11702094227075577, 0.3640221953392029, 0.11595029383897781], [0.2744811773300171, 0.2744811773300171, 0.16858826577663422, 0.19679178297519684, 0.08565761893987656], [0.08394718170166016, 0.061812400817871094, 0.42698317766189575, 0.42698317766189575, 0.00027406378649175167], [0.6646194458007812, 0.01643095165491104, 0.1569584161043167, 0.005032676737755537, 0.1569584161043167], [0.14222024381160736, 0.05404363200068474, 0.015319431200623512, 0.6461964249610901, 0.14222024381160736], [0.3113231062889099, 0.0025758419651538134, 0.3177369236946106, 0.3113231062889099, 0.057040974497795105], [0.00027436940581537783, 0.7520842552185059, 0.24582383036613464, 0.0015431432984769344, 0.00027436940581537783], [0.3875386714935303, 0.02514633908867836, 0.3875386714935303, 0.0014084058348089457, 0.1983678638935089], [0.07842012494802475, 0.13374631106853485, 0.3859657049179077, 0.015902217477560043, 0.3859657049179077], [0.08758264034986496, 0.017687341198325157, 0.754954993724823, 0.06988751143217087, 0.06988751143217087], [0.00862914603203535, 0.4533560872077942, 0.08175740391016006, 0.0029013222083449364, 0.4533560872077942], [0.04461396485567093, 0.019556324928998947, 0.25575312972068787, 0.04461396485567093, 0.6354625225067139], [0.35722002387046814, 0.2518160045146942, 0.01688924990594387, 0.357185423374176, 0.01688924990594387], [0.07711241394281387, 0.2833613157272339, 0.2632724642753601, 0.2632724642753601, 0.11298128962516785], [0.007258731406182051, 0.007258731406182051, 0.28287988901138306, 0.026100849732756615, 0.6765018105506897], [0.0009419633424840868, 0.5269674062728882, 0.2043161541223526, 0.06345825642347336, 0.2043161541223526], [0.0245176050812006, 0.8947873115539551, 0.0245176050812006, 0.05045904964208603, 0.005718422122299671], [0.05135747790336609, 0.017983173951506615, 0.021014565601944923, 0.05135747790336609, 0.8582872748374939], [0.14894463121891022, 0.04328601434826851, 0.014924619346857071, 0.11800257116556168, 0.6748421788215637], [0.17967557907104492, 0.0003826014290098101, 0.8143231868743896, 0.0003826014290098101, 0.005235966760665178], [0.046721380203962326, 0.046721380203962326, 0.00790798757225275, 0.08903387188911438, 0.8096153736114502], [0.44316038489341736, 0.02867497131228447, 0.4293266534805298, 0.02867497131228447, 0.0701630637049675], [0.27216196060180664, 1.9668423192342743e-05, 0.2689777612686157, 0.27216196060180664, 0.18667863309383392], [0.005181760992854834, 0.06325484812259674, 0.005181760992854834, 0.917026162147522, 0.009355525486171246], [0.011607828550040722, 0.38421398401260376, 0.026722978800535202, 0.026722978800535202, 0.5507322549819946], [0.4433991312980652, 0.09948519617319107, 0.013376561924815178, 0.4433991312980652, 0.00033990948577411473], [0.4884386658668518, 0.0037856826093047857, 0.4884386658668518, 0.0010832056868821383, 0.018253764137625694], [0.000226913281949237, 0.16873614490032196, 0.16873614490032196, 0.0353836789727211, 0.6269171833992004], [0.4962936341762543, 0.009158127009868622, 0.1643991470336914, 0.1643991470336914, 0.16575001180171967], [0.1548878699541092, 0.35807663202285767, 0.23511002957820892, 0.01681545190513134, 0.23511002957820892], [0.10585248470306396, 0.8712999224662781, 0.010551339015364647, 0.010551339015364647, 0.0017449079314246774], [0.02065804973244667, 0.05418529361486435, 0.8859383463859558, 0.02065804973244667, 0.018560294061899185], [0.0222726259380579, 0.7579364776611328, 0.0997471734881401, 0.020296519622206688, 0.0997471734881401], [0.4200991988182068, 0.2358475923538208, 0.3364209532737732, 0.003816128708422184, 0.003816128708422184], [0.017490213736891747, 0.3508397042751312, 0.008103372529149055, 0.27272701263427734, 0.3508397042751312], [0.03116823546588421, 0.03968645632266998, 0.03116823546588421, 0.8373790383338928, 0.06059795990586281], [0.013304624706506729, 0.09041336923837662, 0.013377705588936806, 0.013377705588936806, 0.8695265650749207], [0.12007347494363785, 0.531895637512207, 0.03313073515892029, 0.12007347494363785, 0.19482667744159698], [0.18041685223579407, 0.04690093919634819, 0.18041685223579407, 0.5896782875061035, 0.0025870732497423887], [0.06696824729442596, 0.3948991000652313, 0.02333000861108303, 0.11990348249673843, 0.3948991000652313], [0.0017866060370579362, 0.21596074104309082, 0.24084191024303436, 0.2707054018974304, 0.2707054018974304], [0.01408184040337801, 0.02928273193538189, 0.23182453215122223, 0.02928273193538189, 0.6955281496047974], [0.006663988344371319, 0.5995825529098511, 0.05731160566210747, 0.32977786660194397, 0.006663988344371319], [0.5899352431297302, 0.34200701117515564, 0.0050257733091712, 0.05800623819231987, 0.0050257733091712], [0.4722803235054016, 0.031589433550834656, 0.031589433550834656, 0.07693814486265182, 0.38760271668434143], [0.009349600411951542, 0.009349600411951542, 0.055705878883600235, 0.12225103378295898, 0.8033438324928284], [0.3423130214214325, 0.33110520243644714, 0.013318338431417942, 0.013318338431417942, 0.29994502663612366], [0.4915577471256256, 0.0183925349265337, 0.4423326849937439, 0.023858536034822464, 0.023858536034822464], [0.429985910654068, 0.12298854440450668, 0.01959937997162342, 0.12298854440450668, 0.3044375479221344], [0.18113386631011963, 0.1654442548751831, 0.4327874183654785, 0.03950061649084091, 0.18113386631011963], [0.008286763913929462, 0.5528503656387329, 0.021646661683917046, 0.028257885947823524, 0.38895824551582336], [0.060453642159700394, 0.11724559217691422, 0.28944841027259827, 0.297931969165802, 0.23492039740085602], [0.19400161504745483, 0.07640630751848221, 0.642447292804718, 0.07640630751848221, 0.010738394223153591], [0.012953582219779491, 0.012953582219779491, 0.9113718271255493, 0.058918897062540054, 0.003802185645326972], [0.3888688087463379, 0.1342039704322815, 0.018931612372398376, 0.018931612372398376, 0.43906402587890625], [0.14207348227500916, 0.006338725332170725, 0.4114331305027008, 0.028721611946821213, 0.4114331305027008], [0.051985446363687515, 0.051985446363687515, 0.6835744380950928, 0.07113426178693771, 0.14132042229175568], [0.26857033371925354, 0.03014298528432846, 0.03014298528432846, 0.0008867018623277545, 0.670257031917572], [0.21408849954605103, 0.21408849954605103, 0.29015517234802246, 0.07368171960115433, 0.20798610150814056], [0.8218055963516235, 0.06877686828374863, 0.06877686828374863, 0.014863034710288048, 0.025777650997042656], [0.04588274657726288, 0.04588274657726288, 0.020894763991236687, 0.47660031914711, 0.4107394814491272], [0.638433575630188, 0.0025803472381085157, 0.17370375990867615, 0.011578584089875221, 0.17370375990867615], [0.0009303911356255412, 0.631268322467804, 0.0005173815879970789, 0.3070337176322937, 0.06025019288063049], [0.30244603753089905, 0.07655104249715805, 0.30244603753089905, 0.31585556268692017, 0.0027012419886887074], [0.005025592166930437, 0.01716036908328533, 0.7438912987709045, 0.2288970649242401, 0.005025592166930437], [0.6164878606796265, 0.31428706645965576, 0.004171305801719427, 0.004171305801719427, 0.060882434248924255], [0.045910730957984924, 0.13989375531673431, 0.045910730957984924, 0.6405850052833557, 0.12769976258277893], [0.2286180704832077, 0.2866284251213074, 0.004527413751929998, 0.0802050307393074, 0.4000209867954254], [0.03475287929177284, 0.0707772746682167, 0.010453358292579651, 0.8735631704330444, 0.010453358292579651], [0.7067173719406128, 0.009298067539930344, 0.070108562707901, 0.070108562707901, 0.14376750588417053], [0.5341639518737793, 0.1265813410282135, 0.0006089003290981054, 0.00505042402073741, 0.3335953950881958], [0.08962658047676086, 0.009351314045488834, 0.5057073831558228, 0.38596341013908386, 0.009351314045488834], [0.01791306771337986, 0.0007218947284854949, 0.0016883722273632884, 0.5070169568061829, 0.47265973687171936], [0.06626816838979721, 0.2289697229862213, 0.2289697229862213, 0.012522293254733086, 0.4632701277732849], [0.0422842912375927, 0.19457116723060608, 0.0003588239778764546, 0.38139286637306213, 0.38139286637306213], [0.030629552900791168, 0.002292777644470334, 0.002292777644470334, 0.37070992588996887, 0.5940749645233154], [0.14299479126930237, 0.07583526521921158, 0.05600374564528465, 0.05600374564528465, 0.669162392616272], [0.3873046040534973, 0.2679131329059601, 0.0730578824877739, 0.003811267204582691, 0.2679131329059601], [0.4484178423881531, 0.0200504083186388, 0.02892248146235943, 0.05419145151972771, 0.4484178423881531], [0.035625189542770386, 0.08455175906419754, 0.02495509199798107, 0.4274340271949768, 0.4274340271949768], [0.017266839742660522, 0.1321699172258377, 0.41416218876838684, 0.0222388356924057, 0.41416218876838684], [0.2077510505914688, 0.005948976147919893, 0.25533539056777954, 0.2077510505914688, 0.32321345806121826], [0.16874174773693085, 0.01889202371239662, 0.16874174773693085, 0.4843997359275818, 0.15922467410564423], [0.038218460977077484, 0.006635763216763735, 0.8229468464851379, 0.038218460977077484, 0.09398052096366882], [0.2530975341796875, 0.007197067607194185, 0.005564837250858545, 0.005564837250858545, 0.7285757064819336], [0.14734740555286407, 0.27859917283058167, 0.27859917283058167, 0.25022339820861816, 0.04523088037967682], [0.8041555285453796, 0.0524873211979866, 0.004265118855983019, 0.0007957032648846507, 0.13829629123210907], [0.0022250106558203697, 0.0022250106558203697, 0.11390989273786545, 0.0017675379058346152, 0.8798724412918091], [0.2694323658943176, 0.03464949503540993, 0.03464949503540993, 0.3338537812232971, 0.3274148106575012], [0.16179955005645752, 0.009288320317864418, 0.797637939453125, 0.009288320317864418, 0.021985938772559166], [0.050804588943719864, 0.6717690229415894, 0.13833679258823395, 0.13833679258823395, 0.0007528400747105479], [0.36749711632728577, 0.03939301520586014, 0.22552500665187836, 8.774436719249934e-05, 0.36749711632728577], [0.3239150941371918, 0.23809534311294556, 0.3239150941371918, 0.039341047406196594, 0.0747334286570549], [0.06337521970272064, 0.07057599723339081, 0.7850977778434753, 0.010375008918344975, 0.07057599723339081], [0.4451664984226227, 0.4451664984226227, 0.020475495606660843, 0.0474286749958992, 0.04176287725567818], [0.04918434098362923, 0.014052899554371834, 0.3427060544490814, 0.2513507008552551, 0.3427060544490814], [0.8231452107429504, 0.0002080178092001006, 0.008893088437616825, 0.008893088437616825, 0.15886054933071136], [0.09620120376348495, 0.1844213455915451, 0.0036965275648981333, 0.711984395980835, 0.0036965275648981333], [0.5463743805885315, 0.03301481902599335, 0.2993875741958618, 0.08820844441652298, 0.03301481902599335], [0.06522006541490555, 0.020440610125660896, 0.06522006541490555, 0.07090810686349869, 0.7782110571861267], [0.9072774052619934, 0.000850810669362545, 0.027897387742996216, 0.000850810669362545, 0.06312359869480133], [0.16528309881687164, 0.3977721333503723, 0.015310917049646378, 0.3977721333503723, 0.02386169508099556], [0.036819085478782654, 0.036819085478782654, 0.2878230810165405, 0.3094150722026825, 0.32912367582321167], [0.0032089813612401485, 0.0014257936272770166, 0.4835819900035858, 0.4835819900035858, 0.02820124290883541], [0.12966176867485046, 0.45885756611824036, 0.16605211794376373, 0.10844233632087708, 0.13698618113994598], [0.021058762446045876, 0.021058762446045876, 0.02401258796453476, 0.648978590965271, 0.2848912179470062], [0.18551358580589294, 0.015092367306351662, 0.18551358580589294, 5.617028728011064e-05, 0.6138243079185486], [0.0028475814033299685, 5.214186330704251e-06, 0.14191728830337524, 0.7133126258850098, 0.14191728830337524], [0.002672166796401143, 0.03465593233704567, 0.11277623474597931, 0.3129541277885437, 0.5369415879249573], [0.07272758334875107, 0.18670512735843658, 0.07272758334875107, 0.6636193990707397, 0.004220245406031609], [0.12170650064945221, 0.030005376785993576, 0.12170650064945221, 0.0008268503006547689, 0.7257547378540039], [0.002047449816018343, 0.05814095586538315, 0.8942314386367798, 0.002047449816018343, 0.04353267699480057], [0.004308417439460754, 0.02535991556942463, 0.17193131148815155, 0.7730404138565063, 0.02535991556942463], [0.8334189057350159, 0.0001305842015426606, 0.0001305842015426606, 0.11053472757339478, 0.055785275995731354], [0.01742483302950859, 0.30720916390419006, 0.614899754524231, 0.01742483302950859, 0.04304145276546478], [0.007309284061193466, 0.41338130831718445, 0.012593231163918972, 0.012593231163918972, 0.5541229248046875], [0.035021163523197174, 0.0008260518661700189, 0.009692022576928139, 0.0007344268960878253, 0.9537263512611389], [0.2643583118915558, 0.20216374099254608, 0.20216374099254608, 0.30271223187446594, 0.028601935133337975], [0.0843188613653183, 0.020334094762802124, 0.4221484363079071, 0.4221484363079071, 0.0510500967502594], [0.34560057520866394, 0.0006248377030715346, 0.023102134466171265, 0.0013893601717427373, 0.6292831301689148], [0.00980627816170454, 0.8214554190635681, 0.00980627816170454, 0.023145997896790504, 0.13578610122203827], [0.20156899094581604, 0.026232648640871048, 0.20156899094581604, 0.44989514350891113, 0.12073424458503723], [0.0444505549967289, 0.5444994568824768, 0.006966871675103903, 0.0444505549967289, 0.35963255167007446], [0.6540248990058899, 0.0006711395108141005, 0.3396051526069641, 0.005027611739933491, 0.0006711395108141005], [0.07384683191776276, 0.23742860555648804, 0.0007831876282580197, 0.6871582269668579, 0.0007831876282580197], [0.0015291905729100108, 0.14579670131206512, 0.28709498047828674, 0.5640499591827393, 0.0015291905729100108], [0.07490827888250351, 0.3044300377368927, 0.07490827888250351, 0.017669327557086945, 0.5280840396881104], [0.45814958214759827, 0.044195760041475296, 0.07261090725660324, 0.044195760041475296, 0.3808479309082031], [0.09784731268882751, 0.09784731268882751, 0.03831276297569275, 0.061413176357746124, 0.7045794725418091], [0.10293000936508179, 0.5026918649673462, 0.10293000936508179, 0.1780940592288971, 0.11335407197475433], [0.7195425033569336, 0.13794249296188354, 0.13499009609222412, 0.003762412117794156, 0.003762412117794156], [0.009569652378559113, 0.00735259335488081, 0.5062320828437805, 0.23842282593250275, 0.23842282593250275], [0.4672088027000427, 0.0024208994582295418, 0.027246668934822083, 0.0359148345887661, 0.4672088027000427], [0.7344658970832825, 0.038621168583631516, 0.03868914395570755, 0.03868914395570755, 0.149534672498703], [0.010403257794678211, 0.01802881620824337, 0.9360964298248291, 0.01802881620824337, 0.01744273491203785], [0.15082183480262756, 0.019914377480745316, 0.4720141887664795, 0.17862482368946075, 0.17862482368946075], [0.00733685540035367, 0.029799286276102066, 0.00733685540035367, 0.5093836784362793, 0.44614335894584656], [0.0010856972075998783, 0.0010856972075998783, 0.7660186886787415, 0.1334524154663086, 0.09835749864578247], [0.27882203459739685, 0.0012264493852853775, 0.00609670951962471, 0.7126283645629883, 0.0012264493852853775], [0.003245393745601177, 0.49375948309898376, 0.005145874340087175, 0.49375948309898376, 0.00408979831263423], [0.0696595087647438, 0.0696595087647438, 0.03755727782845497, 0.263963907957077, 0.5591598153114319], [0.050171758979558945, 0.19818603992462158, 0.050171758979558945, 0.6673477292060852, 0.03412280231714249], [0.02987787500023842, 0.17284263670444489, 0.02293931506574154, 0.751400887966156, 0.02293931506574154], [0.68095862865448, 0.23021608591079712, 0.012935858219861984, 0.03794467821717262, 0.03794467821717262], [0.001183204585686326, 0.6398107409477234, 0.16988494992256165, 0.18905700743198395, 6.410811329260468e-05], [0.0011214384576305747, 0.0827016606926918, 0.004044209141284227, 0.0827016606926918, 0.8294309973716736], [0.8489215970039368, 0.000933000526856631, 0.01706373132765293, 0.13214871287345886, 0.000933000526856631], [0.052648916840553284, 0.0017217656131833792, 0.0982595756649971, 0.0982595756649971, 0.7491101622581482], [0.0030401970725506544, 0.017907273024320602, 0.12618295848369598, 0.017907273024320602, 0.8349622488021851], [0.03332097455859184, 0.3285229802131653, 0.06359394639730453, 0.3285229802131653, 0.24603909254074097], [0.3713661730289459, 0.23703621327877045, 0.3713661730289459, 0.015949910506606102, 0.004281440284103155], [0.4501866102218628, 0.001374797080643475, 0.4501866102218628, 0.0436628982424736, 0.05458908528089523], [0.1086709126830101, 0.8227684497833252, 0.0015356229851022363, 0.0015356229851022363, 0.06548932939767838], [0.37121662497520447, 0.03160383924841881, 0.21057680249214172, 0.01538606733083725, 0.37121662497520447], [0.3121679425239563, 0.000820925401058048, 0.5544849634170532, 0.000820925401058048, 0.13170523941516876], [0.15675364434719086, 0.2252822369337082, 0.0889161005616188, 0.0889161005616188, 0.44013190269470215], [0.35689887404441833, 0.5167768001556396, 0.1056724563241005, 0.010325952433049679, 0.010325952433049679], [0.07290132343769073, 0.010292296297848225, 0.007649789564311504, 0.45457831025123596, 0.45457831025123596], [0.10637900978326797, 0.22028619050979614, 0.04036308452486992, 0.31648585200309753, 0.31648585200309753], [0.020845552906394005, 0.042016688734292984, 0.4051022231578827, 0.020845552906394005, 0.5111899971961975], [0.24187558889389038, 0.11268297582864761, 0.180712029337883, 0.11268297582864761, 0.352046400308609], [0.4362404942512512, 0.10350385308265686, 0.17752937972545624, 0.17752937972545624, 0.10519697517156601], [0.1584029346704483, 0.07952048629522324, 0.34105604887008667, 0.2626176178455353, 0.1584029346704483], [0.03533239662647247, 0.028595425188541412, 0.028595425188541412, 0.900090754032135, 0.007386030163615942], [0.06042695418000221, 0.0071631139144301414, 0.8428773880004883, 0.0071631139144301414, 0.08236938714981079], [0.38947394490242004, 0.001209027017466724, 0.029826881363987923, 0.1900162249803543, 0.38947394490242004], [0.8423986434936523, 0.027271553874015808, 0.12448674440383911, 0.002921591280028224, 0.002921591280028224], [0.11695476621389389, 0.061681926250457764, 0.061681926250457764, 0.735435426235199, 0.024245936423540115], [0.07363681495189667, 0.3609267771244049, 0.3609267771244049, 0.053435444831848145, 0.1510741263628006], [0.0006376127130351961, 0.7460490465164185, 0.11337234079837799, 0.11337234079837799, 0.02656863071024418], [0.21862776577472687, 0.5456346869468689, 0.10585799813270569, 0.024021530523896217, 0.10585799813270569], [0.06046469509601593, 0.12529073655605316, 0.06046469509601593, 0.6996080875396729, 0.054171785712242126], [0.328209787607193, 0.10066050291061401, 0.24267904460430145, 0.328209787607193, 0.00024081781157292426], [0.17950163781642914, 0.47555011510849, 0.17950163781642914, 0.16514751315116882, 0.00029907122370786965], [0.011456402949988842, 0.011456402949988842, 0.32838112115859985, 0.12119955569505692, 0.5275064706802368], [0.24823744595050812, 0.12268989533185959, 0.042114466428756714, 0.33872076869010925, 0.24823744595050812], [0.06356360018253326, 0.15444444119930267, 0.010970620438456535, 0.15444444119930267, 0.6165768504142761], [0.31524592638015747, 0.007439924869686365, 0.17964106798171997, 0.24883651733398438, 0.24883651733398438], [0.43905553221702576, 0.05634443834424019, 0.01857875846326351, 0.42967689037323, 0.05634443834424019], [0.319460928440094, 0.010538757778704166, 0.319460928440094, 0.15000350773334503, 0.20053596794605255], [0.12240671366453171, 0.05910365283489227, 0.33340996503829956, 0.15166974067687988, 0.33340996503829956], [0.6073964834213257, 0.09864424169063568, 0.24348311126232147, 0.025238066911697388, 0.025238066911697388], [0.029248224571347237, 0.3832061290740967, 0.029248224571347237, 0.26211822032928467, 0.29617923498153687], [0.23089061677455902, 0.28653693199157715, 0.23089061677455902, 0.21479779481887817, 0.036884039640426636], [0.9130010604858398, 5.595361290033907e-05, 5.595361290033907e-05, 0.03397318348288536, 0.05291382968425751], [0.25765517354011536, 0.0012761763064190745, 0.06064441055059433, 0.6791480779647827, 0.0012761763064190745], [0.19436883926391602, 0.007978755980730057, 0.19436883926391602, 0.002990584122017026, 0.600292980670929], [0.3778861165046692, 0.025920525193214417, 0.3778861165046692, 0.21303987503051758, 0.005267299711704254], [0.12765511870384216, 0.4547753632068634, 0.20364990830421448, 0.20364990830421448, 0.01026969589293003], [0.0012965062633156776, 0.45812976360321045, 0.08149924874305725, 0.45812976360321045, 0.0009447507909499109], [0.004749742336571217, 0.09734074771404266, 0.004749742336571217, 0.8665016889572144, 0.026658114045858383], [0.40752583742141724, 0.20774196088314056, 0.028548479080200195, 0.14844177663326263, 0.20774196088314056], [0.057169266045093536, 0.02108146995306015, 0.057169266045093536, 0.6217171549797058, 0.24286282062530518], [0.3817512094974518, 0.18823261559009552, 0.008966690860688686, 0.03929830342531204, 0.3817512094974518], [0.7103310823440552, 0.05070817098021507, 0.05070817098021507, 0.03331418335437775, 0.15493831038475037], [0.3027484714984894, 0.020605631172657013, 0.37349221110343933, 0.3027484714984894, 0.0004052491276524961], [0.16889439523220062, 0.02235727570950985, 0.15083442628383636, 0.3289569616317749, 0.3289569616317749], [0.09040500968694687, 0.16252928972244263, 0.02353552170097828, 0.3617651164531708, 0.3617651164531708], [0.00023461913224309683, 0.9782872796058655, 0.0016020584153011441, 0.01964135654270649, 0.00023461913224309683], [0.4689802825450897, 0.042303673923015594, 0.18689070641994476, 0.18689070641994476, 0.11493464559316635], [0.01669316552579403, 0.033629126846790314, 0.9070398807525635, 0.033629126846790314, 0.00900860596448183], [0.009756071493029594, 0.004918060731142759, 0.32778629660606384, 0.32778629660606384, 0.3297532796859741], [0.00019125090329907835, 0.22777202725410461, 0.25954771041870117, 0.00019125090329907835, 0.5122977495193481], [0.02564021572470665, 0.21331247687339783, 0.26703643798828125, 0.26703643798828125, 0.22697444260120392], [0.04292815551161766, 0.7903109192848206, 0.0889892503619194, 0.038885850459337234, 0.038885850459337234], [0.7150954604148865, 0.004567418713122606, 0.2332913726568222, 0.004567418713122606, 0.042478229850530624], [0.0030474651139229536, 0.025897249579429626, 0.6530646085739136, 0.3149432837963104, 0.0030474651139229536], [0.020359458401799202, 0.3916933834552765, 0.052539028227329254, 0.3916933834552765, 0.14371472597122192], [0.7099019885063171, 0.008436450734734535, 0.14071598649024963, 0.14071598649024963, 0.00022968293342273682], [0.0008652714313939214, 0.43335428833961487, 0.0008652714313939214, 0.2171909064054489, 0.3477242887020111], [0.032006122171878815, 0.14315545558929443, 0.7220644354820251, 0.0513869933784008, 0.0513869933784008], [0.0016562675591558218, 0.1165938675403595, 0.3822699189186096, 0.1165938675403595, 0.38288614153862], [0.27697956562042236, 0.16408401727676392, 0.04479130357503891, 0.23716554045677185, 0.27697956562042236], [0.025343909859657288, 0.004138903226703405, 0.4153692424297333, 0.1397787183523178, 0.4153692424297333], [0.7797486782073975, 0.03974878787994385, 0.00661917170509696, 0.13413459062576294, 0.03974878787994385], [0.39839842915534973, 0.13608933985233307, 0.013289264403283596, 0.053824532777071, 0.39839842915534973], [0.542549192905426, 0.25405436754226685, 0.14938463270664215, 0.005350788589566946, 0.04866104945540428], [0.06378480046987534, 0.4422355592250824, 0.008140704594552517, 0.008140704594552517, 0.4776982069015503], [0.4700566828250885, 0.00041197193786501884, 0.0003027956699952483, 0.059171855449676514, 0.4700566828250885], [0.18294048309326172, 0.04288699850440025, 0.0070149339735507965, 0.0070149339735507965, 0.7601426839828491], [0.08420524001121521, 0.07249867916107178, 0.2006838172674179, 0.5921579003334045, 0.050454381853342056], [0.04322145879268646, 0.4244416654109955, 0.0037762215360999107, 0.4244416654109955, 0.10411901772022247], [0.3079652190208435, 0.004129264038056135, 0.015799645334482193, 0.3079652190208435, 0.36414065957069397], [0.04478175565600395, 0.9321936964988708, 0.015341496095061302, 0.0038415512535721064, 0.0038415512535721064], [0.3035735785961151, 0.31584981083869934, 0.3035735785961151, 0.05510299280285835, 0.021900039166212082], [0.26029983162879944, 0.2337459772825241, 0.2337459772825241, 0.18913795053958893, 0.08307027816772461], [0.0020417331252247095, 0.15046405792236328, 0.8432607054710388, 0.0021917386911809444, 0.0020417331252247095], [3.4090484405169263e-05, 0.002386279869824648, 0.8737182021141052, 3.4090484405169263e-05, 0.12382728606462479], [0.00046611452125944197, 0.00247831828892231, 0.97944176197052, 0.00247831828892231, 0.015135489404201508], [0.10125932097434998, 0.09373021870851517, 0.25177571177482605, 0.30145904421806335, 0.25177571177482605], [0.35156869888305664, 0.06896667927503586, 0.0019612452015280724, 0.35156869888305664, 0.2259347140789032], [0.6153824329376221, 0.1799817532300949, 0.017496298998594284, 0.1799817532300949, 0.007157846353948116], [5.633261025650427e-05, 0.2122153639793396, 0.004213063046336174, 0.7834588885307312, 5.633261025650427e-05], [0.19205112755298615, 0.005606306716799736, 0.7935602068901062, 0.0031760784331709146, 0.005606306716799736], [0.001140569569543004, 0.021618401631712914, 0.001140569569543004, 0.44902437925338745, 0.527076005935669], [0.11224043369293213, 0.10068861395120621, 0.0075454688630998135, 0.10068861395120621, 0.6788368225097656], [0.6449570059776306, 0.01708105579018593, 0.16869375109672546, 0.0005744350492022932, 0.16869375109672546], [0.01275467686355114, 0.09926475584506989, 0.09926475584506989, 0.07158803939819336, 0.717127799987793], [0.35521742701530457, 0.3221248388290405, 0.00029801667551510036, 0.00023490226885769516, 0.3221248388290405], [0.21865564584732056, 0.21865564584732056, 0.14197957515716553, 0.13535965979099274, 0.28534945845603943], [0.018036846071481705, 0.13175208866596222, 0.14036916196346283, 0.018036846071481705, 0.6918050646781921], [0.1152096539735794, 0.5585948824882507, 0.2525422275066376, 0.0453558973968029, 0.028297308832406998], [0.9593124389648438, 0.010708089917898178, 0.005145685281604528, 0.010708089917898178, 0.014125603251159191], [0.00022267841268330812, 0.7805708646774292, 0.13679593801498413, 0.00022267841268330812, 0.08218780905008316], [0.026427216827869415, 0.026427216827869415, 0.24483105540275574, 0.0789576843380928, 0.623356819152832], [0.02743517979979515, 0.1584615856409073, 0.07479748874902725, 0.3696528673171997, 0.3696528673171997], [0.5785319209098816, 0.3261193037033081, 0.047254446893930435, 0.047254446893930435, 0.0008398405043408275], [0.08683200180530548, 0.008121002465486526, 0.1301281601190567, 0.7375020384788513, 0.037416841834783554], [0.7644183039665222, 0.1097232922911644, 0.0008579071727581322, 0.015277178958058357, 0.1097232922911644], [0.04534393921494484, 0.3046274185180664, 0.04534393921494484, 0.13970127701759338, 0.4649835228919983], [0.012829362414777279, 0.2971768081188202, 0.3320281505584717, 0.02593749761581421, 0.3320281505584717], [0.14752542972564697, 0.04361391440033913, 0.39558321237564087, 0.017694175243377686, 0.39558321237564087], [0.2766057848930359, 0.2766057848930359, 0.000833096681162715, 0.4178753197193146, 0.028080016374588013], [0.21633101999759674, 0.021949278190732002, 0.21633101999759674, 0.22780214250087738, 0.3175865709781647], [0.4688413143157959, 0.02810518816113472, 0.02810518816113472, 0.3850744664669037, 0.08987392485141754], [0.001460452564060688, 0.015787893906235695, 0.34605494141578674, 0.001460452564060688, 0.6352362632751465], [0.45666444301605225, 0.23014146089553833, 0.0036480457056313753, 0.07940462231636047, 0.23014146089553833], [0.28030234575271606, 0.011084404774010181, 0.0032044725958257914, 0.6943243741989136, 0.011084404774010181], [0.009260705672204494, 0.18856535851955414, 0.40472203493118286, 0.20888651907444, 0.18856535851955414], [0.18034538626670837, 0.18241359293460846, 0.17927709221839905, 0.05345138907432556, 0.404512494802475], [0.2897781729698181, 0.009780068881809711, 0.3763371407985687, 0.2897781729698181, 0.0343264564871788], [0.1730479747056961, 0.332936555147171, 0.0499395951628685, 0.332936555147171, 0.11113937199115753], [0.03624773770570755, 0.04017472639679909, 0.03624773770570755, 0.8816460371017456, 0.0056837173178792], [0.6672167778015137, 0.09642209857702255, 0.08571101725101471, 0.07532506436109543, 0.07532506436109543], [0.0016311483923345804, 0.21967485547065735, 0.38870394229888916, 0.38870394229888916, 0.0012861527502536774], [0.005225864704698324, 0.0036430906038731337, 0.03564298897981644, 0.4777440130710602, 0.4777440130710602], [0.0007937378832139075, 0.07415218651294708, 0.18643714487552643, 0.0007937378832139075, 0.7378233075141907], [0.18792563676834106, 0.006491693202406168, 0.005210651084780693, 0.4001860022544861, 0.4001860022544861], [0.1017041727900505, 0.43651843070983887, 0.43651843070983887, 0.0050717005506157875, 0.02018720842897892], [0.45231983065605164, 0.45231983065605164, 0.08611928671598434, 0.006422069389373064, 0.0028189695440232754], [0.0014744882937520742, 0.8729887008666992, 0.0014744882937520742, 0.1216120570898056, 0.002450348576530814], [0.41520798206329346, 0.01634114980697632, 0.02962396666407585, 0.41520798206329346, 0.12361889332532883], [0.7501097917556763, 0.12422041594982147, 0.0009009986533783376, 0.12422041594982147, 0.0005484464345499873], [0.8947556614875793, 0.011035441420972347, 0.011035441420972347, 0.07833164930343628, 0.004841809626668692], [0.0006985624204389751, 0.35152721405029297, 0.2644954323768616, 0.03175154700875282, 0.35152721405029297], [0.04240588843822479, 0.04248042777180672, 0.1626051962375641, 0.5899032950401306, 0.1626051962375641], [0.008053496479988098, 0.4413137435913086, 0.10913936048746109, 0.00017968329484574497, 0.4413137435913086], [0.4410305917263031, 0.4410305917263031, 0.0012651828583329916, 0.002194181317463517, 0.11447947472333908], [0.05408163741230965, 5.4254393035080284e-05, 0.8640105724334717, 0.0409267395734787, 0.0409267395734787], [0.015156491659581661, 0.027434630319476128, 0.22229763865470886, 0.6997148394584656, 0.03539644181728363], [0.04821466654539108, 0.3161435127258301, 0.04821466654539108, 0.002737106289714575, 0.5846900343894958], [0.08460827171802521, 0.04013531282544136, 0.0010557054774835706, 0.789592444896698, 0.08460827171802521], [0.015791719779372215, 0.7127919793128967, 0.015791719779372215, 0.252483069896698, 0.00314153078943491], [0.04305971413850784, 0.35009825229644775, 0.22418099641799927, 0.03256276994943619, 0.35009825229644775], [0.008943188935518265, 0.5935011506080627, 0.008943188935518265, 0.34629151225090027, 0.042320944368839264], [0.2885728180408478, 0.04371834546327591, 0.3203093707561493, 0.3203093707561493, 0.027090059593319893], [0.00039115286199375987, 0.5700086951255798, 0.0003146138333249837, 0.25312429666519165, 0.17616130411624908], [0.026196260005235672, 0.17833751440048218, 0.026196260005235672, 0.03608160838484764, 0.7331884503364563], [0.2508239448070526, 0.030509434640407562, 0.6021593809127808, 0.030509434640407562, 0.08599776029586792], [0.0007595555507577956, 0.003642210504040122, 0.4873640239238739, 0.4873640239238739, 0.020870238542556763], [0.005185695830732584, 0.005185695830732584, 0.09149616211652756, 0.7953125834465027, 0.10281987488269806], [0.048896219581365585, 0.15531376004219055, 0.048896219581365585, 0.6183490753173828, 0.12854470312595367], [0.09382478892803192, 0.02518611028790474, 0.8798289895057678, 0.0005800111102871597, 0.0005800111102871597], [0.21771661937236786, 0.5686900019645691, 0.050210148096084595, 0.050210148096084595, 0.11317308247089386], [0.5062907338142395, 0.13846510648727417, 0.0033702566288411617, 0.17593695223331451, 0.17593695223331451], [0.33508357405662537, 0.19129404425621033, 0.05543524771928787, 0.33508357405662537, 0.08310358971357346], [0.11110919713973999, 0.8282108902931213, 0.002189366612583399, 0.05630115419626236, 0.002189366612583399], [0.02509305812418461, 0.0028344285674393177, 0.02509305812418461, 0.9331950545310974, 0.013784384354948997], [0.901984691619873, 0.003701377660036087, 0.06960546225309372, 0.003701377660036087, 0.021007154136896133], [0.6197582483291626, 0.10796567797660828, 0.14795728027820587, 0.06215938180685043, 0.06215938180685043], [0.43400537967681885, 0.2576051354408264, 0.04831044748425484, 0.002473956672474742, 0.2576051354408264], [0.10481006652116776, 0.05431623384356499, 0.002300577238202095, 0.10481006652116776, 0.7337630391120911], [0.6333114504814148, 0.17986717820167542, 0.03049018792808056, 0.07816553860902786, 0.07816553860902786], [0.05139480531215668, 0.06754615902900696, 0.8295899033546448, 7.440686749760062e-05, 0.05139480531215668], [0.021587390452623367, 0.24362102150917053, 0.30389416217803955, 0.18727639317512512, 0.24362102150917053], [0.1901734471321106, 0.01619083806872368, 0.3320443630218506, 0.2307957112789154, 0.2307957112789154], [0.02178865857422352, 0.01797495037317276, 0.01797495037317276, 0.6716979146003723, 0.2705635726451874], [0.1505129486322403, 0.004506632685661316, 0.2877766191959381, 0.27860191464424133, 0.27860191464424133], [0.0210434477776289, 0.4893140494823456, 0.4893140494823456, 2.0961906557204202e-05, 0.0003076036227867007], [0.24837560951709747, 0.2385358214378357, 0.20515267550945282, 0.1027831882238388, 0.20515267550945282], [0.011301425285637379, 0.04854741320014, 0.3830419182777405, 0.43586215376853943, 0.12124712020158768], [0.29621562361717224, 0.6371035575866699, 0.010417929850518703, 0.045844994485378265, 0.010417929850518703], [0.1780976802110672, 0.1597253829240799, 0.14129169285297394, 0.1780976802110672, 0.342787504196167], [0.0029580427799373865, 0.0002031150070251897, 0.5497015714645386, 0.049958277493715286, 0.39717897772789], [0.0018966153729707003, 0.4476102292537689, 0.4476102292537689, 0.010930332355201244, 0.09195259213447571], [0.36284759640693665, 0.2559899687767029, 0.0012455020332708955, 0.36284759640693665, 0.017069349065423012], [0.08275165408849716, 0.6481226682662964, 0.13058438897132874, 0.13058438897132874, 0.007956846617162228], [0.011950218118727207, 0.019442621618509293, 0.019442621618509293, 0.008853042498230934, 0.9403115510940552], [0.04507114738225937, 0.04507114738225937, 0.6828988194465637, 0.09994792193174362, 0.12701091170310974], [0.022949321195483208, 0.7688673734664917, 0.022949321195483208, 0.15323041379451752, 0.03200357034802437], [0.3966307044029236, 0.2230835258960724, 0.06250045448541641, 0.2230835258960724, 0.09470172226428986], [5.3700936405221e-05, 0.22831164300441742, 0.05637635290622711, 0.5476610660552979, 0.16759724915027618], [0.12490087002515793, 0.434648722410202, 0.004111593589186668, 0.434648722410202, 0.0016901075141504407], [0.00095957494340837, 0.0417882464826107, 0.8028808236122131, 0.07718569040298462, 0.07718569040298462], [0.21458855271339417, 0.03072471171617508, 0.5554507374763489, 0.19638054072856903, 0.0028554301243275404], [0.5737653374671936, 0.2130780667066574, 0.2130780667066574, 6.244077667361125e-05, 1.6146223060786724e-05], [0.0038827008102089167, 0.49456658959388733, 0.005215788725763559, 0.49456658959388733, 0.0017683707410469651], [0.564294159412384, 0.011769123375415802, 0.0007704895106144249, 0.011769123375415802, 0.4113970696926117], [0.1255268156528473, 0.280789315700531, 0.11060099303722382, 0.3575560748577118, 0.1255268156528473], [0.23267370462417603, 0.07278759032487869, 0.22389955818653107, 0.07278759032487869, 0.39785149693489075], [0.3068818747997284, 0.3068818747997284, 0.06093689799308777, 0.2680644094944, 0.057234931737184525], [0.4749520719051361, 0.009397669695317745, 0.059199631214141846, 0.22822535037994385, 0.22822535037994385], [0.0006998823373578489, 0.025639737024903297, 0.049116380512714386, 0.8754276037216187, 0.049116380512714386], [0.012549388222396374, 0.009424970485270023, 0.5579769611358643, 0.006308501586318016, 0.41374021768569946], [0.17261524498462677, 0.6331574320793152, 0.021419459953904152, 0.17261524498462677, 0.0001925516116898507], [0.2574881613254547, 0.01545535959303379, 0.46245503425598145, 0.2574881613254547, 0.007113246712833643], [0.265278697013855, 0.06963740289211273, 0.29744964838027954, 0.07018458098173141, 0.29744964838027954], [0.1988202929496765, 0.31047070026397705, 0.02664792910218239, 0.2652408182621002, 0.1988202929496765], [0.6683579683303833, 0.00042148667853325605, 0.04709891229867935, 0.27246755361557007, 0.011654001660645008], [0.3762705326080322, 0.0022684677969664335, 0.5523317456245422, 0.06686080247163773, 0.0022684677969664335], [0.01921653561294079, 0.29773154854774475, 0.38124802708625793, 0.29773154854774475, 0.004072313662618399], [0.18224164843559265, 0.1752527952194214, 0.18224164843559265, 0.04315546154975891, 0.41710853576660156], [0.41832536458969116, 0.41832536458969116, 0.004216515459120274, 0.021784111857414246, 0.1373487114906311], [0.00016838304873090237, 0.022915687412023544, 0.0971224308013916, 0.8568777441978455, 0.022915687412023544], [0.13170719146728516, 0.058017075061798096, 0.4048881232738495, 0.000499475107062608, 0.4048881232738495], [0.33008402585983276, 0.2866707742214203, 0.05067187175154686, 0.002489311620593071, 0.33008402585983276], [0.0049925209023058414, 0.08225731551647186, 0.9033737778663635, 0.0049925209023058414, 0.0043839262798428535], [0.1617896407842636, 0.3122934401035309, 0.3122934401035309, 0.1902252733707428, 0.023398185148835182], [0.09611686319112778, 0.056180134415626526, 0.53657466173172, 0.21501149237155914, 0.09611686319112778], [0.00012710591545328498, 0.022014854475855827, 4.903828084934503e-05, 0.48890450596809387, 0.48890450596809387], [0.21149496734142303, 0.375716894865036, 0.03701384365558624, 5.7383644161745906e-05, 0.375716894865036], [0.2595105767250061, 0.2505706548690796, 0.030556872487068176, 0.030556872487068176, 0.42880502343177795], [0.21525923907756805, 0.07535003870725632, 0.2383577674627304, 0.2326751947402954, 0.2383577674627304], [0.23110133409500122, 0.2683582603931427, 0.23110133409500122, 0.06173959746956825, 0.2076994776725769], [0.08543059974908829, 0.1854482740163803, 0.08543059974908829, 0.2798343896865845, 0.3638560473918915], [0.43640002608299255, 0.43640002608299255, 0.045867856591939926, 0.023180069401860237, 0.05815202742815018], [0.13933290541172028, 0.6323513984680176, 0.03390426188707352, 0.13933290541172028, 0.05507856607437134], [0.003961389418691397, 0.08350420743227005, 0.26108744740486145, 0.5002861618995667, 0.1511608064174652], [0.00710026640444994, 0.009321480058133602, 0.9509473443031311, 0.023309504613280296, 0.009321480058133602], [0.07110029458999634, 0.20316001772880554, 0.07110029458999634, 0.6524077653884888, 0.002231589751318097], [0.34213170409202576, 0.01021985337138176, 0.0001407089876011014, 0.02535143494606018, 0.6221563220024109], [0.5366770029067993, 0.22007279098033905, 0.22007279098033905, 0.010933774523437023, 0.012243588455021381], [0.07887057960033417, 0.4747510552406311, 0.07887057960033417, 0.012773633003234863, 0.3547340929508209], [0.11723814904689789, 0.11723814904689789, 0.1285359412431717, 0.6307442784309387, 0.006243495736271143], [0.17581118643283844, 0.01587807387113571, 0.01587807387113571, 0.011651470325887203, 0.7807811498641968], [0.5003289580345154, 0.08261959254741669, 0.0003553729911800474, 0.08261959254741669, 0.334076464176178], [0.25747838616371155, 0.03168405219912529, 0.597092866897583, 0.08206062763929367, 0.03168405219912529], [0.435844749212265, 0.0005392336752265692, 0.435844749212265, 0.0033319946378469467, 0.12443937361240387], [0.4022783637046814, 0.17059260606765747, 0.20508615672588348, 0.016956761479377747, 0.20508615672588348], [0.17289482057094574, 0.17044556140899658, 0.31914448738098145, 0.31914448738098145, 0.018370632082223892], [0.0025631943717598915, 0.4319865107536316, 0.4319865107536316, 0.0934736505150795, 0.0399901308119297], [0.4451991021633148, 0.0005284281214699149, 0.4451991021633148, 0.06218520551919937, 0.04688817635178566], [0.00010765622573671862, 0.01783466897904873, 0.00010765622573671862, 0.5309109687805176, 0.45103907585144043], [0.03263070806860924, 0.20551125705242157, 0.03263070806860924, 0.007659928407520056, 0.7215672731399536], [0.003589649684727192, 0.003589649684727192, 0.0005551172653213143, 0.09000371396541595, 0.9022619128227234], [0.3674499988555908, 0.25744712352752686, 0.06447585672140121, 0.06447585672140121, 0.2461511194705963], [0.001399090513586998, 0.013816800899803638, 0.910824179649353, 0.07256083190441132, 0.001399090513586998], [0.5735047459602356, 0.001165941939689219, 0.0032597307581454515, 0.0032597307581454515, 0.4188098609447479], [0.0631256252527237, 0.005359577015042305, 0.18128862977027893, 0.7448665499687195, 0.005359577015042305], [0.00020178055274300277, 0.5027795433998108, 0.18542397022247314, 0.06195693090558052, 0.24963778257369995], [0.40512096881866455, 0.008096720091998577, 0.09494316577911377, 0.2459196001291275, 0.2459196001291275], [0.03533254936337471, 0.16380570828914642, 0.6063044667243958, 0.15922468900680542, 0.03533254936337471], [0.0403948575258255, 0.0403948575258255, 0.11023843288421631, 0.002211112529039383, 0.8067607283592224], [0.27217039465904236, 0.0031880775932222605, 0.27217039465904236, 0.36285799741744995, 0.08961319923400879], [0.09395161271095276, 0.20734281837940216, 0.20734281837940216, 0.40009549260139465, 0.09126725792884827], [0.10450922697782516, 0.10450922697782516, 0.07948614656925201, 0.5047736763954163, 0.20672175288200378], [0.347064346075058, 0.004409266635775566, 0.347064346075058, 0.05762990936636925, 0.24383209645748138], [0.23257054388523102, 0.002732690190896392, 0.007541286293417215, 0.5245850086212158, 0.23257054388523102], [0.010193537920713425, 4.473585431696847e-05, 0.19437173008918762, 4.473585431696847e-05, 0.7953451871871948], [0.1247924342751503, 0.15163502097129822, 0.03302203118801117, 0.5657581686973572, 0.1247924342751503], [0.050211381167173386, 0.06406442821025848, 0.18156243860721588, 0.06406442821025848, 0.6400973796844482], [0.14049188792705536, 0.6936166882514954, 0.014616494998335838, 0.010783027857542038, 0.14049188792705536], [0.32441380620002747, 0.14483632147312164, 0.32441380620002747, 0.004731489345431328, 0.20160457491874695], [0.507151186466217, 0.2955282926559448, 0.0059652868658304214, 0.0059652868658304214, 0.18538996577262878], [0.01902819238603115, 0.01902819238603115, 0.14149434864521027, 0.18395450711250305, 0.6364948153495789], [0.4641474783420563, 0.03640460968017578, 0.03414240851998329, 0.4641474783420563, 0.0011580432765185833], [0.4925926923751831, 0.028352243825793266, 0.2311939150094986, 0.12393058836460114, 0.12393058836460114], [0.14532309770584106, 0.03891908749938011, 0.6688005328178406, 0.14532309770584106, 0.0016342197777703404], [0.048604365438222885, 0.24516698718070984, 0.45955345034599304, 0.0015081949532032013, 0.24516698718070984], [0.008043770678341389, 0.017683327198028564, 0.44634121656417847, 0.44634121656417847, 0.08159045875072479], [0.21049952507019043, 0.21049952507019043, 0.18915490806102753, 0.08795299381017685, 0.3018929958343506], [0.7244153618812561, 0.11551599204540253, 0.07166266441345215, 0.016743240877985954, 0.07166266441345215], [0.6371979713439941, 0.235619455575943, 0.01211483869701624, 0.10295291244983673, 0.01211483869701624], [0.7500292658805847, 0.09811864793300629, 0.09811864793300629, 0.05097784847021103, 0.002755502238869667], [0.030466942116618156, 0.004750915803015232, 0.7758198976516724, 0.004750915803015232, 0.1842113733291626], [0.04052041843533516, 0.006143779028207064, 0.9445844292640686, 0.0026075325440615416, 0.006143779028207064], [0.32917141914367676, 0.05475194379687309, 0.053298912942409515, 0.05475194379687309, 0.5080257654190063], [0.3030818998813629, 0.02518649958074093, 0.595410168170929, 0.02518649958074093, 0.0511348657310009], [0.18982799351215363, 0.012315213680267334, 0.7540174126625061, 0.031524237245321274, 0.012315213680267334], [0.4713227450847626, 0.02630387432873249, 0.01701509766280651, 0.014035608619451523, 0.4713227450847626], [0.0006707609281875193, 0.3722008764743805, 0.3722008764743805, 0.2265004962682724, 0.028427034616470337], [0.33418601751327515, 0.33418601751327515, 0.146743044257164, 0.020771227777004242, 0.16411364078521729], [0.07636458426713943, 0.07636458426713943, 0.5272077322006226, 0.04920586943626404, 0.2708572745323181], [0.0026672007516026497, 0.08352601528167725, 0.606839120388031, 0.08352601528167725, 0.22344160079956055], [0.026386311277747154, 0.11070754379034042, 0.12418585270643234, 0.026386311277747154, 0.7123339772224426], [0.2730228900909424, 0.016292182728648186, 0.0032083443365991116, 0.0032083443365991116, 0.7042681574821472], [0.27898281812667847, 0.27898281812667847, 0.011541828513145447, 0.3320888876914978, 0.09840364754199982], [0.12110686302185059, 0.12110686302185059, 0.14168931543827057, 0.4334414303302765, 0.182655468583107], [0.04227399080991745, 0.0041163102723658085, 2.7973293981631286e-05, 0.9535537958145142, 2.7973293981631286e-05], [0.0038828696124255657, 0.3511885702610016, 0.012577829882502556, 0.0038828696124255657, 0.6284679174423218], [0.12647126615047455, 0.5564934015274048, 0.12647126615047455, 0.14172516763210297, 0.04883887246251106], [0.06422211974859238, 0.03326190635561943, 0.08644787967205048, 0.03326190635561943, 0.7828061580657959], [0.24378740787506104, 0.004752413369715214, 0.20026461780071259, 0.3074081242084503, 0.24378740787506104], [0.8996857404708862, 0.0031430684030056, 0.0481753908097744, 0.0481753908097744, 0.0008203947218134999], [0.49430349469184875, 0.20167109370231628, 0.30136269330978394, 0.0013313472736626863, 0.0013313472736626863], [0.0013390923850238323, 0.060970816761255264, 0.26228535175323486, 0.6740656495094299, 0.0013390923850238323], [0.0070542399771511555, 0.2098718285560608, 0.1856062412261963, 0.5896646976470947, 0.007802975829690695], [0.2985559105873108, 0.18133306503295898, 0.0009128699894063175, 0.33786505460739136, 0.18133306503295898], [0.007441048976033926, 0.2131296992301941, 0.7693213224411011, 0.002666886430233717, 0.007441048976033926], [0.452685683965683, 0.452685683965683, 0.04893302544951439, 0.009967206045985222, 0.03572831675410271], [0.008172625675797462, 0.002177832182496786, 0.0010211291955783963, 0.536830484867096, 0.4517979323863983], [0.42977482080459595, 0.0864754468202591, 0.42977482080459595, 9.557593875797465e-05, 0.05387936905026436], [0.15374669432640076, 0.055560674518346786, 0.029676077887415886, 0.15374669432640076, 0.607269823551178], [0.4926692247390747, 0.00204833853058517, 0.008920172229409218, 0.4926692247390747, 0.0036930725909769535], [0.003936409018933773, 0.42741769552230835, 0.12089849263429642, 0.02032969705760479, 0.42741769552230835], [0.9290676116943359, 0.011190242134034634, 0.01846403069794178, 0.020639056339859962, 0.020639056339859962], [0.08274763077497482, 0.02131890505552292, 0.02131890505552292, 0.015560590662062168, 0.8590539693832397], [0.016033362597227097, 0.409330815076828, 0.11217352002859116, 0.409330815076828, 0.05313152074813843], [0.12353551387786865, 0.2049546241760254, 0.2049546241760254, 0.4289803206920624, 0.037574924528598785], [0.38779643177986145, 0.000790136051364243, 0.000790136051364243, 0.596808671951294, 0.013814601115882397], [0.3167087137699127, 0.009583704173564911, 0.16054047644138336, 0.1964583545923233, 0.3167087137699127], [0.002764476928859949, 0.4094468951225281, 0.5490108728408813, 0.019388854503631592, 0.019388854503631592], [0.0031955400481820107, 0.03600690886378288, 0.000904417538549751, 0.9566976428031921, 0.0031955400481820107], [0.7733677625656128, 0.14273758232593536, 0.009008275344967842, 0.03744324669241905, 0.03744324669241905], [0.3944976031780243, 0.1844957321882248, 0.3944976031780243, 0.0004340092127677053, 0.026075033470988274], [0.850401759147644, 0.06754559278488159, 0.010427949018776417, 0.06119684502482414, 0.010427949018776417], [0.013297932222485542, 0.1551678627729416, 0.3768737018108368, 0.44981831312179565, 0.0048421332612633705], [0.4607296586036682, 0.4607296586036682, 0.030133496969938278, 0.000970212509855628, 0.04743701219558716], [0.0109434574842453, 0.055616531521081924, 0.44185471534729004, 0.44185471534729004, 0.049730658531188965], [0.27317866683006287, 0.208807572722435, 0.24616193771362305, 0.02568984217941761, 0.24616193771362305], [0.030344044789671898, 0.5612337589263916, 0.305539071559906, 0.0725390836596489, 0.030344044789671898], [0.006232267711311579, 0.11029832810163498, 0.009949670173227787, 0.7632213830947876, 0.11029832810163498], [0.4053756296634674, 0.0030448974575847387, 0.0030448974575847387, 0.009383614175021648, 0.5791509747505188], [0.11524417251348495, 0.016538208350539207, 0.1806899905204773, 0.11524417251348495, 0.5722835063934326], [0.04021761938929558, 0.2727934420108795, 0.04021761938929558, 8.721507583686616e-06, 0.6467626690864563], [0.026461247354745865, 0.006734753493219614, 0.9113034009933472, 0.027750328183174133, 0.027750328183174133], [0.022040991112589836, 0.022040991112589836, 0.1826050877571106, 0.6088554263114929, 0.1644574999809265], [0.027054788544774055, 0.2574090361595154, 0.027054788544774055, 0.0012825242010876536, 0.6871987581253052], [0.5705000162124634, 0.06374162435531616, 0.2416670322418213, 0.06204569712281227, 0.06204569712281227], [0.6037136912345886, 0.02526494674384594, 0.02526494674384594, 0.006674329284578562, 0.3390819728374481], [0.09679069370031357, 0.3146861791610718, 0.4900621771812439, 0.0016703064320608974, 0.09679069370031357], [0.7540622353553772, 0.03409276157617569, 0.17549367249011993, 0.002258620923385024, 0.03409276157617569], [0.001659271540120244, 0.3772070109844208, 0.3772070109844208, 0.20910122990608215, 0.03482544422149658], [0.2056482434272766, 0.32374751567840576, 0.07659006118774414, 0.32374751567840576, 0.07026666402816772], [0.40471750497817993, 0.5213305950164795, 0.008641875348985195, 0.008641875348985195, 0.05666816607117653], [0.8944391012191772, 0.005261446349322796, 0.005261446349322796, 0.02210378833115101, 0.07293427735567093], [0.741707444190979, 0.0670086070895195, 0.09594828635454178, 0.08736057579517365, 0.007975109852850437], [0.01882029138505459, 0.43036970496177673, 0.43036970496177673, 0.0470338836312294, 0.07340648025274277], [0.2824420928955078, 0.19606198370456696, 0.23375962674617767, 0.2824420928955078, 0.0052942438051104546], [0.009012878872454166, 0.009012878872454166, 0.855688750743866, 0.031842365860939026, 0.09444312751293182], [0.37454503774642944, 0.10011211782693863, 0.0066423979587852955, 0.37454503774642944, 0.14415542781352997], [0.027803760021924973, 0.350992888212204, 0.24873633682727814, 0.050385233014822006, 0.3220817446708679], [0.07277766615152359, 0.018927890807390213, 0.15703049302101135, 0.37563201785087585, 0.37563201785087585], [0.003556536976248026, 0.02424369938671589, 0.4117738902568817, 0.4117738902568817, 0.14865201711654663], [0.01757686957716942, 0.11605681478977203, 0.3713582456111908, 0.3713582456111908, 0.12364980578422546], [0.00617506867274642, 0.014994670636951923, 0.3152177929878235, 0.3483946621417999, 0.3152177929878235], [0.2810489237308502, 0.006463075056672096, 0.35338684916496277, 0.0057142931036651134, 0.35338684916496277], [0.01460949331521988, 0.1691148579120636, 0.01460949331521988, 0.790870189666748, 0.010795974172651768], [0.294844388961792, 0.11468219012022018, 0.2241927534341812, 0.1420878916978836, 0.2241927534341812], [0.00035155611112713814, 0.027261584997177124, 0.9690793752670288, 0.0007480356725864112, 0.0025593978352844715], [0.012401197105646133, 0.06798873841762543, 0.3795446455478668, 0.270032674074173, 0.270032674074173], [0.12333043664693832, 0.006682608742266893, 0.009945276193320751, 0.30590736865997314, 0.5541343092918396], [0.21431981027126312, 0.2793842554092407, 0.10665152221918106, 0.10665152221918106, 0.2929929792881012], [0.4599874019622803, 0.4599874019622803, 0.06920746713876724, 0.0004804912896361202, 0.010337194427847862], [0.7425151467323303, 0.01882152445614338, 0.01882152445614338, 0.18174481391906738, 0.03809696435928345], [0.09476766735315323, 0.2317710965871811, 0.02835897170007229, 0.09476766735315323, 0.550334632396698], [0.005380707792937756, 0.09279482811689377, 0.46460479497909546, 0.09279482811689377, 0.344424843788147], [0.4849052131175995, 0.0013494660379365087, 0.011505835689604282, 0.4849052131175995, 0.017334209755063057], [0.03202412649989128, 0.01009689923375845, 0.9248954057693481, 0.03202412649989128, 0.0009594011935405433], [0.34919819235801697, 0.08773849159479141, 0.34919819235801697, 0.008525875397026539, 0.2053392380475998], [0.006488208658993244, 0.15996481478214264, 0.15996481478214264, 0.39750704169273376, 0.2760751247406006], [0.005670985206961632, 0.13045169413089752, 0.08750640600919724, 0.005670985206961632, 0.7706999182701111], [0.007937520742416382, 0.8530494570732117, 0.023472046479582787, 0.057770464569330215, 0.057770464569330215], [0.2883729934692383, 0.3116355240345001, 0.33678048849105835, 0.03160547837615013, 0.03160547837615013], [0.5299579501152039, 0.008688148111104965, 0.057052671909332275, 0.3472486436367035, 0.057052671909332275], [0.0010847061639651656, 0.5524291396141052, 0.031099975109100342, 0.3842862546443939, 0.031099975109100342], [0.16345998644828796, 0.019966168329119682, 0.4882577061653137, 0.16485610604286194, 0.16345998644828796], [0.025791198015213013, 0.781853199005127, 0.09414418041706085, 0.004067287314683199, 0.09414418041706085], [0.66008460521698, 0.008988337591290474, 0.07236940413713455, 0.12927880883216858, 0.12927880883216858], [0.24966377019882202, 0.1084912046790123, 0.24966377019882202, 0.0013657730305567384, 0.3908155560493469], [0.036641690880060196, 0.025358125567436218, 0.025358125567436218, 0.8948730230331421, 0.017769034951925278], [0.028064068406820297, 0.517244815826416, 0.4224112927913666, 0.028064068406820297, 0.0042157769203186035], [0.40611517429351807, 0.40611517429351807, 0.007807586342096329, 0.10043968260288239, 0.07952231168746948], [0.17040567100048065, 0.20021115243434906, 0.34526026248931885, 0.20021115243434906, 0.08391176909208298], [0.03496706858277321, 0.08975543081760406, 0.8547208309173584, 0.01495795976370573, 0.005598690826445818], [0.046211469918489456, 0.8374294638633728, 0.014695802703499794, 0.055451858788728714, 0.046211469918489456], [0.6387736201286316, 0.007569783367216587, 0.3332110643386841, 0.007569783367216587, 0.012875772081315517], [0.03846537694334984, 0.02242293208837509, 0.3164042532444, 0.3164042532444, 0.3063031733036041], [0.012711629271507263, 0.06857339292764664, 0.023114867508411407, 0.8724851608276367, 0.023114867508411407], [0.8380289673805237, 0.051457468420267105, 0.05331366881728172, 0.003886249614879489, 0.05331366881728172], [0.34384045004844666, 0.08904166519641876, 0.34384045004844666, 0.21747712790966034, 0.005800354294478893], [0.021144500002264977, 0.021144500002264977, 0.024347709491848946, 0.10264179855585098, 0.830721378326416], [0.0956433117389679, 0.03313928097486496, 0.019418206065893173, 0.07424461096525192, 0.7775546312332153], [0.016080036759376526, 0.05146583542227745, 0.4514210820198059, 0.2405165433883667, 0.2405165433883667], [6.86641433276236e-05, 7.421645568683743e-05, 0.06089543551206589, 7.421645568683743e-05, 0.9388875365257263], [0.5543860197067261, 0.03847668319940567, 0.1569453477859497, 0.1569453477859497, 0.09324660897254944], [0.1272004246711731, 2.1741805539932102e-05, 0.6637624502182007, 0.14495530724525452, 0.06406009942293167], [0.41755545139312744, 0.014676726423203945, 0.20668788254261017, 0.20668788254261017, 0.1543920636177063], [0.1263386756181717, 0.3724978268146515, 0.11011803150177002, 0.3724978268146515, 0.018547631800174713], [0.007001124322414398, 0.4262423515319824, 0.3867858946323395, 0.00017153991211671382, 0.1797991245985031], [0.003608854953199625, 0.025065114721655846, 0.09442120790481567, 0.003608854953199625, 0.8732959032058716], [0.024979615584015846, 0.22169539332389832, 0.34054189920425415, 0.0722411498427391, 0.34054189920425415], [0.027471665292978287, 0.2864129841327667, 0.3808786869049072, 0.15261830389499664, 0.15261830389499664], [0.2258029729127884, 0.12852247059345245, 0.006723530124872923, 0.3194755017757416, 0.3194755017757416], [0.007737604435533285, 0.46068909764289856, 0.5311275124549866, 0.00022290197375696152, 0.00022290197375696152], [0.00037542046629823744, 0.10233990848064423, 0.00037542046629823744, 0.12769611179828644, 0.7692131400108337], [0.09956765919923782, 0.07843822985887527, 0.6309521198272705, 0.0914742723107338, 0.09956765919923782], [0.0036623666528612375, 0.9392699003219604, 0.0003249013388995081, 0.0036623666528612375, 0.0530804768204689], [0.43895336985588074, 0.003819101257249713, 0.04834435507655144, 0.43895336985588074, 0.0699298158288002], [0.07111779600381851, 0.8195540904998779, 0.07111779600381851, 0.01603984646499157, 0.02217046171426773], [0.1811257004737854, 0.024640927091240883, 0.4454469084739685, 0.3473421335220337, 0.0014442550018429756], [0.7214928269386292, 0.009942717850208282, 0.08134574443101883, 0.08134574443101883, 0.10587292164564133], [0.07248391956090927, 0.7386714220046997, 0.0012090415693819523, 0.11515171825885773, 0.07248391956090927], [0.19521616399288177, 0.44656720757484436, 0.0035278983414173126, 0.0035278983414173126, 0.35116085410118103], [0.004929907154291868, 0.019921932369470596, 0.019921932369470596, 0.2380407601594925, 0.7171854972839355], [0.24220505356788635, 0.00031886983197182417, 0.3769025206565857, 0.00031886983197182417, 0.38025468587875366], [0.12627021968364716, 0.12627021968364716, 0.7111458778381348, 0.02577180229127407, 0.010541831143200397], [0.9279957413673401, 0.0001944549148902297, 0.0001944549148902297, 0.07060342282056808, 0.001011848682537675], [0.010963589884340763, 0.0009116532746702433, 0.0002372500457568094, 0.0009116532746702433, 0.9869758486747742], [0.0037458627484738827, 0.23248417675495148, 0.23248417675495148, 0.4901365041732788, 0.041149258613586426], [0.2548893690109253, 0.2548893690109253, 0.03323177620768547, 0.1286773681640625, 0.3283122181892395], [0.507952868938446, 0.3500024676322937, 0.07077836245298386, 0.07077836245298386, 0.00048801591037772596], [0.021530507132411003, 0.2574653923511505, 0.7203723192214966, 9.491391392657533e-05, 0.0005369345308281481], [0.673514723777771, 0.020110584795475006, 0.006950222887098789, 0.006950222887098789, 0.2924742102622986], [0.04818831384181976, 0.4506814181804657, 0.17355407774448395, 0.04818831384181976, 0.279387891292572], [0.186096653342247, 0.042613305151462555, 0.7049387693405151, 0.042613305151462555, 0.023737957701086998], [0.001186867244541645, 0.001186867244541645, 0.06502337753772736, 0.07967047393321991, 0.8529323935508728], [0.05317477881908417, 0.5711089968681335, 0.18186667561531067, 0.01198285911232233, 0.18186667561531067], [0.2023807018995285, 0.03851829841732979, 0.01037532091140747, 0.02968214638531208, 0.7190435528755188], [0.0006290553137660027, 0.07584550231695175, 0.001331113395281136, 0.07584550231695175, 0.8463488817214966], [0.0696013942360878, 0.8512986898422241, 0.00010650145850377157, 0.0696013942360878, 0.009392041712999344], [0.24198032915592194, 0.2325342744588852, 0.2447490692138672, 0.2447490692138672, 0.0359872505068779], [0.41401395201683044, 0.030327633023262024, 0.1246735081076622, 0.41401395201683044, 0.016970954835414886], [0.3604951500892639, 0.005304185673594475, 0.31647801399230957, 0.0012446028413251042, 0.31647801399230957], [0.05479300022125244, 0.7128843665122986, 0.17631593346595764, 0.0012136850273236632, 0.05479300022125244], [0.002072218805551529, 0.0013621473917737603, 0.00260650715790689, 0.00260650715790689, 0.9913525581359863], [0.03211541101336479, 0.03211541101336479, 0.23594333231449127, 0.6944286823272705, 0.005397233180701733], [0.0176237840205431, 0.767614483833313, 0.06471429020166397, 0.08533309400081635, 0.06471429020166397], [0.5740727186203003, 0.07048456370830536, 0.10239218920469284, 0.07048456370830536, 0.18256597220897675], [0.3793913424015045, 0.0036983864847570658, 0.02314743958413601, 0.21437150239944458, 0.3793913424015045], [0.02252892777323723, 0.0011229716474190354, 0.0011229716474190354, 0.949672281742096, 0.0255529023706913], [0.04656665027141571, 0.5787734985351562, 0.027763117104768753, 0.1798350065946579, 0.1670617014169693], [0.36916089057922363, 0.2888936400413513, 0.00015428663755301386, 0.34163686633110046, 0.00015428663755301386], [0.003050744067877531, 0.48450416326522827, 0.48450416326522827, 0.019802028313279152, 0.008138949051499367], [0.28029462695121765, 7.63676653150469e-05, 7.63676653150469e-05, 0.6376675963401794, 0.08188505470752716], [0.015838341787457466, 0.16237041354179382, 0.37116098403930664, 0.28825992345809937, 0.16237041354179382], [0.0237454604357481, 0.6666667461395264, 0.03616736829280853, 0.2372530698776245, 0.03616736829280853], [0.6659529209136963, 0.055534590035676956, 0.2057947814464569, 0.06729196757078171, 0.005425752606242895], [0.004450441338121891, 0.00469741877168417, 0.9861440658569336, 0.00469741877168417, 1.060895374394022e-05], [0.2811982035636902, 0.3167436122894287, 0.2811982035636902, 0.001665075309574604, 0.11919485777616501], [0.0018112966790795326, 0.7749887108802795, 0.20867998898029327, 0.012708684429526329, 0.0018112966790795326], [0.6530368328094482, 0.2827553153038025, 0.022588953375816345, 0.022588953375816345, 0.019029954448342323], [0.28110525012016296, 0.02537226304411888, 0.02537226304411888, 0.11513549089431763, 0.5530146360397339], [0.3253161907196045, 0.1350441426038742, 0.21255214512348175, 0.3253161907196045, 0.0017713617999106646], [0.6498401165008545, 0.16546665132045746, 0.1745631992816925, 0.005065005738288164, 0.005065005738288164], [0.03264216333627701, 0.08168565481901169, 0.21891403198242188, 0.03264216333627701, 0.634115993976593], [0.23253971338272095, 0.004086775705218315, 0.23253971338272095, 0.5251331925392151, 0.005700638517737389], [0.012430505827069283, 0.3543885350227356, 0.006836080923676491, 0.6195088624954224, 0.006836080923676491], [0.5205410122871399, 0.04904239624738693, 0.09919382631778717, 0.1656113564968109, 0.1656113564968109], [0.024089666083455086, 0.32502448558807373, 0.3103286921977997, 0.3103286921977997, 0.030228497460484505], [0.879719614982605, 0.05555678904056549, 0.031748078763484955, 0.0012274316977709532, 0.031748078763484955], [0.0007714994135312736, 0.029558250680565834, 0.00013908959226682782, 0.029558250680565834, 0.9399729371070862], [0.13852031528949738, 0.007760857231914997, 0.6196866631507874, 0.11701608449220657, 0.11701608449220657], [0.01636873185634613, 0.8108829259872437, 0.0875745341181755, 0.01636873185634613, 0.06880506873130798], [0.8998462557792664, 0.016802946105599403, 0.02012999914586544, 0.03161041811108589, 0.03161041811108589], [0.16028597950935364, 0.2116117924451828, 0.2372049242258072, 0.195448637008667, 0.195448637008667], [0.03681781515479088, 0.4515262544155121, 0.0011096986709162593, 0.05902009457349777, 0.4515262544155121], [0.009923048317432404, 0.3886740803718567, 0.041754867881536484, 0.3886740803718567, 0.1709739714860916], [0.4225154519081116, 0.003376392414793372, 0.03171634301543236, 0.32896411418914795, 0.21342776715755463], [0.03709014132618904, 0.06758193671703339, 0.439158171415329, 0.01701158471405506, 0.439158171415329], [0.4714408814907074, 0.04419511929154396, 0.4714408814907074, 0.0011878942605108023, 0.011735337786376476], [0.023204255849123, 0.4123374819755554, 0.4123374819755554, 0.12239517271518707, 0.029725581407546997], [0.496831476688385, 0.03548986464738846, 0.19603422284126282, 0.07561007887125015, 0.19603422284126282], [0.033092815428972244, 0.034556563943624496, 0.23905985057353973, 0.4542309045791626, 0.23905985057353973], [0.02195114642381668, 0.4632289409637451, 0.051395922899246216, 0.4632289409637451, 0.00019510718993842602], [0.5230799913406372, 0.16742642223834991, 0.03129838407039642, 0.11076869815587997, 0.16742642223834991], [0.09188607335090637, 0.2629217505455017, 0.09188607335090637, 0.056541167199611664, 0.4967649281024933], [0.038187600672245026, 0.04628420248627663, 0.00020588353800121695, 0.8844215273857117, 0.030900761485099792], [0.47810596227645874, 0.47810596227645874, 0.003178499871864915, 0.039714597165584564, 0.0008950344054028392], [0.041279714554548264, 0.027100970968604088, 0.027100970968604088, 0.07654257863759995, 0.8279757499694824], [0.3069629371166229, 0.060825079679489136, 0.14836184680461884, 0.060825079679489136, 0.423024982213974], [0.7166762351989746, 0.04630643501877785, 0.05405096337199211, 0.12891533970832825, 0.05405096337199211], [0.9392784237861633, 0.016445090994238853, 0.0036937815602868795, 0.0036937815602868795, 0.03688894212245941], [0.9521145224571228, 0.004791968036442995, 0.004791968036442995, 0.03796709328889847, 0.0003343359858263284], [0.038732971996068954, 0.044687386602163315, 0.2994800806045532, 0.044687386602163315, 0.5724121928215027], [0.019991759210824966, 0.5169625282287598, 0.45655399560928345, 0.0032458507921546698, 0.0032458507921546698], [0.3408152461051941, 0.3408152461051941, 0.21406874060630798, 0.07356332242488861, 0.03073742240667343], [0.09679501503705978, 0.018196893855929375, 0.5046470761299133, 0.018196893855929375, 0.36216413974761963], [0.044961076229810715, 0.09478319436311722, 0.3623499274253845, 0.13555581867694855, 0.3623499274253845], [0.43833938241004944, 0.21784229576587677, 0.06596873700618744, 0.21188080310821533, 0.06596873700618744], [0.006222023628652096, 0.7372158169746399, 0.10994689911603928, 0.10994689911603928, 0.0366683192551136], [0.1622730791568756, 0.08923139423131943, 0.2995958924293518, 0.2995958924293518, 0.14930370450019836], [0.033540721982717514, 0.018805664032697678, 0.018805664032697678, 0.0034685779828578234, 0.9253794550895691], [0.044815585017204285, 0.044815585017204285, 0.3798467218875885, 0.008541299030184746, 0.5219807624816895], [0.057233478873968124, 0.33201807737350464, 0.30528101325035095, 0.00018641797942109406, 0.30528101325035095], [0.12167780101299286, 0.19312788546085358, 0.12167780101299286, 0.4194001257419586, 0.14411647617816925], [0.002629792084917426, 0.1584744155406952, 0.00021233463485259563, 0.6802089810371399, 0.1584744155406952], [0.030974801629781723, 0.06496801227331161, 0.2971796691417694, 0.30343878269195557, 0.30343878269195557], [0.4978509843349457, 0.002903565065935254, 0.001391043420881033, 3.44417207998049e-06, 0.4978509843349457], [0.0003175823367200792, 0.9138089418411255, 0.060617584735155106, 0.024938276037573814, 0.0003175823367200792], [0.025535335764288902, 0.2623257339000702, 0.6852802634239197, 0.0013233741046860814, 0.025535335764288902], [0.2944086194038391, 0.17827333509922028, 0.07734270393848419, 0.37263262271881104, 0.07734270393848419], [0.02112729847431183, 0.49107465147972107, 0.3185967803001404, 0.009571622125804424, 0.15962964296340942], [0.24488194286823273, 0.353423535823822, 0.10322803258895874, 0.10322803258895874, 0.1952384114265442], [0.09918948262929916, 0.09918948262929916, 0.18280617892742157, 0.29885777831077576, 0.31995704770088196], [0.01160051953047514, 0.7271826863288879, 0.02377258613705635, 0.11872205883264542, 0.11872205883264542], [0.11669659614562988, 0.005916608963161707, 0.11669659614562988, 0.75339275598526, 0.007297486066818237], [0.1522596925497055, 0.1522596925497055, 0.011418725363910198, 0.173940509557724, 0.5101214051246643], [0.23554043471813202, 0.2126529961824417, 0.020119810476899147, 0.23554043471813202, 0.2961463928222656], [0.45719510316848755, 0.05507955700159073, 0.0023539310786873102, 0.4830174744129181, 0.0023539310786873102], [0.17272698879241943, 0.17272698879241943, 0.5608896017074585, 0.0034909392707049847, 0.09016545861959457], [0.0002559870481491089, 0.9756611585617065, 0.005553151480853558, 0.005553151480853558, 0.012976530939340591], [0.05610956624150276, 0.008980749174952507, 0.8264787197113037, 0.05537273362278938, 0.0530582033097744], [0.037594668567180634, 0.05448715761303902, 0.4436255693435669, 0.23214632272720337, 0.23214632272720337], [0.1971733272075653, 0.0017201873706653714, 0.17804469168186188, 0.0017201873706653714, 0.6213415265083313], [0.0688071995973587, 0.35910263657569885, 0.43271228671073914, 0.0688071995973587, 0.07057067006826401], [0.2759784460067749, 0.1481126993894577, 0.21675413846969604, 0.2759784460067749, 0.08317621797323227], [0.26856863498687744, 0.26856863498687744, 0.4158032238483429, 0.004590528551489115, 0.042469024658203125], [0.20799128711223602, 0.20799128711223602, 0.28231653571128845, 0.25611257553100586, 0.04558836668729782], [0.516238808631897, 0.0005688583478331566, 0.23120319843292236, 0.0005688583478331566, 0.251420259475708], [0.27649396657943726, 0.15856578946113586, 0.1562800407409668, 0.13216623663902283, 0.27649396657943726], [0.2972812354564667, 0.2972812354564667, 0.0922621637582779, 0.008206462487578392, 0.30496886372566223], [0.059364791959524155, 0.39625996351242065, 0.39625996351242065, 0.029406916350126266, 0.11870840936899185], [0.4951432943344116, 0.4951432943344116, 0.004656109493225813, 0.004662267863750458, 0.0003950049576815218], [0.00553887477144599, 0.024124188348650932, 0.0003447977942414582, 0.9644532799720764, 0.00553887477144599], [0.10635851323604584, 0.40159615874290466, 0.10635851323604584, 0.3563278615474701, 0.029358992353081703], [0.21537095308303833, 0.025653501972556114, 0.21537095308303833, 0.5326051115989685, 0.010999541729688644], [0.38017183542251587, 0.040017515420913696, 0.33155110478401184, 0.2082419991493225, 0.040017515420913696], [0.01920298859477043, 0.18272285163402557, 0.3970089852809906, 0.18272285163402557, 0.2183423638343811], [0.0006615881575271487, 0.9381978511810303, 0.0012942407047376037, 0.0006615881575271487, 0.059184759855270386], [0.3134884238243103, 0.2982555329799652, 0.13968810439109802, 0.10887986421585083, 0.13968810439109802], [0.7717949748039246, 0.17855310440063477, 0.010805209167301655, 0.010805209167301655, 0.02804150991141796], [0.0698932558298111, 0.03656362369656563, 0.36628419160842896, 0.16097478568553925, 0.36628419160842896], [0.23235565423965454, 0.23235565423965454, 0.07340523600578308, 0.2627308964729309, 0.19915258884429932], [0.0175644364207983, 0.6419104933738708, 0.33368611335754395, 0.0034195054322481155, 0.0034195054322481155], [0.026300719007849693, 0.7089815735816956, 0.12432119995355606, 0.026300719007849693, 0.1140957921743393], [0.8236048221588135, 0.004341075662523508, 0.041919685900211334, 0.004341075662523508, 0.12579326331615448], [0.7300652265548706, 0.07994305342435837, 0.186588853597641, 0.0017014661571010947, 0.0017014661571010947], [0.019786950200796127, 0.005269376561045647, 0.08574815839529037, 0.005269376561045647, 0.8839259743690491], [0.026643050834536552, 0.05576563626527786, 0.05576563626527786, 0.7894416451454163, 0.07238397002220154], [0.022086597979068756, 0.003097531385719776, 0.5823395848274231, 0.3703897297382355, 0.022086597979068756], [0.0051775136962533, 0.0011370163410902023, 0.46423816680908203, 0.46423816680908203, 0.06520915776491165], [0.3846610486507416, 0.1791486144065857, 0.3846610486507416, 0.051070719957351685, 0.0004586027062032372], [0.35039860010147095, 0.0029298942536115646, 0.04886681213974953, 0.0029298942536115646, 0.5948747396469116], [0.06575272232294083, 0.0063309259712696075, 0.027009526267647743, 0.06575272232294083, 0.8351540565490723], [0.00981494877487421, 0.9544922709465027, 0.00981494877487421, 0.02249475009739399, 0.0033831344917416573], [0.023732785135507584, 0.7712533473968506, 0.03072303719818592, 0.14356772601604462, 0.03072303719818592], [0.004030930809676647, 0.000134061963763088, 0.8801277875900269, 0.11167623102664948, 0.004030930809676647], [0.03205426037311554, 0.12762115895748138, 0.12083752453327179, 0.012612988241016865, 0.7068740725517273], [0.052273813635110855, 0.008253016509115696, 0.052273813635110855, 0.788435697555542, 0.09876371175050735], [0.0004311203374527395, 0.1390399932861328, 0.30203282833099365, 0.41945603489875793, 0.1390399932861328], [0.12920162081718445, 0.12920162081718445, 0.04808718338608742, 0.15626586973667145, 0.5372437238693237], [0.0071992650628089905, 0.0029411131981760263, 0.4888378381729126, 0.4888378381729126, 0.012183893471956253], [0.0830259695649147, 0.8161270022392273, 0.009339116513729095, 0.0830259695649147, 0.00848199613392353], [0.1642870455980301, 0.38098379969596863, 0.07096661627292633, 0.0027787680737674236, 0.38098379969596863], [0.10981640219688416, 0.12714815139770508, 0.37927770614624023, 0.37927770614624023, 0.004479988478124142], [0.0242192130535841, 0.054787591099739075, 0.0057012420147657394, 0.0242192130535841, 0.8910727500915527], [0.38985514640808105, 0.045437686145305634, 0.05128981173038483, 0.38985514640808105, 0.12356218695640564], [0.48779401183128357, 0.009833903051912785, 0.00033082853769883513, 0.48779401183128357, 0.014247290790081024], [0.11370480060577393, 0.15983286499977112, 0.01921231485903263, 0.15983286499977112, 0.5474171042442322], [0.030251288786530495, 0.23425401747226715, 0.2831406891345978, 0.030251288786530495, 0.4221027195453644], [0.0013221409171819687, 0.0013221409171819687, 0.9078124165534973, 0.07582025974988937, 0.013722999021410942], [0.14216819405555725, 0.010240767151117325, 0.5456081032752991, 0.14216819405555725, 0.15981480479240417], [0.004690683446824551, 0.40961727499961853, 0.13253924250602722, 0.40961727499961853, 0.04353556036949158], [0.48658767342567444, 0.016548266634345055, 0.00397541793063283, 0.0063010212033987045, 0.48658767342567444], [0.17556804418563843, 0.45737534761428833, 0.008555521257221699, 0.179250568151474, 0.179250568151474], [0.06536417454481125, 0.6241353154182434, 0.15731726586818695, 0.06536417454481125, 0.08781910687685013], [0.8905019760131836, 0.0010472078574821353, 0.06117503345012665, 0.023637868463993073, 0.023637868463993073], [0.0026393928565084934, 0.010474550537765026, 0.49836018681526184, 0.07133553922176361, 0.4171903431415558], [0.174669548869133, 0.19994701445102692, 0.10216647386550903, 0.2616084814071655, 0.2616084814071655], [0.6125897169113159, 0.13812075555324554, 0.13812075555324554, 0.1096930205821991, 0.001475778641179204], [0.12278584390878677, 0.39047154784202576, 0.02637454681098461, 0.06989650428295135, 0.39047154784202576], [0.003853496164083481, 0.015139615163207054, 0.488584965467453, 0.0038370743859559298, 0.488584965467453], [0.10503221303224564, 0.006086414679884911, 0.0074132937006652355, 0.8753816485404968, 0.006086414679884911], [0.40268653631210327, 0.011197904124855995, 0.0039807152934372425, 0.5470194816589355, 0.03511540964245796], [0.024307217448949814, 0.8350675702095032, 0.028605198487639427, 0.05600999295711517, 0.05600999295711517], [0.1654350310564041, 0.412499338388443, 0.412499338388443, 1.0596435458865017e-05, 0.009555641561746597], [0.12312520295381546, 0.12312520295381546, 0.6243762373924255, 0.12720271944999695, 0.002170671708881855], [0.024220596998929977, 0.024220596998929977, 0.033436961472034454, 0.9130704402923584, 0.005051412619650364], [0.0293242409825325, 0.08857400715351105, 0.009847584180533886, 0.009847584180533886, 0.8624066710472107], [0.6287145018577576, 0.3198375701904297, 0.0005679514724761248, 0.025439981371164322, 0.025439981371164322], [0.19006751477718353, 0.19006751477718353, 0.1347774863243103, 0.11755472421646118, 0.36753278970718384], [0.17662286758422852, 0.016292385756969452, 0.008342275395989418, 0.008342275395989418, 0.7904000878334045], [0.3036031723022461, 0.04787971079349518, 0.146756112575531, 0.25088050961494446, 0.25088050961494446], [0.48506492376327515, 0.02878301590681076, 0.0005725094815716147, 0.48506492376327515, 0.0005146242910996079], [0.7432655096054077, 0.10954984277486801, 0.04874135181307793, 0.04874135181307793, 0.049701955169439316], [0.0009519828017801046, 0.9417434334754944, 0.0035823192447423935, 0.0009519828017801046, 0.05277029797434807], [0.09767170995473862, 0.32791486382484436, 0.49409428238868713, 0.040159597992897034, 0.040159597992897034], [0.3220050632953644, 0.052667874842882156, 0.00745826680213213, 0.30893439054489136, 0.30893439054489136], [0.3228625953197479, 0.3099963963031769, 0.3099963963031769, 0.05442160740494728, 0.0027229879051446915], [0.0066922567784786224, 0.7854881286621094, 0.1498018056154251, 0.029008857905864716, 0.029008857905864716], [0.30487704277038574, 0.2825147211551666, 0.19286774098873138, 0.19286774098873138, 0.026872776448726654], [0.07463471591472626, 0.2667734920978546, 0.07463471591472626, 0.016215842217206955, 0.5677412748336792], [0.3029259443283081, 0.008688968606293201, 0.38044607639312744, 0.008688968606293201, 0.2992500066757202], [0.0009507772629149258, 0.051429178565740585, 0.5172457098960876, 0.24166898429393768, 0.18870531022548676], [0.14583051204681396, 0.060013506561517715, 0.09489571303129196, 0.09489571303129196, 0.6043645739555359], [0.18937896192073822, 0.00494705094024539, 0.28228768706321716, 0.241098552942276, 0.28228768706321716], [0.3521377742290497, 0.12288302183151245, 0.19698277115821838, 0.12288302183151245, 0.20511341094970703], [0.1856788843870163, 0.076894611120224, 0.3630885183811188, 0.3630885183811188, 0.011249431408941746], [0.2394530475139618, 0.15560945868492126, 0.04298362135887146, 0.04298362135887146, 0.518970251083374], [0.039338771253824234, 0.039338771253824234, 0.000718295865226537, 0.7874985933303833, 0.1331055760383606], [0.24179348349571228, 0.0804864689707756, 0.008531891740858555, 0.02112513594329357, 0.6480630040168762], [0.003366669174283743, 0.09138927608728409, 0.25545501708984375, 0.003366669174283743, 0.6464223265647888], [0.19943201541900635, 0.007332232780754566, 0.47488635778427124, 0.31101712584495544, 0.007332232780754566], [0.11116595566272736, 0.11116595566272736, 0.018671780824661255, 0.0436059944331646, 0.7153903245925903], [0.39166486263275146, 0.5300970077514648, 0.0312708355486393, 0.0312708355486393, 0.015696536749601364], [0.04579257220029831, 0.758452296257019, 0.04579257220029831, 0.0022252111230045557, 0.14773736894130707], [0.7115619778633118, 0.15757907927036285, 0.05197666212916374, 0.039441127330064774, 0.039441127330064774], [0.5520987510681152, 0.055959995836019516, 0.31295865774154663, 0.023022593930363655, 0.055959995836019516], [0.5071210265159607, 0.0065327598713338375, 0.07090280205011368, 0.07090280205011368, 0.34454062581062317], [0.005603683181107044, 0.005603683181107044, 0.2717287242412567, 0.13985347747802734, 0.5772104263305664], [0.06487615406513214, 0.8512030839920044, 0.007031602784991264, 0.06487615406513214, 0.012013019993901253], [0.0246026199311018, 0.1764703094959259, 0.19605034589767456, 0.1764703094959259, 0.4264064133167267], [0.3117506206035614, 0.3117506206035614, 0.26058417558670044, 0.032068848609924316, 0.08384571224451065], [0.4552883505821228, 0.03658086434006691, 0.04542312026023865, 0.4552883505821228, 0.007419311907142401], [0.1463634967803955, 0.1463634967803955, 0.09709850698709488, 0.5948367118835449, 0.01533783320337534], [0.04064551740884781, 0.17020395398139954, 0.03249436244368553, 0.5864521861076355, 0.17020395398139954], [0.16539902985095978, 0.06306763738393784, 0.6056329607963562, 0.16539902985095978, 0.000501318194437772], [0.38931870460510254, 0.10638492554426193, 0.25095734000205994, 0.25095734000205994, 0.0023816691245883703], [0.35080528259277344, 0.053049828857183456, 0.004853540565818548, 0.35080528259277344, 0.24048610031604767], [0.09327814728021622, 0.14312070608139038, 0.3145296275615692, 0.14312070608139038, 0.3059508204460144], [0.03899446502327919, 0.8367325663566589, 0.07123022526502609, 0.03899446502327919, 0.014048352837562561], [0.5466693043708801, 0.007417683489620686, 0.017344126477837563, 0.42115113139152527, 0.007417683489620686], [0.4859669506549835, 0.009146930649876595, 0.0173456110060215, 0.001573607325553894, 0.4859669506549835], [0.2329813539981842, 0.08534838259220123, 0.20812781155109406, 0.20812781155109406, 0.2654145658016205], [0.08809289336204529, 0.028298096731305122, 0.08809289336204529, 0.37822675704956055, 0.41728928685188293], [0.06858082115650177, 0.003818822791799903, 0.06858082115650177, 0.717429518699646, 0.14159004390239716], [0.29094454646110535, 0.10906600207090378, 0.29094454646110535, 0.18822921812534332, 0.1208157017827034], [0.4280102849006653, 0.12337028235197067, 0.31408751010894775, 0.12337028235197067, 0.011161706410348415], [0.30129605531692505, 0.08571040630340576, 0.30129605531692505, 0.05838460102677345, 0.2533128261566162], [0.0015809420729056, 0.9911750555038452, 0.0010571019956842065, 0.0015809420729056, 0.004605920519679785], [0.0033357213251292706, 0.13760612905025482, 0.4130095839500427, 0.4130095839500427, 0.0330389179289341], [8.863697439664975e-05, 0.4928218722343445, 0.009389449842274189, 0.4928218722343445, 0.0048781996592879295], [0.01701146550476551, 0.12700694799423218, 0.0006275030900724232, 0.0006275030900724232, 0.8547264933586121], [0.7758486270904541, 0.03706293925642967, 0.051221322268247604, 0.0679335668683052, 0.0679335668683052], [0.014759393408894539, 0.059814874082803726, 0.1006157249212265, 0.7241942882537842, 0.1006157249212265], [0.003573576221242547, 0.060411758720874786, 0.4861885607242584, 0.003573576221242547, 0.4462524354457855], [0.7146605253219604, 0.08198076486587524, 0.05231485515832901, 0.06906308978796005, 0.08198076486587524], [0.004574167542159557, 0.3055192232131958, 0.3393545150756836, 0.3393545150756836, 0.011197582818567753], [0.022970493882894516, 0.019577881321310997, 0.019577881321310997, 0.776106595993042, 0.1617671400308609], [0.145981565117836, 0.6506008505821228, 0.05188445746898651, 0.145981565117836, 0.005551562644541264], [0.24562163650989532, 0.059144921600818634, 0.059144921600818634, 0.007208460476249456, 0.6288800835609436], [0.006491611711680889, 0.09727288782596588, 0.005880828946828842, 0.005880828946828842, 0.8844738006591797], [0.0314260795712471, 0.18665581941604614, 0.38577941060066223, 0.18337352573871613, 0.2127651423215866], [0.028634415939450264, 0.15847928822040558, 0.0025593696627765894, 0.15847928822040558, 0.6518477201461792], [0.12387058883905411, 0.12387058883905411, 0.05898535996675491, 0.35884928703308105, 0.3344241678714752], [0.11331623047590256, 0.04115964099764824, 0.4487006664276123, 0.04115964099764824, 0.35566383600234985], [0.6953060030937195, 0.07089665532112122, 0.006395161151885986, 0.2210070639848709, 0.006395161151885986], [0.08339133858680725, 0.3533763587474823, 0.2814330458641052, 0.00036615002318285406, 0.2814330458641052], [0.18148978054523468, 0.008364924229681492, 0.18148978054523468, 0.5872550010681152, 0.04140051454305649], [0.3126070499420166, 0.09578663110733032, 0.571204423904419, 0.01020093634724617, 0.01020093634724617], [0.029352262616157532, 0.13807202875614166, 0.09071683883666992, 0.5497209429740906, 0.1921379119157791], [0.4460826814174652, 0.047608520835638046, 0.001074542524293065, 0.05915161222219467, 0.4460826814174652], [0.24615426361560822, 0.24615426361560822, 0.022617604583501816, 0.27173304557800293, 0.21334078907966614], [0.1353294998407364, 0.1373952031135559, 0.00019433895067777485, 0.1373952031135559, 0.5896856784820557], [0.22774669528007507, 0.07114147394895554, 0.3070579767227173, 0.16630706191062927, 0.22774669528007507], [0.31176769733428955, 0.324017733335495, 0.001476644305512309, 0.038720253854990005, 0.324017733335495], [0.09880707412958145, 0.09206432849168777, 0.006282202899456024, 0.09880707412958145, 0.7040392756462097], [0.4846757650375366, 0.11722493916749954, 0.39230212569236755, 0.0028986125253140926, 0.0028986125253140926], [0.028120333328843117, 0.004629364237189293, 0.016627777367830276, 0.475311279296875, 0.475311279296875], [0.1226436048746109, 0.1226436048746109, 0.3964063227176666, 0.025504443794488907, 0.3328019976615906], [0.0201016403734684, 0.0201016403734684, 0.19102084636688232, 0.6465333104133606, 0.12224255502223969], [0.3524249792098999, 0.3524249792098999, 0.04891292005777359, 0.11282924562692642, 0.13340793550014496], [0.6672223210334778, 0.06658744066953659, 0.008427951484918594, 0.19117483496665955, 0.06658744066953659], [0.7061144113540649, 0.003090634709224105, 0.2741311192512512, 0.013573174364864826, 0.003090634709224105], [0.4767378270626068, 0.0006748196901753545, 0.04076072946190834, 0.0050887903198599815, 0.4767378270626068], [0.3446999788284302, 0.3446999788284302, 0.014733805321156979, 0.008579228073358536, 0.28728699684143066], [0.2646864354610443, 0.3549683094024658, 0.14904752373695374, 0.0822502076625824, 0.14904752373695374], [0.06115563586354256, 5.2159797633066773e-05, 0.06115563586354256, 0.08066510409116745, 0.7969714999198914], [0.5946947932243347, 0.0011340503115206957, 0.12603113055229187, 0.12603113055229187, 0.15210893750190735], [0.31119394302368164, 0.21075519919395447, 0.1084018349647522, 0.31119394302368164, 0.058455128222703934], [0.0015511970268562436, 0.5651867985725403, 0.21002528071403503, 0.22168555855751038, 0.0015511970268562436], [0.38246774673461914, 0.10431793332099915, 0.02015581540763378, 0.02015581540763378, 0.4729026257991791], [0.0166757982224226, 0.006983407773077488, 0.3699240982532501, 0.5897408723831177, 0.0166757982224226], [0.23982997238636017, 0.017768314108252525, 0.40824005007743835, 0.09433165192604065, 0.23982997238636017], [0.15850482881069183, 0.10043196380138397, 0.10043196380138397, 0.6114414930343628, 0.029189789667725563], [0.08881188929080963, 0.09170622378587723, 0.00022044153593014926, 0.7781192064285278, 0.041142288595438004], [0.5885156393051147, 0.013179308734834194, 0.07255680859088898, 0.07255680859088898, 0.2531914710998535], [0.9600507020950317, 0.008036921732127666, 0.02352355420589447, 0.008036921732127666, 0.000351884460542351], [0.007142559625208378, 0.1640234738588333, 0.0003740720567293465, 0.828085720539093, 0.0003740720567293465], [0.9551406502723694, 0.0436934158205986, 0.0011015167692676187, 3.2187075703404844e-05, 3.2187075703404844e-05], [0.004493213724344969, 0.5404062271118164, 0.14197894930839539, 0.15656079351902008, 0.15656079351902008], [0.001385509967803955, 0.001385509967803955, 0.12265967577695847, 0.2649087905883789, 0.6096605658531189], [0.051431648433208466, 0.0015032972441986203, 0.051431648433208466, 0.8956230878829956, 1.0317187843611464e-05], [0.038797516375780106, 0.005507489200681448, 0.005507489200681448, 0.01889902353286743, 0.931288480758667], [0.046861108392477036, 0.22700807452201843, 0.43855834007263184, 0.22700807452201843, 0.06056441739201546], [0.00019439778407104313, 0.004843597300350666, 0.9435393214225769, 0.02571134641766548, 0.02571134641766548], [0.1302914172410965, 0.32965683937072754, 0.3641674220561981, 0.04559289291501045, 0.1302914172410965], [0.7930350303649902, 0.09648283571004868, 0.013775921426713467, 0.013775921426713467, 0.08293022960424423], [0.032035015523433685, 0.03656971454620361, 0.44566991925239563, 0.04005546122789383, 0.44566991925239563], [0.2562904953956604, 0.2562904953956604, 0.16688522696495056, 0.2915772795677185, 0.028956476598978043], [0.6334773302078247, 0.07409034669399261, 0.13108684122562408, 0.08725515753030777, 0.07409034669399261], [0.9940968751907349, 0.003219461068511009, 0.0025227819569408894, 8.047969458857551e-05, 8.047969458857551e-05], [0.3650681972503662, 0.029630087316036224, 0.44513067603111267, 0.04016386345028877, 0.12000712752342224], [0.3715667724609375, 0.08172056823968887, 0.270995169878006, 0.004722342360764742, 0.270995169878006], [0.6333823800086975, 0.16416195034980774, 0.010322283953428268, 0.04181879013776779, 0.1503145843744278], [0.07523030787706375, 0.07523030787706375, 0.017514782026410103, 0.00942729227244854, 0.8225972056388855], [0.25638699531555176, 0.6343541145324707, 0.012939992360770702, 0.08337892591953278, 0.012939992360770702], [0.08768830448389053, 0.16076457500457764, 0.16076457500457764, 0.12737388908863068, 0.46340861916542053], [0.04153050482273102, 0.37222912907600403, 0.11621252447366714, 0.09779862314462662, 0.37222912907600403], [0.23905827105045319, 0.013186287134885788, 0.028767377138137817, 0.47992977499961853, 0.23905827105045319], [0.42430242896080017, 0.026876524090766907, 0.03920309245586395, 0.4704149067401886, 0.03920309245586395], [0.537697970867157, 0.011656468734145164, 0.194580540060997, 0.12803250551223755, 0.12803250551223755], [0.0017615194665268064, 0.2544586658477783, 0.36375856399536133, 0.016262708231806755, 0.36375856399536133], [0.0028891873080283403, 0.6024581789970398, 0.0028891873080283403, 0.2738807499408722, 0.11788270622491837], [0.07825645804405212, 0.45417672395706177, 0.45417672395706177, 0.00974602997303009, 0.0036440775729715824], [0.04129841551184654, 0.8482725620269775, 0.032626111060380936, 0.045176804065704346, 0.032626111060380936], [0.7586736083030701, 0.19493652880191803, 0.007313413545489311, 0.007313413545489311, 0.03176300972700119], [0.56993168592453, 0.001346966135315597, 0.010720381513237953, 0.010720381513237953, 0.4072805345058441], [0.48770901560783386, 0.007708391174674034, 0.48770901560783386, 0.0028710581827908754, 0.014002451673150063], [0.4517885744571686, 0.08477072417736053, 0.36255308985710144, 0.016116833314299583, 0.08477072417736053], [0.055026065558195114, 0.055026065558195114, 0.7102178335189819, 0.0826830342411995, 0.09704700857400894], [0.0981701985001564, 0.035437844693660736, 0.3309510052204132, 0.5000030994415283, 0.035437844693660736], [0.005072297528386116, 0.005072297528386116, 0.1985660344362259, 0.6254572868347168, 0.16583210229873657], [5.614385827357182e-06, 0.499433696269989, 0.499433696269989, 0.0005374125321395695, 0.0005896459333598614], [0.6029165387153625, 0.17208079993724823, 0.09605918079614639, 0.09605918079614639, 0.03288431465625763], [0.03835470229387283, 0.9083442091941833, 0.0004320745065342635, 0.03835470229387283, 0.01451424602419138], [0.02812107466161251, 0.0026749924290925264, 0.1214383915066719, 0.8196445107460022, 0.02812107466161251], [0.6501234173774719, 0.1636650711297989, 0.02143331617116928, 0.1636650711297989, 0.0011131505016237497], [0.17010992765426636, 0.2675422132015228, 0.3917064964771271, 0.0005314840818755329, 0.17010992765426636], [0.566622793674469, 0.2090492844581604, 0.2090492844581604, 0.0018697284394875169, 0.013408890925347805], [0.4900953471660614, 0.003338384907692671, 0.4900953471660614, 0.0028549490962177515, 0.013616050593554974], [0.2999802827835083, 0.0018302209209650755, 0.34901294112205505, 0.34901294112205505, 0.00016357976710423827], [0.0019774127285927534, 0.11310409009456635, 0.017076872289180756, 0.8102742433547974, 0.05756737291812897], [0.3169766962528229, 0.3416142165660858, 0.01275173295289278, 0.011680608615279198, 0.3169766962528229], [0.5085511207580566, 0.4633043110370636, 0.018831059336662292, 0.004656784236431122, 0.004656784236431122], [0.51251620054245, 0.21721862256526947, 0.04933178797364235, 0.21721862256526947, 0.0037148238625377417], [0.14051751792430878, 0.3410901725292206, 0.11705125868320465, 0.06025087088346481, 0.3410901725292206], [0.6474436521530151, 0.005848133470863104, 0.32181864976882935, 0.012444755993783474, 0.012444755993783474], [0.6436743140220642, 0.2633588910102844, 0.005237081553786993, 0.05390989035367966, 0.03381974250078201], [0.06736283749341965, 0.012353474274277687, 0.05123843252658844, 0.43452268838882446, 0.43452268838882446], [0.13683313131332397, 0.25965121388435364, 0.41803523898124695, 0.04864722490310669, 0.13683313131332397], [0.07896676659584045, 0.07896676659584045, 0.1466517150402069, 0.01248630415648222, 0.6829283833503723], [0.15202675759792328, 0.06496445089578629, 0.23051999509334564, 0.4875243306159973, 0.06496445089578629], [0.11855793744325638, 0.29631757736206055, 0.41850486397743225, 0.11855793744325638, 0.048061709851026535], [0.05768730118870735, 0.011390777304768562, 0.8730722069740295, 0.00016243080608546734, 0.05768730118870735], [0.846901535987854, 0.021182985976338387, 0.021182985976338387, 0.08712392300367355, 0.023608587682247162], [0.1607568860054016, 0.05675855278968811, 0.21573109924793243, 0.05675855278968811, 0.5099948644638062], [0.01820949837565422, 0.012449873611330986, 0.6422538161277771, 0.16354340314865112, 0.16354340314865112], [0.027682127431035042, 0.09103585034608841, 0.22051802277565002, 0.027682127431035042, 0.63308185338974], [0.01873772032558918, 0.2791774272918701, 0.29938310384750366, 0.10331864655017853, 0.29938310384750366], [0.021499933674931526, 0.021499933674931526, 0.7353348731994629, 0.051027946174144745, 0.1706373393535614], [0.22503125667572021, 0.1877172738313675, 0.007002331782132387, 0.3552178144454956, 0.22503125667572021], [0.332659512758255, 0.42791905999183655, 0.11763112246990204, 0.004159170668572187, 0.11763112246990204], [0.07275619357824326, 0.4422745108604431, 0.03457057848572731, 0.008124224841594696, 0.4422745108604431], [0.39974093437194824, 0.17850206792354584, 0.0177505761384964, 0.004265474621206522, 0.39974093437194824], [0.013916121795773506, 0.18241631984710693, 0.6163802742958069, 0.004871004726737738, 0.18241631984710693], [0.10737401992082596, 0.008752038702368736, 0.003173798555508256, 0.8058851957321167, 0.07481495290994644], [0.20001740753650665, 0.005932296626269817, 0.3634331226348877, 0.03200819715857506, 0.3986089825630188], [0.2756043076515198, 0.29583027958869934, 0.12229454517364502, 0.030666599050164223, 0.2756043076515198], [0.017891818657517433, 0.3680066466331482, 0.3893725574016571, 0.017891818657517433, 0.20683716237545013], [0.855281412601471, 0.016181008890271187, 0.01671222783625126, 0.09511304646730423, 0.01671222783625126], [0.08660143613815308, 0.0014552093343809247, 0.01677730493247509, 0.8085646033287048, 0.08660143613815308], [0.09185437858104706, 0.0003571890702005476, 0.6087794303894043, 0.0008940885309129953, 0.2981148958206177], [0.057623591274023056, 0.47421079874038696, 0.40938764810562134, 0.057623591274023056, 0.0011543516302481294], [0.12095938622951508, 0.08406416326761246, 0.6500178575515747, 0.023999230936169624, 0.12095938622951508], [0.04373492673039436, 0.04766308143734932, 0.4467291235923767, 0.4467291235923767, 0.015143677592277527], [0.0013558091595768929, 0.005771474447101355, 0.03827894106507301, 0.03827894106507301, 0.9163148999214172], [0.8839038610458374, 0.04897036403417587, 0.06076632812619209, 0.003179737366735935, 0.003179737366735935], [0.02031075954437256, 0.0021975787822157145, 0.02031075954437256, 0.9563373923301697, 0.000843541813082993], [0.25323355197906494, 8.673623960930854e-05, 0.20513150095939636, 0.13906709849834442, 0.4024811089038849], [0.3173571825027466, 0.061506446450948715, 0.5406941175460815, 0.018935736268758774, 0.061506446450948715], [0.4447133243083954, 5.09657766087912e-05, 0.0010136020136997104, 0.10950876772403717, 0.4447133243083954], [0.48106926679611206, 0.17041026055812836, 0.1481497436761856, 0.052220892161130905, 0.1481497436761856], [0.4035152792930603, 0.02811507321894169, 0.13751749694347382, 0.4035152792930603, 0.02733689732849598], [0.062106821686029434, 0.09273606538772583, 0.21153052151203156, 0.5715197920799255, 0.062106821686029434], [0.20682694017887115, 0.3360949754714966, 0.08960727602243423, 1.9571187294786796e-05, 0.36745113134384155], [0.020563682541251183, 0.00032190774800255895, 0.903069794178009, 0.00032190774800255895, 0.07572279125452042], [0.00019891928241122514, 0.007825293578207493, 0.8345384001731873, 0.14961205422878265, 0.007825293578207493], [0.005290323868393898, 0.0009979803580790758, 0.01165766455233097, 0.0009979803580790758, 0.9810560345649719], [0.03503194823861122, 0.07552735507488251, 0.737266480922699, 0.11714223772287369, 0.03503194823861122], [0.24860645830631256, 0.1815803050994873, 0.2176893651485443, 0.014564563520252705, 0.337559312582016], [0.05653466656804085, 0.8261696100234985, 0.0013660957338288426, 0.05653466656804085, 0.05939497426152229], [0.3365461230278015, 0.03197883814573288, 0.3365461230278015, 0.018707364797592163, 0.27622148394584656], [0.160812109708786, 0.5489760637283325, 0.160812109708786, 7.119469955796376e-05, 0.12932851910591125], [0.007329981308430433, 0.007329981308430433, 0.14039300382137299, 0.010207360610365868, 0.8347396850585938], [0.025379862636327744, 0.3185805082321167, 0.00443998072296381, 0.025379862636327744, 0.6262198090553284], [0.044232599437236786, 0.1748163104057312, 0.12001733481884003, 0.540916383266449, 0.12001733481884003], [0.051332488656044006, 0.10192073881626129, 0.7745971083641052, 0.051332488656044006, 0.020817194133996964], [0.9249124526977539, 0.000217415887163952, 0.037230104207992554, 0.037230104207992554, 0.0004099218058399856], [0.27756208181381226, 0.21984638273715973, 0.27756208181381226, 0.20232491195201874, 0.02270461991429329], [0.38614559173583984, 0.38614559173583984, 0.10557720810174942, 0.0647955909371376, 0.05733601003885269], [0.03686479479074478, 0.3080800771713257, 0.3080800771713257, 0.32958805561065674, 0.01738700270652771], [0.281485915184021, 0.02348218485713005, 0.39412346482276917, 0.281485915184021, 0.019422492012381554], [0.33648914098739624, 0.003052761312574148, 0.022348349913954735, 0.30162057280540466, 0.33648914098739624], [0.02043718285858631, 0.027663106098771095, 0.34947654604911804, 0.5747600793838501, 0.027663106098771095], [0.0020049086306244135, 0.00010109661525348201, 0.42919662594795227, 0.139500692486763, 0.42919662594795227], [0.14125321805477142, 0.05377078428864479, 0.005751343909651041, 0.14125321805477142, 0.6579714417457581], [0.2065921127796173, 0.4175342619419098, 0.0009912120876833797, 0.0009912120876833797, 0.3738912343978882], [0.08916707336902618, 0.43472012877464294, 0.43472012877464294, 0.02911350317299366, 0.012279174290597439], [0.20599760115146637, 0.20599760115146637, 0.035435743629932404, 0.11265645921230316, 0.4399126470088959], [0.4174049496650696, 0.031634148210287094, 0.07999536395072937, 0.05356062203645706, 0.4174049496650696], [0.0065591405145823956, 0.0065591405145823956, 0.3144417703151703, 0.3045072555541992, 0.3679327070713043], [0.3638526499271393, 0.010336870327591896, 0.10833277553319931, 0.15362511575222015, 0.3638526499271393], [0.002449499908834696, 0.8169236779212952, 0.1777094453573227, 0.00046788190957158804, 0.002449499908834696], [0.13513469696044922, 0.34374547004699707, 0.5188713669776917, 0.0021664686501026154, 8.2017584645655e-05], [0.5482897162437439, 0.132863387465477, 0.05831631273031235, 0.12766717374324799, 0.132863387465477], [0.009341618977487087, 0.028162073343992233, 0.007032324559986591, 0.009341618977487087, 0.9461222887039185], [0.4881226718425751, 0.00201900745742023, 0.4881226718425751, 0.01862504333257675, 0.0031105682719498873], [1.608636557648424e-05, 0.8651160597801208, 0.04730358347296715, 0.01573990099132061, 0.07182446867227554], [0.050050072371959686, 0.010641565546393394, 0.0005649102968163788, 0.938178539276123, 0.0005649102968163788], [0.24755282700061798, 0.07499034702777863, 0.24755282700061798, 0.23771639168262482, 0.1921875923871994], [0.0007407920784316957, 0.0007407920784316957, 0.017712293192744255, 0.5306604504585266, 0.4501456618309021], [0.018176546320319176, 0.005935128778219223, 0.005935128778219223, 0.23558063805103302, 0.7343724966049194], [0.3770022690296173, 0.22212691605091095, 0.14759592711925507, 0.14759592711925507, 0.10567902028560638], [0.1338874101638794, 0.377925843000412, 0.02644672989845276, 0.08381422609090805, 0.377925843000412], [0.1269482523202896, 0.4222136437892914, 0.1269482523202896, 0.06130345165729523, 0.26258647441864014], [0.5403797626495361, 0.19543194770812988, 0.19543194770812988, 0.006680752150714397, 0.06207556650042534], [0.05315988510847092, 0.6893393397331238, 0.2015269696712494, 0.0028139075729995966, 0.05315988510847092], [0.029008623212575912, 0.34119054675102234, 0.029008623212575912, 0.05575593188405037, 0.5450363159179688], [0.042196277529001236, 0.031192658469080925, 0.04998627305030823, 0.8754317164421082, 0.0011930686887353659], [0.0054800850339233875, 0.9794514775276184, 0.0054800850339233875, 0.009326295927166939, 0.0002620775194372982], [0.12366391718387604, 0.42590081691741943, 0.0007231449126265943, 0.02381129190325737, 0.42590081691741943], [0.0005695823929272592, 0.12421533465385437, 0.8595391511917114, 0.015106328763067722, 0.0005695823929272592], [0.008118955418467522, 9.278219658881426e-05, 0.005476787220686674, 0.9808346629142761, 0.005476787220686674], [0.643929660320282, 0.0712781473994255, 0.0712781473994255, 0.07870697230100632, 0.13480712473392487], [0.2658698558807373, 0.058875568211078644, 0.2939557135105133, 0.2939557135105133, 0.08734309673309326], [0.004122293088585138, 0.004122293088585138, 0.9904638528823853, 4.4406126107787713e-05, 0.0012471477966755629], [0.041437726467847824, 0.051457829773426056, 0.7227188944816589, 0.051457829773426056, 0.1329278200864792], [0.013286516070365906, 0.2528396248817444, 0.26468878984451294, 0.14722467958927155, 0.32196044921875], [0.4823935031890869, 0.033290937542915344, 0.4823935031890869, 0.0018882272997871041, 3.38413956342265e-05], [0.6974824070930481, 0.013045268133282661, 0.013045268133282661, 0.05437786132097244, 0.22204920649528503], [0.28872641921043396, 0.28872641921043396, 0.2009715735912323, 0.04334660619497299, 0.17822889983654022], [0.0007516859332099557, 0.6326507925987244, 0.09367921948432922, 0.0007516859332099557, 0.27216657996177673], [0.7405024766921997, 0.04537690058350563, 0.00862679909914732, 0.0840400755405426, 0.12145370244979858], [0.1669139862060547, 0.1669139862060547, 0.2572641670703888, 0.04449797794222832, 0.3644099235534668], [0.06147778779268265, 0.2298426330089569, 0.3227178454399109, 0.06324383616447449, 0.3227178454399109], [0.4416325092315674, 0.4416325092315674, 0.001466360641643405, 0.08306105434894562, 0.03220752254128456], [0.03818892687559128, 0.09634140133857727, 0.8198907971382141, 0.03818892687559128, 0.007389890495687723], [0.14412502944469452, 0.00180910958442837, 0.8300710320472717, 0.014508781023323536, 0.00948603916913271], [0.013763118535280228, 0.013763118535280228, 0.04650473967194557, 0.6939548850059509, 0.23201411962509155], [0.05545606091618538, 0.3188621997833252, 0.2656375467777252, 0.2656375467777252, 0.0944066122174263], [0.33908596634864807, 0.2126937210559845, 0.08576846867799759, 0.023365847766399384, 0.33908596634864807], [0.7235745787620544, 0.0026185186579823494, 0.0026185186579823494, 0.269583523273468, 0.0016049192054197192], [0.38782715797424316, 0.5387998819351196, 0.053451646119356155, 0.009960638359189034, 0.009960638359189034], [0.7341439723968506, 0.11280844360589981, 0.03303266689181328, 0.007206473499536514, 0.11280844360589981], [0.43517065048217773, 0.15393252670764923, 0.15393252670764923, 0.024949360638856888, 0.23201492428779602], [0.0036899081896990538, 0.045754849910736084, 0.14154455065727234, 0.05471857637166977, 0.7542920708656311], [0.03649755194783211, 0.03649755194783211, 0.13192901015281677, 0.44709083437919617, 0.34798499941825867], [0.4909471571445465, 0.25346702337265015, 0.25346702337265015, 0.00010482361540198326, 0.002013999503105879], [0.13347597420215607, 0.0732981264591217, 0.555952250957489, 0.1639755666255951, 0.0732981264591217], [0.5113517642021179, 0.4248684346675873, 0.022488119080662727, 0.022488119080662727, 0.01880352757871151], [0.3728713095188141, 0.2459322065114975, 0.00035245015169493854, 0.3728713095188141, 0.007972708903253078], [0.8569706678390503, 0.0016540618380531669, 0.13868461549282074, 0.0016540618380531669, 0.001036583911627531], [0.023677174001932144, 0.05645577609539032, 0.06985902786254883, 0.023677174001932144, 0.8263309001922607], [0.001749051152728498, 0.1356857568025589, 0.6985094547271729, 0.028369922190904617, 0.1356857568025589], [0.030324233695864677, 0.054422225803136826, 0.054422225803136826, 0.5970661640167236, 0.2637650668621063], [0.028559459373354912, 0.00976716261357069, 0.5478466153144836, 0.028559459373354912, 0.3852672874927521], [0.20199912786483765, 0.47910624742507935, 0.20199912786483765, 0.0416252426803112, 0.07527031749486923], [0.27376681566238403, 0.2638845145702362, 0.18460118770599365, 0.2638845145702362, 0.013863016851246357], [0.0261356383562088, 0.07976517826318741, 0.1969054788351059, 0.5002883076667786, 0.1969054788351059], [0.06407081335783005, 0.06407081335783005, 0.008135690353810787, 0.863507091999054, 0.0002155608672183007], [0.0017674091504886746, 0.0017674091504886746, 0.07301338762044907, 0.018744438886642456, 0.9047073125839233], [0.640716552734375, 0.003468290204182267, 0.14611025154590607, 0.14611025154590607, 0.06359470635652542], [0.02569139376282692, 0.0010138163343071938, 0.10722816735506058, 0.7588385343551636, 0.10722816735506058], [0.18173649907112122, 0.06391686946153641, 0.0839940533041954, 0.48861607909202576, 0.18173649907112122], [0.8188424706459045, 1.6234298527706414e-05, 0.17889194190502167, 0.0001892520667752251, 0.0020601495634764433], [0.4395827054977417, 0.0009561615297570825, 0.10705521702766418, 0.4395827054977417, 0.012823091819882393], [0.010036378167569637, 0.0334879495203495, 0.7672804594039917, 0.09459760040044785, 0.09459760040044785], [0.0029787407256662846, 0.7391427755355835, 0.043265823274850845, 0.1073063313961029, 0.1073063313961029], [0.06679649651050568, 0.019146261736750603, 0.02448466047644615, 0.87042635679245, 0.019146261736750603], [0.087065190076828, 0.02185208350419998, 0.7531026601791382, 0.050914786756038666, 0.087065190076828], [0.6862252950668335, 0.08961022645235062, 0.040089089423418045, 0.09446518123149872, 0.08961022645235062], [0.01879008673131466, 0.4099149703979492, 0.10139142721891403, 0.3685120642185211, 0.10139142721891403], [0.23138520121574402, 0.007981274276971817, 0.3210485279560089, 0.23138520121574402, 0.20819979906082153], [0.00029619407723657787, 0.00720948027446866, 0.9496863484382629, 0.00016639924433548003, 0.04264158010482788], [0.059382446110248566, 0.3993256688117981, 0.3993256688117981, 0.007215519435703754, 0.13475069403648376], [0.014585984870791435, 0.15427668392658234, 0.6824804544448853, 0.014585984870791435, 0.13407084345817566], [0.00032850151183083653, 0.4033765494823456, 0.4033765494823456, 0.13996949791908264, 0.05294893682003021], [0.39419084787368774, 0.5054238438606262, 0.0498688742518425, 0.0498688742518425, 0.0006476127891801298], [0.014605548232793808, 0.05977436155080795, 0.060486357659101486, 0.8046473264694214, 0.060486357659101486], [0.6651564836502075, 0.0006604806985706091, 0.25394588708877563, 0.07957661896944046, 0.0006604806985706091], [0.003604411380365491, 0.5484772324562073, 0.02919762209057808, 0.20936036109924316, 0.20936036109924316], [0.011306153610348701, 0.40662112832069397, 0.0014252836117520928, 0.29032373428344727, 0.29032373428344727], [5.017765488446457e-06, 0.001992297125980258, 0.16224762797355652, 0.41787752509117126, 0.41787752509117126], [0.007425031624734402, 0.00017802001093514264, 0.9923096895217896, 4.360476305009797e-05, 4.360476305009797e-05], [0.191209614276886, 0.1857060343027115, 0.1857060343027115, 0.019652489572763443, 0.4177258312702179], [0.00023192793014459312, 0.9664508700370789, 0.010556813329458237, 0.012203569523990154, 0.010556813329458237], [0.0015245273243635893, 0.5681278109550476, 0.43012699484825134, 0.00011035153875127435, 0.00011035153875127435], [0.04654862731695175, 0.04654862731695175, 0.06301714479923248, 0.18097710609436035, 0.6629084348678589], [0.1352791041135788, 0.5181919932365417, 0.001755999168381095, 0.20949383080005646, 0.1352791041135788], [0.48244762420654297, 0.04392559453845024, 0.16052117943763733, 0.15258435904979706, 0.16052117943763733], [0.02706841565668583, 0.6746031045913696, 0.02706841565668583, 0.07639258354902267, 0.19486741721630096], [0.043034400790929794, 0.3526918292045593, 0.5594198703765869, 0.043034400790929794, 0.0018195611191913486], [0.09277147799730301, 0.40605518221855164, 0.05898410081863403, 0.09277147799730301, 0.3494177460670471], [0.2640291750431061, 0.010110664181411266, 0.2660976052284241, 0.19573338329792023, 0.2640291750431061], [0.2922319173812866, 0.2922319173812866, 0.06670134514570236, 0.09246931970119476, 0.2563655376434326], [0.2157144397497177, 0.587346076965332, 0.005184858106076717, 0.18656985461711884, 0.005184858106076717], [0.06563791632652283, 0.7882013916969299, 0.06634718179702759, 0.014175580814480782, 0.06563791632652283], [0.46386268734931946, 0.0009435303509235382, 0.5209986567497253, 0.00481406319886446, 0.009381061419844627], [0.009890906512737274, 0.05686202645301819, 0.22529853880405426, 0.009890906512737274, 0.6980575919151306], [0.006980015896260738, 0.05954251438379288, 0.8975322842597961, 0.028965139761567116, 0.006980015896260738], [0.062006618827581406, 0.028681596741080284, 0.062006618827581406, 0.7754605412483215, 0.07184455543756485], [0.05582989379763603, 0.14100180566310883, 0.7321571111679077, 0.015181305818259716, 0.05582989379763603], [0.14224818348884583, 0.14224818348884583, 0.15875406563282013, 0.04398965463042259, 0.5127599239349365], [0.0009758471860550344, 0.14769820868968964, 0.21950578689575195, 0.48412197828292847, 0.14769820868968964], [0.02858857624232769, 0.40623342990875244, 0.4619050621986389, 0.07468439638614655, 0.02858857624232769], [0.003318882081657648, 0.21438701450824738, 0.5078763961791992, 0.21438701450824738, 0.06003065034747124], [0.03830888867378235, 0.023431558161973953, 0.023431558161973953, 0.23739439249038696, 0.6774336099624634], [0.005253534764051437, 0.0010136631317436695, 0.005253534764051437, 0.22596050798892975, 0.7625187635421753], [0.06622583419084549, 0.24874752759933472, 0.24874752759933472, 0.279163658618927, 0.15711544454097748], [0.6561928987503052, 0.14447139203548431, 0.023267166689038277, 0.023267166689038277, 0.15280139446258545], [0.026939069852232933, 0.4766818583011627, 0.016510719433426857, 0.4766818583011627, 0.0031865735072642565], [0.005202252417802811, 0.079337939620018, 0.3546577990055084, 0.3546577990055084, 0.20614422857761383], [0.10513196140527725, 0.0029679513536393642, 0.8126484751701355, 0.0029679513536393642, 0.07628361880779266], [0.2869417369365692, 0.10404618084430695, 0.3217446804046631, 0.2869417369365692, 0.0003256976488046348], [0.23663470149040222, 0.05436582490801811, 0.5982458591461182, 0.05436582490801811, 0.056387778371572495], [0.007416761480271816, 0.1033325120806694, 0.007416761480271816, 0.765982449054718, 0.11585148423910141], [0.1773880571126938, 0.006082253064960241, 0.36325356364250183, 0.09002256393432617, 0.36325356364250183], [0.06493710726499557, 0.08914431184530258, 0.4106074273586273, 0.21765555441379547, 0.21765555441379547], [0.07052389532327652, 0.000838005100376904, 0.01484031043946743, 0.003776165656745434, 0.9100216627120972], [0.27494046092033386, 0.18934525549411774, 0.0625462532043457, 0.19822752475738525, 0.27494046092033386], [0.0731317326426506, 0.028712471947073936, 0.028712471947073936, 0.5090736150741577, 0.3603696823120117], [0.0003672259917948395, 0.2106403261423111, 0.600337028503418, 0.1882881373167038, 0.0003672259917948395], [0.4146471917629242, 0.04941440373659134, 0.12126141786575317, 2.987058542203158e-05, 0.4146471917629242], [0.3799129128456116, 0.06806955486536026, 0.4085378348827362, 0.06806955486536026, 0.07541009038686752], [0.07683484256267548, 0.6640923619270325, 0.07683484256267548, 0.18098248541355133, 0.0012555142166092992], [0.012167451903223991, 0.005848262459039688, 0.3109782934188843, 0.3355029821395874, 0.3355029821395874], [0.09040922671556473, 0.7267958521842957, 0.06606023013591766, 0.05836733430624008, 0.05836733430624008], [0.07305178046226501, 0.03582004830241203, 0.07305178046226501, 0.8159228563308716, 0.0021534692496061325], [0.04238768294453621, 0.05860608443617821, 0.8208067417144775, 0.019593380391597748, 0.05860608443617821], [0.041583165526390076, 0.24135863780975342, 0.23189358413219452, 0.4435814619064331, 0.041583165526390076], [0.47157996892929077, 0.03947487100958824, 0.01735980249941349, 0.47157996892929077, 5.441454050014727e-06], [0.1127995103597641, 0.261321485042572, 0.623545229434967, 0.001166906557045877, 0.001166906557045877], [0.059244412928819656, 0.3587522506713867, 0.1963212788105011, 0.059244412928819656, 0.3264375925064087], [0.16742095351219177, 0.11764690279960632, 0.4482884407043457, 0.1489967554807663, 0.11764690279960632], [0.4031050503253937, 0.14685797691345215, 0.17795899510383606, 0.14685797691345215, 0.12522004544734955], [0.0008848727447912097, 0.9785066246986389, 0.003696303116157651, 0.008456065319478512, 0.008456065319478512], [0.10689873993396759, 0.10689873993396759, 0.763817548751831, 0.015035044401884079, 0.007349877152591944], [0.0003214303287677467, 0.26212409138679504, 0.021754708141088486, 0.45367565751075745, 0.26212409138679504], [0.03121824748814106, 0.006842712871730328, 0.4699261784553528, 0.006842712871730328, 0.4851701259613037], [0.10195295512676239, 0.10195295512676239, 0.30388861894607544, 0.13761372864246368, 0.3545917272567749], [0.3572356104850769, 0.0090570580214262, 0.3572356104850769, 0.04875079169869423, 0.22772091627120972], [0.02832172065973282, 0.5576772689819336, 0.02832172065973282, 0.022365408018231392, 0.36331385374069214], [0.09686064720153809, 0.03690019249916077, 0.7292395830154419, 0.03690019249916077, 0.10009932518005371], [0.000200103095266968, 0.18333782255649567, 0.000200103095266968, 0.8078562617301941, 0.008405720815062523], [0.1535916030406952, 0.505767285823822, 0.00020523443527054042, 0.1535916030406952, 0.18684421479701996], [0.113413006067276, 0.0011984611628577113, 0.113413006067276, 0.7668663859367371, 0.005109142512083054], [0.15649950504302979, 0.0013951516011729836, 0.041797738522291183, 0.400153785943985, 0.400153785943985], [0.8132560849189758, 0.08441099524497986, 0.010194982402026653, 0.08194293081760406, 0.010194982402026653], [0.09006170183420181, 0.06271243840456009, 0.7251192927360535, 0.09006170183420181, 0.03204488009214401], [0.04089009389281273, 0.43687504529953003, 0.07987631857395172, 0.43687504529953003, 0.005483511835336685], [0.18659716844558716, 0.1133982390165329, 0.2853008806705475, 0.3706871569156647, 0.04401656240224838], [0.09328725934028625, 0.09328725934028625, 0.3238743245601654, 0.3667733371257782, 0.1227777749300003], [0.13167482614517212, 0.034894563257694244, 0.010614177212119102, 0.8122022151947021, 0.010614177212119102], [0.15727326273918152, 0.030865289270877838, 0.15727326273918152, 0.6401443481445312, 0.014443812891840935], [0.27659842371940613, 0.27659842371940613, 0.011693466454744339, 0.3925769627094269, 0.04253276437520981], [0.08225928992033005, 0.34179797768592834, 0.28719064593315125, 0.0015614667208865285, 0.28719064593315125], [0.44475576281547546, 0.01073021162301302, 0.09823714196681976, 0.44475576281547546, 0.0015211689751595259], [0.027141708880662918, 0.003739210544154048, 0.027141708880662918, 0.02370535023510456, 0.918272078037262], [0.05248701572418213, 0.4477405846118927, 0.407749742269516, 0.046011291444301605, 0.046011291444301605], [0.0025773521047085524, 0.33302202820777893, 0.0025773521047085524, 0.014337842352688313, 0.6474854350090027], [0.3530479967594147, 0.17127037048339844, 0.3530479967594147, 0.08517452329397202, 0.03745919093489647], [0.08188025653362274, 0.08188025653362274, 0.0030107563361525536, 0.09121781587600708, 0.7420109510421753], [0.4854961931705475, 0.08177530765533447, 0.08177530765533447, 0.015469036065042019, 0.33548423647880554], [0.005491125863045454, 0.18852978944778442, 0.6315454840660095, 0.005491125863045454, 0.16894248127937317], [0.6011663675308228, 0.11077754944562912, 0.08602867275476456, 0.09124990552663803, 0.11077754944562912], [0.0016027168603613973, 0.0016027168603613973, 0.5842321515083313, 0.06789178401231766, 0.3446706235408783], [0.02914348803460598, 0.16779690980911255, 0.06484200805425644, 0.02914348803460598, 0.7090741395950317], [0.04019416868686676, 0.0038263523019850254, 0.08197170495986938, 0.8701814413070679, 0.0038263523019850254], [0.01779365725815296, 0.9149529337882996, 0.0010559569345787168, 0.0651414543390274, 0.0010559569345787168], [0.0005953078507445753, 0.9800129532814026, 0.007303184829652309, 0.0005953078507445753, 0.011493232101202011], [0.04521792009472847, 0.5678086876869202, 0.19346973299980164, 3.3943837479455397e-05, 0.19346973299980164], [0.30427876114845276, 0.30427876114845276, 0.20830263197422028, 0.007463016081601381, 0.1756768673658371], [0.6996142864227295, 0.2559986412525177, 0.020131736993789673, 0.00412365747615695, 0.020131736993789673], [0.18534934520721436, 0.0008307757088914514, 0.40655815601348877, 0.40655815601348877, 0.000703508616425097], [0.03301037847995758, 0.3617278039455414, 0.3617278039455414, 0.0978061780333519, 0.14572782814502716], [0.0023082667030394077, 0.0023082667030394077, 0.3072073459625244, 0.004711742978543043, 0.6834643483161926], [0.10704746097326279, 0.052853263914585114, 0.023384414613246918, 0.8150463104248047, 0.0016684941947460175], [0.9310974478721619, 0.001897507579997182, 0.06463130563497543, 0.0011868514120578766, 0.0011868514120578766], [0.052344392985105515, 0.45633944869041443, 0.019269684329628944, 0.45633944869041443, 0.015707001090049744], [0.47326210141181946, 0.4972207248210907, 0.0010394785786047578, 0.027438214048743248, 0.0010394785786047578], [0.02690974250435829, 0.9534697532653809, 0.005436391104012728, 0.008747681975364685, 0.005436391104012728], [0.08309365063905716, 0.00484792934730649, 0.44926977157592773, 0.013518871739506721, 0.44926977157592773], [0.24748028814792633, 0.5716487169265747, 0.11743249744176865, 0.031719230115413666, 0.031719230115413666], [0.06349609047174454, 0.47069051861763, 0.2013382911682129, 0.2013382911682129, 0.06313681602478027], [0.004328468814492226, 0.20677879452705383, 0.39200344681739807, 0.00488583417609334, 0.39200344681739807], [0.08076149225234985, 0.3929583430290222, 0.26017725467681885, 0.13305145502090454, 0.13305145502090454], [0.2376784384250641, 0.2376784384250641, 0.013653670437633991, 0.00018019451817963272, 0.5108093023300171], [0.41223078966140747, 0.021727126091718674, 0.017494045197963715, 0.41223078966140747, 0.13631725311279297], [0.22047916054725647, 0.47516459226608276, 0.08059342205524445, 0.019220789894461632, 0.20454202592372894], [0.8789289593696594, 0.04053680598735809, 0.04053680598735809, 0.014515030197799206, 0.02548239752650261], [0.0021605303045362234, 0.0021605303045362234, 0.07679266482591629, 0.017539318650960922, 0.9013468623161316], [0.007684770040214062, 0.8509888648986816, 0.0024431420024484396, 0.0024431420024484396, 0.13644014298915863], [0.18934467434883118, 0.44964510202407837, 0.0743630900979042, 0.09730245918035507, 0.18934467434883118], [0.3438832461833954, 0.2525615692138672, 0.01919570192694664, 0.3438832461833954, 0.040476243942976], [0.00016266370948869735, 0.05323343724012375, 0.45852887630462646, 0.029546141624450684, 0.45852887630462646], [0.01044229231774807, 0.8099926114082336, 0.0018599781906232238, 0.09379331767559052, 0.08391182124614716], [0.7016193866729736, 0.017505692318081856, 0.26111969351768494, 0.017505692318081856, 0.0022495905868709087], [0.17739315330982208, 0.17739315330982208, 0.043163612484931946, 0.5949581265449524, 0.007091927342116833], [0.008300736546516418, 0.006666059140115976, 0.07521793246269226, 0.9035556316375732, 0.006259579211473465], [0.020008208230137825, 0.03507719188928604, 0.8931458592414856, 0.03507719188928604, 0.016691626980900764], [0.01676614210009575, 0.5639650225639343, 0.3966071307659149, 0.005895561538636684, 0.01676614210009575], [0.005144094116985798, 0.005144094116985798, 0.0013231419725343585, 0.9785217046737671, 0.009867043234407902], [0.25006917119026184, 0.021716173738241196, 0.335362046957016, 0.335362046957016, 0.057490624487400055], [0.20391160249710083, 0.20391160249710083, 0.4236496090888977, 0.07082166522741318, 0.09770546108484268], [0.013852476142346859, 9.183050860883668e-05, 0.1815093457698822, 0.40227317810058594, 0.40227317810058594], [0.11184464395046234, 0.7863089442253113, 7.955988985486329e-05, 0.1008821353316307, 0.0008847957942634821], [0.7675634622573853, 0.07515345513820648, 0.013048366643488407, 0.07515345513820648, 0.06908129900693893], [0.2478291541337967, 0.023715313524007797, 0.7045517563819885, 0.0001885291130747646, 0.023715313524007797], [0.014464858919382095, 0.037243954837322235, 0.050658464431762695, 0.014464858919382095, 0.8831678032875061], [0.4658718705177307, 0.20878329873085022, 0.0006267260177992284, 0.11593479663133621, 0.20878329873085022], [0.0828852504491806, 0.1192900612950325, 0.0828852504491806, 0.36995550990104675, 0.34498387575149536], [0.18008935451507568, 0.05282828211784363, 0.44622695446014404, 0.05282828211784363, 0.2680271863937378], [0.018118420615792274, 0.29125112295150757, 0.6734240055084229, 0.00860324501991272, 0.00860324501991272], [0.0013474371517077088, 0.040902845561504364, 0.0013474371517077088, 0.9393467903137207, 0.017055517062544823], [0.16242636740207672, 0.00014410234871320426, 3.90860514016822e-05, 0.8372463583946228, 0.00014410234871320426], [0.0540393590927124, 0.1006351187825203, 0.7010830640792847, 0.0540393590927124, 0.09020309895277023], [0.3400872051715851, 0.3400872051715851, 0.05254657194018364, 0.17054779827594757, 0.0967312678694725], [0.0002870537282433361, 0.06253143399953842, 0.3106039762496948, 0.06253143399953842, 0.5640461444854736], [0.003370456164702773, 0.2798651456832886, 0.2798651456832886, 0.15022599697113037, 0.28667324781417847], [0.05294124782085419, 0.3973574936389923, 0.0035341759212315083, 0.3973574936389923, 0.1488095223903656], [0.19821558892726898, 0.02643611840903759, 0.0004321219748817384, 0.19821558892726898, 0.5767005681991577], [0.11132428050041199, 0.03649725764989853, 0.03649725764989853, 0.04140482097864151, 0.7742763757705688], [0.09950698912143707, 0.7197651863098145, 0.0025323908776044846, 0.08909770846366882, 0.08909770846366882], [0.3051513135433197, 0.1409911960363388, 0.017455317080020905, 0.23125088214874268, 0.3051513135433197], [0.23450344800949097, 0.3123077154159546, 0.13822610676288605, 0.08045926690101624, 0.23450344800949097], [0.32962846755981445, 0.32962846755981445, 0.020500842481851578, 0.3190443813800812, 0.0011978666298091412], [0.6501222252845764, 0.0017939145909622312, 0.0017939145909622312, 0.0024276869371533394, 0.34386223554611206], [0.2462698221206665, 0.10084350407123566, 0.550938069820404, 0.0011051067849621177, 0.10084350407123566], [0.001361484406515956, 0.17353440821170807, 0.21708039939403534, 0.21708039939403534, 0.3909432888031006], [0.019481446593999863, 0.2598944306373596, 0.006622548680752516, 0.2598944306373596, 0.4541071057319641], [0.2995383143424988, 0.3355347514152527, 0.022059541195631027, 0.00733253313228488, 0.3355347514152527], [0.19191358983516693, 0.0526517890393734, 0.0526517890393734, 0.6859596967697144, 0.016823146492242813], [0.06454910337924957, 0.04537804052233696, 0.017467154189944267, 0.8272276520729065, 0.04537804052233696], [0.18231309950351715, 0.31182578206062317, 0.31182578206062317, 0.004416747950017452, 0.18961861729621887], [0.03349539265036583, 0.006298782303929329, 0.8097351789474487, 0.11697524785995483, 0.03349539265036583], [0.021689821034669876, 0.011674025095999241, 0.01308993250131607, 0.9057716131210327, 0.04777464270591736], [0.015121618285775185, 0.10020878911018372, 0.5850340723991394, 0.10020878911018372, 0.19942671060562134], [0.0005469875759445131, 0.0005469875759445131, 0.6994406580924988, 0.25684866309165955, 0.04261666163802147], [0.010397475212812424, 0.09745858609676361, 0.4202600121498108, 0.4614863991737366, 0.010397475212812424], [0.16432924568653107, 0.021808354184031487, 0.3473544120788574, 0.11915348470211029, 0.3473544120788574], [0.1409830003976822, 0.4094679653644562, 0.4094679653644562, 0.0029605545569211245, 0.03712048754096031], [0.24034063518047333, 0.0059590996243059635, 0.0673670694231987, 0.6803740859031677, 0.0059590996243059635], [0.6623031497001648, 0.20969118177890778, 0.04340910166501999, 0.04229825735092163, 0.04229825735092163], [0.3156087100505829, 0.18136300146579742, 0.00021387540618889034, 0.5026006102561951, 0.00021387540618889034], [0.05177178978919983, 0.007006272207945585, 0.9392992258071899, 0.0010040017077699304, 0.0009187653195112944], [0.14146479964256287, 0.14146479964256287, 0.003911084961146116, 0.05474784970283508, 0.6584115028381348], [0.0032744896598160267, 0.9096673130989075, 0.07709642499685287, 0.0032744896598160267, 0.006687346380203962], [0.5363160967826843, 0.033511437475681305, 0.042237430810928345, 0.042237430810928345, 0.3456975221633911], [0.43125954270362854, 0.04055003821849823, 0.43125954270362854, 0.002639578655362129, 0.09429125487804413], [0.05541548877954483, 0.8679943084716797, 0.03630341216921806, 0.003983384929597378, 0.03630341216921806], [0.14764980971813202, 0.23525695502758026, 0.16657312214374542, 0.23525695502758026, 0.21526314318180084], [0.383880078792572, 0.01734907180070877, 0.2066424936056137, 0.008248340338468552, 0.383880078792572], [0.008323943242430687, 0.7034897804260254, 0.14315326511859894, 0.001879664370790124, 0.14315326511859894], [0.14509880542755127, 0.30528420209884644, 0.00039351446321234107, 0.14509880542755127, 0.40412473678588867], [0.07606417685747147, 0.31081053614616394, 0.0005786883411929011, 0.30627331137657166, 0.30627331137657166], [0.2548052668571472, 0.007191472686827183, 0.25271329283714294, 0.2304847240447998, 0.2548052668571472], [0.052742715924978256, 0.439598023891449, 0.0678323283791542, 0.0002289747353643179, 0.439598023891449], [0.02240559086203575, 0.6425131559371948, 0.31259846687316895, 0.02240559086203575, 7.724574243184179e-05], [0.11167385429143906, 0.6705107092857361, 0.08197882026433945, 0.11167385429143906, 0.02416279911994934], [0.19297856092453003, 0.0004964614054188132, 0.44471168518066406, 0.0004964614054188132, 0.3613167703151703], [0.3403182625770569, 0.01638060063123703, 0.15778987109661102, 0.46220940351486206, 0.023301897570490837], [0.24314408004283905, 0.24314408004283905, 0.026478465646505356, 0.39050376415252686, 0.09672968834638596], [0.1741185188293457, 0.1741185188293457, 0.23263074457645416, 0.006848777178674936, 0.41228342056274414], [0.02775035984814167, 0.38550350069999695, 0.03062986023724079, 0.17061272263526917, 0.38550350069999695], [0.4351026713848114, 0.014954772777855396, 0.001142307068221271, 0.11369752883911133, 0.4351026713848114], [0.5584433674812317, 0.15009376406669617, 0.14377638697624207, 0.14377638697624207, 0.003910135477781296], [0.285981684923172, 0.5671901702880859, 0.00899979192763567, 0.06891413033008575, 0.06891413033008575], [0.004256094805896282, 0.8821899890899658, 0.034095291048288345, 0.034095291048288345, 0.04536332190036774], [0.002042459324002266, 0.9332810044288635, 0.0006147196399979293, 0.0006147196399979293, 0.06344711035490036], [0.01425386406481266, 0.4750036299228668, 0.003698009066283703, 0.4750036299228668, 0.03204081952571869], [0.0019603222608566284, 0.4842049181461334, 0.19627119600772858, 0.025806238874793053, 0.29175740480422974], [0.2000969499349594, 0.03300965204834938, 0.3455471694469452, 0.3455471694469452, 0.07579910755157471], [0.6210744380950928, 0.16922663152217865, 0.0004918346530757844, 0.16922663152217865, 0.039980448782444], [0.48246774077415466, 0.025357414036989212, 0.0034353130031377077, 0.006271770689636469, 0.48246774077415466], [0.20305484533309937, 0.3959306478500366, 0.3959306478500366, 0.0032775113359093666, 0.001806270913220942], [0.005755333695560694, 0.07884900271892548, 0.9004467725753784, 0.007474454585462809, 0.007474454585462809], [0.41504064202308655, 0.0006231249426491559, 0.016814284026622772, 0.41504064202308655, 0.15248137712478638], [0.01680368185043335, 0.025553423911333084, 0.9383861422538757, 0.002453030087053776, 0.01680368185043335], [0.0795099139213562, 0.016546621918678284, 0.8114473223686218, 0.0795099139213562, 0.012986109592020512], [0.003128449432551861, 0.24678875505924225, 0.2606070637702942, 0.2606070637702942, 0.22886866331100464], [0.045172058045864105, 0.0010571596212685108, 0.8758767247200012, 0.045172058045864105, 0.032721973955631256], [0.004986853804439306, 0.003011955413967371, 0.0012000342831015587, 0.0012000342831015587, 0.989601194858551], [0.016646087169647217, 0.34444066882133484, 0.05803581699728966, 0.016646087169647217, 0.5642313361167908], [0.029274066910147667, 0.008348780684173107, 0.8119737505912781, 0.09540410339832306, 0.05499928072094917], [0.139568030834198, 0.477744996547699, 0.343436062335968, 0.019625499844551086, 0.019625499844551086], [0.06392168253660202, 0.13097414374351501, 0.6287673711776733, 0.04536265507340431, 0.13097414374351501], [0.009693208150565624, 0.22905749082565308, 0.07250436395406723, 0.3443724811077118, 0.3443724811077118], [0.02224460430443287, 0.005208893679082394, 0.18451321125030518, 0.6035200953483582, 0.18451321125030518], [0.06977276504039764, 0.7395235300064087, 0.06977276504039764, 0.08931256830692291, 0.03161831200122833], [0.001984998816624284, 0.004291106481105089, 0.017878198996186256, 0.971554696559906, 0.004291106481105089], [0.5922278761863708, 0.06925776600837708, 0.0013505883980542421, 0.3321194648742676, 0.005044293124228716], [0.0879586711525917, 0.032996710389852524, 0.0879586711525917, 0.39235323667526245, 0.3987328112125397], [0.19286726415157318, 0.013833632692694664, 0.013833632692694664, 0.03933491185307503, 0.7401304841041565], [0.012370229698717594, 0.012370229698717594, 0.5709767937660217, 0.04474026337265968, 0.35954251885414124], [0.11614116281270981, 0.5336990356445312, 0.218705415725708, 0.11614116281270981, 0.015313235111534595], [0.001283218851312995, 0.5127934217453003, 0.18933728337287903, 0.001283218851312995, 0.2953028678894043], [0.0018366531003266573, 0.5670583248138428, 0.2943570017814636, 0.027245301753282547, 0.10950271785259247], [0.08374436944723129, 0.08917424827814102, 0.23051707446575165, 0.23051707446575165, 0.3660472333431244], [0.3382906913757324, 0.2224244326353073, 0.01458179671317339, 0.3382906913757324, 0.08641233295202255], [0.19056907296180725, 0.34056779742240906, 0.07140933722257614, 0.19056907296180725, 0.2068846970796585], [0.10737184435129166, 0.3225061297416687, 0.10580557584762573, 0.10737184435129166, 0.3569445312023163], [0.2151130735874176, 0.2151130735874176, 0.14318527281284332, 0.03248172253370285, 0.39410683512687683], [0.0657348558306694, 0.11389898508787155, 0.11389898508787155, 0.5985878109931946, 0.10787935554981232], [0.6783957481384277, 0.08411884307861328, 0.025707799941301346, 0.08411884307861328, 0.12765878438949585], [0.3810634911060333, 0.046681102365255356, 0.3810634911060333, 0.18073301017284393, 0.010459012351930141], [0.6732016205787659, 0.14207316935062408, 0.012444120831787586, 0.14207316935062408, 0.030207930132746696], [0.026391537860035896, 0.46995919942855835, 0.46995919942855835, 0.00010588985605863854, 0.03358412906527519], [0.436458945274353, 0.2712186872959137, 0.005388617515563965, 0.2712186872959137, 0.015715042129158974], [0.00012926242197863758, 0.006133036222308874, 0.4167909324169159, 0.5768175721168518, 0.00012926242197863758], [0.5314390063285828, 0.43823739886283875, 0.008769956417381763, 0.012783719226717949, 0.008769956417381763], [0.8545888066291809, 0.047528959810733795, 0.03875305503606796, 0.03875305503606796, 0.020376106724143028], [0.3285190463066101, 0.004923409782350063, 0.5412501096725464, 0.06265372037887573, 0.06265372037887573], [0.27089598774909973, 0.0823398232460022, 0.3450794517993927, 0.15084236860275269, 0.15084236860275269], [0.439863920211792, 0.0043752314522862434, 0.00949315819889307, 0.2731338441371918, 0.2731338441371918], [0.07146946340799332, 0.017518656328320503, 0.07146946340799332, 0.7261897921562195, 0.1133526936173439], [0.16280139982700348, 0.19581373035907745, 0.16280139982700348, 0.006420760881155729, 0.47216275334358215], [0.00033620934118516743, 0.05426446720957756, 0.23201030492782593, 0.7130528688430786, 0.00033620934118516743], [0.4387918710708618, 0.07020752876996994, 0.4387918710708618, 0.04392232745885849, 0.008286483585834503], [0.011831343173980713, 0.09914396703243256, 0.8741849660873413, 0.0030084201134741306, 0.011831343173980713], [0.07763060927391052, 0.0023547133896499872, 0.42124032974243164, 0.0023547133896499872, 0.49641966819763184], [0.15137842297554016, 0.010921087116003036, 0.6830019354820251, 0.0033201395999640226, 0.15137842297554016], [0.06714025139808655, 0.30766844749450684, 0.3407811224460602, 0.2172698676586151, 0.06714025139808655], [0.007717673666775227, 0.5331122279167175, 0.009923981502652168, 0.4418396055698395, 0.007406536024063826], [0.25069957971572876, 0.006286062300205231, 0.6861798167228699, 0.028417272493243217, 0.028417272493243217], [0.01303500309586525, 0.3102100193500519, 0.3298678398132324, 0.017019277438521385, 0.3298678398132324], [0.40356558561325073, 0.007703338749706745, 0.5351730585098267, 0.007703338749706745, 0.04585469141602516], [0.2554345726966858, 0.0017597628757357597, 6.601373752346262e-05, 0.4873051941394806, 0.2554345726966858], [0.08241298049688339, 0.0005672374973073602, 0.10253163427114487, 0.10253163427114487, 0.7119565010070801], [0.015068890526890755, 0.02439202181994915, 0.40734440088272095, 0.40734440088272095, 0.14585022628307343], [0.15061084926128387, 0.12232416123151779, 0.5745035409927368, 0.12232416123151779, 0.030237233266234398], [0.26429280638694763, 0.34248408675193787, 0.3190601170063019, 0.0370815210044384, 0.0370815210044384], [0.03060118667781353, 0.0037821363657712936, 0.34825751185417175, 0.34825751185417175, 0.269101619720459], [0.015546119771897793, 0.26585349440574646, 0.29663246870040894, 0.15611445903778076, 0.26585349440574646], [0.45932257175445557, 0.0004886785172857344, 0.45932257175445557, 0.07973257452249527, 0.0011336408788338304], [0.24845880270004272, 0.028050962835550308, 0.0028844440821558237, 0.6925548315048218, 0.028050962835550308], [0.12624993920326233, 0.15224547684192657, 0.32774344086647034, 0.0660177618265152, 0.32774344086647034], [0.42373359203338623, 0.017356641590595245, 0.017356641590595245, 0.013001768849790096, 0.5285513401031494], [0.03907531127333641, 0.445553719997406, 0.011216814629733562, 0.492937296628952, 0.011216814629733562], [0.08015906810760498, 0.08794121444225311, 0.11031083017587662, 0.6336477398872375, 0.08794121444225311], [0.5084103941917419, 0.4073690176010132, 0.023542895913124084, 0.03033883310854435, 0.03033883310854435], [0.20815443992614746, 0.015094212256371975, 0.061159323900938034, 0.20815443992614746, 0.5074375867843628], [0.004695030860602856, 0.48470041155815125, 0.18249337375164032, 0.323416143655777, 0.004695030860602856], [0.2730353772640228, 0.036538016051054, 0.17397350072860718, 0.24341772496700287, 0.2730353772640228], [0.006585676688700914, 0.006585676688700914, 0.16974253952503204, 0.0010916675673797727, 0.8159944415092468], [0.21280744671821594, 0.5357180237770081, 0.10723410546779633, 0.037006303668022156, 0.10723410546779633], [0.32141032814979553, 0.0875219851732254, 0.0875219851732254, 0.19106349349021912, 0.3124822676181793], [0.022311130538582802, 0.3830317258834839, 0.1680309772491455, 0.3830317258834839, 0.0435943678021431], [0.141444593667984, 0.010845202021300793, 0.8343830704689026, 0.00248195743188262, 0.010845202021300793], [0.01775677315890789, 0.8557804226875305, 0.03346175327897072, 0.01775677315890789, 0.0752442255616188], [0.2723795473575592, 0.0012250333093106747, 0.010271034203469753, 0.4437447786331177, 0.2723795473575592], [0.7954973578453064, 0.07830696552991867, 0.05392986163496971, 0.018336039036512375, 0.05392986163496971], [0.9154163599014282, 0.003455379279330373, 0.019274337217211723, 0.05839865654706955, 0.003455379279330373], [0.8416593074798584, 0.012831532396376133, 0.07348904013633728, 0.012831532396376133, 0.05918857082724571], [0.024373512715101242, 0.4020301401615143, 0.14730863273143768, 0.4020301401615143, 0.024257579818367958], [0.5046539306640625, 0.12231922149658203, 0.03783143311738968, 0.03783143311738968, 0.2973639965057373], [0.023993784561753273, 0.023993784561753273, 0.5065265893936157, 0.044219840317964554, 0.4012659788131714], [0.002996316645294428, 0.17250575125217438, 0.561737060546875, 0.09025508910417557, 0.17250575125217438], [0.8752537369728088, 0.06159262731671333, 0.0005757001927122474, 0.0009852700168266892, 0.06159262731671333], [0.36463096737861633, 0.2614758610725403, 0.005923205986618996, 0.0033390014432370663, 0.36463096737861633], [0.30005013942718506, 0.0071939267218112946, 0.3177054524421692, 0.3177054524421692, 0.05734505131840706], [0.6680267453193665, 0.124037966132164, 0.0615377351641655, 0.124037966132164, 0.022359682247042656], [0.289095401763916, 0.18131399154663086, 0.25116482377052307, 0.25116482377052307, 0.02726093679666519], [0.0014132596552371979, 0.0014132596552371979, 0.008249131962656975, 0.18759779632091522, 0.8013265132904053], [0.07457525283098221, 0.2866118550300598, 0.07457525283098221, 0.007944056764245033, 0.5562936663627625], [0.01374145969748497, 0.01374145969748497, 0.8782594203948975, 0.006276415195316076, 0.08798123896121979], [0.01390552707016468, 0.022746004164218903, 0.8978708386421204, 0.022746004164218903, 0.04273160919547081], [0.5899151563644409, 0.08472979813814163, 0.08472979813814163, 0.2218283712863922, 0.018796907737851143], [0.09372485429048538, 0.27908504009246826, 0.09372485429048538, 0.2510802447795868, 0.2823849320411682], [0.19394035637378693, 0.01950453780591488, 0.003300535259768367, 0.7227294445037842, 0.06052515283226967], [0.5488950610160828, 0.05065033957362175, 0.11921274662017822, 0.16202908754348755, 0.11921274662017822], [0.0036758671049028635, 0.24959689378738403, 0.000575075566302985, 0.24959689378738403, 0.49655526876449585], [0.0072625307366251945, 0.0012806871673092246, 0.38437366485595703, 0.22270947694778442, 0.38437366485595703], [0.13877804577350616, 0.003554664086550474, 0.4280434548854828, 0.001580356969498098, 0.4280434548854828], [0.0010622054105624557, 0.30841299891471863, 0.33412718772888184, 0.04798467829823494, 0.30841299891471863], [0.004580937325954437, 0.00251262285746634, 0.7689931392669678, 0.22140060365200043, 0.00251262285746634], [0.20003151893615723, 0.31206798553466797, 0.21038299798965454, 0.07748601585626602, 0.20003151893615723], [0.2548210620880127, 0.1418050080537796, 0.47158247232437134, 0.06589572131633759, 0.06589572131633759], [0.057436536997556686, 0.13089752197265625, 0.29070550203323364, 0.46352383494377136, 0.057436536997556686], [0.014127944596111774, 0.009558716788887978, 0.009558716788887978, 0.01743018440902233, 0.949324369430542], [0.4582945704460144, 0.0477568581700325, 0.07669894397258759, 0.369492769241333, 0.0477568581700325], [0.02937421202659607, 0.29418760538101196, 0.3587542772293091, 0.29418760538101196, 0.023496277630329132], [0.0136469891294837, 0.3681512176990509, 0.046415120363235474, 0.3681512176990509, 0.20363552868366241], [0.027266018092632294, 0.8059343695640564, 0.1378578245639801, 0.027266018092632294, 0.0016758078709244728], [0.02326022833585739, 0.24118149280548096, 0.24118149280548096, 0.4354865849018097, 0.05889023467898369], [0.118462935090065, 0.118462935090065, 0.17874498665332794, 0.5080271363258362, 0.07630200684070587], [0.0650487020611763, 0.1645893156528473, 0.25328460335731506, 0.0490105114877224, 0.4680668115615845], [0.0008293548598885536, 0.04866012930870056, 0.8571565747261047, 0.04469385743141174, 0.04866012930870056], [0.9056678414344788, 0.0035720549058169127, 0.00013144277909304947, 0.09049728512763977, 0.00013144277909304947], [0.04988795518875122, 0.0012245189864188433, 0.33717721700668335, 0.33717721700668335, 0.2745330333709717], [0.11142168939113617, 0.028672298416495323, 0.33081844449043274, 0.1982690840959549, 0.33081844449043274], [0.00015854649245738983, 0.0019562223460525274, 0.4874519407749176, 0.022981392219662666, 0.4874519407749176], [0.09021580219268799, 0.05237646400928497, 0.2072841376066208, 0.2072841376066208, 0.4428394138813019], [0.5098478198051453, 0.1648392379283905, 0.010438816621899605, 0.1648392379283905, 0.1500348448753357], [0.0036183532793074846, 0.2478366494178772, 0.0026323844213038683, 0.2478366494178772, 0.4980759918689728], [0.1757153570652008, 0.37913447618484497, 0.15968479216098785, 0.1257806271314621, 0.15968479216098785], [0.0012835938250645995, 0.0037610172294080257, 0.03460055589675903, 0.48017746210098267, 0.48017746210098267], [0.047881223261356354, 0.27492401003837585, 0.386200487613678, 0.01607033796608448, 0.27492401003837585], [0.05382375046610832, 0.22543677687644958, 0.3859664499759674, 0.1492381989955902, 0.18553481996059418], [0.010500062257051468, 0.06567873060703278, 0.607858419418335, 0.3054627478122711, 0.010500062257051468], [0.9761161208152771, 0.008087248541414738, 0.008087248541414738, 0.0025997248012572527, 0.005109694786369801], [1.0469968401594087e-05, 0.4262300431728363, 0.4262300431728363, 0.0010770350927487016, 0.14645244181156158], [0.0035293307155370712, 0.0826130360364914, 0.0035293307155370712, 0.44222158193588257, 0.4681067168712616], [0.2076627016067505, 0.1228010356426239, 0.029975319281220436, 0.4318982660770416, 0.2076627016067505], [0.14010801911354065, 0.11314719170331955, 0.6063182950019836, 0.000318494945531711, 0.14010801911354065], [0.725677490234375, 0.09378861635923386, 0.016004778444767, 0.1485244631767273, 0.016004778444767], [0.03411730378866196, 0.0032825947273522615, 0.08133064210414886, 0.08133064210414886, 0.7999387979507446], [0.2662808895111084, 0.12722130119800568, 0.2876242399215698, 0.052592623978853226, 0.2662808895111084], [0.06599640101194382, 0.5635194778442383, 0.06599640101194382, 0.06462451815605164, 0.23986323177814484], [0.4103120267391205, 0.16464202105998993, 0.012859405018389225, 0.4103120267391205, 0.0018745203269645572], [0.07787822186946869, 0.04950876533985138, 0.0323590412735939, 0.4201269745826721, 0.4201269745826721], [0.2537117302417755, 0.17699268460273743, 0.05832076072692871, 0.45265403389930725, 0.05832076072692871], [0.01647212542593479, 0.41375452280044556, 0.41375452280044556, 0.14104515314102173, 0.014973725192248821], [0.21101634204387665, 0.006661999970674515, 0.01079105120152235, 0.7648685574531555, 0.006661999970674515], [0.666812539100647, 0.27012190222740173, 0.022104283794760704, 0.018857061862945557, 0.022104283794760704], [0.3451536297798157, 0.009999778121709824, 0.3451536297798157, 0.053004294633865356, 0.24668866395950317], [0.870629072189331, 0.05080394074320793, 0.05460112914443016, 0.011982903815805912, 0.011982903815805912], [0.00908453855663538, 0.870311975479126, 0.023100823163986206, 0.08841817826032639, 0.00908453855663538], [0.07352267950773239, 0.015651732683181763, 0.28536537289619446, 0.07352267950773239, 0.5519375801086426], [0.015895087271928787, 0.5810828804969788, 0.26474738121032715, 0.012231740169227123, 0.12604297697544098], [0.03174109756946564, 0.10721826553344727, 0.2132214456796646, 0.5406009554862976, 0.10721826553344727], [0.009388124570250511, 0.6676365733146667, 0.29792070388793945, 0.015666456893086433, 0.009388124570250511], [0.0041922167874872684, 0.45711347460746765, 0.07884682714939117, 0.45711347460746765, 0.002734006615355611], [0.233913391828537, 0.233913391828537, 0.07255280762910843, 0.021721530705690384, 0.4378988742828369], [0.024168290197849274, 0.04706282541155815, 0.024168290197849274, 0.0704992413520813, 0.8341013193130493], [0.006655239500105381, 0.5405128002166748, 0.44279879331588745, 0.006655239500105381, 0.0033780131489038467], [0.010145983658730984, 0.5400930643081665, 0.3582371473312378, 0.08137785643339157, 0.010145983658730984], [0.23790083825588226, 0.23790083825588226, 0.5139240026473999, 0.0013719683047384024, 0.008902360685169697], [0.10745043307542801, 0.7439939975738525, 0.10636857151985168, 0.021093513816595078, 0.021093513816595078], [0.27444469928741455, 0.008357113227248192, 0.6496796607971191, 0.022869236767292023, 0.04464927688241005], [0.201021209359169, 0.5937108397483826, 0.201021209359169, 0.003632051171734929, 0.0006147195235826075], [0.69210284948349, 0.0125686414539814, 0.14604465663433075, 0.0032391559798270464, 0.14604465663433075], [0.12185215204954147, 0.1364988535642624, 0.02970145456492901, 0.6822460889816284, 0.02970145456492901], [0.3788788318634033, 0.06102154403924942, 0.06102154403924942, 0.3408266007900238, 0.15825143456459045], [0.6296759843826294, 0.012454244308173656, 0.3093419373035431, 0.012454244308173656, 0.03607356920838356], [0.6510105133056641, 0.09838860481977463, 0.06296657770872116, 0.08924565464258194, 0.09838860481977463], [0.2821630835533142, 0.007566479034721851, 0.09585415571928024, 0.5185621380805969, 0.09585415571928024], [0.6181417107582092, 0.17359377443790436, 0.007533624768257141, 0.06975412368774414, 0.13097676634788513], [0.7066838145256042, 0.2081507444381714, 0.02226865664124489, 0.04062807559967041, 0.02226865664124489], [0.052417606115341187, 0.05627388879656792, 0.22909078001976013, 0.22909078001976013, 0.43312692642211914], [0.008430738002061844, 0.00011257016740273684, 0.008430738002061844, 0.020328423008322716, 0.9626976251602173], [0.1546233892440796, 0.5582433342933655, 0.1197403073310852, 0.012769563123583794, 0.1546233892440796], [0.0025091981515288353, 0.6937215924263, 0.14784270524978638, 0.008083855733275414, 0.14784270524978638], [0.2101002186536789, 0.5328799486160278, 0.2101002186536789, 0.012418652884662151, 0.03450094535946846], [0.94926917552948, 0.014959351159632206, 0.01004793681204319, 0.014959351159632206, 0.010764187201857567], [0.7953783869743347, 0.0363583080470562, 0.0363583080470562, 0.0030172348488122225, 0.12888768315315247], [0.13443607091903687, 0.23669041693210602, 0.0017076923977583647, 0.49272972345352173, 0.13443607091903687], [0.04031240940093994, 0.1919746994972229, 0.025309568271040916, 0.5504286885261536, 0.1919746994972229], [0.04413149878382683, 0.06388791650533676, 0.04413149878382683, 0.7936341762542725, 0.05421484261751175], [0.06999970972537994, 0.46154409646987915, 0.0005420932429842651, 0.46154409646987915, 0.006369987968355417], [0.3003685772418976, 0.013693846762180328, 0.10840124636888504, 0.0005487166927196085, 0.5769876837730408], [0.3391093909740448, 0.2708943486213684, 0.11328130215406418, 0.2708943486213684, 0.005820621270686388], [0.049334120005369186, 0.7365558743476868, 0.14999394118785858, 0.014782003127038479, 0.049334120005369186], [0.469716340303421, 0.013279221951961517, 0.469716340303421, 0.022326456382870674, 0.024961594492197037], [0.0005107328179292381, 0.9479281902313232, 0.03772997856140137, 0.0037322796415537596, 0.010098849423229694], [0.18355987966060638, 0.18355987966060638, 0.01260590273886919, 0.588761568069458, 0.0315127894282341], [0.07463081181049347, 0.4084773659706116, 0.25752022862434387, 0.25752022862434387, 0.0018513859249651432], [0.1520889550447464, 0.020568089559674263, 0.1520889550447464, 0.0005279633915051818, 0.6747260689735413], [0.41000351309776306, 0.3283316493034363, 0.0033453269861638546, 0.2578156888484955, 0.0005037252558395267], [0.00937892496585846, 0.040609702467918396, 0.4454088807106018, 0.1138216108083725, 0.39078089594841003], [0.071689672768116, 0.015449242666363716, 0.7071071267127991, 0.071689672768116, 0.13406430184841156], [0.17191678285598755, 0.016826383769512177, 0.48076748847961426, 0.17191678285598755, 0.15857253968715668], [0.0824156254529953, 0.019388658925890923, 0.1903686225414276, 0.6884384751319885, 0.019388658925890923], [0.004092907067388296, 0.984723687171936, 0.006965708918869495, 0.004092907067388296, 0.000124837490147911], [0.49347203969955444, 0.08699150383472443, 0.006553769111633301, 0.08699150383472443, 0.32599112391471863], [0.024799898266792297, 0.02712801657617092, 0.9206357002258301, 0.0003084076743107289, 0.02712801657617092], [0.3954019546508789, 0.04242389649152756, 0.3954019546508789, 0.128535658121109, 0.038236506283283234], [0.032121967524290085, 0.13550712168216705, 0.8265610933303833, 0.0029049089644104242, 0.0029049089644104242], [0.003176789963617921, 0.003176789963617921, 0.42869842052459717, 0.1593436896800995, 0.4056043326854706], [0.12580008804798126, 0.3319109380245209, 0.3319109380245209, 0.13769803941249847, 0.0726800188422203], [0.07879487425088882, 0.008170933462679386, 0.4019116163253784, 0.43232759833335876, 0.07879487425088882], [0.08924232423305511, 0.44603079557418823, 0.018681852146983147, 0.44603079557418823, 1.4218713658920024e-05], [0.5701856017112732, 0.016570119187235832, 0.05887097865343094, 0.17718665301799774, 0.17718665301799774], [0.12013734132051468, 0.027603860944509506, 0.12013734132051468, 0.07179088890552521, 0.6603305339813232], [0.006150988396257162, 0.013277673162519932, 0.47367051243782043, 0.008925110101699829, 0.4979757070541382], [0.020541014149785042, 0.7156810760498047, 0.2589920461177826, 0.002392973517999053, 0.002392973517999053], [0.00012375629739835858, 0.0025278509128838778, 0.12893500924110413, 0.12893500924110413, 0.7394782900810242], [0.06815654784440994, 0.08628305792808533, 0.06815654784440994, 0.002691586036235094, 0.774712324142456], [0.2025619000196457, 0.005276490468531847, 0.004193066619336605, 0.2025619000196457, 0.5854066014289856], [0.037087779492139816, 0.3783115744590759, 0.3783115744590759, 0.012968691997230053, 0.19332042336463928], [0.3405194878578186, 0.01201258972287178, 0.29704082012176514, 0.29704082012176514, 0.053386345505714417], [0.2995714247226715, 0.013699056580662727, 0.1926393359899521, 0.1926393359899521, 0.30145081877708435], [0.2737865149974823, 0.009465858340263367, 0.2737865149974823, 0.06941572576761246, 0.37354546785354614], [0.039492249488830566, 0.7227011322975159, 0.039492249488830566, 0.05281271040439606, 0.14550168812274933], [0.4453258216381073, 0.10385250300168991, 0.00464200833812356, 0.0008537792018614709, 0.4453258216381073], [0.0371074341237545, 0.24992366135120392, 0.010548722930252552, 0.6563072800636292, 0.04611286520957947], [0.0005831446615047753, 0.5322262048721313, 0.40494558215141296, 0.0616619698703289, 0.0005831446615047753], [0.23637424409389496, 0.31927093863487244, 0.31927093863487244, 0.09492269158363342, 0.030161205679178238], [0.3103329539299011, 0.006543425377458334, 0.17635522782802582, 0.19643548130989075, 0.3103329539299011], [0.0034962743520736694, 0.020546909421682358, 0.9711934924125671, 0.0034962743520736694, 0.0012670531868934631], [0.004326328635215759, 0.4927985370159149, 0.0002717138850130141, 0.4927985370159149, 0.009804857894778252], [0.2151186764240265, 0.2510643005371094, 0.2642451524734497, 0.00532670458778739, 0.2642451524734497], [0.011261073872447014, 0.008098889142274857, 0.05324619263410568, 0.8741475939750671, 0.05324619263410568], [0.15793165564537048, 0.037784237414598465, 0.023616556078195572, 0.7570509910583496, 0.023616556078195572], [0.18379054963588715, 0.1636296659708023, 0.09462007135152817, 0.09462007135152817, 0.463339626789093], [0.21209026873111725, 0.042847733944654465, 0.6430307030677795, 0.05918360874056816, 0.042847733944654465], [0.40859442949295044, 0.05001005530357361, 0.30842533707618713, 0.1829601228237152, 0.05001005530357361], [0.03304658830165863, 0.03834415599703789, 0.00974033772945404, 0.03304658830165863, 0.8858222961425781], [0.0005811604205518961, 0.1331438422203064, 0.17301717400550842, 0.5202406644821167, 0.17301717400550842], [0.49400919675827026, 0.007503043860197067, 0.49400919675827026, 0.0013641455443575978, 0.003114491468295455], [0.004671221598982811, 0.2866404354572296, 0.004671221598982811, 0.35352352261543274, 0.3504936099052429], [0.13152454793453217, 0.13152454793453217, 0.002455934649333358, 0.6615347266197205, 0.07296036183834076], [0.037539128214120865, 0.7708213329315186, 0.00637300917878747, 0.037539128214120865, 0.1477273851633072], [0.04601224139332771, 0.4755883514881134, 0.04601224139332771, 0.41353869438171387, 0.01884855516254902], [0.3468140959739685, 0.0002608056820463389, 0.011736626736819744, 0.0002608056820463389, 0.6409276723861694], [0.21809984743595123, 0.001980480505153537, 0.3898544907569885, 0.0002106503234244883, 0.3898544907569885], [0.1085454672574997, 0.21072962880134583, 0.33914321660995483, 0.002438440453261137, 0.33914321660995483], [0.8236575722694397, 0.006835706997662783, 0.006835706997662783, 0.06879976391792297, 0.09387116134166718], [0.05710718408226967, 0.013365131802856922, 0.8280282020568848, 0.05710718408226967, 0.04439223185181618], [0.15505151450634003, 0.6177550554275513, 0.20398001372814178, 0.01160673052072525, 0.01160673052072525], [0.21812914311885834, 0.016333580017089844, 0.2503591477870941, 0.49884456396102905, 0.016333580017089844], [0.004268786869943142, 0.05410240590572357, 0.15983285009860992, 0.15983285009860992, 0.6219632029533386], [0.37169763445854187, 0.2412223368883133, 0.007092887070029974, 0.008289555087685585, 0.37169763445854187], [0.5980929136276245, 0.12014967203140259, 0.011581414379179478, 0.25859466195106506, 0.011581414379179478], [0.11774975061416626, 0.18263742327690125, 0.5281903743743896, 0.11774975061416626, 0.0536726675927639], [0.5786904096603394, 0.000182787305675447, 0.08576976507902145, 0.33517417311668396, 0.000182787305675447], [0.8441879749298096, 0.059447549283504486, 0.01941434107720852, 0.05753587558865547, 0.01941434107720852], [0.23361124098300934, 0.03580113872885704, 1.893786247819662e-05, 1.893786247819662e-05, 0.7305497527122498], [0.0001988959265872836, 0.018829455599188805, 0.10071388632059097, 0.0001988959265872836, 0.8800588250160217], [0.0053033167496323586, 0.46806830167770386, 0.012729538604617119, 0.04583052918314934, 0.46806830167770386], [0.0794411450624466, 0.0033839785028249025, 0.0794411450624466, 0.23131214082241058, 0.6064215302467346], [0.09047116339206696, 0.29934820532798767, 0.011484247632324696, 0.29934820532798767, 0.29934820532798767], [0.09601052850484848, 0.02312663570046425, 0.41929489374160767, 0.41929489374160767, 0.04227301478385925], [0.006737181451171637, 0.36321648955345154, 0.1895408183336258, 0.07728895545005798, 0.36321648955345154], [0.008348070085048676, 0.0015609686961397529, 0.48372700810432434, 0.022636989131569862, 0.48372700810432434], [0.18695805966854095, 0.3327230215072632, 0.3327230215072632, 0.13064129650592804, 0.016954613849520683], [0.00649555679410696, 0.23044012486934662, 0.14773553609848022, 0.3848886489868164, 0.23044012486934662], [0.2112443894147873, 0.0016418901504948735, 0.7476017475128174, 0.019756002351641655, 0.019756002351641655], [0.10090583562850952, 0.10090583562850952, 0.025299547240138054, 0.1286412626504898, 0.6442475318908691], [0.2171686291694641, 0.08790477365255356, 0.4140431880950928, 0.06371477246284485, 0.2171686291694641], [0.3546469211578369, 0.3546469211578369, 0.21259644627571106, 0.061407752335071564, 0.016701947897672653], [0.22272494435310364, 0.6315109133720398, 0.008467542938888073, 0.09914777427911758, 0.03814876079559326], [0.036899011582136154, 0.3528508245944977, 0.19615446031093597, 0.19615446031093597, 0.2179412543773651], [0.20044681429862976, 0.0002509423065930605, 0.33419308066368103, 0.0002509423065930605, 0.4648582637310028], [0.9072120785713196, 0.03444144129753113, 0.023656358942389488, 0.03444144129753113, 0.0002487818419467658], [0.08918114006519318, 0.14956621825695038, 0.37519651651382446, 0.010859565809369087, 0.37519651651382446], [0.09677903354167938, 0.013898968696594238, 0.6128443479537964, 0.26257866621017456, 0.013898968696594238], [0.06180575117468834, 0.11152252554893494, 0.0166068933904171, 0.7482591271400452, 0.06180575117468834], [0.03545883297920227, 0.14894568920135498, 0.7272050976753235, 0.04419518634676933, 0.04419518634676933], [0.06428838521242142, 0.06428838521242142, 0.491428405046463, 0.23031248152256012, 0.14968232810497284], [0.3891471028327942, 0.1490117758512497, 0.21879801154136658, 0.09403140097856522, 0.1490117758512497], [0.0057260580360889435, 0.3239332139492035, 0.5378587245941162, 0.0057260580360889435, 0.12675593793392181], [0.16306760907173157, 0.12220306694507599, 0.6055898070335388, 0.05456976220011711, 0.05456976220011711], [0.36988893151283264, 0.36988893151283264, 0.04476894065737724, 0.2153625339269638, 9.069086809176952e-05], [0.2257729321718216, 0.003531212452799082, 0.7119517922401428, 0.003531212452799082, 0.05521286651492119], [0.200251504778862, 0.200251504778862, 0.08841647952795029, 0.29918113350868225, 0.2118993103504181], [0.0005212374380789697, 0.8718239665031433, 0.12189947068691254, 0.002877692459151149, 0.002877692459151149], [0.05675862357020378, 0.7686253786087036, 0.05675862357020378, 0.0008468672749586403, 0.11701048165559769], [0.293226420879364, 0.004101642407476902, 0.37953898310661316, 0.31903132796287537, 0.004101642407476902], [0.019592147320508957, 0.004133749287575483, 0.008617080748081207, 0.9670702219009399, 0.0005868371808901429], [0.25386494398117065, 0.17212456464767456, 0.17212456464767456, 0.3190333843231201, 0.0828525722026825], [0.14141911268234253, 0.1866605579853058, 0.30904877185821533, 0.05382275581359863, 0.30904877185821533], [0.10362038761377335, 0.6402872204780579, 0.03405464440584183, 0.18798312544822693, 0.03405464440584183], [0.02250644937157631, 0.4655744731426239, 0.02250644937157631, 0.323341965675354, 0.1660706251859665], [0.5406425595283508, 0.17597603797912598, 0.013196723535656929, 0.13509231805801392, 0.13509231805801392], [0.004664044827222824, 0.2458733320236206, 0.28087571263313293, 0.2458733320236206, 0.22271355986595154], [0.06003210321068764, 0.008912320248782635, 0.7111930847167969, 0.06003210321068764, 0.15983033180236816], [0.3408619165420532, 0.13701146841049194, 0.035104937851428986, 0.1461597979068756, 0.3408619165420532], [0.33741527795791626, 0.00035493532777763903, 0.07564293593168259, 0.07564293593168259, 0.5109438896179199], [0.0015713144093751907, 0.2707986533641815, 0.11366090178489685, 0.5003082156181335, 0.11366090178489685], [0.48841479420661926, 0.21222008764743805, 0.021162759512662888, 0.2570396661758423, 0.021162759512662888], [0.0003119280154351145, 0.6391335725784302, 0.02305539697408676, 0.3144436776638031, 0.02305539697408676], [0.4967917501926422, 0.0037391495425254107, 0.4967917501926422, 0.0008224917110055685, 0.0018547913059592247], [0.31706368923187256, 0.012184251099824905, 0.6581450700759888, 0.0054013715125620365, 0.0072056688368320465], [0.14238199591636658, 0.03009326197206974, 0.10379532724618912, 0.36186474561691284, 0.36186474561691284], [0.024580370634794235, 0.5695990920066833, 0.024580370634794235, 0.031375035643577576, 0.3498651087284088], [0.02175206132233143, 0.04146560654044151, 0.2488231211900711, 0.02175206132233143, 0.6662071347236633], [0.0013347213389351964, 0.3265899121761322, 0.3247702419757843, 0.3247702419757843, 0.022534875199198723], [0.020567111670970917, 0.013551673851907253, 0.7781798243522644, 0.15112772583961487, 0.0365736223757267], [0.4670810401439667, 0.07664329558610916, 0.08703544735908508, 0.08703544735908508, 0.2822047472000122], [0.012749431654810905, 0.32641443610191345, 0.012749431654810905, 0.008599381893873215, 0.6394874453544617], [0.038319043815135956, 0.6966146230697632, 0.038319043815135956, 0.21793217957019806, 0.008815037086606026], [0.24583488702774048, 0.2256418764591217, 0.2256418764591217, 0.2111118584871292, 0.09176945686340332], [0.005184744019061327, 0.8099889159202576, 0.005184744019061327, 0.11358247697353363, 0.06605914980173111], [0.04001834988594055, 0.6433684229850769, 0.1864357590675354, 0.09015912562608719, 0.04001834988594055], [0.001981650246307254, 0.001981650246307254, 0.7805125117301941, 0.05041643604636192, 0.16510775685310364], [0.108906589448452, 0.24150189757347107, 0.08606474101543427, 0.24150189757347107, 0.3220248818397522], [0.02982565388083458, 0.2667490541934967, 0.2667490541934967, 0.4118613302707672, 0.0248149111866951], [0.12422952055931091, 0.012972841039299965, 0.3966824412345886, 0.0694328024983406, 0.3966824412345886], [0.17391572892665863, 0.020835399627685547, 0.5839098691940308, 0.20050360262393951, 0.020835399627685547], [0.0006155146984383464, 0.04312150925397873, 0.7726173400878906, 0.0006155146984383464, 0.1830301135778427], [0.38290977478027344, 0.16850963234901428, 0.38290977478027344, 0.044107455760240555, 0.02156335860490799], [0.010493593290448189, 0.22910645604133606, 0.25674208998680115, 0.2518289387226105, 0.2518289387226105], [0.23262596130371094, 0.23262596130371094, 0.1750182807445526, 0.025303861126303673, 0.3344259262084961], [0.49845683574676514, 0.2504635155200958, 0.11168849468231201, 0.06969557702541351, 0.06969557702541351], [0.040777578949928284, 0.00014818235649727285, 0.865874707698822, 0.08650429546833038, 0.006695148069411516], [0.09298212826251984, 0.09298212826251984, 0.023071344941854477, 0.12387412786483765, 0.6670902967453003], [0.13603653013706207, 0.11042571067810059, 0.030518069863319397, 0.5869831442832947, 0.13603653013706207], [0.9255262613296509, 0.004187615588307381, 0.014341065660119057, 0.004187615588307381, 0.051757365465164185], [0.024564499035477638, 0.04562915489077568, 0.8135035037994385, 0.05815144628286362, 0.05815144628286362], [0.32001662254333496, 0.0026051276363432407, 0.3347073495388031, 0.3347073495388031, 0.007963531650602818], [0.03944499045610428, 0.03944499045610428, 0.14494198560714722, 0.09139290452003479, 0.6847751140594482], [0.03468426689505577, 0.016729960218071938, 0.05676900967955589, 0.875086784362793, 0.016729960218071938], [0.002258024178445339, 0.43070924282073975, 0.10871512442827225, 0.027608297765254974, 0.43070924282073975], [0.19818739593029022, 0.08001799881458282, 0.5730147957801819, 0.08001799881458282, 0.06876184046268463], [0.05199889466166496, 0.0063353776931762695, 0.05199889466166496, 0.0379578061401844, 0.8517090082168579], [0.04143544286489487, 0.031644001603126526, 0.6766197681427002, 0.04143544286489487, 0.20886531472206116], [0.3726063668727875, 0.23928165435791016, 0.01941715180873871, 0.18434742093086243, 0.18434742093086243], [0.004500572569668293, 0.015024821273982525, 0.004500572569668293, 0.221907839179039, 0.7540661096572876], [0.046934958547353745, 0.22713430225849152, 0.34657996892929077, 0.03277074173092842, 0.34657996892929077], [0.12600019574165344, 0.08104642480611801, 0.39413467049598694, 0.004683970008045435, 0.39413467049598694], [0.4809078276157379, 0.4814531207084656, 0.0008430829038843513, 0.03595292195677757, 0.0008430829038843513], [0.3472103178501129, 0.29268378019332886, 0.004557234235107899, 0.0083384420722723, 0.3472103178501129], [0.002969855209812522, 0.7438600659370422, 0.027758929878473282, 0.027758929878473282, 0.19765229523181915], [0.5974633693695068, 0.14017300307750702, 0.043744590133428574, 0.043744590133428574, 0.1748744398355484], [0.16731813549995422, 0.13042716681957245, 0.32909902930259705, 0.32909902930259705, 0.04405666142702103], [0.1147494912147522, 0.2110985964536667, 0.2110985964536667, 0.44152575731277466, 0.021527523174881935], [0.034995436668395996, 0.3537544012069702, 0.30554383993148804, 0.30554383993148804, 0.0001624947035452351], [0.12315776199102402, 0.22177956998348236, 0.18288536369800568, 0.22177956998348236, 0.2503977417945862], [0.031780436635017395, 0.2650090456008911, 0.031780436635017395, 0.6680439710617065, 0.003386138938367367], [0.08845149725675583, 0.004010883625596762, 0.08845149725675583, 0.29142701625823975, 0.5276591777801514], [0.027863433584570885, 0.051431749016046524, 0.08289843797683716, 0.7549079656600952, 0.08289843797683716], [0.4610418677330017, 0.04198083281517029, 0.12638512253761292, 0.18529608845710754, 0.18529608845710754], [0.9192551970481873, 0.00808335654437542, 0.004431536886841059, 0.060146573930978775, 0.00808335654437542], [0.00980176031589508, 0.7797359228134155, 0.07773347198963165, 0.0549953356385231, 0.07773347198963165], [0.11610855162143707, 0.013522486202418804, 0.013522486202418804, 0.7343279123306274, 0.12251860648393631], [0.5812823176383972, 0.01567554846405983, 0.00011080711556132883, 0.00011080711556132883, 0.40282055735588074], [0.3452777862548828, 0.11249873787164688, 0.328111857175827, 0.10161285102367401, 0.11249873787164688], [0.018825966864824295, 0.017155222594738007, 0.00726329954341054, 0.9396003484725952, 0.017155222594738007], [0.6217412948608398, 0.026208320632576942, 0.026208320632576942, 0.31832706928253174, 0.007514952681958675], [0.46628013253211975, 0.0076621221378445625, 0.058230724185705185, 0.0015468135243281722, 0.46628013253211975], [0.02164195105433464, 0.4617522954940796, 0.0404561385512352, 0.4617522954940796, 0.014397257938981056], [0.43352678418159485, 0.02920514903962612, 0.02920514903962612, 0.4679890275001526, 0.0400739461183548], [0.6334613561630249, 0.2673342823982239, 0.07113223522901535, 0.014036091975867748, 0.014036091975867748], [0.02691066637635231, 0.07760170847177505, 0.11857672035694122, 0.6583342552185059, 0.11857672035694122], [0.619122326374054, 0.001758294878527522, 0.0003729336604010314, 0.0003729336604010314, 0.37837356328964233], [0.01663271337747574, 0.01663271337747574, 0.7699801921844482, 0.006117143668234348, 0.19063718616962433], [0.42120543122291565, 0.12111838907003403, 0.1929301619529724, 0.14362755417823792, 0.12111838907003403], [0.010282852686941624, 0.5047562718391418, 0.02862069196999073, 0.3151872158050537, 0.14115296304225922], [0.8288668394088745, 0.10066137462854385, 0.02584412880241871, 0.02584412880241871, 0.018783580511808395], [0.024919411167502403, 0.31743794679641724, 0.31743794679641724, 0.28851252794265747, 0.051692187786102295], [0.2932528555393219, 0.23689137399196625, 0.21427084505558014, 0.21427084505558014, 0.04131404310464859], [0.00943622924387455, 0.002181015210226178, 0.25747138261795044, 0.7287303805351257, 0.002181015210226178], [0.053279854357242584, 0.35839614272117615, 0.21269859373569489, 0.35839614272117615, 0.017229262739419937], [0.001021632575429976, 0.19010001420974731, 0.3559236526489258, 0.09703109413385391, 0.3559236526489258], [0.7535232901573181, 0.039168305695056915, 0.005298908334225416, 0.039168305695056915, 0.16284121572971344], [0.1585245132446289, 0.011156420223414898, 0.1585245132446289, 0.06340063363313675, 0.6083939075469971], [0.6994428038597107, 0.030886242166161537, 0.015063867904245853, 0.23954325914382935, 0.015063867904245853], [0.04602741822600365, 0.04602741822600365, 0.8177326321601868, 0.01536204107105732, 0.07485051453113556], [0.0013494326267391443, 0.0009198295301757753, 0.01715758442878723, 0.689317524433136, 0.2912556231021881], [0.22884145379066467, 0.22884145379066467, 0.4117858111858368, 0.019822509959340096, 0.1107088178396225], [0.024737544357776642, 0.17043179273605347, 0.18797610700130463, 0.4464227855205536, 0.17043179273605347], [0.17354291677474976, 0.018143227323889732, 0.39249926805496216, 0.17354291677474976, 0.24227167665958405], [0.0016968885902315378, 0.49629056453704834, 0.0006778549286536872, 0.49629056453704834, 0.005044060759246349], [0.0040590884163975716, 0.2547265291213989, 0.09025553613901138, 0.2547265291213989, 0.39623233675956726], [0.17345024645328522, 0.030319180339574814, 0.6319079399108887, 0.16136476397514343, 0.002957945689558983], [0.00010530593863222748, 0.07982023060321808, 0.07982023060321808, 0.03741944581270218, 0.8028348684310913], [0.021802304312586784, 0.012349778786301613, 0.0026451717130839825, 0.9508530497550964, 0.012349778786301613], [0.004196489695459604, 0.7777417302131653, 0.17515544593334198, 0.004196489695459604, 0.038709841668605804], [0.516352117061615, 0.38335123658180237, 0.09344423562288284, 0.003426233073696494, 0.003426233073696494], [0.010569779202342033, 0.3649616241455078, 0.3649616241455078, 0.23216021060943604, 0.027346758171916008], [0.3847745358943939, 0.011853525415062904, 0.3847745358943939, 0.008876635693013668, 0.20972079038619995], [0.22795884311199188, 0.06792540848255157, 0.34984225034713745, 0.004431245848536491, 0.34984225034713745], [0.8536689877510071, 0.001273730886168778, 0.13567321002483368, 0.001273730886168778, 0.008110356517136097], [0.3435279428958893, 0.04905441775918007, 0.033089809119701385, 0.3435279428958893, 0.2307998687028885], [0.19611027836799622, 0.16217565536499023, 0.14450092613697052, 0.16217565536499023, 0.3350374698638916], [0.7446438074111938, 0.012091412208974361, 0.12107131630182266, 0.0011222348548471928, 0.12107131630182266], [0.027279293164610863, 0.0526837557554245, 0.3549897074699402, 0.5123634934425354, 0.0526837557554245], [0.038262542337179184, 0.038262542337179184, 0.02703768014907837, 0.017591403797268867, 0.8788458108901978], [0.02714919112622738, 0.008546264842152596, 0.08356604725122452, 0.8657257556915283, 0.015012676827609539], [0.38517701625823975, 0.0001362532057100907, 0.013205287978053093, 0.013205287978053093, 0.5882760882377625], [0.29652610421180725, 0.02197343297302723, 0.3405183255672455, 0.3405183255672455, 0.00046380894491449], [0.1007799282670021, 0.1007799282670021, 0.021931881085038185, 0.5844250321388245, 0.1920831799507141], [0.18412458896636963, 0.2265179455280304, 0.003115566447377205, 0.18412458896636963, 0.4021173119544983], [0.36999815702438354, 0.13486862182617188, 0.36999815702438354, 0.0572303906083107, 0.06790465861558914], [0.18096277117729187, 0.33916816115379333, 0.13263463973999023, 0.008066282607614994, 0.33916816115379333], [0.7367241382598877, 0.016915244981646538, 0.08424512296915054, 0.07787025719881058, 0.08424512296915054], [0.014107294380664825, 0.7670773267745972, 0.202882319688797, 0.014107294380664825, 0.0018257555784657598], [0.9454907774925232, 0.0006779467221349478, 0.01782684400677681, 0.01782684400677681, 0.018177492544054985], [0.24141283333301544, 0.15244796872138977, 0.27095362544059753, 0.27095362544059753, 0.06423191726207733], [0.13641108572483063, 0.0011242582695558667, 0.015778884291648865, 0.13641108572483063, 0.7102746367454529], [0.025097185745835304, 0.5585149526596069, 0.1985853761434555, 0.01921708695590496, 0.1985853761434555], [0.0024046318139880896, 0.07562323659658432, 0.058658186346292496, 0.058658186346292496, 0.8046557903289795], [0.9129199981689453, 0.0645218938589096, 0.005431434605270624, 0.008563380688428879, 0.008563380688428879], [7.354913395829499e-05, 0.09083224087953568, 0.09083224087953568, 0.43311017751693726, 0.3851517140865326], [0.03436511754989624, 0.5989394783973694, 0.05637940764427185, 0.2539365887641907, 0.05637940764427185], [0.13224075734615326, 0.13224075734615326, 0.6426535844802856, 0.07404689490795135, 0.018817976117134094], [0.9914889335632324, 0.00444136094301939, 0.00363046838901937, 0.00021962972823530436, 0.00021962972823530436], [0.27555251121520996, 0.27555251121520996, 0.245980367064476, 0.08129803091287613, 0.12161654978990555], [0.6995193362236023, 0.27848851680755615, 0.010443438775837421, 0.0011053013149648905, 0.010443438775837421], [0.03929087147116661, 0.7920649647712708, 0.01402000430971384, 0.1406041979789734, 0.01402000430971384], [0.0025006846990436316, 0.5263432860374451, 0.012950328178703785, 0.22910284996032715, 0.22910284996032715], [0.34258636832237244, 0.34258636832237244, 0.012449538335204124, 0.2652745842933655, 0.03710310533642769], [0.2876702845096588, 0.04797607660293579, 0.0642685517668724, 0.5095783472061157, 0.09050673246383667], [0.437697172164917, 0.02026670053601265, 0.3428460359573364, 0.1789233386516571, 0.02026670053601265], [0.001381171285174787, 0.33223751187324524, 0.3045193552970886, 0.029624449089169502, 0.33223751187324524], [0.0001958819484570995, 0.07104271650314331, 0.0001958819484570995, 0.2164383828639984, 0.7121272087097168], [0.17912694811820984, 0.31963062286376953, 0.31963062286376953, 0.010291056707501411, 0.17132076621055603], [0.008611517958343029, 0.28784093260765076, 0.22349682450294495, 0.22349682450294495, 0.25655391812324524], [0.012715175747871399, 0.2914903163909912, 0.10103651136159897, 0.3032677173614502, 0.2914903163909912], [0.003922442439943552, 0.005171502474695444, 0.2752179801464081, 0.2752179801464081, 0.4404700696468353], [0.3589111566543579, 0.06515754014253616, 0.16792351007461548, 0.20400391519069672, 0.20400391519069672], [0.010456564836204052, 0.08310885727405548, 0.0051990835927426815, 0.8907788395881653, 0.010456564836204052], [0.020461909472942352, 0.0023968806490302086, 0.1068374440073967, 0.8679068684577942, 0.0023968806490302086], [0.003754893084987998, 0.1839674860239029, 0.28551748394966125, 0.2633800506591797, 0.2633800506591797], [0.07001682370901108, 0.004674427676945925, 0.004674427676945925, 0.4291183054447174, 0.4915160536766052], [0.07478564977645874, 0.0006663770182058215, 0.8178645968437195, 0.0006663770182058215, 0.10601703077554703], [0.10734318196773529, 0.14893324673175812, 0.012253130786120892, 0.012253130786120892, 0.7192173004150391], [0.0024838438257575035, 0.6671991348266602, 0.09433521330356598, 0.1179909035563469, 0.1179909035563469], [0.03748774901032448, 0.10263115167617798, 0.7520633339881897, 0.10263115167617798, 0.005186624359339476], [0.08708818256855011, 0.008196511305868626, 0.23283512890338898, 0.08708818256855011, 0.5847920179367065], [0.008634363301098347, 0.34570392966270447, 0.1095326766371727, 0.1095326766371727, 0.426596462726593], [0.35210880637168884, 0.011178597807884216, 0.011178597807884216, 0.31635960936546326, 0.30917438864707947], [0.012946751900017262, 0.5452982783317566, 0.014147251844406128, 0.4134604334831238, 0.014147251844406128], [0.00039923240547068417, 0.5253121256828308, 0.009481986984610558, 0.4553246796131134, 0.009481986984610558], [0.45505526661872864, 0.01570221409201622, 0.025531437247991562, 0.048655763268470764, 0.45505526661872864], [0.21365055441856384, 0.18938295543193817, 0.26016825437545776, 0.07662999629974365, 0.26016825437545776], [0.0009168962715193629, 0.036840617656707764, 0.46770787239074707, 0.026826824992895126, 0.46770787239074707], [0.11534644663333893, 0.07343227416276932, 0.2915832996368408, 0.11534644663333893, 0.40429142117500305], [0.24299238622188568, 0.3526245653629303, 0.3526245653629303, 0.015975618734955788, 0.035782892256975174], [0.015456180088222027, 0.04684771969914436, 0.11956214159727097, 0.015456180088222027, 0.8026778697967529], [0.011053885333240032, 0.1251319944858551, 0.0009143599309027195, 0.011053885333240032, 0.8518458008766174], [0.014146159403026104, 0.9198689460754395, 0.03243372589349747, 0.03243372589349747, 0.0011173844104632735], [0.07545652985572815, 0.4936560392379761, 0.07545652985572815, 0.017908908426761627, 0.3375220000743866], [0.04197756201028824, 0.08789514005184174, 0.023400891572237015, 0.08789514005184174, 0.758831262588501], [0.058709241449832916, 0.07924353331327438, 0.7186822891235352, 0.06412143260240555, 0.07924353331327438], [0.016595810651779175, 0.4714932441711426, 0.019231721758842468, 0.4714932441711426, 0.021185947582125664], [0.475289523601532, 0.008965856395661831, 0.03711193799972534, 0.003343181684613228, 0.475289523601532], [0.042021095752716064, 0.004027191083878279, 0.7494186758995056, 0.10226651281118393, 0.10226651281118393], [0.004761427640914917, 0.00020864054386038333, 0.42521652579307556, 0.14459693431854248, 0.42521652579307556], [0.08805523812770844, 0.01122573297470808, 0.0032743916381150484, 0.08805523812770844, 0.8093894124031067], [0.03932764008641243, 0.07516621053218842, 0.03932764008641243, 0.0036652872804552317, 0.8425133228302002], [0.11477623134851456, 0.16876250505447388, 0.5964250564575195, 0.11477623134851456, 0.005259972531348467], [0.036898523569107056, 0.05383703112602234, 0.11731468886137009, 0.4736034870147705, 0.3183462619781494], [0.1781509667634964, 0.02777980826795101, 0.1781509667634964, 0.58871990442276, 0.027198340743780136], [0.034227192401885986, 0.7770230770111084, 0.034227192401885986, 0.14424893260002136, 0.010273590683937073], [0.4240868389606476, 0.12280427664518356, 0.4240868389606476, 0.02712211012840271, 0.0018999645253643394], [0.10281071066856384, 0.1651630848646164, 0.5159369111061096, 0.1607668697834015, 0.05532246083021164], [0.0009042537421919405, 0.002468660706654191, 0.0009042537421919405, 0.9793528914451599, 0.01636994443833828], [0.30299949645996094, 0.034315455704927444, 0.034315455704927444, 0.572017252445221, 0.056352272629737854], [0.024717651307582855, 0.024814821779727936, 0.47378823161125183, 0.47378823161125183, 0.00289103202521801], [0.5449245572090149, 0.08944538235664368, 0.17346781492233276, 0.17346781492233276, 0.018694402649998665], [0.0007341413875110447, 0.0007341413875110447, 0.08077570796012878, 0.6394426226615906, 0.27831336855888367], [0.12821677327156067, 0.3281031847000122, 0.1100163608789444, 0.12821677327156067, 0.30544692277908325], [0.09123881906270981, 0.00048114979290403426, 0.8708656430244446, 5.0550384912639856e-05, 0.03736380860209465], [0.005309291649609804, 0.39266493916511536, 0.18170392513275146, 0.009805387817323208, 0.4105164408683777], [0.01311002392321825, 0.19047226011753082, 0.25099197030067444, 0.2727128565311432, 0.2727128565311432], [0.31925827264785767, 0.053665101528167725, 0.40408435463905334, 0.16932715475559235, 0.053665101528167725], [0.0098824892193079, 0.05815885588526726, 0.03743324056267738, 0.0098824892193079, 0.8846428394317627], [0.1693408340215683, 0.1895354688167572, 0.2975729703903198, 0.2975729703903198, 0.04597775265574455], [0.0026216604746878147, 0.28834500908851624, 0.0026216604746878147, 0.49247682094573975, 0.21393486857414246], [0.09964194148778915, 0.0055771092884242535, 0.0055771092884242535, 0.6240779161453247, 0.26512593030929565], [0.26766544580459595, 0.031301770359277725, 0.11261781305074692, 0.031301770359277725, 0.5571131706237793], [0.005832124035805464, 0.47492673993110657, 0.005832124035805464, 0.291597455739975, 0.22181150317192078], [0.13261452317237854, 0.000470382918138057, 0.7949463129043579, 0.000470382918138057, 0.07149849832057953], [0.19895632565021515, 0.09866749495267868, 0.0146018760278821, 0.3438871502876282, 0.3438871502876282], [0.24104148149490356, 0.1256060153245926, 0.21444736421108246, 0.2094525396823883, 0.2094525396823883], [0.36412322521209717, 0.004644656553864479, 0.10075888782739639, 0.36412322521209717, 0.16634996235370636], [0.3492436110973358, 0.007524922490119934, 0.3517840802669525, 0.283922404050827, 0.007524922490119934], [0.13123856484889984, 0.003653137478977442, 0.0034694510977715254, 0.0034694510977715254, 0.858169436454773], [0.15149560570716858, 0.3233203589916229, 0.15149560570716858, 0.0004875399172306061, 0.373200923204422], [0.17714373767375946, 0.7598609924316406, 0.014103949069976807, 0.0002883702691178769, 0.04860285297036171], [0.8116645812988281, 0.02517520636320114, 0.13791653513908386, 0.02517520636320114, 6.838708213763312e-05], [0.013794692233204842, 0.006746255327016115, 0.4443841278553009, 0.09069084376096725, 0.4443841278553009], [0.022347532212734222, 0.0516863614320755, 0.004038975108414888, 0.556938648223877, 0.3649884760379791], [0.3914095461368561, 0.013268408365547657, 0.14198903739452362, 0.44006457924842834, 0.013268408365547657], [0.01715724542737007, 0.08648132532835007, 0.01715724542737007, 0.8260030746459961, 0.0532011054456234], [0.09145061671733856, 0.2610645294189453, 0.2610645294189453, 0.06999453902244568, 0.31642577052116394], [0.3660421669483185, 0.07221214473247528, 0.1478770226240158, 0.3828662931919098, 0.03100235015153885], [0.48960253596305847, 0.00710012624040246, 0.3200136721134186, 0.00710012624040246, 0.1761835217475891], [0.004016685299575329, 0.4384846091270447, 0.1626475751399994, 0.3908344507217407, 0.004016685299575329], [0.17705005407333374, 0.0019460744224488735, 0.1825055181980133, 0.17705005407333374, 0.4614483118057251], [0.2072143852710724, 0.06074763461947441, 0.33904701471328735, 0.33904701471328735, 0.053943950682878494], [0.8427220582962036, 0.0008635655394755304, 0.15292741358280182, 0.0017434590263292193, 0.0017434590263292193], [0.13708579540252686, 0.0049062371253967285, 0.4091378450393677, 0.039732325822114944, 0.4091378450393677], [0.05648994818329811, 4.953989991918206e-05, 0.1653110533952713, 0.15144096314907074, 0.6267085075378418], [0.20741604268550873, 0.0005512009374797344, 0.17640918493270874, 0.20741604268550873, 0.4082074761390686], [0.07005251944065094, 0.051050979644060135, 0.40668314695358276, 0.40668314695358276, 0.06553012877702713], [0.0741710290312767, 0.4310718774795532, 0.24736414849758148, 0.24736414849758148, 2.8782253139070235e-05], [0.14099904894828796, 0.002878594910725951, 0.8411440849304199, 0.012099704705178738, 0.002878594910725951], [0.03567018732428551, 0.01476878859102726, 0.01476878859102726, 0.7454525232315063, 0.18933966755867004], [0.46095532178878784, 0.05283041670918465, 0.46095532178878784, 0.0003194812743458897, 0.024939395487308502], [0.019512362778186798, 0.0007192138000391424, 0.9131669402122498, 0.0007192138000391424, 0.06588221341371536], [0.3234648108482361, 0.5050631165504456, 0.0780787542462349, 0.015314547345042229, 0.0780787542462349], [0.2371099293231964, 0.05155664682388306, 0.4949665069580078, 0.05155664682388306, 0.16481034457683563], [0.004008455201983452, 0.11420085281133652, 0.06873957067728043, 0.002246019197627902, 0.810805082321167], [0.4253372848033905, 0.09582877904176712, 0.23646584153175354, 0.0059023573994636536, 0.23646584153175354], [0.006549428682774305, 0.0067479875870049, 0.006549428682774305, 0.9787597060203552, 0.0013934149174019694], [0.9000705480575562, 0.09162676334381104, 0.0010721980361267924, 0.0036152296233922243, 0.0036152296233922243], [0.4019463360309601, 0.16590355336666107, 0.06461473554372787, 0.18376769125461578, 0.18376769125461578], [0.41033023595809937, 0.03140974044799805, 0.03140974044799805, 0.5264500379562378, 0.00040022769826464355], [0.018033653497695923, 0.19229625165462494, 0.19229625165462494, 0.5393293499946594, 0.05804450064897537], [0.49830517172813416, 0.00021771779574919492, 0.0030906377360224724, 8.135767711792141e-05, 0.49830517172813416], [0.2303912490606308, 0.20978687703609467, 0.13917486369609833, 0.2303912490606308, 0.1902557611465454], [0.0002568949421402067, 0.10936453193426132, 0.7715033292770386, 0.009510793723165989, 0.10936453193426132], [0.0036149106454104185, 0.4494962990283966, 0.2681642770767212, 0.010560187511146069, 0.2681642770767212], [0.08098621666431427, 0.5833664536476135, 0.08098621666431427, 0.0011320133926346898, 0.2535291314125061], [0.08285016566514969, 0.02106492780148983, 0.7011204361915588, 0.1935606300830841, 0.0014037807704880834], [0.12313394248485565, 0.07221522927284241, 0.18764802813529968, 0.6156039834022522, 0.001398848951794207], [0.015318886376917362, 0.44013017416000366, 0.029893118888139725, 0.44013017416000366, 0.07452772557735443], [0.11051647365093231, 0.0001359362358925864, 0.0007011656416580081, 0.7781299948692322, 0.11051647365093231], [0.006293774116784334, 0.2812400460243225, 0.3346296548843384, 0.06352928280830383, 0.31430721282958984], [0.7527429461479187, 0.10363364964723587, 2.1513978936127387e-05, 0.039968185126781464, 0.10363364964723587], [0.5351575613021851, 0.04781051725149155, 0.04781051725149155, 0.10361771285533905, 0.2656037211418152], [0.7423009276390076, 0.08730685710906982, 0.08091238141059875, 0.08091238141059875, 0.0085674449801445], [0.02473399043083191, 0.16709385812282562, 0.02473399043083191, 0.056577637791633606, 0.7268604636192322], [0.11973796039819717, 0.43939971923828125, 0.0006034030229784548, 0.00085923116421327, 0.43939971923828125], [0.025441624224185944, 0.5151970982551575, 2.462514203216415e-05, 0.4338950216770172, 0.025441624224185944], [0.01067704800516367, 0.3990364372730255, 0.25697845220565796, 0.07632961869239807, 0.25697845220565796], [0.33764076232910156, 0.0062203011475503445, 0.0028770039789378643, 0.33764076232910156, 0.3156210780143738], [0.2908436357975006, 0.2908436357975006, 0.00868070125579834, 0.02188795618712902, 0.38774406909942627], [0.8987678289413452, 0.014439836144447327, 0.035703834146261215, 0.03664867579936981, 0.014439836144447327], [0.4701525866985321, 0.05829242989420891, 0.00026379982591606677, 0.001138710300438106, 0.4701525866985321], [0.0007150272140279412, 0.6999363899230957, 0.0050798882730305195, 0.0002043611602857709, 0.29406434297561646], [0.03230912983417511, 0.03829503804445267, 0.8961908221244812, 0.03230912983417511, 0.0008958502439782023], [0.003261368488892913, 0.32070112228393555, 0.08192870765924454, 0.32070112228393555, 0.2734076976776123], [0.48461106419563293, 0.0007810756214894354, 0.0005378041532821953, 0.48018863797187805, 0.03388144448399544], [0.0010029739933088422, 0.3471483588218689, 0.16920402646064758, 0.1354963183403015, 0.3471483588218689], [0.14646027982234955, 0.5026624202728271, 0.1210155114531517, 0.14646027982234955, 0.08340153843164444], [0.03080011159181595, 0.020857078954577446, 0.24914783239364624, 0.6783379316329956, 0.020857078954577446], [0.43722084164619446, 0.07340198010206223, 0.006869425065815449, 0.24125385284423828, 0.24125385284423828], [0.10115893930196762, 0.5197420120239258, 0.10115893930196762, 0.14564236998558044, 0.13229775428771973], [0.0963408574461937, 0.5405706763267517, 0.15698711574077606, 0.004132898990064859, 0.20196841657161713], [0.09661144018173218, 0.00017854454927146435, 0.4192332923412323, 0.00017854454927146435, 0.48379814624786377], [0.18308643996715546, 0.18308643996715546, 0.17690540850162506, 0.23685622215270996, 0.22006544470787048], [6.436038529500365e-05, 0.08387705683708191, 6.436038529500365e-05, 0.027106577530503273, 0.8888877630233765], [0.08548668026924133, 0.07878542691469193, 0.04182722419500351, 0.08548668026924133, 0.7084138989448547], [0.3025978207588196, 0.39138442277908325, 0.0003321511030662805, 0.003087828401476145, 0.3025978207588196], [0.09235269576311111, 0.6476464867591858, 0.10044380277395248, 0.05911322310566902, 0.10044380277395248], [0.008547413162887096, 0.45616161823272705, 0.008547413162887096, 0.5021259188652039, 0.024617601186037064], [0.28487712144851685, 0.003540641162544489, 0.2389214038848877, 0.2389214038848877, 0.23373949527740479], [0.061945270746946335, 0.03988017141819, 0.3020144999027252, 0.061945270746946335, 0.5342147946357727], [0.27447494864463806, 0.004691300913691521, 0.5923470258712769, 0.06424334645271301, 0.06424334645271301], [0.058081142604351044, 0.4243977665901184, 0.17379020154476166, 0.17186544835567474, 0.17186544835567474], [0.06356912106275558, 0.0002375743060838431, 0.7067753672599792, 0.007857580669224262, 0.22156041860580444], [0.004797553177922964, 0.004797553177922964, 0.3334825932979584, 0.06903921812772751, 0.5878830552101135], [0.3156072795391083, 0.3156072795391083, 0.0002453151100780815, 0.016813889145851135, 0.3517262637615204], [0.1891457885503769, 0.02899329550564289, 0.2658846974372864, 0.3268304169178009, 0.1891457885503769], [0.016290128231048584, 0.12349947541952133, 0.17972281575202942, 0.6641974449157715, 0.016290128231048584], [0.05092393234372139, 0.09455394744873047, 0.05092393234372139, 0.10488750040531158, 0.6987107396125793], [0.17048174142837524, 0.4043039381504059, 0.01958874613046646, 0.4043039381504059, 0.0013216182123869658], [0.46066033840179443, 0.06151903420686722, 0.01538906991481781, 0.46066033840179443, 0.0017712657572701573], [0.08183373510837555, 0.03944094851613045, 0.6219373345375061, 0.08183373510837555, 0.17495420575141907], [0.13141079246997833, 0.4104631841182709, 0.04762495681643486, 3.792501229327172e-05, 0.4104631841182709], [0.04874807968735695, 0.22235579788684845, 0.1868126094341278, 0.059246428310871124, 0.48283711075782776], [0.006033435929566622, 0.2024596631526947, 0.18032866716384888, 0.2024596631526947, 0.4087185263633728], [0.021243195980787277, 0.4619607627391815, 0.5017288327217102, 0.0075335875153541565, 0.0075335875153541565], [0.025981182232499123, 0.0011881929822266102, 0.056033018976449966, 0.9031773209571838, 0.013620205223560333], [0.0810457095503807, 0.020693356171250343, 0.34391075372695923, 0.34391075372695923, 0.21043945848941803], [0.3345923125743866, 0.22843459248542786, 0.012564766220748425, 0.22843459248542786, 0.195973739027977], [0.6685650944709778, 0.07937226444482803, 0.07937226444482803, 0.10330058634281158, 0.06938981264829636], [0.30663353204727173, 0.25422653555870056, 0.30663353204727173, 0.002318443963304162, 0.13018794357776642], [0.19795680046081543, 0.05245474353432655, 0.728119432926178, 0.010734514333307743, 0.010734514333307743], [0.21364828944206238, 0.21364828944206238, 0.06213308498263359, 0.5097172260284424, 0.0008530675549991429], [0.829521894454956, 0.009728782810270786, 0.03168018162250519, 0.11934046447277069, 0.009728782810270786], [0.0018694024765864015, 0.4836066961288452, 0.4836066961288452, 0.023253368213772774, 0.0076638259924948215], [0.1094573438167572, 0.07101035118103027, 0.7350853085517883, 0.013436631299555302, 0.07101035118103027], [0.6324324011802673, 0.09189274907112122, 0.03723637014627457, 0.03723637014627457, 0.20120206475257874], [0.0027296890038996935, 0.10702808946371078, 0.002150637563318014, 0.8853619694709778, 0.0027296890038996935], [0.02658333256840706, 0.45593056082725525, 0.08971608430147171, 0.08971608430147171, 0.33805394172668457], [0.11559023708105087, 0.5494773983955383, 0.006702177692204714, 0.11559023708105087, 0.2126399427652359], [0.009761198423802853, 0.1936739981174469, 0.1936739981174469, 0.5513136982917786, 0.051577094942331314], [0.008769971318542957, 0.8534039855003357, 0.008769971318542957, 0.06509687006473541, 0.06395916640758514], [0.04960459843277931, 0.8474981784820557, 0.03181454911828041, 0.035541363060474396, 0.035541363060474396], [0.02211659401655197, 0.010663934983313084, 0.941769540309906, 0.02211659401655197, 0.003333403030410409], [0.22691649198532104, 0.14062047004699707, 0.22691649198532104, 0.34845221042633057, 0.057094309478998184], [9.913776739267632e-05, 0.09966594725847244, 0.8263097405433655, 9.913776739267632e-05, 0.07382605224847794], [0.24378874897956848, 0.05208834633231163, 0.05208834633231163, 0.6453243494033813, 0.006710227578878403], [0.016011320054531097, 0.011704567819833755, 0.29454439878463745, 0.6617283225059509, 0.016011320054531097], [0.32688748836517334, 0.2927207946777344, 0.046163108199834824, 0.007341073360294104, 0.32688748836517334], [0.6158064603805542, 0.05132351443171501, 0.0004546993877738714, 0.16620764136314392, 0.16620764136314392], [0.28037768602371216, 0.7008071541786194, 0.0025512271095067263, 0.013712693937122822, 0.0025512271095067263], [0.1427002251148224, 0.16394272446632385, 0.025977550074458122, 0.613158106803894, 0.05422142520546913], [0.2994703948497772, 0.32066091895103455, 0.2994703948497772, 0.038331273943185806, 0.04206704720854759], [0.21594752371311188, 0.13682471215724945, 0.10003094375133514, 0.21594752371311188, 0.33124929666519165], [0.02366117760539055, 0.028608232736587524, 0.259945273399353, 0.259945273399353, 0.4278400242328644], [0.6082003116607666, 0.00029634672682732344, 0.06145033612847328, 0.3297567069530487, 0.00029634672682732344], [0.15202611684799194, 0.10009554773569107, 0.00018783812993206084, 0.004178384318947792, 0.7435121536254883], [0.0027002040296792984, 0.654045820236206, 0.11258110404014587, 0.11809175461530685, 0.11258110404014587], [0.38083702325820923, 0.06536952406167984, 0.38083702325820923, 0.04395798593759537, 0.12899842858314514], [0.2853921949863434, 0.01315008383244276, 0.2853921949863434, 0.06499314308166504, 0.35107237100601196], [0.45270591974258423, 0.0024642234202474356, 0.21653753519058228, 0.21653753519058228, 0.11175483465194702], [0.428810715675354, 0.2468208372592926, 0.04645436629652977, 0.23145970702171326, 0.04645436629652977], [0.018352555111050606, 0.3788570165634155, 0.057189442217350006, 0.5272484421730042, 0.018352555111050606], [0.015506762079894543, 0.12213118374347687, 0.015506762079894543, 0.840215802192688, 0.006639488041400909], [0.17523373663425446, 0.003557668998837471, 0.4091089367866516, 0.002990679582580924, 0.4091089367866516], [0.008999795652925968, 0.32667654752731323, 0.008999795652925968, 0.010354666970670223, 0.6449692249298096], [0.8798847198486328, 0.05489538609981537, 0.0008148835622705519, 0.009509689174592495, 0.05489538609981537], [0.4045504331588745, 0.007959121838212013, 0.15710040926933289, 0.025839583948254585, 0.4045504331588745], [0.017265621572732925, 9.799700637813658e-05, 0.018341541290283203, 9.799700637813658e-05, 0.9641968607902527], [0.1179451048374176, 0.006176231428980827, 0.7518115639686584, 0.1179451048374176, 0.006122084334492683], [0.08453425765037537, 0.7628996968269348, 0.048984453082084656, 0.08453425765037537, 0.0190473273396492], [0.6851865649223328, 0.15557295083999634, 0.12681187689304352, 0.001957789994776249, 0.030470803380012512], [0.033810801804065704, 0.8048534989356995, 0.03116198070347309, 0.03116198070347309, 0.09901174157857895], [0.11519528180360794, 0.34952691197395325, 0.11519528180360794, 0.3231532871723175, 0.09692925214767456], [0.23298873007297516, 0.000856460421346128, 0.0028992185834795237, 0.7603563666343689, 0.0028992185834795237], [0.13521333038806915, 0.016295915469527245, 0.13521333038806915, 0.08304920047521591, 0.6302282810211182], [0.8373945355415344, 0.14303210377693176, 0.007978811860084534, 0.003615748602896929, 0.007978811860084534], [0.01486162468791008, 0.27448567748069763, 0.27448567748069763, 0.43608465790748596, 8.244159107562155e-05], [0.1253080517053604, 0.04845144599676132, 0.2242344617843628, 0.5535545945167542, 0.04845144599676132], [0.05215618759393692, 0.8172355890274048, 0.010135594755411148, 0.12046525627374649, 7.423049737553811e-06], [0.4420768618583679, 0.4420768618583679, 0.08104177564382553, 0.034587785601615906, 0.0002166955528082326], [0.028676465153694153, 0.6930726766586304, 0.2346901297569275, 0.014884207397699356, 0.028676465153694153], [0.015287660993635654, 0.009234391152858734, 0.0021722177043557167, 0.9580181241035461, 0.015287660993635654], [0.1800081729888916, 0.1800081729888916, 0.13042709231376648, 0.10107843577861786, 0.40847811102867126], [0.14212730526924133, 0.3303605020046234, 0.15252944827079773, 0.14212730526924133, 0.23285537958145142], [0.09765329211950302, 0.0005015326314605772, 0.0005015326314605772, 0.8668010234832764, 0.03454257920384407], [0.2625042200088501, 0.2063276767730713, 0.16141368448734283, 0.20834070444107056, 0.16141368448734283], [0.04407654330134392, 0.00012215912283863872, 0.17189514636993408, 0.00012215912283863872, 0.7837839722633362], [0.07876203209161758, 0.2198682576417923, 0.016465691849589348, 0.07876203209161758, 0.6061420440673828], [0.013279460370540619, 0.10892251133918762, 0.10972342640161514, 0.7547951340675354, 0.013279460370540619], [0.006332096178084612, 0.00040672134491615, 0.9841691255569458, 0.00040672134491615, 0.00868535228073597], [0.28670641779899597, 0.19202199578285217, 0.19202199578285217, 0.3028112053871155, 0.02643837407231331], [0.28952720761299133, 0.28952720761299133, 0.23468880355358124, 0.14507173001766205, 0.04118501767516136], [0.3979150652885437, 0.3979150652885437, 0.10430167615413666, 0.08018958568572998, 0.019678592681884766], [0.07009159028530121, 0.4167303144931793, 0.0013348506763577461, 0.4167303144931793, 0.0951128900051117], [0.06757514178752899, 0.06757514178752899, 0.0005479472456499934, 0.025008050724864006, 0.8392937183380127], [0.3132609724998474, 0.07301892340183258, 0.04438641667366028, 0.04438641667366028, 0.5249472856521606], [0.0005459634121507406, 0.7887260317802429, 0.015300942584872246, 0.015300942584872246, 0.1801261603832245], [0.12069091945886612, 0.15002883970737457, 0.558475136756897, 0.0501142181456089, 0.12069091945886612], [0.0645391047000885, 0.019923847168684006, 0.0645391047000885, 0.42638975381851196, 0.4246082305908203], [0.45137259364128113, 0.238290473818779, 0.04642169177532196, 0.238290473818779, 0.02562474086880684], [0.30381280183792114, 2.1580737666226923e-05, 0.30381280183792114, 8.444222476100549e-05, 0.3922683894634247], [0.2713702619075775, 0.24098531901836395, 0.23912537097930908, 0.23912537097930908, 0.009393727406859398], [0.11904392391443253, 0.1061503067612648, 0.014253135770559311, 0.38027632236480713, 0.38027632236480713], [0.03757255896925926, 0.24840351939201355, 0.4492742419242859, 0.016346106305718422, 0.24840351939201355], [0.3880128562450409, 1.3759696230408736e-05, 0.037239380180835724, 0.5374946594238281, 0.037239380180835724], [0.8223021030426025, 0.02252022922039032, 0.09807884693145752, 0.02854936756193638, 0.02854936756193638], [0.5595561861991882, 0.0007287617772817612, 0.30556848645210266, 0.0007287617772817612, 0.13341780006885529], [0.0021901053842157125, 0.23931008577346802, 0.007130443584173918, 0.48363178968429565, 0.26773762702941895], [0.10720526427030563, 0.004761339630931616, 0.855797290802002, 0.01611803099513054, 0.01611803099513054], [0.016137009486556053, 0.4605168402194977, 0.17192867398262024, 0.3352804183959961, 0.016137009486556053], [0.07717449963092804, 0.30192267894744873, 0.3025903105735779, 0.015722209587693214, 0.3025903105735779], [0.49584314227104187, 0.0001271237269975245, 0.003839918877929449, 0.004346586298197508, 0.49584314227104187], [0.006519592832773924, 0.006519592832773924, 0.6810817718505859, 0.0032971070613712072, 0.30258187651634216], [0.01657332293689251, 0.029309963807463646, 0.2534782290458679, 0.029309963807463646, 0.6713284850120544], [0.1265491545200348, 0.645820140838623, 0.07649488002061844, 0.07649488002061844, 0.07464093714952469], [0.030319571495056152, 0.8610067367553711, 0.0908794179558754, 0.008897158317267895, 0.008897158317267895], [0.008582507260143757, 0.004651482217013836, 0.06228850036859512, 0.9158949851989746, 0.008582507260143757], [0.1053987443447113, 0.4341106414794922, 0.18667134642601013, 0.18667134642601013, 0.0871480256319046], [0.9215641021728516, 0.009331063367426395, 9.387664613313973e-05, 0.009331063367426395, 0.059679873287677765], [0.03215877711772919, 0.07757698744535446, 0.07757698744535446, 0.6466930508613586, 0.16599424183368683], [0.18503105640411377, 0.16255512833595276, 0.03711417689919472, 0.4527445137500763, 0.16255512833595276], [0.004053183365613222, 0.004053183365613222, 0.016130546107888222, 2.550483259255998e-05, 0.9757376909255981], [0.0021763017866760492, 0.0021763017866760492, 0.022191619500517845, 0.6018356084823608, 0.37162017822265625], [0.011068268679082394, 0.14432992041110992, 0.5516729950904846, 0.14859893918037415, 0.14432992041110992], [0.014796736650168896, 0.7109237313270569, 0.0532320961356163, 0.0532320961356163, 0.16781529784202576], [0.01787714846432209, 0.14500494301319122, 0.0028440586756914854, 0.36592963337898254, 0.46834421157836914], [0.47508302330970764, 0.00214095669798553, 0.0005792626761831343, 0.0005792626761831343, 0.5216174721717834], [0.056470997631549835, 0.0033789225853979588, 0.031457506120204926, 0.8522216081619263, 0.056470997631549835], [0.004632302559912205, 0.1887616366147995, 0.2125001847743988, 0.4053441882133484, 0.1887616366147995], [0.42271021008491516, 0.017944591119885445, 0.13628794252872467, 0.42271021008491516, 0.0003470000228844583], [0.0675048977136612, 0.0071813324466347694, 0.10776301473379135, 0.7097877264022827, 0.10776301473379135], [0.04041526839137077, 0.001239966368302703, 0.956684947013855, 0.001239966368302703, 0.0004198290698695928], [0.11888562142848969, 0.0038120062090456486, 0.01282405760139227, 0.025571998208761215, 0.8389062881469727], [0.25487422943115234, 0.26780542731285095, 0.237216055393219, 0.237216055393219, 0.0028881763573735952], [0.010748731903731823, 0.02875344827771187, 0.7779253125190735, 0.17182376980781555, 0.010748731903731823], [0.0082820700481534, 0.21970941126346588, 0.016633562743663788, 0.0082820700481534, 0.7470929026603699], [0.3386843800544739, 0.17288483679294586, 0.008034015074372292, 0.14171244204044342, 0.3386843800544739], [0.003424720373004675, 0.14313817024230957, 0.14313817024230957, 0.3249644637107849, 0.3853345215320587], [0.01232842169702053, 0.02314385026693344, 0.01232842169702053, 0.4497281312942505, 0.5024712085723877], [0.5375372767448425, 0.20083938539028168, 0.1276446133852005, 0.1276446133852005, 0.006334141828119755], [0.07553581893444061, 0.2927210330963135, 0.48140472173690796, 0.07553581893444061, 0.07480257749557495], [0.29896414279937744, 0.05469384789466858, 0.3234459459781647, 0.29896414279937744, 0.023931896314024925], [0.18333882093429565, 0.14975059032440186, 0.42688605189323425, 0.05668571963906288, 0.18333882093429565], [0.14552521705627441, 0.00011041078687412664, 0.024279693141579628, 0.8107547760009766, 0.019329991191625595], [0.6872302889823914, 0.027206536382436752, 0.05286487191915512, 0.05286487191915512, 0.17983336746692657], [0.06252709031105042, 0.0021042884327471256, 0.0021042884327471256, 0.020514048635959625, 0.9127503037452698], [0.05572133511304855, 0.0451778843998909, 0.0451778843998909, 0.7702779769897461, 0.08364491909742355], [0.14389075338840485, 0.10616926848888397, 0.10616926848888397, 0.5690059065818787, 0.07476479560136795], [0.36284688115119934, 0.1981263905763626, 0.36284688115119934, 0.05773230269551277, 0.018447518348693848], [0.01718372292816639, 0.1259632259607315, 0.58104407787323, 0.13790449500083923, 0.13790449500083923], [0.3275761902332306, 0.2031717151403427, 0.008538268506526947, 0.3275761902332306, 0.13313764333724976], [0.23967161774635315, 0.32194727659225464, 0.42289888858795166, 0.007741106674075127, 0.007741106674075127], [0.00013264727022033185, 0.057413581758737564, 0.9391409754753113, 0.00013264727022033185, 0.003180223749950528], [0.4613865911960602, 0.2219015508890152, 0.08955764025449753, 0.005252703558653593, 0.2219015508890152], [0.13039007782936096, 0.004316273611038923, 0.39549747109413147, 0.004316273611038923, 0.46547991037368774], [5.813151801703498e-05, 0.07161419093608856, 0.012355421669781208, 0.844357967376709, 0.07161419093608856], [0.0007440748740918934, 0.8001688122749329, 0.09715571999549866, 0.09715571999549866, 0.00477561354637146], [0.018701378256082535, 0.07075022906064987, 0.25950708985328674, 0.25950708985328674, 0.3915342390537262], [0.12803304195404053, 0.13700741529464722, 0.36247143149375916, 0.12803304195404053, 0.24445505440235138], [0.6893389225006104, 0.010112931951880455, 0.19399946928024292, 0.010112931951880455, 0.09643568843603134], [0.41000545024871826, 0.41000545024871826, 0.010462900623679161, 0.09871847182512283, 0.07080774754285812], [0.36127910017967224, 0.2146563082933426, 0.09264971315860748, 0.09264971315860748, 0.238765150308609], [0.04756287857890129, 0.3005302846431732, 0.3005302846431732, 0.08908338844776154, 0.2622931897640228], [0.14830131828784943, 0.14830131828784943, 0.028051059693098068, 0.43190106749534607, 0.24344521760940552], [0.24190139770507812, 0.0424930639564991, 0.6819176077842712, 0.025788282975554466, 0.007899655029177666], [0.17622849345207214, 0.27441930770874023, 0.003136412473395467, 0.3699873089790344, 0.17622849345207214], [0.10037188231945038, 0.5193194150924683, 0.09822123497724533, 0.09822123497724533, 0.1838662326335907], [0.008872968144714832, 0.00042481147102080286, 0.11447916179895401, 0.8757982850074768, 0.00042481147102080286], [0.27782851457595825, 0.13919612765312195, 0.09733325988054276, 0.4089534282684326, 0.07668863981962204], [0.2532723546028137, 0.48816871643066406, 0.0047133928164839745, 0.2532723546028137, 0.0005732376012019813], [0.8092383742332458, 0.0013218820095062256, 0.18699871003627777, 0.0013218820095062256, 0.0011192539241164923], [0.32915428280830383, 0.00014971454220358282, 0.0453980378806591, 0.2961437404155731, 0.32915428280830383], [0.3906134366989136, 0.012627365067601204, 0.005617039278149605, 0.5855250954627991, 0.005617039278149605], [0.156825453042984, 0.0613054595887661, 0.0613054595887661, 0.7115619778633118, 0.009001628495752811], [0.7689108848571777, 0.16717608273029327, 0.01017668005079031, 0.026868164539337158, 0.026868164539337158], [0.17237825691699982, 0.34176966547966003, 0.22832362353801727, 0.22832362353801727, 0.0292048379778862], [0.024847710505127907, 0.03679243475198746, 0.7018263936042786, 0.03679243475198746, 0.19974106550216675], [0.4474629759788513, 0.06036290153861046, 0.4474629759788513, 0.007440683897584677, 0.037270497530698776], [0.001306514022871852, 0.07786796241998672, 0.3956844210624695, 0.3956844210624695, 0.12945663928985596], [0.0939653217792511, 0.12105046957731247, 0.12105046957731247, 0.1922871321439743, 0.47164657711982727], [0.0014812834560871124, 0.16509130597114563, 0.04144285246729851, 0.28965744376182556, 0.5023270845413208], [0.000248456810368225, 0.027326960116624832, 0.9668669104576111, 0.005309234373271465, 0.000248456810368225], [0.1806737780570984, 0.006705619394779205, 0.6270008683204651, 0.1806737780570984, 0.004946017172187567], [0.33590707182884216, 0.22638104856014252, 0.33590707182884216, 0.002909494796767831, 0.09889523684978485], [0.020968465134501457, 0.16332478821277618, 0.31063446402549744, 0.020968465134501457, 0.48410385847091675], [0.008479778654873371, 0.4280410408973694, 0.4280410408973694, 0.00656282901763916, 0.12887535989284515], [0.18474026024341583, 0.016382971778512, 0.0022845405619591475, 0.7943077087402344, 0.0022845405619591475], [0.018489740788936615, 0.10444691777229309, 0.018489740788936615, 0.8463069200515747, 0.012266621924936771], [0.0012434546370059252, 0.002759101102128625, 0.8398893475532532, 0.07805407047271729, 0.07805407047271729], [0.006028022617101669, 0.34540310502052307, 0.26802241802215576, 0.34540310502052307, 0.035143256187438965], [0.5005815029144287, 0.0059008514508605, 0.4676830768585205, 0.019933659583330154, 0.0059008514508605], [0.14738556742668152, 0.004336383193731308, 0.3849133849143982, 0.23168236017227173, 0.23168236017227173], [0.1810363084077835, 0.1624480038881302, 0.14540822803974152, 0.1810363084077835, 0.3300711214542389], [0.0502496212720871, 0.21707138419151306, 0.007646618410944939, 0.5079610347747803, 0.21707138419151306], [0.3144734501838684, 0.20775124430656433, 0.20775124430656433, 0.011248634196817875, 0.2587754428386688], [0.6319628357887268, 0.010654669255018234, 0.052364546805620193, 0.1525089591741562, 0.1525089591741562], [0.02378590777516365, 0.2684817612171173, 0.40675047039985657, 0.02378590777516365, 0.2771959602832794], [0.011424664407968521, 0.011424664407968521, 0.8133551478385925, 0.13291658461093903, 0.03087897226214409], [0.022983059287071228, 0.4383600056171417, 0.053213801234960556, 0.04708314687013626, 0.4383600056171417], [0.0016355511033907533, 0.3236643970012665, 0.3236643970012665, 0.00024268589913845062, 0.3507930040359497], [0.16836649179458618, 0.4308840334415436, 0.10540709644556046, 0.16836649179458618, 0.126975879073143], [0.46627652645111084, 0.006485808175057173, 0.028352633118629456, 0.4705323874950409, 0.028352633118629456], [0.1520150750875473, 0.049034662544727325, 0.1636248230934143, 0.6314582228660583, 0.0038672355003654957], [0.1526334285736084, 0.5167639255523682, 0.011571778915822506, 0.15951547026634216, 0.15951547026634216], [0.6247988343238831, 0.001455406891182065, 0.19683252274990082, 0.08845663070678711, 0.08845663070678711], [0.06794486194849014, 0.8275772929191589, 0.02469760924577713, 0.06794486194849014, 0.011835422366857529], [0.2531321346759796, 0.2000063806772232, 0.2000063806772232, 0.0026572984643280506, 0.34419775009155273], [0.05834803730249405, 0.8733377456665039, 0.0016767794732004404, 0.0016767794732004404, 0.06496060639619827], [0.00315740704536438, 0.695426344871521, 0.00315740704536438, 0.08240513503551483, 0.2158537358045578], [0.3447754979133606, 0.39797958731651306, 0.03147183358669281, 0.03147183358669281, 0.19430124759674072], [0.029517391696572304, 0.8349747657775879, 0.029517391696572304, 0.10298324376344681, 0.0030072908848524094], [0.04225361719727516, 0.21905577182769775, 0.0016468869289383292, 0.21905577182769775, 0.5179879665374756], [0.04089871048927307, 0.0009637171751819551, 0.47417980432510376, 0.00977793987840414, 0.47417980432510376], [0.22713108360767365, 0.2577466666698456, 0.0053155082277953625, 0.22713108360767365, 0.28267568349838257], [0.013889077119529247, 0.6909562945365906, 0.016007954254746437, 0.053180303424596786, 0.22596636414527893], [0.4499302804470062, 0.004402971360832453, 0.0038691021036356688, 0.09186737984418869, 0.4499302804470062], [0.026400944218039513, 0.7438028454780579, 0.10781009495258331, 0.014176038093864918, 0.10781009495258331], [0.33348649740219116, 0.17541752755641937, 0.2054819017648697, 0.2054819017648697, 0.0801321342587471], [0.32122868299484253, 0.27517005801200867, 0.32122868299484253, 0.06910455971956253, 0.013268055394291878], [0.09211596101522446, 0.8574303388595581, 0.0019909453112632036, 0.04647188261151314, 0.0019909453112632036], [0.27879077196121216, 0.25843194127082825, 0.02331709861755371, 0.25843194127082825, 0.18102823197841644], [0.5167475342750549, 0.15892153978347778, 0.15892153978347778, 0.16282770037651062, 0.002581613138318062], [0.23869970440864563, 0.04621940106153488, 0.3802143633365631, 0.23869970440864563, 0.09616679698228836], [0.03842320293188095, 0.24003814160823822, 0.26447540521621704, 0.21702514588832855, 0.24003814160823822], [0.10943014919757843, 0.0025460824836045504, 0.24751654267311096, 0.15686941146850586, 0.48363780975341797], [0.3346874415874481, 0.1037711501121521, 0.16602547466754913, 0.060828499495983124, 0.3346874415874481], [0.025362547487020493, 0.4878450036048889, 0.1927301585674286, 0.10133210569620132, 0.1927301585674286], [0.07274321466684341, 0.16948848962783813, 0.5268299579620361, 0.15819516777992249, 0.07274321466684341], [0.042122285813093185, 0.07205396890640259, 0.05295930057764053, 0.07205396890640259, 0.7608105540275574], [0.0008559196721762419, 0.008628085255622864, 0.15476469695568085, 0.0008559196721762419, 0.8348953127861023], [0.1654585748910904, 0.1342158019542694, 0.5314555168151855, 0.1654585748910904, 0.003411512356251478], [0.34120988845825195, 0.4187447428703308, 0.11131000518798828, 0.017425421625375748, 0.11131000518798828], [0.5439526438713074, 0.16057023406028748, 0.11272881925106049, 0.16057023406028748, 0.022178104147315025], [0.16909275949001312, 0.01355104148387909, 0.4071943759918213, 0.2410690188407898, 0.16909275949001312], [0.0018154430435970426, 0.16473186016082764, 0.3554922640323639, 0.3554922640323639, 0.12246815860271454], [0.4434341788291931, 0.004531756974756718, 0.02058066427707672, 0.5108727812767029, 0.02058066427707672], [0.03382553160190582, 0.2677127420902252, 0.5464774370193481, 0.11815881729125977, 0.03382553160190582], [0.004448312800377607, 0.915363609790802, 0.06584649533033371, 0.0071708266623318195, 0.0071708266623318195], [0.2427624762058258, 0.08160347491502762, 0.09026268124580383, 0.2427624762058258, 0.34260889887809753], [0.00011261155304964632, 0.03784192353487015, 0.5126663446426392, 0.41153717041015625, 0.03784192353487015], [0.013315054588019848, 0.6047984957695007, 0.13825279474258423, 0.24246656894683838, 0.0011670636013150215], [0.0004752771637868136, 0.21507690846920013, 0.21507690846920013, 0.17202182114124298, 0.39734911918640137], [0.2715468406677246, 0.49333086609840393, 0.04789954051375389, 0.04789954051375389, 0.1393231898546219], [0.0625450611114502, 0.07369006425142288, 0.7192699313163757, 0.07080493122339249, 0.07369006425142288], [0.00040897249709814787, 0.3360760509967804, 0.15498854219913483, 0.17245040833950043, 0.3360760509967804], [0.872860848903656, 0.07902370393276215, 0.01667797565460205, 0.014759569428861141, 0.01667797565460205], [0.014590497128665447, 0.15435266494750977, 0.3591117858886719, 0.11283327639102936, 0.3591117858886719], [0.022835759446024895, 0.0635724738240242, 0.03679639846086502, 0.8399990200996399, 0.03679639846086502], [0.0020678003784269094, 0.0020678003784269094, 5.479689207277261e-05, 0.03476518765091896, 0.961044430732727], [0.002802693983539939, 0.036481987684965134, 0.04187760129570961, 0.44138312339782715, 0.47745460271835327], [0.4811525046825409, 0.20534834265708923, 0.20534834265708923, 0.05334928631782532, 0.05480153486132622], [0.06180339306592941, 0.36662963032722473, 0.36662963032722473, 0.0004090364964213222, 0.20452824234962463], [0.8750242590904236, 0.02103697881102562, 0.0691789835691452, 0.014103695750236511, 0.020656101405620575], [0.01612342894077301, 0.3415955603122711, 0.5205910205841064, 0.10556652396917343, 0.01612342894077301], [0.646888792514801, 0.08527762442827225, 0.08527762442827225, 0.1822129786014557, 0.0003429809003137052], [0.04362634941935539, 0.4288807809352875, 0.4288807809352875, 9.804341243579984e-05, 0.09851396828889847], [0.06741069257259369, 0.06741069257259369, 0.8308447003364563, 0.03219979628920555, 0.002134118229150772], [0.39093151688575745, 0.2728724777698517, 0.2728724777698517, 0.01994716376066208, 0.043376367539167404], [0.2739287316799164, 0.11720333993434906, 0.3244878351688385, 0.2739287316799164, 0.010451335459947586], [0.9818645715713501, 0.0005931706982664764, 0.01686217077076435, 0.0004298895946703851, 0.00025011005345731974], [0.00016936392057687044, 0.1851998120546341, 0.00016936392057687044, 0.5641866326332092, 0.2502748370170593], [0.05227736383676529, 0.008796097710728645, 0.0713624432682991, 0.7962015867233276, 0.0713624432682991], [0.03528672084212303, 0.4605047404766083, 0.03567449375987053, 0.4332473576068878, 0.03528672084212303], [0.8601283431053162, 0.00949776265770197, 0.10665378719568253, 0.01422233134508133, 0.00949776265770197], [0.005539583042263985, 0.01656806282699108, 0.17969822883605957, 0.01656806282699108, 0.7816260457038879], [0.07207226008176804, 0.056074175983667374, 0.7025896906852722, 0.11318974941968918, 0.056074175983667374], [0.24977697432041168, 0.16135132312774658, 0.31142938137054443, 0.16135132312774658, 0.1160910502076149], [0.20465251803398132, 0.7412437200546265, 0.000443927914602682, 0.05321580544114113, 0.000443927914602682], [0.009640674106776714, 0.009640674106776714, 0.17261406779289246, 0.03588654100894928, 0.7722180485725403], [0.3916926383972168, 0.2098456621170044, 0.0025993145536631346, 0.004169709514826536, 0.3916926383972168], [0.09224317967891693, 0.09224317967891693, 0.2550297975540161, 0.020437544211745262, 0.5400462746620178], [0.43342554569244385, 0.46048691868782043, 0.0005098541732877493, 0.10506785660982132, 0.0005098541732877493], [0.23717623949050903, 0.06110720708966255, 0.32212167978286743, 0.14241859316825867, 0.23717623949050903], [0.024325309321284294, 0.48127245903015137, 1.2922018868266605e-05, 0.013116840273141861, 0.48127245903015137], [0.35510268807411194, 0.625041127204895, 0.0005275766015984118, 0.009664304554462433, 0.009664304554462433], [0.30166974663734436, 0.18744337558746338, 0.04638867452740669, 0.30166974663734436, 0.16282840073108673], [0.1507965624332428, 0.1507965624332428, 0.6231776475906372, 0.06145840138196945, 0.013770932331681252], [0.0025503826327621937, 0.01196658331900835, 0.01196658331900835, 0.9454699158668518, 0.02804649993777275], [0.3570200204849243, 0.011388987302780151, 0.608375608921051, 0.011826376430690289, 0.011388987302780151], [0.02243090234696865, 0.33952605724334717, 0.02243090234696865, 0.0214268546551466, 0.5941851735115051], [0.001044306787662208, 0.011603599414229393, 0.049207888543605804, 0.4690721035003662, 0.4690721035003662], [0.008478743024170399, 0.4557775557041168, 0.06316199153661728, 0.06316199153661728, 0.4094196856021881], [0.16741526126861572, 0.1340000480413437, 0.2735973298549652, 0.29098737239837646, 0.1340000480413437], [0.796409010887146, 0.09246668219566345, 0.09246668219566345, 0.011586996726691723, 0.007070732768625021], [0.012130964547395706, 0.14025947451591492, 0.001454145647585392, 0.001454145647585392, 0.8447012305259705], [0.24719329178333282, 0.24719329178333282, 0.03874538838863373, 0.011419475078582764, 0.4554485082626343], [0.21557778120040894, 0.21557778120040894, 0.10026545822620392, 0.006224098615348339, 0.4623549282550812], [0.4580623209476471, 0.4580623209476471, 0.010006221011281013, 0.045568641275167465, 0.028300510719418526], [0.2341032326221466, 6.73206159262918e-05, 0.07029274106025696, 0.6252440214157104, 0.07029274106025696], [0.000954028160776943, 0.47794005274772644, 0.016570106148719788, 0.47794005274772644, 0.026595689356327057], [0.08473489433526993, 0.2425958812236786, 0.08473489433526993, 0.5877400636672974, 0.00019432790577411652], [0.007157749962061644, 0.3091776371002197, 0.023769808933138847, 0.35071706771850586, 0.3091776371002197], [0.5140005350112915, 0.06167357787489891, 0.34901997447013855, 0.013632315210998058, 0.06167357787489891], [0.0006820849375799298, 0.770779550075531, 0.03623691573739052, 0.03623691573739052, 0.15606461465358734], [0.7130940556526184, 0.006921708583831787, 0.09959747642278671, 0.006921708583831787, 0.17346517741680145], [0.32569414377212524, 0.011219420470297337, 0.32569414377212524, 0.2633807957172394, 0.07401154190301895], [0.38439103960990906, 0.38439103960990906, 0.23056773841381073, 0.0005486059235408902, 0.00010158655641134828], [0.002570562530308962, 0.06312958896160126, 0.8710834980010986, 0.06312958896160126, 8.673192496644333e-05], [0.41144612431526184, 0.0626598671078682, 0.11080378293991089, 0.41144612431526184, 0.0036441346164792776], [0.061322953552007675, 0.9121922254562378, 0.00015360723773483187, 0.026177672669291496, 0.00015360723773483187], [0.19951660931110382, 0.03173884376883507, 0.0032885647378861904, 0.0032885647378861904, 0.7621673345565796], [0.5602428913116455, 0.25747472047805786, 0.11714744567871094, 0.06420861184597015, 0.0009263396495953202], [0.384506493806839, 0.04763009771704674, 0.04763009771704674, 0.4776019752025604, 0.042631324380636215], [0.24112160503864288, 0.05751625820994377, 0.035562265664339066, 0.33289992809295654, 0.33289992809295654], [0.018839668482542038, 0.45306992530822754, 0.08571460098028183, 0.10899275541305542, 0.3333830237388611], [0.2560373544692993, 0.02520247921347618, 0.6871254444122314, 0.006432208698242903, 0.02520247921347618], [0.08795047551393509, 0.10601052641868591, 0.6957384943962097, 0.004290000535547733, 0.10601052641868591], [0.9610873460769653, 0.0013398845912888646, 0.0013398845912888646, 0.03497716411948204, 0.0012556675355881453], [0.012811252847313881, 0.06304686516523361, 0.9240139722824097, 6.400353595381603e-05, 6.400353595381603e-05], [0.18762093782424927, 0.0003636005276348442, 0.0003636005276348442, 0.049416422843933105, 0.7622354030609131], [0.0020983980502933264, 0.04615491256117821, 0.0020983980502933264, 0.6120969653129578, 0.33755138516426086], [0.17848257720470428, 0.060161154717206955, 0.6592485308647156, 0.041461702436208725, 0.06064603105187416], [0.02915007807314396, 0.09920383244752884, 0.3347424864768982, 0.09920383244752884, 0.4376998245716095], [0.35185256600379944, 0.007078111171722412, 0.35185256600379944, 0.264506459236145, 0.024710312485694885], [0.606145441532135, 0.04644757881760597, 0.04644757881760597, 0.029957594349980354, 0.27100181579589844], [0.0021904241293668747, 0.06088007614016533, 0.06088007614016533, 0.8322969079017639, 0.043752506375312805], [0.010834845714271069, 0.1639835089445114, 0.00019921509374398738, 0.1639835089445114, 0.6609989404678345], [0.0002727406390476972, 0.00033263041405007243, 0.9532553553581238, 0.04580666124820709, 0.00033263041405007243], [0.35998356342315674, 0.5232836604118347, 0.05795660242438316, 0.05795660242438316, 0.0008195277769118547], [0.09409623593091965, 0.4768906831741333, 0.02463315613567829, 0.20218993723392487, 0.20218993723392487], [0.33674919605255127, 0.06524620950222015, 0.003354452783241868, 0.2579008638858795, 0.33674919605255127], [0.27716100215911865, 0.024177471175789833, 0.42509883642196655, 0.24158446490764618, 0.031978148967027664], [0.0001903969096019864, 0.029270565137267113, 0.13648593425750732, 0.8338627219200134, 0.0001903969096019864], [0.7127058506011963, 0.13643020391464233, 0.00016751422663219273, 0.13643020391464233, 0.014266200363636017], [0.5930955410003662, 0.08292406797409058, 0.024747950956225395, 0.2971968948841095, 0.002035624347627163], [0.20160701870918274, 0.03055788390338421, 0.6265956163406372, 0.11068155616521835, 0.03055788390338421], [0.592199981212616, 0.05673934891819954, 0.3244123160839081, 0.01725834235548973, 0.009390045888721943], [0.9832693338394165, 0.004014953505247831, 0.0005409866571426392, 0.011633806861937046, 0.0005409866571426392], [0.21792380511760712, 0.08548396825790405, 0.11245152354240417, 0.08548396825790405, 0.49865666031837463], [0.4594247043132782, 0.005950598511844873, 0.005950598511844873, 0.18894389271736145, 0.3397301435470581], [0.47837063670158386, 0.042829982936382294, 0.00017150930943898857, 0.47837063670158386, 0.0002571692457422614], [0.30148494243621826, 0.3033294677734375, 0.30148494243621826, 0.09355083107948303, 0.00014978965918999165], [0.18180318176746368, 0.2357305884361267, 0.1242542639374733, 0.22248142957687378, 0.2357305884361267], [0.06322970986366272, 0.02879137545824051, 0.44692304730415344, 0.14890404045581818, 0.31215184926986694], [0.2871156632900238, 0.3524678647518158, 0.3524678647518158, 0.00045160428271628916, 0.007497044280171394], [0.014266259036958218, 0.013278215192258358, 0.1386701464653015, 0.013278215192258358, 0.8205071091651917], [0.011417770758271217, 0.011417770758271217, 0.3508561849594116, 0.524428129196167, 0.10188008099794388], [0.006733474787324667, 0.27855047583580017, 0.1804010570049286, 0.1804010570049286, 0.3539138734340668], [0.4800204336643219, 0.5048846006393433, 0.0009147977107204497, 0.013265306130051613, 0.0009147977107204497], [0.001798480050638318, 0.8239734172821045, 0.001798480050638318, 0.08547386527061462, 0.08695570379495621], [0.43428894877433777, 7.163477857830003e-05, 0.006274866871535778, 0.43428894877433777, 0.125075563788414], [0.005069602746516466, 0.005069602746516466, 0.582271158695221, 0.03610066697001457, 0.37148892879486084], [0.2646319270133972, 0.2646319270133972, 0.4636504054069519, 0.00472297053784132, 0.0023628089111298323], [0.04129556939005852, 0.42273402214050293, 0.04129556939005852, 0.4938635230064392, 0.0008112560026347637], [0.37992626428604126, 0.08907432109117508, 0.0007663615397177637, 0.5301811695098877, 5.1885261200368404e-05], [0.356721967458725, 0.15640106797218323, 0.11071491241455078, 0.356721967458725, 0.019440006464719772], [0.1944596767425537, 0.35449686646461487, 0.12290233373641968, 0.1944596767425537, 0.1336815059185028], [0.12082334607839584, 0.010633209720253944, 0.11151423305273056, 0.11151423305273056, 0.645514965057373], [0.8139030337333679, 0.0343448705971241, 0.13236303627490997, 0.009694531559944153, 0.009694531559944153], [0.1182270348072052, 0.8536306619644165, 0.0197824165225029, 0.004179933574050665, 0.004179933574050665], [0.04967028647661209, 0.22408202290534973, 0.2596266567707062, 0.24253904819488525, 0.22408202290534973], [0.02087246999144554, 0.8540183305740356, 0.04363061487674713, 0.06060611084103584, 0.02087246999144554], [0.015002773143351078, 0.17845867574214935, 0.7178309559822083, 0.015002773143351078, 0.07370481640100479], [0.007462881971150637, 0.0033002395648509264, 0.2111205905675888, 0.5669956803321838, 0.2111205905675888], [0.007334406953305006, 0.34223562479019165, 0.34223562479019165, 0.008479483425617218, 0.2997148931026459], [0.24637579917907715, 0.24637579917907715, 0.4774101972579956, 0.02481294795870781, 0.005025308579206467], [0.4290432929992676, 0.006781727075576782, 0.006781727075576782, 0.4562686085700989, 0.10112465918064117], [0.009425423108041286, 0.009425423108041286, 0.033802781254053116, 0.9338309168815613, 0.013515363447368145], [0.15867459774017334, 0.12695062160491943, 0.0512772798538208, 0.15867459774017334, 0.5044229030609131], [0.6314060688018799, 0.0234508253633976, 0.0234508253633976, 0.3145996332168579, 0.007092671003192663], [0.026836277917027473, 0.000688389700371772, 0.026836277917027473, 0.9048056602478027, 0.040833428502082825], [0.09593664854764938, 0.08284366875886917, 0.01714898832142353, 0.01714898832142353, 0.7869216799736023], [0.43931281566619873, 0.14021086692810059, 0.034378986805677414, 0.3136877417564392, 0.07240952551364899], [0.4744100570678711, 0.26083239912986755, 0.0033112887758761644, 0.26083239912986755, 0.0006138010649010539], [0.03148689121007919, 0.05301397293806076, 0.4281020760536194, 0.4281020760536194, 0.05929499864578247], [0.04572630673646927, 0.004564743489027023, 0.08241964131593704, 0.04572630673646927, 0.8215629458427429], [0.34372657537460327, 0.019926663488149643, 0.2248995155096054, 0.34372657537460327, 0.0677206739783287], [0.12386003881692886, 0.37875109910964966, 0.13582655787467957, 0.11171159893274307, 0.24985073506832123], [0.3062698245048523, 0.20473064482212067, 0.2196660339832306, 0.06460285186767578, 0.20473064482212067], [0.09995973855257034, 0.11270998418331146, 0.018139036372303963, 0.6692314147949219, 0.09995973855257034], [0.1642235368490219, 0.005644018296152353, 0.1642235368490219, 0.665049135684967, 0.0008597474079579115], [0.22905650734901428, 0.12817789614200592, 0.22905650734901428, 0.39225250482559204, 0.02145659551024437], [0.32019245624542236, 0.15746977925300598, 0.32019245624542236, 0.010998011566698551, 0.1911473423242569], [0.1165672093629837, 0.1165672093629837, 0.26855841279029846, 0.020110901445150375, 0.47819632291793823], [0.018550856038928032, 0.018550856038928032, 0.8691937327384949, 0.07215400040149689, 0.021550452336668968], [0.04208717122673988, 0.17570087313652039, 0.13393336534500122, 0.5143451690673828, 0.13393336534500122], [0.4356353282928467, 0.40584036707878113, 0.07465119659900665, 0.07465119659900665, 0.009221854619681835], [0.17740774154663086, 0.034889187663793564, 0.04474964737892151, 0.034889187663793564, 0.7080642580986023], [0.030940480530261993, 0.02093493938446045, 0.773492157459259, 0.02093493938446045, 0.15369750559329987], [0.32207560539245605, 0.08908595144748688, 0.08908595144748688, 0.4986923635005951, 0.001060070819221437], [0.00018442548753228039, 0.7535058259963989, 0.00018442548753228039, 0.0006361065316013992, 0.24548915028572083], [0.001926177297718823, 0.001926177297718823, 0.2634420692920685, 0.1275549978017807, 0.605150580406189], [0.2185131162405014, 0.023062648251652718, 0.08302050828933716, 0.49269387125968933, 0.18270987272262573], [0.38429394364356995, 0.47104766964912415, 0.05259470269083977, 0.05259470269083977, 0.03946899622678757], [0.25558653473854065, 0.28610578179359436, 0.0010184200946241617, 0.22864463925361633, 0.22864463925361633], [0.3494499921798706, 0.6369518041610718, 0.005886572878807783, 0.001825177576392889, 0.005886572878807783], [0.45512962341308594, 0.5065935254096985, 0.014593935571610928, 0.009088972583413124, 0.014593935571610928], [0.22302201390266418, 0.5308772921562195, 0.20886561274528503, 0.03693802282214165, 0.00029704091139137745], [0.08549036085605621, 0.2738400995731354, 0.4960029423236847, 0.08549036085605621, 0.05917622894048691], [0.23731665313243866, 0.044843096286058426, 0.44351673126220703, 0.03700682893395424, 0.23731665313243866], [0.875059187412262, 0.11034996062517166, 0.0060091824270784855, 0.0060091824270784855, 0.0025725169107317924], [0.3418005406856537, 0.05091943219304085, 0.06464758515357971, 0.20083186030387878, 0.3418005406856537], [0.3941277265548706, 0.07942750304937363, 0.3941277265548706, 0.11425220221281052, 0.018064819276332855], [0.2665380835533142, 0.15083041787147522, 0.1875331997871399, 0.12856018543243408, 0.2665380835533142], [0.011895422823727131, 0.3364400565624237, 0.109212227165699, 0.3364400565624237, 0.20601223409175873], [0.00674451282247901, 0.00674451282247901, 0.049400296062231064, 0.9350934028625488, 0.0020172959193587303], [0.8579316735267639, 0.09944304078817368, 0.0217213723808527, 0.002007312374189496, 0.018896663561463356], [0.05155474320054054, 0.030861379578709602, 0.40208813548088074, 0.030861379578709602, 0.48463431000709534], [0.171547994017601, 0.10772557556629181, 0.5353068113327026, 0.171547994017601, 0.01387164555490017], [0.02629375271499157, 0.5936999917030334, 0.2953447103500366, 0.05484221503138542, 0.029819315299391747], [0.0029568267054855824, 0.009000048972666264, 0.4534243941307068, 0.531661868095398, 0.0029568267054855824], [0.16730841994285583, 0.08752502501010895, 0.5530490875244141, 0.10459239035844803, 0.08752502501010895], [0.24558383226394653, 0.24558383226394653, 0.11320725828409195, 0.0024026171304285526, 0.39322251081466675], [0.33114245533943176, 0.053087931126356125, 0.18815921247005463, 0.33114245533943176, 0.09646797180175781], [0.06375403702259064, 0.844858705997467, 0.0011391900479793549, 0.0891089141368866, 0.0011391900479793549], [0.2726229727268219, 0.1783880889415741, 0.21275334060192108, 0.12348227202892303, 0.21275334060192108], [0.000549152260646224, 0.16933573782444, 0.4143679738044739, 0.001379182911477983, 0.4143679738044739], [0.33889931440353394, 0.15092426538467407, 0.03864523395895958, 0.33889931440353394, 0.13263189792633057], [0.48198026418685913, 0.02143809013068676, 0.012802641838788986, 0.48198026418685913, 0.0017988021718338132], [0.3261246085166931, 0.3261246085166931, 0.06596363335847855, 0.15971137583255768, 0.12207574397325516], [0.0006870003999210894, 0.7779814004898071, 0.02394513413310051, 0.0006870003999210894, 0.19669945538043976], [0.03452162817120552, 0.049674659967422485, 0.04608374834060669, 0.4348600208759308, 0.4348600208759308], [0.46632078289985657, 0.04837546497583389, 0.01113281399011612, 0.007850180380046368, 0.46632078289985657], [0.13613556325435638, 0.13613556325435638, 0.24936449527740479, 0.03689068928360939, 0.44147366285324097], [0.08739711344242096, 0.13989534974098206, 0.014625818468630314, 0.0479968897998333, 0.7100847959518433], [0.12121479958295822, 0.004969777073711157, 0.5126943588256836, 0.18056052923202515, 0.18056052923202515], [0.009907525032758713, 0.16869941353797913, 0.41736623644828796, 0.16869941353797913, 0.23532739281654358], [0.44890761375427246, 0.27437514066696167, 0.09930459409952164, 0.08870632201433182, 0.08870632201433182], [0.027299664914608, 0.6913989186286926, 0.008328710682690144, 0.26464396715164185, 0.008328710682690144], [0.0748826339840889, 0.0748826339840889, 0.027447214350104332, 0.7939544320106506, 0.028833121061325073], [0.4598034620285034, 0.029488034546375275, 0.46401193737983704, 0.029488034546375275, 0.017208587378263474], [0.31678876280784607, 0.31678876280784607, 0.1078198254108429, 0.00027850570040754974, 0.25832420587539673], [0.3267962336540222, 0.034837789833545685, 0.21658462285995483, 0.20519675314426422, 0.21658462285995483], [0.040808890014886856, 0.040808890014886856, 0.7447502613067627, 0.010142289102077484, 0.1634897142648697], [0.20645242929458618, 0.20645242929458618, 0.019988277927041054, 0.5655409097671509, 0.0015659785130992532], [0.25972506403923035, 0.386993944644928, 0.25972506403923035, 0.017672769725322723, 0.07588306814432144], [0.28867992758750916, 0.01901177689433098, 0.3392813503742218, 0.013745627366006374, 0.3392813503742218], [0.013440659269690514, 0.013440659269690514, 0.15782113373279572, 0.5084375739097595, 0.3068599998950958], [0.01071092113852501, 0.3799763321876526, 0.3799763321876526, 0.03847360610961914, 0.190862774848938], [0.36485689878463745, 0.042414575815200806, 0.2619580328464508, 0.16538526117801666, 0.16538526117801666], [0.325842946767807, 0.006429644301533699, 0.325842946767807, 0.33864647150039673, 0.003237972967326641], [0.5057386159896851, 0.010110832750797272, 0.010110832750797272, 0.015460995957255363, 0.4585787057876587], [0.0615377314388752, 0.08875677734613419, 0.24981559813022614, 0.08875677734613419, 0.5111331343650818], [0.0005619202856905758, 0.5884156227111816, 0.0005619202856905758, 0.3784479796886444, 0.03201255574822426], [0.25341230630874634, 0.007286993321031332, 0.7230461835861206, 0.015662942081689835, 0.0005915983929298818], [0.10507890582084656, 0.0005833945469930768, 9.81741050054552e-06, 0.5983373522758484, 0.29599061608314514], [0.2188054770231247, 0.029483456164598465, 0.2188054770231247, 0.025714175775647163, 0.5071914196014404], [0.08963347971439362, 0.16601461172103882, 0.026560764759778976, 0.08963347971439362, 0.6281576156616211], [0.01747465692460537, 0.12768740952014923, 0.8124064803123474, 0.024956755340099335, 0.01747465692460537], [0.13882359862327576, 0.02324170619249344, 0.13882359862327576, 0.6957681775093079, 0.0033429721370339394], [0.002158057177439332, 0.10291602462530136, 0.022450517863035202, 0.769559383392334, 0.10291602462530136], [0.03973838686943054, 0.14961501955986023, 0.17274072766304016, 0.5981674790382385, 0.03973838686943054], [0.032910775393247604, 0.15967205166816711, 0.022450093179941177, 0.15967205166816711, 0.6252950429916382], [0.04776215925812721, 0.008365491405129433, 0.04776215925812721, 0.20287810266017914, 0.693231999874115], [0.4039030075073242, 0.061880335211753845, 0.12275614589452744, 0.28870445489883423, 0.12275614589452744], [0.6462381482124329, 0.10189053416252136, 0.032844167202711105, 0.10951357334852219, 0.10951357334852219], [0.08910268545150757, 0.22419114410877228, 0.5828355550765991, 0.014767877757549286, 0.08910268545150757], [0.4955533444881439, 0.4955533444881439, 7.860545883886516e-05, 0.006909708492457867, 0.0019049273105338216], [0.0009505979833193123, 0.1822800189256668, 0.29638180136680603, 0.1822800189256668, 0.3381075859069824], [0.4727836549282074, 0.45322081446647644, 0.03132596239447594, 0.011343585327267647, 0.03132596239447594], [0.3717622756958008, 0.0007933748420327902, 0.24039161205291748, 0.3717622756958008, 0.015290477313101292], [0.6193034052848816, 0.014995071105659008, 0.13893908262252808, 0.014995071105659008, 0.21176740527153015], [0.0077247354201972485, 0.11600615084171295, 0.11600615084171295, 0.039596349000930786, 0.7206665873527527], [0.30102846026420593, 0.10656718164682388, 0.014847800135612488, 0.30102846026420593, 0.2765280604362488], [0.29289835691452026, 0.3737940490245819, 0.29289835691452026, 0.03993500769138336, 0.0004743267490994185], [0.3138359487056732, 0.3138359487056732, 0.042152438312768936, 0.3045290410518646, 0.02564660832285881], [0.4720991551876068, 0.0032082523684948683, 0.4720991551876068, 0.00026423190138302743, 0.05232924595475197], [0.2038174569606781, 0.18286362290382385, 0.2038174569606781, 0.3992030918598175, 0.010298357345163822], [0.00029986031586304307, 0.4398467540740967, 0.4398467540740967, 0.10359396785497665, 0.01641257293522358], [0.22311751544475555, 0.028242938220500946, 0.22311751544475555, 0.38413068652153015, 0.14139139652252197], [0.1854841411113739, 0.20767392218112946, 0.05043834447860718, 0.0006449550855904818, 0.5557586550712585], [0.18358643352985382, 0.16985268890857697, 0.18358643352985382, 0.46194443106651306, 0.0010299236746504903], [0.06256181001663208, 0.37789177894592285, 0.37789177894592285, 0.1809617131948471, 0.0006928709335625172], [0.4676070809364319, 0.054498713463544846, 0.4676070809364319, 0.005914890673011541, 0.004372223746031523], [0.127058744430542, 0.04318121075630188, 0.04318121075630188, 0.3727223873138428, 0.4138564467430115], [0.024270741268992424, 0.305710107088089, 0.10741959512233734, 0.2568894028663635, 0.305710107088089], [0.005966622848063707, 0.46511000394821167, 0.46511000394821167, 0.02246382273733616, 0.041349511593580246], [7.307495252462104e-05, 0.003661985509097576, 0.8425921201705933, 0.08908054977655411, 0.06459224969148636], [0.07349509000778198, 0.4332801103591919, 0.4332801103591919, 0.030723966658115387, 0.029220661148428917], [0.07152748107910156, 0.00039152507088147104, 0.8907891511917114, 0.00039152507088147104, 0.03690030425786972], [0.048264604061841965, 0.015583954751491547, 0.1967773735523224, 0.123446524143219, 0.6159275770187378], [0.022616788744926453, 0.012514512054622173, 0.08522313088178635, 0.012514512054622173, 0.8671311140060425], [0.25891637802124023, 0.23284754157066345, 0.23284754157066345, 0.0018787862500175834, 0.27350977063179016], [0.22135744988918304, 0.0017573436489328742, 9.349916217615828e-05, 0.11666341871023178, 0.6601282954216003], [0.03859143331646919, 0.0010585386771708727, 0.0010585386771708727, 0.33141809701919556, 0.6278734803199768], [0.08475099503993988, 0.7411647439002991, 0.07697704434394836, 0.08475099503993988, 0.012356174178421497], [0.21714721620082855, 0.26204022765159607, 0.010991227813065052, 0.26204022765159607, 0.24778111279010773], [0.8709476590156555, 0.01970202848315239, 0.05429061874747276, 0.05429061874747276, 0.0007690349011681974], [0.40806829929351807, 0.07672931998968124, 0.10644865036010742, 0.40806829929351807, 0.0006853695958852768], [0.06725233048200607, 0.09938056766986847, 0.09938056766986847, 0.06212073192000389, 0.6718658208847046], [0.10443770885467529, 0.6346294283866882, 0.13069184124469757, 0.04273602366447449, 0.08750501275062561], [0.06281888484954834, 0.5402799248695374, 0.1655387282371521, 0.1655387282371521, 0.06582368165254593], [0.8473044633865356, 0.045572906732559204, 0.002903552493080497, 0.052935849875211716, 0.05128321424126625], [0.028448862954974174, 0.004580342676490545, 0.004580342676490545, 0.8156086206436157, 0.1467818319797516], [0.013091139495372772, 0.04493331536650658, 0.02853313647210598, 0.4567212462425232, 0.4567212462425232], [0.003424223978072405, 0.15860450267791748, 0.15860450267791748, 0.6790663599967957, 0.00030042222351767123], [0.2737281322479248, 0.2737281322479248, 0.11123227328062057, 0.18077588081359863, 0.160535529255867], [0.0008867565775290132, 0.09251275658607483, 0.09251275658607483, 0.0036444568540900946, 0.8104433417320251], [0.0379338301718235, 0.0920880138874054, 0.08331894129514694, 0.08331894129514694, 0.7033402919769287], [0.051888369023799896, 0.016639461740851402, 0.7711477875709534, 0.14368495345115662, 0.016639461740851402], [0.2774108052253723, 0.37502267956733704, 0.04732895642518997, 0.022826721891760826, 0.2774108052253723], [0.07676806300878525, 0.0007883363869041204, 0.45709511637687683, 0.45709511637687683, 0.008253265172243118], [0.037512242794036865, 0.2785801887512207, 0.13527120649814606, 0.2785801887512207, 0.27005621790885925], [0.22418512403964996, 0.45396721363067627, 0.30729636549949646, 0.0072756665758788586, 0.0072756665758788586], [0.08606763184070587, 0.003059073118492961, 0.07462061196565628, 0.012845912016928196, 0.8234067559242249], [0.1134195327758789, 0.1716431975364685, 0.1134195327758789, 0.5672972798347473, 0.034220416098833084], [0.13581664860248566, 0.0073747108690440655, 0.09873116761445999, 0.6222608685493469, 0.13581664860248566], [0.2178962081670761, 0.30412524938583374, 0.24150992929935455, 0.2178962081670761, 0.0185723677277565], [0.06539896130561829, 0.06539896130561829, 0.009680635295808315, 0.060028403997421265, 0.7994930148124695], [0.153548002243042, 0.5130202770233154, 0.153548002243042, 0.08791282027959824, 0.09197092056274414], [0.04912859946489334, 0.04941261559724808, 0.6920010447502136, 0.04941261559724808, 0.16004517674446106], [0.46643999218940735, 0.04906894266605377, 0.0056672003120183945, 0.46643999218940735, 0.012383857741951942], [0.004070440772920847, 0.004070440772920847, 0.007960906252264977, 0.00028028470114804804, 0.9836179614067078], [0.00018294945766683668, 0.027343373745679855, 0.03211657702922821, 0.908240556716919, 0.03211657702922821], [0.3769533932209015, 0.3769533932209015, 0.07985664904117584, 0.009038091637194157, 0.1571984887123108], [0.25541937351226807, 0.25541937351226807, 0.2966729402542114, 0.17359206080436707, 0.018896227702498436], [0.0681619793176651, 0.263576477766037, 0.3287948668003082, 0.263576477766037, 0.07589022070169449], [0.0026889939326792955, 0.39104658365249634, 0.1098933219909668, 0.24818557500839233, 0.24818557500839233], [0.5090962052345276, 0.4571908116340637, 0.005754221696406603, 0.022204581648111343, 0.005754221696406603], [0.0452730767428875, 0.4499669671058655, 0.047943245619535446, 0.4499669671058655, 0.006849774159491062], [0.047926295548677444, 0.5306892991065979, 0.11802613735198975, 0.2554319500923157, 0.047926295548677444], [0.37602511048316956, 0.22355905175209045, 0.17410442233085632, 0.002752370201051235, 0.22355905175209045], [0.3569372892379761, 0.08419624716043472, 0.3569372892379761, 0.03251268342137337, 0.16941645741462708], [0.06318636238574982, 0.7025164365768433, 0.05991772934794426, 0.11119311302900314, 0.06318636238574982], [0.0002306189271621406, 0.39177414774894714, 0.28510698676109314, 0.05735673010349274, 0.2655315101146698], [0.04666176810860634, 0.4404384195804596, 0.46405720710754395, 0.04666176810860634, 0.0021807807497680187], [0.34924134612083435, 0.0005399066722020507, 0.0012124845525249839, 0.324503093957901, 0.324503093957901], [0.00825808010995388, 0.41261109709739685, 0.03430958092212677, 0.41261109709739685, 0.13221018016338348], [0.4453328251838684, 0.001699744607321918, 0.5431656241416931, 0.001699744607321918, 0.008102070540189743], [0.3135979175567627, 0.5355656147003174, 0.05669824406504631, 0.08023937791585922, 0.013898825272917747], [1.908410013129469e-05, 0.4940239191055298, 0.2584385573863983, 0.24749937653541565, 1.908410013129469e-05], [0.3740588426589966, 0.23872146010398865, 0.3740588426589966, 0.00013095902977511287, 0.013029842637479305], [0.018014244735240936, 0.44654011726379395, 0.44654011726379395, 0.03870515525341034, 0.050200384110212326], [0.4200427830219269, 0.03995952755212784, 0.4200427830219269, 0.05779293179512024, 0.06216202676296234], [0.6434447765350342, 0.33904001116752625, 0.0013567103305831552, 0.00807926058769226, 0.00807926058769226], [0.08587748557329178, 6.765533180441707e-05, 0.6332054138183594, 0.19497188925743103, 0.08587748557329178], [0.12327861040830612, 5.693982893717475e-05, 5.693982893717475e-05, 0.8660093545913696, 0.010598143562674522], [0.347384512424469, 0.06590425223112106, 0.24690505862236023, 0.24690505862236023, 0.09290112555027008], [0.0070741246454417706, 0.173088937997818, 0.173088937997818, 0.45279407501220703, 0.19395385682582855], [0.30030956864356995, 0.02224503457546234, 0.02224503457546234, 0.5939218401908875, 0.06127851456403732], [0.12248247861862183, 0.010994813404977322, 0.010994813404977322, 0.8526397347450256, 0.002888208255171776], [0.0011003311956301332, 0.08737599849700928, 0.15983863174915314, 0.0011003311956301332, 0.7505847811698914], [0.25408536195755005, 0.039281222969293594, 0.45155608654022217, 0.1849575638771057, 0.07011979073286057], [0.611068069934845, 0.0180105771869421, 0.16700057685375214, 0.03692025691270828, 0.16700057685375214], [0.06414933502674103, 0.0068878838792443275, 0.7463210225105286, 0.06414933502674103, 0.11849240958690643], [0.8175836801528931, 0.010263964533805847, 0.010263964533805847, 0.02111285924911499, 0.14077547192573547], [0.08518290519714355, 0.03516852483153343, 0.13806600868701935, 0.7064141035079956, 0.03516852483153343], [0.10777197033166885, 0.017475754022598267, 0.017475754022598267, 0.6620323657989502, 0.1952441781759262], [0.015571771189570427, 0.015571771189570427, 0.007022349163889885, 0.2399882972240448, 0.7218458652496338], [0.4690348207950592, 0.053277239203453064, 0.004670021589845419, 0.4690348207950592, 0.003983107395470142], [0.5712584853172302, 0.004876723978668451, 0.003949863836169243, 0.41503816843032837, 0.004876723978668451], [0.2782857120037079, 0.019125644117593765, 0.30325567722320557, 0.0960773229598999, 0.30325567722320557], [0.017078449949622154, 0.015093168243765831, 0.05891845375299454, 0.4544549584388733, 0.4544549584388733], [0.44874170422554016, 0.00012540032912511379, 0.44874170422554016, 0.023662816733121872, 0.07872834801673889], [0.014395083300769329, 0.014395083300769329, 0.19569078087806702, 0.1054626852273941, 0.6700564026832581], [0.10095881670713425, 0.08167961239814758, 0.5316237807273865, 0.20405814051628113, 0.08167961239814758], [0.006707650609314442, 0.006707650609314442, 0.3614448010921478, 0.11246292293071747, 0.5126769542694092], [0.5231658816337585, 0.0015316641656681895, 0.4659419059753418, 0.004680277779698372, 0.004680277779698372], [0.002535893814638257, 0.0794198140501976, 0.2447105348110199, 0.0794198140501976, 0.5939139127731323], [0.42722710967063904, 0.007459551095962524, 0.42722710967063904, 0.006786921992897987, 0.1312992423772812], [0.4974519610404968, 0.4974519610404968, 0.003134698374196887, 0.0004911875003017485, 0.001470270100980997], [0.012263256125152111, 0.9235830903053284, 0.0008571739308536053, 0.06243925914168358, 0.0008571739308536053], [0.32120558619499207, 0.0014750362606719136, 0.0014750362606719136, 0.5248205661773682, 0.15102370083332062], [0.25161513686180115, 0.32527175545692444, 0.026654161512851715, 0.32527175545692444, 0.07118719816207886], [0.5114837288856506, 0.13967832922935486, 0.16740646958351135, 0.014025055803358555, 0.16740646958351135], [0.07817033678293228, 0.07817033678293228, 0.7779228091239929, 0.034021660685539246, 0.0317147932946682], [0.05453244224190712, 0.05453244224190712, 0.06225327029824257, 0.019650356844067574, 0.8090314865112305], [0.26527395844459534, 0.14035649597644806, 0.26527395844459534, 0.3213856518268585, 0.007709931582212448], [0.2591376006603241, 0.18271097540855408, 0.18271097540855408, 0.3705606460571289, 0.004879766143858433], [0.09623470902442932, 0.2165529876947403, 0.3310280442237854, 0.3560968041419983, 8.748179243411869e-05], [0.09936817735433578, 0.43045905232429504, 9.016962576424703e-05, 0.03962352126836777, 0.43045905232429504], [0.010699802078306675, 0.24139390885829926, 0.010699802078306675, 0.5630359053611755, 0.1741706281900406], [0.020153267309069633, 0.020153267309069633, 0.31575024127960205, 0.22503747045993805, 0.41890576481819153], [0.3587053716182709, 0.3587053716182709, 0.0002262510679429397, 0.24586454033851624, 0.03649849072098732], [0.4449903666973114, 0.03851686790585518, 0.0002490034094080329, 0.4449903666973114, 0.07125327736139297], [0.2837640643119812, 0.2837640643119812, 0.014550620689988136, 0.033625636249780655, 0.38429561257362366], [0.01864941604435444, 0.7918024063110352, 0.01864941604435444, 0.1704268753528595, 0.0004718777199741453], [0.055415891110897064, 0.49370476603507996, 0.055415891110897064, 0.3931872546672821, 0.002276201266795397], [0.008851807564496994, 0.008851807564496994, 0.3959217369556427, 0.034015730023384094, 0.5523589253425598], [0.10644571483135223, 0.500989556312561, 0.03501661866903305, 0.322531521320343, 0.03501661866903305], [0.03322352096438408, 0.24065755307674408, 0.11014554649591446, 0.11014554649591446, 0.5058278441429138], [0.14373669028282166, 0.002813227940350771, 0.5991628170013428, 0.12714362144470215, 0.12714362144470215], [0.020360859110951424, 0.14463506639003754, 0.20299138128757477, 0.3160063624382019, 0.3160063624382019], [0.16098223626613617, 0.01960175670683384, 0.1868014633655548, 0.6130127906799316, 0.01960175670683384], [0.3881078064441681, 0.3881078064441681, 0.04414505138993263, 0.007615670561790466, 0.17202366888523102], [0.021985560655593872, 0.5331995487213135, 0.044710054993629456, 0.2000524252653122, 0.2000524252653122], [0.09036852419376373, 0.09036852419376373, 0.009577739983797073, 0.7560184597969055, 0.053666770458221436], [0.0005293262074701488, 0.19227270781993866, 0.2514154016971588, 0.3635098338127136, 0.19227270781993866], [0.009027048014104366, 0.4564405083656311, 0.02938426099717617, 0.4564405083656311, 0.04870771989226341], [5.108056211611256e-05, 0.32430216670036316, 5.108056211611256e-05, 0.6337732672691345, 0.041822414845228195], [0.31345829367637634, 0.22762127220630646, 0.0752892941236496, 0.15600988268852234, 0.22762127220630646], [0.10860120505094528, 0.10860120505094528, 0.0018209137488156557, 0.4609399735927582, 0.32003673911094666], [0.06896890699863434, 0.5911049842834473, 0.23112954199314117, 0.00018552561232354492, 0.10861103236675262], [0.17399969696998596, 0.3527950942516327, 0.029469642788171768, 0.09094050526618958, 0.3527950942516327], [0.3539557456970215, 0.020796988159418106, 0.12583163380622864, 0.3539557456970215, 0.14545996487140656], [0.059437960386276245, 0.059437960386276245, 0.32229867577552795, 0.5571747422218323, 0.0016506045358255506], [0.043800193816423416, 0.7108690142631531, 0.0014319510664790869, 0.24246682226657867, 0.0014319510664790869], [0.2899589240550995, 0.10257401317358017, 0.14800286293029785, 0.31146129965782166, 0.14800286293029785], [0.014403692446649075, 0.016289426013827324, 0.016289426013827324, 0.07795720547437668, 0.8750603199005127], [0.0011410388397052884, 0.5992724299430847, 0.07316535711288452, 0.004633656702935696, 0.3217875063419342], [0.3726343512535095, 0.09727128595113754, 0.02231443300843239, 0.02231443300843239, 0.48546555638313293], [0.7248777747154236, 0.10658898949623108, 0.10658898949623108, 0.0003077780129387975, 0.06163646653294563], [0.008183995261788368, 0.011107026599347591, 0.027051568031311035, 0.9425504207611084, 0.011107026599347591], [0.3931271731853485, 0.22129540145397186, 0.19150009751319885, 0.00257728504948318, 0.19150009751319885], [0.08648867905139923, 0.008962404914200306, 0.08648867905139923, 0.790849506855011, 0.027210697531700134], [0.0001229845074703917, 0.7371548414230347, 0.2171950340270996, 0.045404259115457535, 0.0001229845074703917], [0.04562612622976303, 0.3911221921443939, 0.3911221921443939, 0.016302360221743584, 0.1558271199464798], [0.1678817719221115, 0.40237972140312195, 0.40237972140312195, 0.012419928796589375, 0.014938928186893463], [0.26890140771865845, 0.16130472719669342, 0.43198448419570923, 0.13692647218704224, 0.0008828519494272768], [0.019115258008241653, 0.021472111344337463, 0.4471561312675476, 0.06510039418935776, 0.4471561312675476], [0.08689296245574951, 0.42254868149757385, 0.058737482875585556, 0.009272207506000996, 0.42254868149757385], [0.039293646812438965, 0.013998731039464474, 0.0028155578766018152, 0.47194600105285645, 0.47194600105285645], [0.5616419911384583, 0.035077959299087524, 0.005637164693325758, 0.19882145524024963, 0.19882145524024963], [0.0031948816031217575, 0.14132879674434662, 0.39433538913726807, 0.0031948816031217575, 0.4579460322856903], [0.0012150806142017245, 0.0012486673658713698, 0.20614640414714813, 0.7901411652565002, 0.0012486673658713698], [0.07645820081233978, 0.0015255003236234188, 0.002431616187095642, 0.002431616187095642, 0.9171531200408936], [0.004422944504767656, 0.08010038733482361, 0.3827175796031952, 0.15004153549671173, 0.3827175796031952], [0.2290644347667694, 0.2290644347667694, 0.0022171593736857176, 0.5395274758338928, 0.00012650215649046004], [0.019434576854109764, 0.078170046210289, 0.0029599745757877827, 0.4497177302837372, 0.4497177302837372], [0.00198766915127635, 0.2723878026008606, 0.00198766915127635, 0.4682161808013916, 0.25542065501213074], [0.0898994505405426, 0.0898994505405426, 0.7556280493736267, 0.0215953066945076, 0.04297766461968422], [0.020426973700523376, 0.017064014449715614, 0.020426973700523376, 0.7060945630073547, 0.2359875738620758], [0.03688521310687065, 0.01325272861868143, 0.03879612684249878, 0.9054986238479614, 0.005567291751503944], [0.07014717161655426, 0.07014717161655426, 0.00923776812851429, 0.0074148522689938545, 0.8430530428886414], [0.5120474100112915, 0.08485572785139084, 0.034929241985082626, 0.008604815229773521, 0.35956278443336487], [0.006632955279201269, 0.006632955279201269, 0.035028599202632904, 0.8531402349472046, 0.09856533259153366], [0.017402248457074165, 0.0007305879262275994, 0.03227565437555313, 0.017402248457074165, 0.9321892857551575], [0.004396855365484953, 0.08096808195114136, 0.003366565564647317, 0.4556342661380768, 0.4556342661380768], [0.35110199451446533, 0.028038406744599342, 0.1467229425907135, 0.1467229425907135, 0.32741373777389526], [0.019548630341887474, 0.3877389430999756, 0.08065901696681976, 0.08065901696681976, 0.43139442801475525], [0.28986644744873047, 0.07836892455816269, 0.04071852192282677, 0.3011797070503235, 0.28986644744873047], [0.006629671901464462, 0.935686469078064, 9.22080798773095e-05, 0.05715739727020264, 0.00043418840505182743], [0.027417002245783806, 0.1022106185555458, 0.017283469438552856, 0.05143309384584427, 0.8016557693481445], [0.0853034257888794, 0.7928075790405273, 0.0853034257888794, 0.0006399685516953468, 0.035945694893598557], [0.03862788528203964, 0.03862788528203964, 0.08161558955907822, 0.08927581459283829, 0.7518528699874878], [0.026889193803071976, 0.003138870233669877, 0.12047901004552841, 0.026889193803071976, 0.8226037621498108], [0.27934107184410095, 0.38452139496803284, 0.030672580003738403, 0.00182202341966331, 0.3036428987979889], [0.06646951287984848, 0.20535698533058167, 0.20535698533058167, 0.5211734771728516, 0.00164308852981776], [0.02485334314405918, 0.37878382205963135, 0.02485334314405918, 0.16087831556797028, 0.4106312394142151], [0.026513582095503807, 0.4304032623767853, 0.1188473254442215, 0.39772215485572815, 0.026513582095503807], [0.0076787834987044334, 0.0076787834987044334, 0.33616015315055847, 0.5759634971618652, 0.07251884043216705], [0.02620009146630764, 0.005843819584697485, 0.02620009146630764, 0.02473296783864498, 0.9170230627059937], [0.17009246349334717, 0.3420408368110657, 0.1386779397726059, 0.0071479096077382565, 0.3420408368110657], [0.026088019832968712, 0.02426825650036335, 0.9043743014335632, 0.021001173183321953, 0.02426825650036335], [0.004932668525725603, 0.013963764533400536, 0.9654630422592163, 0.003251575632020831, 0.012388925068080425], [0.43162164092063904, 0.009732618927955627, 0.1029038205742836, 0.024120280519127846, 0.43162164092063904], [0.7654997706413269, 0.003384730312973261, 0.06788910925388336, 0.15984171628952026, 0.003384730312973261], [0.0006676423363387585, 0.27185845375061035, 0.05204544961452484, 0.27185845375061035, 0.4035699665546417], [0.990874171257019, 0.00512031652033329, 0.001440536230802536, 0.001440536230802536, 0.0011245321948081255], [0.2909186780452728, 0.005814899690449238, 0.31627124547958374, 0.0707240030169487, 0.31627124547958374], [0.03131193295121193, 0.0939079001545906, 0.030402518808841705, 0.030402518808841705, 0.8139751553535461], [0.018414676189422607, 0.0004762308089993894, 0.5605029463768005, 0.0004762308089993894, 0.4201298952102661], [0.004991928581148386, 0.07622526586055756, 0.0013049544068053365, 0.916172981262207, 0.0013049544068053365], [0.46603450179100037, 0.46603450179100037, 0.04124609753489494, 0.01925896294414997, 0.007425948046147823], [0.017666330561041832, 0.376583069562912, 0.06640318036079407, 0.47820407152175903, 0.06114332005381584], [0.21890874207019806, 0.22444595396518707, 0.05609220266342163, 0.05609220266342163, 0.4444608688354492], [0.004102280829101801, 0.14205843210220337, 0.3658429682254791, 0.34593796730041504, 0.14205843210220337], [0.4135516285896301, 0.01208034809678793, 0.159480482339859, 0.4135516285896301, 0.0013359141303226352], [0.3635445535182953, 0.05583975836634636, 0.0715535581111908, 0.0715535581111908, 0.43750855326652527], [0.1915004849433899, 0.2959662675857544, 0.5061889290809631, 0.0031721671111881733, 0.0031721671111881733], [0.0011103326687589288, 0.4425606429576874, 0.4425606429576874, 0.005418871529400349, 0.10834956914186478], [0.702729344367981, 0.001053055515512824, 0.0007764603360556066, 0.2943880558013916, 0.001053055515512824], [0.42272642254829407, 0.028546791523694992, 0.03335162252187729, 0.03999083489179611, 0.475384384393692], [0.04840850085020065, 0.11361641436815262, 0.11361641436815262, 0.6232165694236755, 0.10114205628633499], [0.4201853275299072, 0.003080597147345543, 0.48799780011177063, 0.044368140399456024, 0.044368140399456024], [0.3592480719089508, 0.3592480719089508, 0.20492565631866455, 0.01704963855445385, 0.059528496116399765], [0.011469277553260326, 0.1512080430984497, 0.1512080430984497, 0.552021861076355, 0.1340928077697754], [0.423958957195282, 0.423958957195282, 0.02755393274128437, 0.057991333305835724, 0.06653688102960587], [0.009066194295883179, 0.37762877345085144, 0.0014975484227761626, 0.37762877345085144, 0.23417870700359344], [0.08335880190134048, 0.5575354099273682, 0.025787508115172386, 0.30753082036972046, 0.025787508115172386], [0.18863213062286377, 0.18863213062286377, 0.17465221881866455, 0.36028772592544556, 0.08779580146074295], [0.26245734095573425, 0.26245734095573425, 0.11596062779426575, 0.32492756843566895, 0.03419710695743561], [0.32856136560440063, 0.026028048247098923, 0.12681064009666443, 0.32856136560440063, 0.1900385320186615], [0.9397380352020264, 0.00017842398665379733, 0.03749696537852287, 0.011293337680399418, 0.011293337680399418], [0.014270685613155365, 0.08177357167005539, 0.4018934667110443, 0.1001688614487648, 0.4018934667110443], [0.0071642776019871235, 0.1850229948759079, 0.6040480136871338, 0.018741728737950325, 0.1850229948759079], [0.0018073010724037886, 0.628571093082428, 0.11935057491064072, 0.0018073010724037886, 0.24846380949020386], [0.08825986832380295, 0.1781110018491745, 0.5480427742004395, 0.1781110018491745, 0.007475391961634159], [0.18305306136608124, 0.03663179278373718, 0.039268407970666885, 0.039268407970666885, 0.7017783522605896], [0.5311399102210999, 0.11170810461044312, 0.11170810461044312, 0.12685342133045197, 0.11859049648046494], [0.0008085019653663039, 0.003587286686524749, 0.9108286499977112, 0.08396714180707932, 0.0008085019653663039], [0.001513267052359879, 0.11351647228002548, 0.038221750408411026, 0.8452352285385132, 0.001513267052359879], [0.3010989725589752, 0.15473294258117676, 0.12405715882778168, 0.29605376720428467, 0.12405715882778168], [0.02952534332871437, 0.021455606445670128, 0.02952534332871437, 0.9146732091903687, 0.004820501897484064], [0.30810636281967163, 0.03800062835216522, 0.30751046538352966, 0.038276199251413345, 0.30810636281967163], [0.022602491080760956, 0.0001723791501717642, 0.021076010540127754, 0.9335466027259827, 0.022602491080760956], [0.059930577874183655, 0.43500569462776184, 0.00375793082639575, 0.06630010902881622, 0.43500569462776184], [0.04261801391839981, 0.10391135513782501, 0.31715720891952515, 0.10018420219421387, 0.43612927198410034], [0.003617949550971389, 0.934965968132019, 0.003617949550971389, 0.009515887126326561, 0.04828229546546936], [0.4193759560585022, 0.4193759560585022, 0.0795435830950737, 0.005695117637515068, 0.07600931078195572], [0.031046012416481972, 0.015899982303380966, 0.015899982303380966, 0.827664315700531, 0.10948965698480606], [0.043530598282814026, 0.6381931304931641, 0.010941565036773682, 0.1536673605442047, 0.1536673605442047], [0.022323843091726303, 0.0224937591701746, 0.022323843091726303, 0.4924609959125519, 0.4403976500034332], [0.49228423833847046, 0.013891938142478466, 0.08897975832223892, 0.08897975832223892, 0.31586432456970215], [0.047467317432165146, 0.0201883427798748, 0.16681188344955444, 0.047467317432165146, 0.7180651426315308], [0.13877564668655396, 0.08848042041063309, 0.08848042041063309, 0.5907127857208252, 0.09355070441961288], [0.0023132208734750748, 0.006906515918672085, 0.7505053877830505, 0.12013743817806244, 0.12013743817806244], [0.016221528872847557, 0.42275017499923706, 0.2744029760360718, 0.012222333811223507, 0.2744029760360718], [0.15664784610271454, 0.0576200895011425, 0.6055908203125, 0.15664784610271454, 0.023493345826864243], [0.1170257106423378, 0.00024670938728377223, 0.6287050247192383, 0.00024670938728377223, 0.25377580523490906], [0.04549667239189148, 0.19638989865779877, 0.09135281294584274, 0.5230311751365662, 0.14372950792312622], [0.9878911972045898, 0.00014909726451151073, 0.003907753154635429, 0.007902906276285648, 0.00014909726451151073], [0.24826256930828094, 0.24826256930828094, 0.4876006841659546, 0.0006526553770527244, 0.0152214877307415], [0.0012598399771377444, 0.05059980973601341, 0.27009013295173645, 0.0012598399771377444, 0.6767904162406921], [0.08055857568979263, 0.009925630874931812, 0.001858516945503652, 0.001858516945503652, 0.9057986736297607], [0.05152779445052147, 0.16558368504047394, 0.013252533972263336, 0.7181081771850586, 0.05152779445052147], [0.00018860837735701352, 0.00014625904441345483, 0.7890340089797974, 0.00014625904441345483, 0.2104848474264145], [0.6082804203033447, 0.030320102348923683, 0.23761142790317535, 0.0618940107524395, 0.0618940107524395], [0.007859433069825172, 0.27773234248161316, 0.01666627638041973, 0.609144926071167, 0.08859693259000778], [0.08534584194421768, 0.4347030818462372, 0.4347030818462372, 0.02083008736371994, 0.02441781759262085], [0.2586921453475952, 0.11131883412599564, 0.0024399461690336466, 0.2586921453475952, 0.36885687708854675], [0.06624279916286469, 0.0011705568758770823, 0.006481779273599386, 0.06624279916286469, 0.8598619699478149], [0.1276838332414627, 0.3028234541416168, 0.004945236723870039, 0.26172399520874023, 0.3028234541416168], [0.9527499675750732, 5.1755967433564365e-05, 0.0013012131676077843, 0.0007245129090733826, 0.04517246410250664], [0.016554398462176323, 0.2944881021976471, 0.07182983309030533, 0.3226395547389984, 0.2944881021976471], [0.34060367941856384, 0.02137725055217743, 0.02137725055217743, 0.05239974334836006, 0.5642420649528503], [8.420868834946305e-05, 0.058560166507959366, 0.35375386476516724, 0.23384788632392883, 0.35375386476516724], [0.899872899055481, 0.0184372179210186, 0.06227831169962883, 0.0184372179210186, 0.0009743591072037816], [0.04888991639018059, 0.04888991639018059, 0.8305689096450806, 0.04164944216609001, 0.03000178560614586], [0.023975737392902374, 0.45510074496269226, 0.019540881738066673, 0.04628191515803337, 0.45510074496269226], [0.6530671715736389, 0.16374094784259796, 0.16374094784259796, 0.01585123874247074, 0.0035996793303638697], [0.3727787137031555, 0.136533722281456, 0.006352843251079321, 0.3727787137031555, 0.1115560531616211], [0.060677420347929, 0.007747857365757227, 0.09149090200662613, 0.8323359489440918, 0.007747857365757227], [0.04689688980579376, 0.4664399027824402, 0.4664399027824402, 0.01620250940322876, 0.004020815249532461], [0.093978151679039, 0.03865436092019081, 0.05868411809206009, 0.808000385761261, 0.0006830450729466975], [0.8901069164276123, 0.03834937885403633, 0.03834937885403633, 0.0055442675948143005, 0.027649957686662674], [0.023847026750445366, 0.23191502690315247, 0.4729055166244507, 0.13566623628139496, 0.13566623628139496], [0.23297874629497528, 0.2617294192314148, 0.12559080123901367, 0.23297874629497528, 0.14672227203845978], [0.5904346108436584, 0.00044636460370384157, 0.17066816985607147, 0.17066816985607147, 0.0677826926112175], [0.124372199177742, 0.10855409502983093, 0.09473901987075806, 0.3790041208267212, 0.293330579996109], [0.4437607228755951, 0.11013659834861755, 0.0020364089868962765, 0.00030548058566637337, 0.4437607228755951], [0.8571897745132446, 0.009433741681277752, 0.12298501282930374, 0.009098086506128311, 0.0012933671241626143], [0.12202621251344681, 0.12202621251344681, 0.661780059337616, 0.029179394245147705, 0.06498812884092331], [0.10522580146789551, 0.07956542819738388, 0.07956542819738388, 0.03412697836756706, 0.7015163898468018], [0.09613955765962601, 0.12581616640090942, 0.09093022346496582, 0.09613955765962601, 0.5909745097160339], [0.46619725227355957, 0.025134511291980743, 0.46619725227355957, 0.027734726667404175, 0.014736349694430828], [0.22715561091899872, 0.0005046847509220243, 0.10758350789546967, 0.6642515063285828, 0.0005046847509220243], [0.4212312400341034, 0.03567098081111908, 0.44820550084114075, 0.03567098081111908, 0.05922124534845352], [0.8634247183799744, 0.12866011261940002, 0.0003233480965718627, 0.0003233480965718627, 0.007268507964909077], [0.026215365156531334, 0.0018488009227439761, 0.002139890333637595, 0.9435806274414062, 0.026215365156531334], [0.10679035633802414, 0.15601634979248047, 0.15761548280715942, 0.47278738021850586, 0.10679035633802414], [0.8827690482139587, 0.05536428838968277, 0.0015508437063544989, 0.0587649866938591, 0.0015508437063544989], [0.1406647264957428, 0.6397721767425537, 0.1406647264957428, 0.041775837540626526, 0.03712254762649536], [0.3880258798599243, 0.10014063119888306, 0.3880258798599243, 0.11124607175588608, 0.012561501935124397], [0.027425969019532204, 0.05860244110226631, 0.37222549319267273, 0.16952049732208252, 0.37222549319267273], [0.33641308546066284, 0.22990581393241882, 0.07808186113834381, 0.1256933957338333, 0.22990581393241882], [0.22535184025764465, 0.6510714888572693, 0.048059768974781036, 0.048059768974781036, 0.027457114309072495], [2.8326996471150778e-05, 0.008577384054660797, 0.042425643652677536, 0.4744843542575836, 0.4744843542575836], [0.10318795591592789, 0.10318795591592789, 0.26837584376335144, 0.4970920979976654, 0.028156179934740067], [0.018453439697623253, 0.8618953824043274, 0.10040529072284698, 0.0007924303645268083, 0.018453439697623253], [0.2542247176170349, 0.2542247176170349, 0.4300350546836853, 0.053112469613552094, 0.00840296782553196], [0.011145737022161484, 0.09241880476474762, 0.30367112159729004, 0.5003455281257629, 0.09241880476474762], [0.36327141523361206, 0.014879899099469185, 0.26498842239379883, 0.26498842239379883, 0.09187177568674088], [0.020894765853881836, 0.007990925572812557, 0.0009915571426972747, 0.9621317982673645, 0.007990925572812557], [0.6620939373970032, 0.2036857306957245, 0.013739427551627159, 0.0986214354634285, 0.021859437227249146], [0.38056400418281555, 0.02289637178182602, 0.10143343359231949, 0.10143343359231949, 0.39367279410362244], [0.7457001209259033, 0.0006897351122461259, 0.0027990941889584064, 0.12540549039840698, 0.12540549039840698], [0.3365154564380646, 0.1068391427397728, 0.17915146052837372, 0.17915146052837372, 0.19834250211715698], [0.26837560534477234, 0.06816568225622177, 0.018882032483816147, 0.5764109492301941, 0.06816568225622177], [0.023583469912409782, 0.6718385815620422, 0.08855212479829788, 0.08855212479829788, 0.12747369706630707], [0.49110984802246094, 0.0009194019949063659, 0.010557091794908047, 0.49110984802246094, 0.006303749978542328], [0.0014158590929582715, 0.030800381675362587, 0.0014158590929582715, 0.09605246037244797, 0.8703153729438782], [0.07523642480373383, 0.0010222112759947777, 0.9225886464118958, 0.0010222112759947777, 0.00013041529746260494], [0.07068629562854767, 0.2169419229030609, 0.05167984589934349, 0.33034592866897583, 0.33034592866897583], [0.06442941725254059, 0.7129857540130615, 0.049028802663087845, 0.1245272308588028, 0.049028802663087845], [0.001055999891832471, 0.9840492010116577, 0.008608506992459297, 0.005230268929153681, 0.001055999891832471], [0.07678370922803879, 0.01277768611907959, 0.4541870057582855, 0.4541870057582855, 0.002064520725980401], [0.0004987341235391796, 0.8629353046417236, 0.0792144313454628, 0.0004987341235391796, 0.05685282126069069], [0.11884242296218872, 0.0009871445363387465, 0.7581014037132263, 0.11884242296218872, 0.003226648783311248], [0.009500347077846527, 0.009500347077846527, 0.21129223704338074, 0.053968120366334915, 0.7157388925552368], [0.058926571160554886, 0.058926571160554886, 0.048290807753801346, 0.8320232033729553, 0.0018327943980693817], [0.0733562633395195, 0.6867032647132874, 0.04794233292341232, 0.11864195019006729, 0.0733562633395195], [0.002816573716700077, 0.061927586793899536, 0.24955692887306213, 0.4361419677734375, 0.24955692887306213], [0.845615804195404, 0.0027546356432139874, 0.10483279824256897, 0.0027546356432139874, 0.04404206946492195], [0.633061945438385, 0.11236467957496643, 0.1085989773273468, 0.044588491320610046, 0.10138595104217529], [0.10530246049165726, 0.3195481598377228, 0.10840319842100143, 0.3195481598377228, 0.14719806611537933], [0.0610896460711956, 0.2365230917930603, 0.38368913531303406, 0.08217502385377884, 0.2365230917930603], [0.2196577787399292, 0.5287126898765564, 0.008627569302916527, 0.0006908867508172989, 0.24231110513210297], [0.08505874127149582, 0.1894349902868271, 0.4850673973560333, 0.1894349902868271, 0.05100392922759056], [0.026866452768445015, 0.43850743770599365, 0.09458408504724503, 0.43850743770599365, 0.0015345802530646324], [0.07158549129962921, 0.3720570504665375, 0.3720570504665375, 0.057795025408267975, 0.12650547921657562], [0.13349641859531403, 0.11231561750173569, 0.13349641859531403, 0.6074364185333252, 0.013255203142762184], [0.005530050024390221, 0.0003017839335370809, 0.4709826409816742, 0.052202850580215454, 0.4709826409816742], [0.3788565993309021, 0.2035965919494629, 0.028537217527627945, 0.3788565993309021, 0.010152953676879406], [0.4140625298023224, 0.005225029774010181, 0.5471300482749939, 0.01679118722677231, 0.01679118722677231], [0.017260223627090454, 0.11330021172761917, 0.42270782589912415, 0.42270782589912415, 0.02402392588555813], [0.23272579908370972, 0.23272579908370972, 0.0015466196928173304, 0.22056224942207336, 0.312439501285553], [0.04923698678612709, 0.20311374962329865, 0.411361426115036, 0.1331740766763687, 0.20311374962329865], [0.09552483260631561, 0.10413054376840591, 0.21227572858333588, 0.10413054376840591, 0.48393842577934265], [0.01136488001793623, 0.005366902332752943, 0.4172143340110779, 0.4172143340110779, 0.14883951842784882], [0.03254569694399834, 0.4758540987968445, 0.011652634479105473, 0.004093450494110584, 0.4758540987968445], [0.3220365345478058, 0.12654481828212738, 0.22373473644256592, 0.10394913703203201, 0.22373473644256592], [0.003423708491027355, 0.003423708491027355, 0.09990163147449493, 0.01489932369440794, 0.8783516883850098], [0.008616035804152489, 0.052030593156814575, 0.052030593156814575, 0.31415078043937683, 0.5731720328330994], [0.06194572150707245, 0.16081343591213226, 0.44119757413864136, 0.16081343591213226, 0.17522980272769928], [0.24454011023044586, 0.1871398687362671, 0.2265828549861908, 0.15459726750850677, 0.1871398687362671], [0.009023458696901798, 0.48692813515663147, 0.009023458696901798, 0.47463589906692505, 0.020389098674058914], [0.0028275877702981234, 0.0028275877702981234, 0.993093729019165, 0.0005082982825115323, 0.0007428574026562274], [0.017779042944312096, 0.5538778305053711, 0.013039094395935535, 0.2076520025730133, 0.2076520025730133], [0.48585623502731323, 0.027935098856687546, 0.000298820756142959, 5.3626550652552396e-05, 0.48585623502731323], [0.08767963200807571, 0.017086274921894073, 0.017086274921894073, 0.8433103561401367, 0.03483743965625763], [0.011601956561207771, 0.07132730633020401, 0.09964203089475632, 0.011601956561207771, 0.8058266639709473], [0.15125228464603424, 0.45670610666275024, 0.13771015405654907, 0.11662127822637558, 0.13771015405654907], [0.196692556142807, 0.026087764650583267, 0.001926204189658165, 0.38764670491218567, 0.38764670491218567], [0.0019822027534246445, 0.1863277107477188, 0.1262354999780655, 0.6834723949432373, 0.0019822027534246445], [0.028374534100294113, 0.515652596950531, 0.10756123065948486, 0.10756123065948486, 0.24085037410259247], [0.20003831386566162, 0.0023087046574801207, 0.4196105897426605, 0.046777237206697464, 0.3312651515007019], [0.034211087971925735, 0.3066573739051819, 0.011404402554035187, 0.3066573739051819, 0.341069757938385], [0.44876837730407715, 0.07293860614299774, 0.1989518254995346, 0.1989518254995346, 0.08038948476314545], [0.47311386466026306, 0.08083295077085495, 0.08697953820228577, 0.08697953820228577, 0.27209413051605225], [0.05518951639533043, 0.021481428295373917, 0.1756727546453476, 0.37382814288139343, 0.37382814288139343], [0.6511989831924438, 0.23973409831523895, 0.002421354642137885, 0.04410557821393013, 0.06254000961780548], [0.2560010254383087, 0.2560010254383087, 0.39569610357284546, 0.039532795548439026, 0.05276906490325928], [0.026106346398591995, 0.4924165904521942, 0.026106346398591995, 0.011395360343158245, 0.4439753293991089], [0.3020035922527313, 0.09254028648138046, 0.01688632369041443, 0.49602943658828735, 0.09254028648138046], [0.010567525401711464, 0.04964466392993927, 0.6178856492042542, 0.16095104813575745, 0.16095104813575745], [8.000905654625967e-05, 0.8154494166374207, 8.000905654625967e-05, 0.18435445427894592, 3.6175544664729387e-05], [0.0006339600658975542, 0.7076238989830017, 0.13939765095710754, 0.13939765095710754, 0.012946871109306812], [0.374968558549881, 0.5166049003601074, 0.038871537894010544, 0.03068338893353939, 0.038871537894010544], [0.02443436160683632, 0.02443436160683632, 0.22312773764133453, 0.005997152999043465, 0.7220063209533691], [0.12638647854328156, 0.1611344963312149, 0.06001356244087219, 0.12638647854328156, 0.526078999042511], [0.019879821687936783, 0.337291419506073, 0.13041210174560547, 0.17512528598308563, 0.337291419506073], [0.7109032273292542, 0.13054212927818298, 0.07283540070056915, 0.07283540070056915, 0.012883841060101986], [0.5701788067817688, 0.0435190387070179, 0.03783378377556801, 0.0435190387070179, 0.3049493730068207], [0.1765446811914444, 0.3802123963832855, 0.18008945882320404, 0.1765446811914444, 0.08660879731178284], [0.001235602772794664, 0.9773672223091125, 0.013604851439595222, 0.0065567162819206715, 0.001235602772794664], [0.03308524563908577, 0.03308524563908577, 0.01645190641283989, 0.13094595074653625, 0.7864316701889038], [0.006788787432014942, 0.11879930645227432, 0.11879930645227432, 0.3045801818370819, 0.45103248953819275], [0.17341387271881104, 0.4686122238636017, 0.17578822374343872, 0.17341387271881104, 0.008771788328886032], [0.1555011123418808, 0.0001088366043404676, 0.6789180636405945, 0.1555011123418808, 0.009970849379897118], [0.24210324883460999, 0.288882851600647, 0.288882851600647, 0.17151355743408203, 0.008617492392659187], [0.0012442886363714933, 0.0024492209777235985, 0.04960786923766136, 0.0024492209777235985, 0.9442494511604309], [0.00047276532859541476, 0.03322525694966316, 0.28889915347099304, 0.33870139718055725, 0.33870139718055725], [0.22001908719539642, 0.4391403794288635, 0.010500992648303509, 0.16516979038715363, 0.16516979038715363], [0.9021131992340088, 0.0023197010159492493, 0.009079597890377045, 0.08207399398088455, 0.004413470160216093], [0.43235793709754944, 0.016873100772500038, 0.10007605701684952, 0.018334945663809776, 0.43235793709754944], [0.014247437939047813, 0.8020721673965454, 0.034055933356285095, 0.13537701964378357, 0.014247437939047813], [0.009496849030256271, 0.009496849030256271, 4.623208224074915e-05, 0.30030402541160583, 0.6806560754776001], [0.0752427726984024, 0.8501640558242798, 0.017348866909742355, 0.03989541158080101, 0.017348866909742355], [0.7211800813674927, 0.16481071710586548, 0.017510343343019485, 0.07898855209350586, 0.017510343343019485], [0.0016100391512736678, 0.013695177622139454, 0.07367319613695145, 0.8973263502120972, 0.013695177622139454], [0.14709436893463135, 0.398080050945282, 0.0682821199297905, 0.23944909870624542, 0.14709436893463135], [0.00010804855992319062, 0.013722019270062447, 0.9698500037193298, 0.013722019270062447, 0.0025978856720030308], [0.08819688111543655, 0.03834681957960129, 0.8378987312316895, 0.0058543193154037, 0.029703253880143166], [0.3601963222026825, 0.06422435492277145, 0.3601963222026825, 0.08494584262371063, 0.13043706119060516], [0.3036976158618927, 0.6367356777191162, 0.0006085530621930957, 0.02947906032204628, 0.02947906032204628], [0.4929083585739136, 0.0017486944561824203, 0.09324801713228226, 0.3188468813896179, 0.09324801713228226], [0.1021038144826889, 0.014558333903551102, 0.7673391699790955, 0.01389481034129858, 0.1021038144826889], [0.4249275028705597, 0.4249275028705597, 0.031945787370204926, 0.03534776717424393, 0.08285143226385117], [0.06319743394851685, 0.4178429841995239, 0.019875241443514824, 0.019875241443514824, 0.4792090952396393], [0.1748248189687729, 0.0018567321822047234, 0.41113516688346863, 0.0010481016943231225, 0.41113516688346863], [0.3260473310947418, 0.10597408562898636, 0.10597408562898636, 0.10097599774599075, 0.3610285222530365], [0.12682867050170898, 0.002788912272080779, 0.002788912272080779, 0.07987549901008606, 0.7877179980278015], [0.10944109410047531, 0.10944109410047531, 0.030736785382032394, 0.09129998832941055, 0.6590810418128967], [0.02256726659834385, 0.5088599324226379, 0.2609718441963196, 0.011708316393196583, 0.19589263200759888], [0.06461343914270401, 0.12958520650863647, 0.20795278251171112, 0.3898957669734955, 0.20795278251171112], [0.19223187863826752, 0.29878053069114685, 0.2528145909309387, 0.003358389250934124, 0.2528145909309387], [0.05598966032266617, 0.0010023096110671759, 0.4706587791442871, 0.4706587791442871, 0.0016904743388295174], [0.08830675482749939, 0.011179069057106972, 0.009182152338325977, 0.8030253052711487, 0.08830675482749939], [0.05364866927266121, 0.01705009490251541, 0.05364866927266121, 0.8731066584587097, 0.002545923227444291], [0.5265911221504211, 0.15204913914203644, 0.16898639500141144, 0.15204913914203644, 0.000324177643051371], [0.739477813243866, 0.03531801328063011, 0.03531801328063011, 0.14882872998714447, 0.04105746001005173], [0.22052143514156342, 0.22052143514156342, 0.026859218254685402, 0.03576165810227394, 0.4963362514972687], [0.06461041420698166, 0.17979471385478973, 0.06461041420698166, 0.6891307234764099, 0.001853682566434145], [0.04755805805325508, 0.06469026952981949, 0.12356887012720108, 0.06469026952981949, 0.6994925141334534], [0.044978879392147064, 0.44177690148353577, 0.06043597683310509, 0.44177690148353577, 0.0110313193872571], [0.006674372591078281, 0.22520609200000763, 0.5472479462623596, 0.0019591476302593946, 0.21891243755817413], [0.24747556447982788, 0.2096737027168274, 0.2096737027168274, 0.33174675703048706, 0.0014302225317806005], [0.3261960744857788, 0.27530285716056824, 0.07174450159072876, 0.2550120949745178, 0.07174450159072876], [0.834728479385376, 0.0010306679178029299, 0.14158877730369568, 0.0010306679178029299, 0.0216214582324028], [0.015265144407749176, 0.030427360907197, 0.4464563727378845, 0.4464563727378845, 0.06139470264315605], [0.3536059260368347, 0.024358538910746574, 0.3536059260368347, 0.008309892378747463, 0.2601197361946106], [0.032849207520484924, 0.2981870472431183, 0.032849207520484924, 0.0746723935008049, 0.5614421367645264], [0.37272241711616516, 0.00714956084266305, 0.37272241711616516, 0.00768893351778388, 0.23971663415431976], [0.3798171579837799, 0.3798171579837799, 0.11091261357069016, 0.0063497209921479225, 0.12310341745615005], [0.006439348217099905, 0.006439348217099905, 0.024486098438501358, 0.00881049782037735, 0.9538246989250183], [0.0015662467340007424, 0.01780540682375431, 0.01780540682375431, 0.0011521321721374989, 0.9616707563400269], [0.2926618456840515, 0.003703857073560357, 0.6194842457771301, 0.003703857073560357, 0.08044623583555222], [0.377809077501297, 0.015968386083841324, 0.12544482946395874, 0.377809077501297, 0.10296867042779922], [0.6115427613258362, 0.25139304995536804, 0.06033126637339592, 0.01640177145600319, 0.06033126637339592], [0.07377869635820389, 0.008111895062029362, 0.006360198836773634, 0.008111895062029362, 0.9036372900009155], [0.13093622028827667, 0.13093622028827667, 0.36298853158950806, 0.01477891020476818, 0.36036011576652527], [0.016408439725637436, 0.7614291906356812, 0.10186533629894257, 0.10186533629894257, 0.018431726843118668], [0.08693607151508331, 0.5126959681510925, 0.3366532325744629, 0.03185736760497093, 0.03185736760497093], [0.022960318252444267, 0.022960318252444267, 0.8782610893249512, 0.023567767813801765, 0.052250511944293976], [0.004626386798918247, 0.18331803381443024, 0.1528416872024536, 0.47589582204818726, 0.18331803381443024], [0.08768457919359207, 0.27382513880729675, 0.46375182271003723, 0.08736923336982727, 0.08736923336982727], [0.21695804595947266, 0.1312825083732605, 0.38953089714050293, 0.13094602525234222, 0.1312825083732605], [0.13119611144065857, 0.05748996511101723, 0.3575155735015869, 0.05748996511101723, 0.3963083028793335], [0.03210758790373802, 0.001759673235937953, 0.0007547451532445848, 0.4826890230178833, 0.4826890230178833], [0.18371464312076569, 0.021768663078546524, 0.007157365791499615, 0.7771481871604919, 0.010211124084889889], [0.14627040922641754, 0.15311472117900848, 0.35194841027259827, 0.17433324456214905, 0.17433324456214905], [0.003421233268454671, 0.8360949754714966, 0.1412590593099594, 0.015803487971425056, 0.003421233268454671], [0.000672261870931834, 0.5258161425590515, 0.3523104786872864, 0.000672261870931834, 0.12052886188030243], [0.07147455960512161, 0.195358008146286, 0.7251770496368408, 0.005204180721193552, 0.0027862200513482094], [0.4894898533821106, 0.014065365307033062, 0.003539028111845255, 0.003539028111845255, 0.4893667697906494], [0.2571721076965332, 0.010363911278545856, 0.3450297713279724, 0.13026215136051178, 0.2571721076965332], [0.0208898913115263, 0.1524578332901001, 0.8053726553916931, 0.0003897055867128074, 0.0208898913115263], [0.012188976630568504, 0.14516209065914154, 0.4204447269439697, 0.4204447269439697, 0.0017594568198546767], [0.1863960176706314, 0.039141424000263214, 0.039141424000263214, 0.24488304555416107, 0.4904380738735199], [0.04665730521082878, 0.0017750926781445742, 0.9216435551643372, 0.028148891404271126, 0.0017750926781445742], [0.18980106711387634, 0.4436407685279846, 0.0037092927377671003, 0.3546333611011505, 0.008215535432100296], [0.23305414617061615, 0.025373876094818115, 0.07549364119768143, 0.07549364119768143, 0.5905847549438477], [0.0035816302988678217, 0.14879094064235687, 0.6988205313682556, 0.14879094064235687, 1.5937373973429203e-05], [0.052319761365652084, 0.02255253866314888, 0.00920908059924841, 0.00920908059924841, 0.9067094922065735], [0.5190725326538086, 0.07230092585086823, 0.10102152824401855, 0.07230092585086823, 0.2353041172027588], [0.05507218465209007, 0.022095084190368652, 0.6003679037094116, 0.022095084190368652, 0.3003697395324707], [0.40363258123397827, 0.010060419328510761, 0.40363258123397827, 0.009026034735143185, 0.17364835739135742], [0.08452814072370529, 0.08452814072370529, 0.04703858122229576, 0.7726441621780396, 0.01126100029796362], [0.10308429598808289, 0.004778534639626741, 0.004778534639626741, 0.29786762595176697, 0.5894910097122192], [0.07724625617265701, 0.1652631163597107, 0.1652631163597107, 0.5819659233093262, 0.01026152353733778], [0.2539672255516052, 0.002583369379863143, 0.004957552999258041, 0.004957552999258041, 0.7335342764854431], [0.12343711405992508, 0.3480572998523712, 0.12343711405992508, 0.13768216967582703, 0.2673862874507904], [0.7302939891815186, 0.03411898389458656, 0.03411898389458656, 0.195442795753479, 0.006025301292538643], [0.0010438921162858605, 0.001821960206143558, 0.006334727630019188, 0.49539974331855774, 0.49539974331855774], [0.01945505104959011, 0.9059885740280151, 0.027271166443824768, 0.01945505104959011, 0.027830109000205994], [0.6540059447288513, 0.2598353326320648, 0.005720008164644241, 0.005720008164644241, 0.07471867650747299], [0.051737021654844284, 0.0013365873601287603, 0.0013365873601287603, 0.8316696882247925, 0.11392013728618622], [0.5920848846435547, 0.03506981581449509, 0.10362812876701355, 0.23414738476276398, 0.03506981581449509], [0.2548181116580963, 0.15192359685897827, 0.2824845612049103, 0.05595571920275688, 0.2548181116580963], [0.004607656039297581, 0.03015816956758499, 0.5187572836875916, 0.024316517636179924, 0.4221603572368622], [0.817230761051178, 0.0009702993556857109, 0.0048302169889211655, 0.08848432451486588, 0.08848432451486588], [0.09888748824596405, 0.2205909937620163, 0.14500361680984497, 0.4131178855895996, 0.12240005284547806], [0.07818705588579178, 0.004854599945247173, 0.028564704582095146, 0.2711154520511627, 0.6172782182693481], [0.0951024740934372, 0.6688397526741028, 0.056775886565446854, 0.056775886565446854, 0.1225060448050499], [0.1944470852613449, 0.07312528043985367, 0.024357672780752182, 0.024357672780752182, 0.6837122440338135], [0.3801555037498474, 0.0025423935148864985, 0.0025423935148864985, 0.003237267956137657, 0.6115224957466125], [0.06376636028289795, 0.23364420235157013, 0.022302275523543358, 0.022302275523543358, 0.6579849720001221], [0.46823352575302124, 0.005268850829452276, 0.03828245773911476, 0.44993263483047485, 0.03828245773911476], [0.4651683568954468, 0.12700065970420837, 0.010248961858451366, 0.12700065970420837, 0.27058130502700806], [0.327278733253479, 0.327278733253479, 0.2697720527648926, 0.06717263907194138, 0.008497804403305054], [0.018070505931973457, 0.2009095400571823, 0.2670707404613495, 0.2468784898519516, 0.2670707404613495], [0.3011420965194702, 0.0025953634176403284, 0.2611628770828247, 0.3011420965194702, 0.13395757973194122], [0.023722978308796883, 0.09007617831230164, 0.7975194454193115, 0.0019405216444283724, 0.0867409035563469], [0.23745669424533844, 0.23745669424533844, 0.3512003719806671, 0.000134609843371436, 0.17375166714191437], [0.005371829494833946, 0.32401034235954285, 0.32401034235954285, 0.08810954540967941, 0.2584978938102722], [0.13312262296676636, 0.26392480731010437, 0.06258128583431244, 0.26392480731010437, 0.27644649147987366], [0.06584540754556656, 0.06584540754556656, 0.11675523221492767, 0.022241121158003807, 0.7293127775192261], [0.0021016306709498167, 0.43656933307647705, 0.43656933307647705, 0.0008209221414290369, 0.12393876165151596], [0.25111955404281616, 0.006502457894384861, 0.002498574322089553, 0.7333769798278809, 0.006502457894384861], [0.5913434624671936, 0.20003771781921387, 0.16745343804359436, 0.02058272249996662, 0.02058272249996662], [8.767369581619278e-05, 0.0030665211379528046, 0.993293285369873, 0.00048595445696264505, 0.0030665211379528046], [0.4469452500343323, 0.3685934841632843, 0.05114709958434105, 0.06665708869695663, 0.06665708869695663], [0.1157887727022171, 0.6974219679832458, 0.01194289606064558, 0.01194289606064558, 0.16290345788002014], [0.014342308044433594, 0.4667562246322632, 0.0038982019759714603, 0.3282063901424408, 0.18679691851139069], [0.09095043689012527, 0.0003623668453656137, 0.5797892212867737, 0.018642045557498932, 0.31025588512420654], [0.04433639347553253, 0.2693210244178772, 0.6416463255882263, 0.04433639347553253, 0.0003599039919208735], [0.030118806287646294, 0.030118806287646294, 0.9113500118255615, 0.015704408288002014, 0.012707961723208427], [0.03890783339738846, 0.0056280093267560005, 0.04587841406464577, 0.1589030623435974, 0.7506825923919678], [0.0012942396569997072, 0.14788733422756195, 0.0012942396569997072, 0.0688549280166626, 0.7806693315505981], [0.0006079536979086697, 0.2584553360939026, 0.36941981315612793, 0.0020971233025193214, 0.36941981315612793], [0.08622171729803085, 0.0001780847815098241, 0.45121458172798157, 0.45121458172798157, 0.01117109227925539], [0.029607366770505905, 0.9181777834892273, 0.029607366770505905, 0.00015331307076849043, 0.022454122081398964], [0.0022652982734143734, 0.08825216442346573, 0.08825216442346573, 0.7773641347885132, 0.043866194784641266], [0.0587574802339077, 0.14028215408325195, 0.14028215408325195, 0.18921159207820892, 0.47146663069725037], [2.0984556613257155e-05, 0.09150054305791855, 0.8095427751541138, 0.013827049173414707, 0.08510864526033401], [0.32547828555107117, 0.23487329483032227, 0.16639038920402527, 0.23487329483032227, 0.03838468715548515], [0.13299496471881866, 0.08998074382543564, 0.011530324816703796, 0.011530324816703796, 0.7539635896682739], [0.00033270296989940107, 0.3221566081047058, 0.13848406076431274, 0.13848406076431274, 0.4005425274372101], [0.09965956211090088, 0.434226393699646, 0.1733359396457672, 0.030344100669026375, 0.2624339163303375], [0.045592501759529114, 0.0310230553150177, 0.7837966680526733, 0.13616418838500977, 0.0034235429484397173], [0.01764187403023243, 0.3500403165817261, 0.26879259943962097, 0.013484873808920383, 0.3500403165817261], [1.4544397345161997e-05, 0.30138787627220154, 0.3492688834667206, 0.3492688834667206, 5.982587026664987e-05], [0.7023072242736816, 0.01264417078346014, 0.11908409744501114, 0.046880386769771576, 0.11908409744501114], [0.5232172608375549, 0.08346720784902573, 0.08346720784902573, 0.29766207933425903, 0.01218633633106947], [0.04457259923219681, 0.004471650347113609, 0.7065601348876953, 0.23992404341697693, 0.004471650347113609], [0.00015337041986640543, 0.2989537715911865, 0.26520854234695435, 0.13673050701618195, 0.2989537715911865], [0.01735266111791134, 0.018328147009015083, 0.0020684737246483564, 0.0020684737246483564, 0.960182249546051], [0.46775558590888977, 0.061465900391340256, 0.08517396450042725, 0.3004305958747864, 0.08517396450042725], [0.2718547582626343, 0.17142648994922638, 0.039863742887973785, 0.2718547582626343, 0.2450002133846283], [0.7991906404495239, 0.07643488049507141, 0.054199911653995514, 0.015974638983607292, 0.054199911653995514], [0.08249689638614655, 0.21107277274131775, 0.08249689638614655, 0.5656206011772156, 0.05831285938620567], [0.4881815016269684, 0.02042069099843502, 0.0017802650108933449, 0.4881815016269684, 0.0014361669309437275], [0.04804524406790733, 0.03540473431348801, 0.03540473431348801, 0.8382004499435425, 0.04294483736157417], [0.15039677917957306, 0.004163484554737806, 0.22892311215400696, 0.15039677917957306, 0.4661199152469635], [0.09834602475166321, 0.09834602475166321, 0.000138200877700001, 0.15040160715579987, 0.652768075466156], [0.13067084550857544, 0.3335702121257782, 0.036894623190164566, 0.3335702121257782, 0.1652940958738327], [0.030415691435337067, 0.4477943181991577, 0.030415691435337067, 0.2360515147447586, 0.25532275438308716], [0.6025572419166565, 0.034416016191244125, 0.034416016191244125, 0.2239401638507843, 0.10467050969600677], [0.002471167128533125, 0.4982938766479492, 0.4982938766479492, 0.0006015218677930534, 0.0003396429237909615], [0.014053517021238804, 0.4066886305809021, 0.4066886305809021, 0.09368899464607239, 0.07888023555278778], [0.11791516840457916, 0.020986903458833694, 0.13569451868534088, 0.5170937776565552, 0.2083096206188202], [0.023305563256144524, 0.00123186397831887, 0.9735957384109497, 0.00123186397831887, 0.0006349870236590505], [0.7943288087844849, 0.11109061539173126, 0.0011272969422861934, 0.09232599288225174, 0.0011272969422861934], [0.10470125079154968, 0.7203482389450073, 0.030767709016799927, 0.09778372943401337, 0.04639912396669388], [0.19839008152484894, 0.46926671266555786, 0.033651482313871384, 0.19839008152484894, 0.10030168294906616], [0.053640060126781464, 0.0026665821205824614, 0.6453415155410767, 0.14917592704296112, 0.14917592704296112], [0.22773568332195282, 0.006321329157799482, 0.22773568332195282, 0.48636388778686523, 0.05184347182512283], [0.0665934756398201, 0.5378091931343079, 0.0665934756398201, 0.32826152443885803, 0.0007423206698149443], [0.01649041287600994, 0.00042883024434559047, 0.2860853374004364, 0.6805049777030945, 0.01649041287600994], [0.004983158782124519, 0.05912486091256142, 0.05912486091256142, 0.0509171262383461, 0.8258500099182129], [0.001984769944101572, 0.07602033019065857, 0.5650256276130676, 0.35498449206352234, 0.001984769944101572], [0.2088720202445984, 0.329508513212204, 0.2088720202445984, 0.23491384088993073, 0.017833642661571503], [0.014207403175532818, 0.08003009110689163, 0.06808803975582123, 0.08003009110689163, 0.7576443552970886], [0.35482797026634216, 0.0699140802025795, 0.04690632224082947, 0.1735236495733261, 0.35482797026634216], [0.120133176445961, 0.03960020840167999, 0.12233097106218338, 0.5978025197982788, 0.120133176445961], [0.0011382745578885078, 0.11659622937440872, 0.0011382745578885078, 0.23768793046474457, 0.6434392929077148], [0.08932347595691681, 0.3743961751461029, 0.08932347595691681, 0.01691930741071701, 0.43003758788108826], [0.003957792185246944, 0.003957792185246944, 0.48843491077423096, 0.2703741192817688, 0.2332753986120224], [0.38136526942253113, 0.008895663544535637, 0.2512837052345276, 0.2512837052345276, 0.10717163980007172], [0.008691418915987015, 0.012925376184284687, 0.4865379333496094, 0.005307300947606564, 0.4865379333496094], [0.45575249195098877, 0.02309214510023594, 0.49278005957603455, 0.005283189006149769, 0.02309214510023594], [6.6576944846019614e-06, 0.315104603767395, 0.13726435601711273, 0.18368829786777496, 0.3639361262321472], [0.013749518431723118, 0.01759607531130314, 0.48085159063339233, 0.48085159063339233, 0.006951230578124523], [0.49875369668006897, 0.001002988894470036, 0.0003793369687628001, 0.49875369668006897, 0.0011103827273473144], [0.021636711433529854, 0.02241845242679119, 0.03348863869905472, 0.8889676332473755, 0.03348863869905472], [0.016304051503539085, 0.5392187237739563, 0.20630186796188354, 0.03187357261776924, 0.20630186796188354], [0.0018920855363830924, 0.024120638146996498, 0.036023907363414764, 0.46898168325424194, 0.46898168325424194], [0.22721053659915924, 0.01688234694302082, 0.22721053659915924, 0.042996376752853394, 0.48570016026496887], [0.33784744143486023, 0.020337438210844994, 0.017916787415742874, 0.33784744143486023, 0.2860509157180786], [0.094764344394207, 0.1422846019268036, 0.1422846019268036, 0.44897425174713135, 0.1716921627521515], [0.8935074210166931, 0.003083360381424427, 0.0024648671969771385, 0.002602281514555216, 0.09834202378988266], [0.005110016092658043, 0.35496482253074646, 0.29648977518081665, 0.04694562405347824, 0.29648977518081665], [0.06908983737230301, 0.008500494994223118, 0.7925047874450684, 0.06495244055986404, 0.06495244055986404], [0.033340148627758026, 0.033340148627758026, 0.6089127659797668, 0.0998709425330162, 0.2245360165834427], [0.29211097955703735, 0.0679197683930397, 0.29211097955703735, 0.1915551722049713, 0.15630316734313965], [0.039261594414711, 0.375345915555954, 0.01647310145199299, 0.5296578407287598, 0.039261594414711], [0.5422877669334412, 0.04855607822537422, 0.11230363696813583, 0.18454892933368683, 0.11230363696813583], [0.03159939870238304, 0.6230173110961914, 0.07044528424739838, 0.0031105431262403727, 0.27182745933532715], [0.029320474714040756, 0.9484705328941345, 0.0004077996127307415, 0.021393459290266037, 0.0004077996127307415], [3.393357474124059e-05, 0.14512501657009125, 3.393357474124059e-05, 0.6645303964614868, 0.19027666747570038], [0.7508339285850525, 0.04372482746839523, 0.054840944707393646, 0.009295412339270115, 0.1413048803806305], [0.00878759566694498, 0.17484262585639954, 0.48468655347824097, 0.15684057772159576, 0.17484262585639954], [0.056409772485494614, 0.006407857406884432, 0.056409772485494614, 0.5358092188835144, 0.344963401556015], [0.004774110391736031, 0.31286877393722534, 0.3615693151950836, 0.0079190107062459, 0.31286877393722534], [0.5550234317779541, 0.13669808208942413, 0.15354107320308685, 0.01803932897746563, 0.13669808208942413], [0.22525103390216827, 0.02591051161289215, 0.3262346386909485, 0.09636923670768738, 0.3262346386909485], [0.36699503660202026, 0.241119384765625, 0.241119384765625, 0.10103469341993332, 0.04973154515028], [0.007355200592428446, 0.9718629717826843, 0.007355200592428446, 0.012968872673809528, 0.0004578331718221307], [0.1673213243484497, 0.02672768570482731, 0.5727881789207458, 0.11658141016960144, 0.11658141016960144], [0.33355122804641724, 0.0015515760751441121, 0.42818132042884827, 0.2351643294095993, 0.0015515760751441121], [0.0004843634378630668, 0.09959827363491058, 0.0019941122736781836, 0.09959827363491058, 0.7983248829841614], [0.14312724769115448, 0.14312724769115448, 0.08256202936172485, 0.16046085953712463, 0.47072258591651917], [0.4302156865596771, 0.006832407787442207, 0.4302156865596771, 0.11335451900959015, 0.019381651654839516], [0.0824129581451416, 0.4595635235309601, 0.22255510091781616, 0.22255510091781616, 0.012913335114717484], [0.0036979943979531527, 0.08141402155160904, 0.44387975335121155, 0.08141402155160904, 0.3895942270755768], [0.0918627604842186, 0.029475266113877296, 0.17662806808948517, 0.35101693868637085, 0.35101693868637085], [0.19541478157043457, 0.0055559598840773106, 0.40452611446380615, 0.197251558303833, 0.197251558303833], [0.020188722759485245, 0.7511435747146606, 0.19047710299491882, 0.020188722759485245, 0.018001889809966087], [0.35385212302207947, 0.17468704283237457, 0.04282127320766449, 0.0747874304652214, 0.35385212302207947], [0.18728791177272797, 0.02385718561708927, 0.5950155854225159, 0.006551376078277826, 0.18728791177272797], [0.22422048449516296, 0.22422048449516296, 0.3197823762893677, 0.053183455020189285, 0.178593248128891], [0.429634153842926, 4.009013355243951e-05, 0.429634153842926, 0.13964791595935822, 0.0010436800075694919], [0.46219632029533386, 0.00493896659463644, 0.005889634136110544, 0.06477875262498856, 0.46219632029533386], [0.01327337883412838, 0.4031287729740143, 0.4031287729740143, 0.0040821414440870285, 0.1763869673013687], [0.03967778757214546, 0.09550867974758148, 0.09550867974758148, 0.5807687640190125, 0.1885361224412918], [0.5518797039985657, 0.0018988385563716292, 0.0018988385563716292, 0.40192002058029175, 0.04240266978740692], [0.011904403567314148, 0.5095483064651489, 0.05337449163198471, 0.3717983067035675, 0.05337449163198471], [0.4040190875530243, 0.033680424094200134, 0.4040190875530243, 0.10699168592691422, 0.05128971114754677], [0.3204326331615448, 0.3204326331615448, 0.0005200778832659125, 0.00821777805685997, 0.35039690136909485], [0.504956841468811, 0.22147196531295776, 0.04207604378461838, 0.22147196531295776, 0.010023248381912708], [0.44971564412117004, 0.0017607505433261395, 0.03987836837768555, 0.44971564412117004, 0.05892953649163246], [0.8447995781898499, 0.019366554915905, 0.09010249376296997, 0.02636481449007988, 0.019366554915905], [0.1513371765613556, 0.07576575875282288, 0.41718241572380066, 0.005135832820087671, 0.35057881474494934], [0.46706265211105347, 0.04540909826755524, 0.46706265211105347, 0.01145078893750906, 0.009014747105538845], [0.008296024985611439, 0.07150451093912125, 0.07150451093912125, 0.03901069611310959, 0.809684157371521], [0.05738404020667076, 0.2232740819454193, 0.1744358092546463, 0.1744358092546463, 0.3704702854156494], [0.08093132078647614, 0.2077312022447586, 0.6108766198158264, 0.08093132078647614, 0.019529489800333977], [0.04661835357546806, 0.0006319250096566975, 0.037804096937179565, 0.13206344842910767, 0.7828822135925293], [0.006681591738015413, 0.13737079501152039, 0.006681591738015413, 0.8355483412742615, 0.01371767371892929], [0.3723929226398468, 0.0029337028972804546, 0.0026336442679166794, 0.3723929226398468, 0.24964681267738342], [4.3110459955642e-05, 0.08431512117385864, 0.05794254690408707, 0.08431512117385864, 0.7733840942382812], [0.05266847461462021, 0.05266847461462021, 0.2759053111076355, 0.2879968583583832, 0.3307608962059021], [0.1354389190673828, 0.03647435083985329, 0.019038937985897064, 0.019038937985897064, 0.7900087833404541], [0.07286686450242996, 0.2742503881454468, 0.006516372784972191, 0.07286686450242996, 0.5734995603561401], [0.11826936155557632, 0.006675346288830042, 0.0019052685238420963, 0.4365749955177307, 0.4365749955177307], [0.506335973739624, 0.3954455554485321, 0.04569659382104874, 0.0006014269310981035, 0.05192049592733383], [0.6101489067077637, 0.10147876292467117, 0.05473071709275246, 0.10147876292467117, 0.1321628987789154], [0.013914714567363262, 0.019861914217472076, 0.024239694699645042, 0.019861914217472076, 0.9221217632293701], [0.007353568449616432, 0.33321332931518555, 0.20680135488510132, 0.20680135488510132, 0.24583037197589874], [0.013343018479645252, 0.78642737865448, 0.007890631444752216, 0.1844482570886612, 0.007890631444752216], [0.08561702817678452, 0.011855849996209145, 0.6465299725532532, 0.17038017511367798, 0.08561702817678452], [0.36596202850341797, 0.36596202850341797, 0.05159365013241768, 0.01968897320330143, 0.19679327309131622], [0.020448455587029457, 0.2991292178630829, 2.5773688321351074e-05, 0.6599480509757996, 0.020448455587029457], [0.09795854985713959, 0.016357265412807465, 0.7890136241912842, 0.04833532124757767, 0.04833532124757767], [0.01082939188927412, 0.0033082596492022276, 0.0033082596492022276, 0.7990859746932983, 0.18346811830997467], [0.0479234904050827, 0.8101542592048645, 0.053997550159692764, 0.03392715007066727, 0.053997550159692764], [0.16097743809223175, 0.26306238770484924, 0.0212409570813179, 0.26306238770484924, 0.29165682196617126], [0.6389606595039368, 0.012458797544240952, 0.012458797544240952, 0.1062222346663475, 0.22989951074123383], [0.2659609615802765, 0.10226713865995407, 0.30703863501548767, 0.01769464835524559, 0.30703863501548767], [0.5500726103782654, 0.012987266294658184, 0.04895097762346268, 0.34581834077835083, 0.04217086359858513], [0.21360279619693756, 0.2946482002735138, 0.07962006330490112, 0.23701690137386322, 0.1751120388507843], [0.06728606671094894, 0.4150344431400299, 0.04767879843711853, 0.4150344431400299, 0.05496622249484062], [0.015614012256264687, 0.5668832063674927, 0.3899235725402832, 0.015614012256264687, 0.011965162120759487], [0.1364349126815796, 0.2150896042585373, 0.04811130464076996, 0.5522528886795044, 0.04811130464076996], [0.008644193410873413, 0.5565596222877502, 0.1289108842611313, 0.2606886327266693, 0.04519663378596306], [5.0127746362704784e-05, 0.025579942390322685, 0.9275792837142944, 0.021210642531514168, 0.025579942390322685], [0.2702121436595917, 0.41845765709877014, 0.2702121436595917, 0.039281655102968216, 0.001836390350945294], [0.018881533294916153, 0.0012941728346049786, 0.10950695723295212, 0.760810375213623, 0.10950695723295212], [0.1378020942211151, 0.28752827644348145, 0.0047212028875947, 0.1378020942211151, 0.4321463406085968], [0.058271005749702454, 0.058271005749702454, 0.8605148196220398, 0.018051007762551308, 0.004892216995358467], [0.010059578344225883, 0.066788449883461, 0.10806926339864731, 0.7070134282112122, 0.10806926339864731], [0.3700416088104248, 0.044717345386743546, 0.1966690868139267, 0.018530303612351418, 0.3700416088104248], [0.25517037510871887, 0.6851982474327087, 0.002814504085108638, 0.05400236323475838, 0.002814504085108638], [0.017342040315270424, 0.442956805229187, 0.39783671498298645, 0.017342040315270424, 0.12452244758605957], [0.01131008006632328, 0.0626409649848938, 0.4119729697704315, 0.5049217343330383, 0.009154302068054676], [0.030404573306441307, 0.6911764740943909, 0.18720518052577972, 0.0608091801404953, 0.030404573306441307], [0.09649164229631424, 0.023787321522831917, 0.40935400128364563, 0.09649164229631424, 0.3738754093647003], [0.006917709019035101, 0.22389771044254303, 0.6394864320755005, 0.019892727956175804, 0.1098053976893425], [0.10235641151666641, 0.04293592646718025, 0.036928940564394, 0.7748427987098694, 0.04293592646718025], [0.04612194001674652, 0.1813105195760727, 0.0696488544344902, 0.0696488544344902, 0.6332698464393616], [0.15858429670333862, 0.025751745328307152, 0.40058568120002747, 0.01449255645275116, 0.40058568120002747], [0.0019450233085080981, 0.4696263074874878, 0.4696263074874878, 0.03125390037894249, 0.027548454701900482], [0.06955046951770782, 0.06955046951770782, 0.02371610701084137, 0.5613180994987488, 0.2758648693561554], [0.7594444751739502, 0.014424978755414486, 0.0793069377541542, 0.1419704407453537, 0.004853148944675922], [0.10890576243400574, 0.2552594542503357, 0.2146628499031067, 0.2552594542503357, 0.16591249406337738], [0.19543705880641937, 0.17007018625736237, 0.33444300293922424, 0.12997956573963165, 0.17007018625736237], [0.04371856153011322, 0.02856527455151081, 0.9256711602210999, 0.0010224521392956376, 0.0010224521392956376], [0.7214563488960266, 0.00473538925871253, 0.26042428612709045, 0.008648629300296307, 0.00473538925871253], [0.0004963580286130309, 0.08389899134635925, 0.024132685735821724, 0.8075730204582214, 0.08389899134635925], [0.0022639089729636908, 0.7282267212867737, 0.11506681144237518, 0.006661239080131054, 0.14778141677379608], [0.071123868227005, 0.36597007513046265, 0.08642596751451492, 0.36597007513046265, 0.11051003634929657], [0.005924593657255173, 0.07511056214570999, 0.2630307674407959, 0.5849350094795227, 0.07099904865026474], [0.07340098917484283, 0.4025562107563019, 0.08295337855815887, 0.4025562107563019, 0.038533229380846024], [0.0036951827351003885, 0.33539941906929016, 0.026230445131659508, 0.3173374831676483, 0.3173374831676483], [0.23793362081050873, 0.21904996037483215, 0.011120078153908253, 0.3128463327884674, 0.21904996037483215], [0.020336927846074104, 0.1821197271347046, 0.33627423644065857, 0.1821197271347046, 0.27914947271347046], [0.12383514642715454, 0.1273181140422821, 0.1273181140422821, 0.6132094264030457, 0.008319152519106865], [0.002958273282274604, 0.27660030126571655, 0.28914982080459595, 0.14214175939559937, 0.28914982080459595], [0.008653255179524422, 0.002254849299788475, 0.04969831183552742, 0.9307402968406677, 0.008653255179524422], [0.009452593512833118, 0.031221164390444756, 0.11737211048603058, 0.11737211048603058, 0.7245820164680481], [0.05913189798593521, 0.10409770160913467, 0.41352736949920654, 0.009715625084936619, 0.41352736949920654], [0.3497602343559265, 0.0034862328320741653, 0.3497602343559265, 0.06439467519521713, 0.23259864747524261], [0.2982214391231537, 0.3359220623970032, 0.2982214391231537, 0.0023415694013237953, 0.06529346853494644], [0.04560866206884384, 0.015213221311569214, 0.4541926681995392, 0.030792679637670517, 0.4541926681995392], [0.11239650845527649, 0.27875328063964844, 0.0009909416548907757, 0.3039296567440033, 0.3039296567440033], [0.09113936871290207, 0.005589988548308611, 0.059060730040073395, 0.005589988548308611, 0.8386199474334717], [0.8729907274246216, 0.0023543776478618383, 0.1009090319275856, 0.021391553804278374, 0.0023543776478618383], [0.029605170711874962, 0.0023324270732700825, 0.029605170711874962, 0.8942915201187134, 0.044165752828121185], [0.009878473356366158, 0.8271195888519287, 0.08005962520837784, 0.08005962520837784, 0.002882673405110836], [0.3855437934398651, 0.28726503252983093, 0.0002976427203975618, 0.039628490805625916, 0.28726503252983093], [0.24884770810604095, 0.34616002440452576, 0.34616002440452576, 0.05547603219747543, 0.0033562066964805126], [0.5506770014762878, 0.13595470786094666, 0.12436407804489136, 0.12436407804489136, 0.06464012712240219], [0.04410049691796303, 0.01844894513487816, 0.4453502893447876, 0.4453502893447876, 0.046749986708164215], [0.18468716740608215, 0.050895269960165024, 0.18468716740608215, 0.0006876856205053627, 0.5790427327156067], [0.3968730866909027, 0.16276781260967255, 0.1955869495868683, 0.16276781260967255, 0.08200431615114212], [0.008203721605241299, 0.3702351152896881, 0.056352127343416214, 0.28260448575019836, 0.28260448575019836], [0.033647410571575165, 0.7062506079673767, 0.23135454952716827, 0.0011381529038771987, 0.027609284967184067], [0.47544461488723755, 0.47544461488723755, 0.01538968738168478, 0.02004387229681015, 0.013677210547029972], [0.09839383512735367, 0.08783859014511108, 0.22288046777248383, 0.3680066168308258, 0.22288046777248383], [0.40801700949668884, 0.2390546053647995, 0.10912517458200455, 0.004748689476400614, 0.2390546053647995], [0.09007462114095688, 0.32685258984565735, 0.1943528950214386, 0.06186729669570923, 0.32685258984565735], [0.3767029047012329, 0.08015128970146179, 0.46232929825782776, 0.00066522101406008, 0.08015128970146179], [0.2740265130996704, 0.5619940161705017, 0.023009367287158966, 0.07048505544662476, 0.07048505544662476], [0.0005435092025436461, 0.001906341640278697, 0.47881320118904114, 0.47881320118904114, 0.039923787117004395], [3.964781717513688e-05, 0.4670189917087555, 0.4670189917087555, 0.0018692297162488103, 0.06405308842658997], [0.614880383014679, 0.07438475638628006, 0.177351176738739, 0.07438475638628006, 0.05899893492460251], [0.050500668585300446, 0.050500668585300446, 0.5450096130371094, 0.3443697690963745, 0.009619289077818394], [0.04116145148873329, 0.11926041543483734, 0.000421568111050874, 0.04116145148873329, 0.7979951500892639], [0.039606355130672455, 0.07456184923648834, 0.0514398068189621, 0.07456184923648834, 0.7598301768302917], [0.07497845590114594, 0.2495339959859848, 2.645357199071441e-05, 0.2495339959859848, 0.425927072763443], [0.07833264023065567, 0.04030073434114456, 0.04030073434114456, 0.015678079798817635, 0.8253877758979797], [0.26659440994262695, 0.010159660130739212, 0.26659440994262695, 0.3447851836681366, 0.11186635494232178], [0.4738755226135254, 0.039589475840330124, 0.4738755226135254, 0.006748572923243046, 0.005911009386181831], [0.1960916966199875, 0.10124526917934418, 0.5064825415611267, 8.878158405423164e-05, 0.1960916966199875], [0.2503109574317932, 0.009939517825841904, 0.1605692356824875, 0.1605692356824875, 0.4186110198497772], [0.2781091630458832, 0.15536785125732422, 0.4887683391571045, 0.03887733444571495, 0.03887733444571495], [0.05454137548804283, 0.07159663736820221, 0.802173912525177, 9.144056093646213e-05, 0.07159663736820221], [0.126726433634758, 0.09325624257326126, 0.05479904264211655, 0.7245141863822937, 0.0007041183416731656], [0.3800031840801239, 0.3800031840801239, 0.037309419363737106, 0.07752285897731781, 0.12516140937805176], [0.00013648654567077756, 0.5178627967834473, 0.15085189044475555, 0.3310123682022095, 0.00013648654567077756], [0.10981745272874832, 0.0016746221808716655, 0.03686581924557686, 0.3892888128757477, 0.46235334873199463], [0.5906555652618408, 0.10041589289903641, 0.10041589289903641, 0.1590290516614914, 0.049483560025691986], [0.6632049083709717, 0.00840067770332098, 0.1092090755701065, 0.1092090755701065, 0.10997629165649414], [0.0009097234578803182, 0.06756964325904846, 0.13676492869853973, 0.6579908132553101, 0.13676492869853973], [0.015260507352650166, 0.3686223030090332, 0.3686223030090332, 0.2472696602344513, 0.00022528624685946852], [0.5543894171714783, 0.005019596312195063, 0.01356939971446991, 0.01356939971446991, 0.4134522080421448], [0.0570022314786911, 0.019389519467949867, 0.16854673624038696, 0.7356719970703125, 0.019389519467949867], [0.001751220552250743, 0.018843602389097214, 0.11907394230365753, 0.7412572503089905, 0.11907394230365753], [0.025174882262945175, 0.02363915927708149, 0.07275550067424774, 0.08122821152210236, 0.7972022891044617], [0.24838776886463165, 0.0005869775777682662, 0.0005869775777682662, 0.013232424855232239, 0.7372058629989624], [0.05919366329908371, 0.22876188158988953, 0.7065179944038391, 0.00276323314756155, 0.00276323314756155], [0.2868784964084625, 0.20868656039237976, 0.2868784964084625, 0.18233714997768402, 0.03521929681301117], [0.4441612660884857, 0.014677533879876137, 0.039275430142879486, 0.4441612660884857, 0.057724520564079285], [0.008596663363277912, 0.8605690598487854, 0.12160605192184448, 0.008596663363277912, 0.0006315683131106198], [0.024350561201572418, 0.8139613270759583, 0.10428082197904587, 0.0007803809712640941, 0.05662684887647629], [0.519930362701416, 0.013457585126161575, 0.0014745582593604922, 0.0014745582593604922, 0.4636629521846771], [0.2633003294467926, 0.17636975646018982, 0.23347461223602295, 0.17636975646018982, 0.15048560500144958], [0.2501991093158722, 0.04227150231599808, 0.08518067002296448, 0.08518067002296448, 0.537168025970459], [0.010686674155294895, 0.07010878622531891, 0.8117353916168213, 0.07010878622531891, 0.037360381335020065], [0.853046178817749, 0.021238330751657486, 0.008967333473265171, 0.050779182463884354, 0.06596902012825012], [0.9184675812721252, 0.00042896729428321123, 0.005802859086543322, 0.00042896729428321123, 0.07487161457538605], [0.7248107194900513, 0.12097807973623276, 0.14664368331432343, 0.0037837657146155834, 0.0037837657146155834], [0.04211429879069328, 0.7143435478210449, 0.050918810069561005, 0.1884925365447998, 0.0041307187639176846], [0.6832720637321472, 0.1048661395907402, 0.03570777550339699, 0.07128795981407166, 0.1048661395907402], [0.15576928853988647, 0.15576928853988647, 0.07170204818248749, 0.31188327074050903, 0.3048761487007141], [0.13758595287799835, 0.015151948668062687, 0.008849726058542728, 0.8232604265213013, 0.015151948668062687], [0.910898745059967, 0.035239327698946, 0.0022018947638571262, 0.01642068289220333, 0.035239327698946], [0.15351180732250214, 0.0005932858912274241, 0.15351180732250214, 0.22229225933551788, 0.4700908660888672], [0.04620278626680374, 0.3862275779247284, 0.3862275779247284, 0.0531083308160305, 0.12823376059532166], [0.013581616804003716, 0.1244935393333435, 0.005562835372984409, 0.428180992603302, 0.428180992603302], [0.0015388638712465763, 0.8157882690429688, 0.09379951655864716, 0.00959478598088026, 0.07927851378917694], [0.745438277721405, 0.038109224289655685, 0.05812137946486473, 0.0791655108332634, 0.0791655108332634], [0.010782445780932903, 0.09211840480566025, 0.0006262681563384831, 0.4482364356517792, 0.4482364356517792], [0.27473777532577515, 0.000502087757922709, 0.05058949068188667, 0.054761242121458054, 0.6194093823432922], [0.06762027740478516, 0.46448615193367004, 0.31595322489738464, 0.06762027740478516, 0.08432012051343918], [0.4378054738044739, 0.05125189200043678, 0.012694556266069412, 0.012694556266069412, 0.48555347323417664], [0.01988750509917736, 0.01988750509917736, 0.5958957672119141, 0.3601720333099365, 0.004157206974923611], [0.0005682342452928424, 0.812102198600769, 0.1867159903049469, 4.52640451840125e-05, 0.0005682342452928424], [0.30925673246383667, 0.0018859044648706913, 0.0010132592869922519, 0.3785874843597412, 0.30925673246383667], [0.48471882939338684, 0.04935434088110924, 0.007189337629824877, 0.007189337629824877, 0.45154809951782227], [0.35092803835868835, 0.04273276776075363, 0.22079189121723175, 0.13536205887794495, 0.2501853108406067], [0.0017257193103432655, 0.002811182290315628, 0.4403337836265564, 0.11479553580284119, 0.4403337836265564], [0.0019066351233050227, 0.004971757996827364, 0.1960761994123459, 0.6009692549705505, 0.1960761994123459], [0.2503296136856079, 0.003722490044310689, 0.003722490044310689, 0.1211763247847557, 0.6210491061210632], [0.2266150265932083, 0.2266150265932083, 0.006019398104399443, 0.15318632125854492, 0.3875643312931061], [0.6041824817657471, 0.00021031151118222624, 0.004964713007211685, 0.003539544064551592, 0.3871029019355774], [0.013755365274846554, 0.29007384181022644, 0.21451295912265778, 0.2671448588371277, 0.21451295912265778], [0.4253617525100708, 0.5064611434936523, 0.00035482863313518465, 0.00035482863313518465, 0.06746745109558105], [0.1708325296640396, 0.4693272113800049, 0.165171816945076, 0.1708325296640396, 0.023835962638258934], [0.09442698210477829, 0.0006002935697324574, 0.25084859132766724, 0.3036079406738281, 0.350516140460968], [0.13833023607730865, 0.0008820234215818346, 0.13833023607730865, 0.5614326000213623, 0.16102488338947296], [0.02507813274860382, 0.02507813274860382, 0.8951273560523987, 0.012291081249713898, 0.042425382882356644], [0.0012232032604515553, 0.19406357407569885, 0.4632267653942108, 0.19406357407569885, 0.14742280542850494], [0.16876712441444397, 0.37451669573783875, 0.00014074629871174693, 0.08205868303775787, 0.37451669573783875], [0.26587727665901184, 0.029313109815120697, 0.3490830063819885, 0.3490830063819885, 0.0066436040215194225], [0.057835448533296585, 0.008317039348185062, 0.00013365117774810642, 0.057835448533296585, 0.8758783936500549], [8.007016003830358e-05, 0.14309868216514587, 0.8451250195503235, 0.005848105996847153, 0.005848105996847153], [0.0328926183283329, 0.054344531148672104, 0.8027554154396057, 0.07711480557918549, 0.0328926183283329], [0.17944295704364777, 0.17944295704364777, 0.024043431505560875, 0.10408084094524384, 0.51298987865448], [0.2865322530269623, 0.040463026612997055, 0.2865322530269623, 0.29855629801750183, 0.08791612833738327], [0.41078367829322815, 7.194687350420281e-05, 7.194687350420281e-05, 0.4895334541797638, 0.09953901171684265], [0.4629329442977905, 0.5009311437606812, 0.0009623753139749169, 0.0009623753139749169, 0.0342111811041832], [0.2203245908021927, 0.03265320509672165, 0.7092974185943604, 0.03265320509672165, 0.005071505904197693], [0.2890143394470215, 0.2890143394470215, 0.12105687707662582, 0.15850570797920227, 0.14240865409374237], [0.09983173757791519, 0.1913646161556244, 0.5084126591682434, 0.1913646161556244, 0.009026416577398777], [0.20852130651474, 0.01852572150528431, 0.5346530675888062, 0.21977421641349792, 0.01852572150528431], [0.0367187038064003, 0.2534279227256775, 0.6506351828575134, 0.022499529644846916, 0.0367187038064003], [0.0008082333952188492, 0.0005674262065440416, 0.25678500533103943, 0.0005674262065440416, 0.7412719130516052], [0.4439352750778198, 0.03667457401752472, 0.06934445351362228, 0.0061104209162294865, 0.4439352750778198], [0.17254678905010223, 0.0033787847496569157, 0.6473692059516907, 0.004158422816544771, 0.17254678905010223], [2.795450018311385e-05, 0.7858104705810547, 0.07161185145378113, 0.07093783468008041, 0.07161185145378113], [0.0013860586332157254, 0.006464606616646051, 0.4957720637321472, 0.0006053012912161648, 0.4957720637321472], [0.051266636699438095, 0.7686169147491455, 0.001262708567082882, 0.051266636699438095, 0.12758708000183105], [0.3784146010875702, 0.0189084280282259, 0.14582553505897522, 0.4379429817199707, 0.0189084280282259], [0.00042670147377066314, 0.00504940003156662, 0.3189772367477417, 0.3565693497657776, 0.3189772367477417], [0.056782208383083344, 0.0005966893513686955, 0.7265414595603943, 0.10803983360528946, 0.10803983360528946], [0.00015836655802559108, 0.2522079050540924, 0.49134498834609985, 0.004080815706402063, 0.2522079050540924], [0.35897156596183777, 0.01319462712854147, 0.05027307569980621, 0.21858911216259003, 0.35897156596183777], [0.2423926144838333, 0.08023253083229065, 0.0021491593215614557, 0.0021491593215614557, 0.6730765104293823], [0.02551599033176899, 0.4997154772281647, 0.02551599033176899, 0.14190419018268585, 0.30734825134277344], [0.11237248033285141, 0.47724077105522156, 0.13171690702438354, 0.14695300161838531, 0.13171690702438354], [0.0029308325611054897, 0.3358572721481323, 0.3358572721481323, 0.056960731744766235, 0.2683938145637512], [0.21691985428333282, 0.02076561376452446, 0.45984014868736267, 0.21691985428333282, 0.08555455505847931], [0.015241341665387154, 0.06606075167655945, 0.015241341665387154, 0.08869241923093796, 0.814764142036438], [0.015433945693075657, 0.2872582674026489, 0.5572729706764221, 0.07001741975545883, 0.07001741975545883], [0.11935008317232132, 0.01719880849123001, 0.034105084836483, 0.034105084836483, 0.7952408790588379], [0.7476891279220581, 0.13597993552684784, 0.044702060520648956, 0.026926815509796143, 0.044702060520648956], [0.12646488845348358, 0.005633159540593624, 0.372538685798645, 0.12282456457614899, 0.372538685798645], [0.23649606108665466, 0.19357608258724213, 0.33103129267692566, 0.045320477336645126, 0.19357608258724213], [0.1935712844133377, 0.3947421908378601, 0.015182473696768284, 0.0017617513658478856, 0.3947421908378601], [0.0823783427476883, 0.41290774941444397, 0.0070583452470600605, 0.4152772128582001, 0.0823783427476883], [0.00227461033500731, 0.09133350849151611, 0.00227461033500731, 0.0005008074222132564, 0.9036164879798889], [0.00015306429122574627, 0.36957287788391113, 0.2531977891921997, 0.007503431756049395, 0.36957287788391113], [0.039652060717344284, 0.20400992035865784, 0.3976972699165344, 0.15463075041770935, 0.20400992035865784], [0.04996470734477043, 0.11358976364135742, 0.04996470734477043, 0.7857295274734497, 0.0007513247546739876], [0.2001274973154068, 0.22076444327831268, 0.3765469789505005, 0.2001274973154068, 0.0024336311034858227], [0.369151771068573, 0.05130413547158241, 0.16582204401493073, 0.04457026347517967, 0.369151771068573], [0.5696321725845337, 0.017765356227755547, 0.039991140365600586, 0.33262017369270325, 0.039991140365600586], [0.13825663924217224, 0.01947958581149578, 0.3549693524837494, 0.13232508301734924, 0.3549693524837494], [0.5265311002731323, 0.00023648093338124454, 0.00023648093338124454, 0.46216028928756714, 0.010835692286491394], [0.3950458765029907, 0.3950458765029907, 0.08549098670482635, 0.04826660454273224, 0.07615065574645996], [0.31025072932243347, 0.018444204702973366, 0.35334035754203796, 0.0077140601351857185, 0.31025072932243347], [0.4097664952278137, 0.07646766304969788, 0.055246129631996155, 0.048753272742033005, 0.4097664952278137], [0.005662277340888977, 0.49333643913269043, 0.0003115517902188003, 0.007353250402957201, 0.49333643913269043], [0.00913817249238491, 0.08932512253522873, 0.00023607586626894772, 0.00913817249238491, 0.8921624422073364], [0.00928749330341816, 0.9568594694137573, 0.0015428641345351934, 0.0015428641345351934, 0.030767260119318962], [0.02031342126429081, 0.02031342126429081, 0.7982926368713379, 0.07978516817092896, 0.08129534870386124], [0.3434367775917053, 0.3762054443359375, 0.27920565009117126, 0.00066062604309991, 0.0004915153258480132], [0.08891892433166504, 0.3239220082759857, 0.08891892433166504, 0.001404283451847732, 0.4968358278274536], [0.06395366042852402, 0.2873108983039856, 0.03246615082025528, 0.30813464522361755, 0.30813464522361755], [0.18149591982364655, 0.18149591982364655, 0.0007711664657108486, 0.21218925714492798, 0.4240477681159973], [0.17618536949157715, 0.40101468563079834, 0.40101468563079834, 0.0007914899615570903, 0.020993828773498535], [0.002537793479859829, 0.002537793479859829, 0.5245345234870911, 1.2756427167914808e-05, 0.4703770875930786], [0.39503613114356995, 0.030156347900629044, 0.3026687204837799, 0.030156347900629044, 0.24198247492313385], [0.4486980736255646, 0.013196691870689392, 0.4486980736255646, 0.05875222757458687, 0.03065492771565914], [0.12394022196531296, 0.039452385157346725, 0.7375662922859192, 0.04952054098248482, 0.04952054098248482], [0.2933862507343292, 0.5331096649169922, 0.07271528244018555, 0.028073515743017197, 0.07271528244018555], [0.9055688977241516, 0.0015159553149715066, 0.09237277507781982, 0.0002711445849854499, 0.0002711445849854499], [0.3628714680671692, 0.07013074308633804, 0.3628714680671692, 0.18536962568759918, 0.018756700679659843], [0.1337605118751526, 0.6493294835090637, 0.1337605118751526, 0.07625055313110352, 0.006898865569382906], [0.3946422040462494, 0.002832830650731921, 0.5904396176338196, 0.0015828334726393223, 0.010502506047487259], [0.001846776227466762, 0.5240495204925537, 0.10324986279010773, 0.36900705099105835, 0.001846776227466762], [0.7749589085578918, 0.1120678186416626, 0.11035899072885513, 0.001307150349020958, 0.001307150349020958], [0.05615892633795738, 0.015197847969830036, 0.05615892633795738, 0.8720468282699585, 0.00043749247561208904], [0.000810020137578249, 0.012692061252892017, 0.3780018091201782, 0.23049426078796387, 0.3780018091201782], [0.05859679356217384, 0.006757063325494528, 0.00037188647547736764, 0.8756774067878723, 0.05859679356217384], [0.21307039260864258, 0.014939432963728905, 0.12870395183563232, 0.5145822763442993, 0.12870395183563232], [0.30000466108322144, 0.0791483223438263, 0.0791483223438263, 0.1278420239686966, 0.41385674476623535], [0.21553239226341248, 0.28050288558006287, 0.18991199135780334, 0.28050288558006287, 0.03354983776807785], [0.004603185225278139, 0.36388054490089417, 0.36388054490089417, 0.13723266124725342, 0.13040311634540558], [0.0018423486035317183, 0.9167224168777466, 0.0018423486035317183, 0.003296168055385351, 0.07629665732383728], [0.015370656736195087, 0.4075956642627716, 0.18361696600914001, 0.3932855427265167, 0.00013118832430336624], [0.03541400656104088, 0.5446298122406006, 0.33821266889572144, 0.03541400656104088, 0.04632945731282234], [0.5139798521995544, 0.22337324917316437, 0.031271666288375854, 0.22337324917316437, 0.008002033457159996], [0.031484369188547134, 0.031484369188547134, 0.15285411477088928, 0.01876208744943142, 0.7654150128364563], [0.3272259831428528, 0.021913466975092888, 0.24175386130809784, 0.20455336570739746, 0.20455336570739746], [0.011458855122327805, 0.1766372174024582, 0.1766372174024582, 0.48807621002197266, 0.14719046652317047], [0.37472105026245117, 0.01340293325483799, 0.01870059408247471, 0.01870059408247471, 0.5744748115539551], [3.7133548175916076e-05, 3.7133548175916076e-05, 0.4281919300556183, 0.004931301344186068, 0.5668025016784668], [0.002685959218069911, 0.002816163469105959, 0.477882444858551, 0.03873302415013313, 0.477882444858551], [0.02167043462395668, 0.1408679038286209, 0.12249956279993057, 0.6932916045188904, 0.02167043462395668], [0.13205933570861816, 0.14962540566921234, 0.1284784972667694, 0.1284784972667694, 0.46135827898979187], [0.0797148197889328, 0.6600298881530762, 0.0797148197889328, 0.17085376381874084, 0.009686695411801338], [0.39317458868026733, 0.23582975566387177, 0.016872871667146683, 0.11829303205013275, 0.23582975566387177], [0.11591751128435135, 0.0015412986977025867, 0.7458009719848633, 0.13519896566867828, 0.0015412986977025867], [0.0038461724761873484, 0.12081724405288696, 0.0038461724761873484, 0.8322831988334656, 0.039207179099321365], [0.3936997354030609, 0.14965026080608368, 0.006853363011032343, 0.3936997354030609, 0.056096989661455154], [0.051852013915777206, 0.0008040037355385721, 0.9437617063522339, 0.0017911770846694708, 0.0017911770846694708], [0.6539599299430847, 0.04132295027375221, 0.14390970766544342, 0.14390970766544342, 0.016897697001695633], [0.8493956923484802, 0.005211383104324341, 0.005211383104324341, 0.023533040657639503, 0.11664853245019913], [0.003403924172744155, 0.45204615592956543, 0.08919181674718857, 0.003311943029984832, 0.45204615592956543], [0.14247186481952667, 0.14247186481952667, 0.17622707784175873, 0.3678482174873352, 0.17098090052604675], [0.2511475384235382, 0.2511475384235382, 0.36328020691871643, 0.06270246207714081, 0.07172228395938873], [0.1904834359884262, 0.17135415971279144, 0.31673797965049744, 0.004686450120061636, 0.31673797965049744], [0.34335121512413025, 0.4410702884197235, 0.020202692598104477, 0.17517320811748505, 0.020202692598104477], [0.3126868009567261, 0.12362072616815567, 0.02440776862204075, 0.12362072616815567, 0.4156639575958252], [0.2805727422237396, 0.10534556955099106, 0.10534556955099106, 0.24434290826320648, 0.26439324021339417], [0.009012417867779732, 0.2896232604980469, 0.3487173020839691, 0.003929684404283762, 0.3487173020839691], [0.009719541296362877, 0.2586129903793335, 0.03911232203245163, 0.682835578918457, 0.009719541296362877], [0.006928110960870981, 0.0002582344750408083, 0.0002582344750408083, 0.9638518691062927, 0.028703639283776283], [0.01252683624625206, 0.34304431080818176, 0.34304431080818176, 0.019067665562033653, 0.28231683373451233], [0.36711838841438293, 0.30462515354156494, 0.30462515354156494, 0.013525830581784248, 0.010105518624186516], [0.0043708328157663345, 0.044462330639362335, 0.03973289206624031, 0.45571696758270264, 0.45571696758270264], [0.028602058067917824, 0.7847865223884583, 0.05672796815633774, 0.05672796815633774, 0.07315551489591599], [0.015323298051953316, 0.32493528723716736, 0.25167250633239746, 0.32493528723716736, 0.08313361555337906], [0.06906305253505707, 0.06906305253505707, 0.0024516847915947437, 0.013471613638103008, 0.845950722694397], [0.05505847558379173, 0.2576669454574585, 0.34331393241882324, 0.34331393241882324, 0.0006467323983088136], [0.0018114300910383463, 0.023281164467334747, 0.8755507469177246, 0.07607552409172058, 0.023281164467334747], [0.8080694675445557, 0.044832319021224976, 0.06836298853158951, 0.06836298853158951, 0.010372299700975418], [0.005887881387025118, 0.3660186231136322, 0.005887881387025118, 0.2730560004711151, 0.3491496443748474], [0.2523546516895294, 0.2523546516895294, 0.012439165264368057, 0.17235863208770752, 0.3104929029941559], [0.1213591992855072, 0.5392320156097412, 0.1646611988544464, 0.1646611988544464, 0.010086414404213428], [0.013327212072908878, 0.40780723094940186, 0.14134357869625092, 0.40780723094940186, 0.02971474826335907], [0.003281339770182967, 0.03988834470510483, 0.46179017424583435, 0.003281339770182967, 0.4917588233947754], [0.2243811935186386, 0.01708483137190342, 0.2243811935186386, 0.21852467954158783, 0.31562814116477966], [0.054015208035707474, 0.12467888742685318, 0.12467888742685318, 0.694221556186676, 0.0024054506793618202], [0.6904640197753906, 0.18838821351528168, 0.050868622958660126, 0.050868622958660126, 0.019410550594329834], [4.2281229980289936e-05, 0.16016492247581482, 0.05249987170100212, 0.7872506976127625, 4.2281229980289936e-05], [0.6476553082466125, 0.05696176365017891, 0.08645591884851456, 0.12247109413146973, 0.08645591884851456], [0.0016791227972134948, 0.1333455592393875, 0.0871531218290329, 0.6444767117500305, 0.1333455592393875], [0.08352594077587128, 0.0240109134465456, 0.7359957695007324, 0.13245652616024017, 0.0240109134465456], [6.448725616792217e-05, 0.001005110563710332, 0.0035487806890159845, 0.04852832481265068, 0.9468533992767334], [0.008719608187675476, 0.3313550651073456, 0.3046540915966034, 0.023916199803352356, 0.3313550651073456], [0.033238183706998825, 0.045808713883161545, 0.07488404959440231, 0.8002603054046631, 0.045808713883161545], [0.35617876052856445, 0.19052861630916595, 0.12032393366098404, 0.14244012534618378, 0.19052861630916595], [6.901029701111838e-05, 0.49237945675849915, 6.901029701111838e-05, 0.435218870639801, 0.07226358354091644], [0.6410197615623474, 0.0002834024780895561, 0.0002834024780895561, 0.08891191333532333, 0.26950153708457947], [0.49019762873649597, 0.41872110962867737, 0.07661418616771698, 0.00723355682566762, 0.00723355682566762], [0.3823789358139038, 6.91289606038481e-05, 0.3823789358139038, 0.012910404242575169, 0.22226260602474213], [0.04716099426150322, 0.41379496455192566, 0.4469827711582184, 0.04490027204155922, 0.04716099426150322], [0.994418740272522, 0.004500299226492643, 0.0004921306972391903, 0.0004921306972391903, 9.678237984189764e-05], [0.022242803126573563, 0.0009759831009432673, 0.08035908639431, 0.8160631060600281, 0.08035908639431], [0.4656067192554474, 0.02403973788022995, 0.04424315690994263, 0.0005036881775595248, 0.4656067192554474], [0.08098594099283218, 0.16038131713867188, 0.023969784379005432, 0.0018307531718164682, 0.7328322529792786], [0.001845931401476264, 0.4928346276283264, 0.0005790649447590113, 0.4928346276283264, 0.011905733495950699], [5.472897828440182e-05, 0.0005770103307440877, 0.0028342013247311115, 5.472897828440182e-05, 0.996479332447052], [0.184689000248909, 0.32454851269721985, 0.24512001872062683, 0.0005224840715527534, 0.24512001872062683], [0.13251173496246338, 0.17045840620994568, 0.17045840620994568, 0.2783006727695465, 0.24827075004577637], [0.11130544543266296, 0.11130544543266296, 0.19644060730934143, 0.13200156390666962, 0.44894686341285706], [0.28788095712661743, 0.6032088398933411, 0.016289450228214264, 0.016289450228214264, 0.07633131742477417], [0.31115248799324036, 0.042714376002550125, 0.3262665867805481, 0.31115248799324036, 0.008714092895388603], [0.08621001243591309, 0.02506803348660469, 0.7895702719688416, 0.012941610999405384, 0.08621001243591309], [0.008075403049588203, 0.7925919890403748, 0.007428292650729418, 0.1838289350271225, 0.008075403049588203], [0.35697871446609497, 0.35697871446609497, 0.22716987133026123, 0.0572424978017807, 0.0016301404684782028], [0.11295952647924423, 0.0017563285073265433, 0.041359495371580124, 0.0021197327878326178, 0.8418049216270447], [0.21085576713085175, 0.570728600025177, 0.21085576713085175, 0.005396740976721048, 0.002163067227229476], [0.0006026235059835017, 0.42998552322387695, 0.11304087191820145, 0.02638540230691433, 0.42998552322387695], [0.11794212460517883, 0.06931868940591812, 0.6869134902954102, 0.00788354966789484, 0.11794212460517883], [0.3338785171508789, 0.32178637385368347, 0.010233051143586636, 0.3338785171508789, 0.0002235743886558339], [0.5686686635017395, 0.13028772175312042, 0.06981091946363449, 0.0813254863023758, 0.1499072015285492], [0.3963622748851776, 0.08205960690975189, 0.036284107714891434, 0.3963622748851776, 0.08893177658319473], [0.015988407656550407, 0.955933690071106, 0.004309519659727812, 0.007779906038194895, 0.015988407656550407], [0.01990329660475254, 0.03230064734816551, 0.7444257140159607, 0.10168518126010895, 0.10168518126010895], [0.695275068283081, 0.0502491295337677, 0.1885867863893509, 0.0502491295337677, 0.015639927238225937], [0.11051890254020691, 0.2859264016151428, 0.39858853816986084, 0.09444721788167953, 0.11051890254020691], [0.3388284742832184, 0.17269267141819, 0.10702712833881378, 0.3388284742832184, 0.042623307555913925], [0.06400680541992188, 0.901083767414093, 0.002605228219181299, 0.029698938131332397, 0.002605228219181299], [0.0013703049626201391, 0.0013703049626201391, 0.44781622290611267, 0.28473082184791565, 0.2647123336791992], [0.08727526664733887, 0.37142378091812134, 0.14687888324260712, 0.37142378091812134, 0.02299829013645649], [0.020557167008519173, 0.21615828573703766, 0.2311684638261795, 0.3159577548503876, 0.21615828573703766], [0.1483188420534134, 0.4021037518978119, 0.003906374331563711, 0.4021037518978119, 0.04356731101870537], [0.34111225605010986, 0.07941833138465881, 0.5108289122581482, 0.03432023897767067, 0.03432023897767067], [0.0942879244685173, 0.2680673599243164, 0.02276555448770523, 0.5921135544776917, 0.02276555448770523], [0.006025881506502628, 0.008105289191007614, 0.006025881506502628, 0.15592177212238312, 0.8239213228225708], [0.23800143599510193, 0.4604703187942505, 0.06184253469109535, 0.0016842707991600037, 0.23800143599510193], [0.28035768866539, 0.18688124418258667, 0.1695554554462433, 0.08284790813922882, 0.28035768866539], [0.5621758699417114, 0.1147673949599266, 0.1147673949599266, 0.19230182468891144, 0.01598755270242691], [0.05532044917345047, 0.2650682032108307, 0.1627127230167389, 0.2518303692340851, 0.2650682032108307], [0.07744430005550385, 0.10187771916389465, 0.6780024170875549, 0.04079783335328102, 0.10187771916389465], [0.029254507273435593, 0.015952149406075478, 0.26752933859825134, 0.4197346270084381, 0.26752933859825134], [0.26202332973480225, 0.37300240993499756, 0.0087668988853693, 0.1985059380531311, 0.15770135819911957], [0.26746752858161926, 0.31768420338630676, 0.20585115253925323, 0.20585115253925323, 0.003145923838019371], [0.7515139579772949, 0.07767760008573532, 0.04397118091583252, 0.06341864168643951, 0.06341864168643951], [0.2942441999912262, 0.0016345612239092588, 0.6875970959663391, 0.0082620894536376, 0.0082620894536376], [0.12230654805898666, 0.04867594689130783, 0.4135727286338806, 0.4135727286338806, 0.0018720801454037428], [0.6323692202568054, 0.025468606501817703, 0.025468606501817703, 0.0006514693959616125, 0.31604212522506714], [0.05399048328399658, 0.03573424741625786, 0.07028099149465561, 0.7803041934967041, 0.059690024703741074], [0.1677759289741516, 4.066178735229187e-05, 4.066178735229187e-05, 0.8320739269256592, 6.884457980049774e-05], [0.0052934992127120495, 0.3763446509838104, 0.0052934992127120495, 0.554797887802124, 0.05827045813202858], [0.5688378810882568, 0.1918504685163498, 0.0006893202662467957, 0.04677183926105499, 0.1918504685163498], [0.38912510871887207, 0.053775835782289505, 0.15228696167469025, 0.38912510871887207, 0.015687040984630585], [0.0007331665838137269, 0.005733591970056295, 0.09662117063999176, 0.4484560489654541, 0.4484560489654541], [0.0140189528465271, 0.6694800853729248, 0.2656298577785492, 0.03685221076011658, 0.0140189528465271], [0.06330540031194687, 0.008112798444926739, 0.06330540031194687, 0.33348169922828674, 0.5317946672439575], [0.298004150390625, 0.04076489806175232, 0.298004150390625, 0.3211221396923065, 0.042104609310626984], [0.499653697013855, 0.000388587563065812, 7.922318218334112e-06, 0.499653697013855, 0.0002960971323773265], [0.005054824519902468, 0.032934028655290604, 0.1316288858652115, 0.032934028655290604, 0.7974482774734497], [0.03535674884915352, 0.21313579380512238, 0.3644023835659027, 0.02270263433456421, 0.3644023835659027], [0.4935111701488495, 0.4935111701488495, 0.0004935390898026526, 0.012091347016394138, 0.0003927490906789899], [0.01895417645573616, 0.09486207365989685, 0.005899796728044748, 0.01895417645573616, 0.8613297939300537], [0.11007390916347504, 0.3981380760669708, 0.0005174049874767661, 0.0005174049874767661, 0.4907532334327698], [0.09263718873262405, 0.5859822034835815, 0.038423165678977966, 0.24453425407409668, 0.038423165678977966], [0.04151388257741928, 0.7867681980133057, 0.04151388257741928, 0.11375194042921066, 0.016452087089419365], [0.10887150466442108, 0.10887150466442108, 0.05500379204750061, 0.6585464477539062, 0.06870678067207336], [0.567838191986084, 0.045900966972112656, 0.045900966972112656, 0.010340412147343159, 0.33001944422721863], [0.12776635587215424, 0.2853182554244995, 0.576904296875, 0.005005538929253817, 0.005005538929253817], [0.041023872792720795, 0.8931502103805542, 0.041023872792720795, 0.019534919410943985, 0.005267126951366663], [0.008752481080591679, 0.6020158529281616, 0.062059108167886734, 0.2651135325431824, 0.062059108167886734], [0.004043906927108765, 0.002397997537627816, 0.2846156656742096, 0.44405031204223633, 0.26489201188087463], [0.4355226159095764, 0.05060970410704613, 0.5035693049430847, 0.0051491656340658665, 0.0051491656340658665], [0.009700723923742771, 0.0018014783272519708, 0.19017595052719116, 0.7886211276054382, 0.009700723923742771], [0.03918598219752312, 0.035607632249593735, 0.46222734451293945, 0.23148952424526215, 0.23148952424526215], [0.025993380695581436, 0.0012290900340303779, 0.013403009623289108, 0.47968727350234985, 0.47968727350234985], [0.7420203685760498, 0.10322936624288559, 0.07707000523805618, 0.07707000523805618, 0.0006102932966314256], [0.015127557329833508, 0.03710682690143585, 0.06415003538131714, 0.868488073348999, 0.015127557329833508], [0.010525674559175968, 0.33916908502578735, 0.33916908502578735, 0.3068980276584625, 0.004238085355609655], [0.11487501114606857, 0.038412805646657944, 0.16219450533390045, 0.5223231911659241, 0.16219450533390045], [0.011834911070764065, 0.004650250542908907, 0.002710432279855013, 0.22084562480449677, 0.7599587440490723], [0.0011319072218611836, 0.02225450985133648, 0.28738006949424744, 0.34461674094200134, 0.34461674094200134], [0.02694661356508732, 0.11542335152626038, 0.02694661356508732, 0.23239348828792572, 0.5982898473739624], [0.30014756321907043, 0.19554503262043, 0.004111903719604015, 0.25009775161743164, 0.25009775161743164], [0.7584437727928162, 0.01236377190798521, 0.07920299470424652, 0.01236377190798521, 0.13762572407722473], [0.354127436876297, 0.007908944971859455, 0.2665988802909851, 0.354127436876297, 0.0172373428940773], [0.09088010340929031, 0.09088010340929031, 0.4922037124633789, 0.16611818969249725, 0.159917950630188], [0.1857750415802002, 0.16797810792922974, 0.013063129968941212, 0.4652056097984314, 0.16797810792922974], [0.16200445592403412, 0.26852142810821533, 0.2989060878753662, 0.0020466046407818794, 0.26852142810821533], [0.00697820819914341, 0.00697820819914341, 0.6324187517166138, 0.017918149009346962, 0.3357067406177521], [0.013638169504702091, 0.05078417807817459, 0.5038191080093384, 0.05078417807817459, 0.38097435235977173], [0.16309069097042084, 0.014842597767710686, 0.8134938478469849, 0.0026448399294167757, 0.005928046070039272], [0.21410323679447174, 0.1405840665102005, 0.502092182636261, 0.002636453602463007, 0.1405840665102005], [0.20754927396774292, 0.06553788483142853, 0.04066624492406845, 0.6455803513526917, 0.04066624492406845], [0.12607209384441376, 0.12607209384441376, 0.43833425641059875, 0.10355623811483383, 0.2059653103351593], [0.12209486216306686, 0.2938883900642395, 0.29090505838394165, 0.0022065509110689163, 0.29090505838394165], [0.013402474112808704, 0.01770102232694626, 0.7207180857658386, 0.12408921122550964, 0.12408921122550964], [0.1062462106347084, 0.362348347902298, 0.2979544997215271, 0.12720462679862976, 0.1062462106347084], [0.01235160417854786, 0.05159711837768555, 0.01003523450344801, 0.46300795674324036, 0.46300795674324036], [0.08432796597480774, 0.23033715784549713, 0.08432796597480774, 0.1556207686662674, 0.4453860819339752], [0.3420546352863312, 0.30966678261756897, 0.0029053783509880304, 0.3420546352863312, 0.003318590810522437], [0.0009503497276455164, 0.0009503497276455164, 0.03660145774483681, 0.7612690329551697, 0.200228750705719], [0.028305258601903915, 0.08097691088914871, 0.006484166253358126, 0.8032567501068115, 0.08097691088914871], [0.0080837057903409, 0.6120743751525879, 0.1739347279071808, 0.1739347279071808, 0.03197242319583893], [0.00638360483571887, 0.18965566158294678, 0.8038049936294556, 7.78558969614096e-05, 7.78558969614096e-05], [0.0883074700832367, 0.717315673828125, 0.036868274211883545, 0.07875427603721619, 0.07875427603721619], [0.07341623306274414, 0.7788698077201843, 0.07341623306274414, 0.017579277977347374, 0.05671844631433487], [0.11710816621780396, 0.02449675090610981, 0.42566192150115967, 0.007071186322718859, 0.42566192150115967], [0.011686685495078564, 0.021642295643687248, 0.7368065118789673, 0.0021754279732704163, 0.2276890128850937], [0.0031724523287266493, 5.346200487110764e-05, 0.47771626710891724, 0.5190044045448303, 5.346200487110764e-05], [0.018914498388767242, 0.2710418403148651, 0.012985983863472939, 0.42601579427719116, 0.2710418403148651], [0.28174084424972534, 0.059470757842063904, 0.2736456096172333, 0.059470757842063904, 0.3256720304489136], [0.008915641345083714, 0.055567141622304916, 0.5095000863075256, 0.41710150241851807, 0.008915641345083714], [0.7457475066184998, 0.01605799049139023, 0.20009636878967285, 0.02204015478491783, 0.01605799049139023], [0.010485026985406876, 0.4648304283618927, 0.01912650093436241, 0.4648304283618927, 0.0407276451587677], [0.027036627754569054, 0.03600550442934036, 0.4421442449092865, 0.24740681052207947, 0.24740681052207947], [0.0006007957272231579, 0.045812830328941345, 0.045812830328941345, 0.4171617329120636, 0.4906117916107178], [0.3262905180454254, 0.04210919141769409, 0.061672043055295944, 0.3262905180454254, 0.24363775551319122], [0.20943999290466309, 0.08647534251213074, 0.20943999290466309, 0.4305607080459595, 0.06408394873142242], [0.3037315011024475, 0.015171697363257408, 0.05947573482990265, 0.05947573482990265, 0.5621453523635864], [0.0015278980135917664, 0.10548822581768036, 0.7078566551208496, 0.07963896542787552, 0.10548822581768036], [0.002589636715129018, 0.002589636715129018, 0.12524989247322083, 0.12012803554534912, 0.7494428157806396], [0.37704402208328247, 0.001843704143539071, 0.37704402208328247, 0.10366008430719376, 0.14040817320346832], [0.04094374552369118, 0.13495099544525146, 0.16629618406295776, 0.49151286482810974, 0.16629618406295776], [0.15494388341903687, 0.27123120427131653, 0.0032718321308493614, 0.4156091511249542, 0.15494388341903687], [0.16370126605033875, 0.014688762836158276, 0.2069936841726303, 0.4076225459575653, 0.2069936841726303], [0.003033204236999154, 0.020447056740522385, 0.4974379241466522, 0.4586348235607147, 0.020447056740522385], [7.194495992735028e-05, 0.09495559334754944, 0.4324682056903839, 0.4324682056903839, 0.04003611207008362], [0.4680393934249878, 0.009614846669137478, 0.49706417322158813, 0.01566677913069725, 0.009614846669137478], [0.0948619470000267, 0.00032350531546399, 0.3176176846027374, 0.2695792615413666, 0.3176176846027374], [0.04054153710603714, 0.02393055148422718, 0.6375980973243713, 0.04054153710603714, 0.25738823413848877], [0.43698909878730774, 0.0043953340500593185, 0.002051623072475195, 0.11957483738660812, 0.43698909878730774], [0.2342105656862259, 0.3562339246273041, 0.051499780267477036, 0.3562339246273041, 0.001821755664423108], [0.013260879553854465, 0.03767168149352074, 0.07543016970157623, 0.8603764176368713, 0.013260879553854465], [0.24410884082317352, 0.11376722157001495, 0.24410884082317352, 0.3281288146972656, 0.06988626718521118], [0.44040074944496155, 0.08669519424438477, 0.44040074944496155, 0.014345365576446056, 0.01815790683031082], [0.005631164647638798, 0.47026121616363525, 0.04143170639872551, 0.47026121616363525, 0.012414691969752312], [0.13840363919734955, 0.04732757434248924, 0.4000650942325592, 0.4000650942325592, 0.014138532802462578], [0.6690544486045837, 0.000793434854131192, 0.15977595746517181, 0.010600191541016102, 0.15977595746517181], [0.2708996832370758, 0.2708996832370758, 0.26733702421188354, 0.1663772612810135, 0.024486353620886803], [0.04093771055340767, 0.7884439826011658, 0.04093771055340767, 0.05007476359605789, 0.07960579544305801], [0.0510905422270298, 0.0510905422270298, 0.025794310495257378, 0.8074671030044556, 0.06455746293067932], [0.49792641401290894, 0.001475263386964798, 0.13857460021972656, 0.22344912588596344, 0.13857460021972656], [0.5160613656044006, 0.4298330545425415, 0.0043975492008030415, 0.0043975492008030415, 0.045310501009225845], [0.008136969059705734, 0.2287408411502838, 0.3744019865989685, 0.15997937321662903, 0.2287408411502838], [0.003881353186443448, 0.0941077247262001, 0.003881353186443448, 0.10031561553478241, 0.7978140711784363], [0.07709072530269623, 0.7266663908958435, 0.07709072530269623, 0.004236477427184582, 0.11491565406322479], [0.02236461639404297, 0.053873106837272644, 0.150860995054245, 0.3864506185054779, 0.3864506185054779], [0.1446799486875534, 0.5277389883995056, 0.01992492564022541, 0.1446799486875534, 0.16297614574432373], [0.11197125166654587, 0.07416323572397232, 0.5509607195854187, 0.188741534948349, 0.07416323572397232], [0.2702958881855011, 0.2702958881855011, 0.03303403779864311, 0.42173847556114197, 0.004635666962713003], [0.053099315613508224, 0.2513143718242645, 0.17016996443271637, 0.3552463948726654, 0.17016996443271637], [0.0033453714568167925, 0.2583463490009308, 0.42993006110191345, 0.0500318668782711, 0.2583463490009308], [0.027258791029453278, 0.027258791029453278, 0.07740048319101334, 0.01409154012799263, 0.853990375995636], [0.007061617448925972, 0.009365379810333252, 0.007061617448925972, 0.9671630859375, 0.0093482481315732], [0.28755810856819153, 0.19809426367282867, 0.024937855079770088, 0.024937855079770088, 0.46447187662124634], [0.42005154490470886, 0.0028330273926258087, 0.42005154490470886, 0.1569916009902954, 7.223857392091304e-05], [0.004440636374056339, 0.48296335339546204, 0.48296335339546204, 0.0009463287424296141, 0.028686340898275375], [0.0006655097822658718, 0.2741509675979614, 0.006976757664233446, 0.5264168977737427, 0.19178986549377441], [0.004081317223608494, 0.033255673944950104, 0.11864253878593445, 0.7253779172897339, 0.11864253878593445], [0.20562659204006195, 0.012104148045182228, 0.20562659204006195, 0.039669401943683624, 0.536973237991333], [0.0005513515206985176, 4.228211400914006e-05, 0.37174585461616516, 0.002988249994814396, 0.6246722936630249], [0.20327576994895935, 0.009791444055736065, 0.46155139803886414, 0.05289381742477417, 0.2724876403808594], [0.0003272234171163291, 0.5476296544075012, 0.4478663206100464, 0.0003272234171163291, 0.003849632339552045], [0.07034578919410706, 0.00106709823012352, 0.07034578919410706, 0.08414095640182495, 0.7741004228591919], [0.15713822841644287, 0.006092675030231476, 0.39514607191085815, 0.04647701978683472, 0.39514607191085815], [0.529995322227478, 0.0019338327692821622, 0.2012568563222885, 0.2012568563222885, 0.06555710732936859], [0.10939104855060577, 0.08359207957983017, 0.08359207957983017, 0.43807733058929443, 0.28534746170043945], [0.003161420114338398, 0.05779462680220604, 0.05779462680220604, 0.12883295118808746, 0.7524164319038391], [0.4216481149196625, 0.019287558272480965, 0.03948882594704628, 0.09792743623256683, 0.4216481149196625], [0.20223216712474823, 0.3368402123451233, 0.20223216712474823, 0.013797296211123466, 0.24489817023277283], [0.2175980806350708, 0.10914088785648346, 0.33597174286842346, 0.33597174286842346, 0.0013175348285585642], [0.058325622230768204, 0.4352925419807434, 0.05237458273768425, 0.4352925419807434, 0.018714718520641327], [0.348691463470459, 0.0027498442213982344, 0.348691463470459, 0.2067405730485916, 0.09312663972377777], [0.00021270180877763778, 0.00021270180877763778, 0.06074698641896248, 0.9351310729980469, 0.0036965804174542427], [0.3617188632488251, 0.3617188632488251, 0.2057851403951645, 0.042996861040592194, 0.027780259028077126], [0.051591500639915466, 0.0574507899582386, 0.0947684496641159, 0.7445977926254272, 0.051591500639915466], [0.46247920393943787, 0.46247920393943787, 0.005777330603450537, 0.02588951401412487, 0.043374743312597275], [0.045212943106889725, 0.683072030544281, 0.23569710552692413, 0.01800895854830742, 0.01800895854830742], [0.005220182240009308, 0.11185228079557419, 0.147544726729393, 0.2933942675590515, 0.4419885575771332], [0.01059375237673521, 0.006342523731291294, 0.006342523731291294, 0.9624629020690918, 0.014258306473493576], [0.5496857762336731, 0.09169209748506546, 0.24228449165821075, 0.09169209748506546, 0.02464558742940426], [0.0006191468564793468, 0.44998449087142944, 0.04061284288764, 0.44998449087142944, 0.058799006044864655], [0.005102823488414288, 0.3273888826370239, 0.005102823488414288, 0.0010352734243497252, 0.6613701581954956], [0.002940875245258212, 0.001466807210817933, 0.009651383385062218, 0.5935456156730652, 0.39239534735679626], [0.15411248803138733, 0.010588294826447964, 0.05027782917022705, 0.010588294826447964, 0.7744331359863281], [0.21592551469802856, 0.009195601567626, 0.07227238267660141, 0.6303341388702393, 0.07227238267660141], [0.36690399050712585, 0.36690399050712585, 0.07012539356946945, 0.013982102274894714, 0.18208448588848114], [0.0670279711484909, 0.0758601576089859, 0.6813920736312866, 0.0758601576089859, 0.09985964000225067], [0.05847175419330597, 0.002150903223082423, 0.46500957012176514, 0.009358187206089497, 0.46500957012176514], [0.6038124561309814, 0.010762661695480347, 0.3172302544116974, 0.05743192508816719, 0.010762661695480347], [0.45511648058891296, 0.14920160174369812, 0.18920987844467163, 0.01726216822862625, 0.18920987844467163], [0.24177733063697815, 0.05958380177617073, 0.009611520916223526, 0.05958380177617073, 0.6294435262680054], [0.11099487543106079, 0.11099487543106079, 0.00026537259691394866, 0.7731338739395142, 0.004610917065292597], [0.05457140505313873, 0.05457140505313873, 0.1417124718427658, 0.7299672961235046, 0.019177459180355072], [0.9287965297698975, 0.0020456453785300255, 0.0020456453785300255, 0.06092438846826553, 0.006187743507325649], [0.04526307061314583, 0.000456405890872702, 0.000456405890872702, 0.01975085586309433, 0.9340732097625732], [0.28298085927963257, 0.3002098500728607, 0.11397131532430649, 0.0026280961465090513, 0.3002098500728607], [0.003057591849938035, 0.0015644063241779804, 0.5025209784507751, 0.02020087279379368, 0.47265613079071045], [0.0097814267501235, 0.7307355403900146, 0.020175984129309654, 0.020175984129309654, 0.21913108229637146], [0.16806749999523163, 0.5283966660499573, 0.11695287376642227, 0.16806749999523163, 0.018515530973672867], [0.0014044318813830614, 0.9945929646492004, 0.0007757170242257416, 0.0024512512609362602, 0.0007757170242257416], [0.0018241332145407796, 0.45412442088127136, 0.45412442088127136, 0.006504460703581572, 0.08342257887125015], [0.011679630726575851, 0.10434421896934509, 0.16487066447734833, 0.16487066447734833, 0.5542348027229309], [0.41678473353385925, 0.41678473353385925, 0.07872770726680756, 0.08256008476018906, 0.005142762791365385], [0.006101197563111782, 0.4534401297569275, 0.3115387558937073, 0.006101197563111782, 0.22281865775585175], [0.027568502351641655, 0.027568502351641655, 0.0035281286109238863, 0.37076786160469055, 0.5705670714378357], [0.014697607606649399, 0.014697607606649399, 0.6654320359230042, 0.04279318451881409, 0.26237952709198], [0.966840386390686, 0.0014297362649813294, 0.0014297362649813294, 0.00409358274191618, 0.026206573471426964], [0.2103702276945114, 0.017094986513257027, 0.37001287937164307, 0.37001287937164307, 0.032509054988622665], [0.013192069716751575, 0.4688543975353241, 0.04081505537033081, 0.0082840071991086, 0.4688543975353241], [0.3745756149291992, 0.11549872159957886, 0.013513610698282719, 0.2482060194015503, 0.2482060194015503], [0.0037399984430521727, 0.31292495131492615, 0.0037399984430521727, 0.460673063993454, 0.21892201900482178], [0.2863403558731079, 0.2863403558731079, 0.3965071439743042, 0.02357538416981697, 0.007236817851662636], [0.07505837082862854, 0.2580912113189697, 0.23663875460624695, 0.2580912113189697, 0.17212043702602386], [0.07741936296224594, 0.09139969944953918, 0.3849228322505951, 0.06133531779050827, 0.3849228322505951], [0.0022845964413136244, 0.42925316095352173, 0.42925316095352173, 0.05929099768400192, 0.07991807907819748], [0.21898435056209564, 0.15453138947486877, 0.2837015688419342, 0.188251331448555, 0.15453138947486877], [0.0379716195166111, 0.24855105578899384, 0.6559435725212097, 0.0195621345192194, 0.0379716195166111], [0.2234729677438736, 0.011185307055711746, 0.7175242900848389, 0.011185307055711746, 0.03663216158747673], [0.35442930459976196, 0.05711571127176285, 0.07275812327861786, 0.4429387152194977, 0.07275812327861786], [0.3497547209262848, 0.11645668745040894, 0.17539529502391815, 0.3497547209262848, 0.008638566359877586], [0.21302767097949982, 0.08981987833976746, 0.3506883978843689, 0.25664418935775757, 0.08981987833976746], [0.16022317111492157, 0.16022317111492157, 0.08750040084123611, 0.02348441071808338, 0.5685688853263855], [0.18657708168029785, 0.040659502148628235, 0.040659502148628235, 0.3598349392414093, 0.372268944978714], [0.4335317313671112, 0.49844998121261597, 0.00018646054377313703, 0.03391590341925621, 0.03391590341925621], [0.010137293487787247, 0.039038948714733124, 0.6254823207855225, 0.039038948714733124, 0.28630244731903076], [0.0006430731154978275, 0.028902990743517876, 0.028902990743517876, 0.09270617365837097, 0.8488448262214661], [0.0932283103466034, 0.0932283103466034, 0.590338408946991, 0.10425561666488647, 0.11894930154085159], [0.3238184452056885, 0.3238184452056885, 0.0573621541261673, 0.08899760246276855, 0.2060033529996872], [0.0028717981185764074, 0.3178194761276245, 0.005051081068813801, 0.33712881803512573, 0.33712881803512573], [0.2569589912891388, 0.35928991436958313, 0.002058702753856778, 0.02240249700844288, 0.35928991436958313], [0.2514224648475647, 0.42598697543144226, 0.044089630246162415, 0.23441128432750702, 0.044089630246162415], [0.33121126890182495, 0.06818708032369614, 0.4071964621543884, 0.12521812319755554, 0.06818708032369614], [0.39447638392448425, 0.16153191030025482, 0.012800807133316994, 0.036714524030685425, 0.39447638392448425], [0.9049370288848877, 0.0026387106627225876, 0.0018894595559686422, 0.0011156074469909072, 0.08941920846700668], [0.27788347005844116, 0.03387242555618286, 0.27788347005844116, 0.001472036587074399, 0.4088885486125946], [0.9322087168693542, 0.018176021054387093, 0.008892407640814781, 0.0225467998534441, 0.018176021054387093], [0.3496377468109131, 0.25385329127311707, 0.027772488072514534, 0.3496377468109131, 0.019098808988928795], [0.32907184958457947, 0.03110341727733612, 0.03110341727733612, 0.20497159659862518, 0.4037497341632843], [0.266110897064209, 0.379086971282959, 0.12421339005231857, 0.10637536644935608, 0.12421339005231857], [0.6816169619560242, 0.1910003274679184, 0.03874499723315239, 0.04989270493388176, 0.03874499723315239], [0.0002884450077544898, 0.05643651261925697, 0.05643651261925697, 0.009425731375813484, 0.877412736415863], [0.22538892924785614, 0.5512511730194092, 0.015503458678722382, 0.19233089685440063, 0.01552554126828909], [0.028694869950413704, 0.25193727016448975, 0.002987787825986743, 0.7133923172950745, 0.002987787825986743], [0.8461176753044128, 0.09653539955615997, 0.0006575355073437095, 0.0006575355073437095, 0.056031838059425354], [0.008980362676084042, 0.4821930229663849, 0.4821930229663849, 0.00043713138438761234, 0.02619647979736328], [0.10896410793066025, 0.014442626386880875, 0.15540176630020142, 0.6122273206710815, 0.10896410793066025], [0.28043708205223083, 0.02430618181824684, 0.28043708205223083, 0.2544950842857361, 0.16032464802265167], [0.2886344790458679, 0.00019764332682825625, 0.20273052155971527, 0.30570682883262634, 0.20273052155971527], [0.6806275248527527, 0.04302401468157768, 0.04302401468157768, 0.22694379091262817, 0.006380633916705847], [0.032044053077697754, 0.32162269949913025, 0.007911779917776585, 0.3192107379436493, 0.3192107379436493], [0.008769254200160503, 0.00031722671701572835, 0.9150618314743042, 0.067082479596138, 0.008769254200160503], [0.3558688759803772, 0.013696575537323952, 0.008813058957457542, 0.31081074476242065, 0.31081074476242065], [0.33808913826942444, 0.04741494357585907, 0.19911110401153564, 0.21627368032932281, 0.19911110401153564], [0.055328793823719025, 0.055328793823719025, 0.1691093146800995, 0.7146926522254944, 0.005540499463677406], [0.056457798928022385, 0.03521467372775078, 0.03521467372775078, 0.5188061594963074, 0.3543066680431366], [0.16117531061172485, 0.009751250967383385, 0.2876439690589905, 0.25378549098968506, 0.2876439690589905], [0.8159783482551575, 0.08188793063163757, 0.08188793063163757, 0.0030323283281177282, 0.01721346378326416], [0.6663746237754822, 0.15955230593681335, 0.06606657803058624, 0.041939958930015564, 0.06606657803058624], [0.3209441006183624, 0.05236459895968437, 0.0453808419406414, 0.0453808419406414, 0.5359296202659607], [0.10837724804878235, 0.10837724804878235, 0.0004997108480893075, 0.7825232744216919, 0.000222565999138169], [0.4698568880558014, 0.08036604523658752, 0.08036604523658752, 0.11643032729625702, 0.2529807388782501], [0.45973336696624756, 0.4824749827384949, 0.036044325679540634, 0.00157311768271029, 0.020174236968159676], [0.009812263771891594, 0.1196073368191719, 0.5987226963043213, 0.15225037932395935, 0.1196073368191719], [0.30135732889175415, 0.012769421562552452, 0.08094228804111481, 0.3035736680030823, 0.30135732889175415], [0.014920253306627274, 0.32071852684020996, 0.13184872269630432, 0.32071852684020996, 0.21179398894309998], [0.21412286162376404, 0.21412286162376404, 0.4741799831390381, 0.07513335347175598, 0.022440999746322632], [0.030319705605506897, 0.030319705605506897, 0.06751393526792526, 0.004282910376787186, 0.8675637245178223], [0.26513293385505676, 0.1740231215953827, 0.2888931632041931, 0.006817868445068598, 0.26513293385505676], [0.297037810087204, 0.297037810087204, 0.0012594270519912243, 0.2561606168746948, 0.14850439131259918], [0.2073388248682022, 0.04310493916273117, 0.4170815646648407, 0.12513582408428192, 0.2073388248682022], [0.2705214321613312, 0.35502293705940247, 0.11549419909715652, 0.11549419909715652, 0.1434672623872757], [0.09973669797182083, 0.7862874865531921, 0.002727035665884614, 0.055624376982450485, 0.055624376982450485], [0.10640061646699905, 0.35458987951278687, 0.2600995898246765, 0.018810352310538292, 0.2600995898246765], [0.11119901388883591, 0.8298107981681824, 0.00017081908299587667, 0.00017081908299587667, 0.058648522943258286], [0.15797095000743866, 0.13822896778583527, 0.0131560442969203, 0.6774880290031433, 0.0131560442969203], [0.3635053038597107, 0.03028944879770279, 0.055565014481544495, 0.3635053038597107, 0.18713495135307312], [0.3215504586696625, 0.12078289687633514, 0.27296608686447144, 0.011734534054994583, 0.27296608686447144], [0.060042109340429306, 0.060042109340429306, 0.24217034876346588, 0.003669837024062872, 0.6340755820274353], [0.0981074795126915, 0.005173157900571823, 0.6785603761672974, 0.10907949507236481, 0.10907949507236481], [0.42728105187416077, 0.021070150658488274, 0.08559610694646835, 0.0387716069817543, 0.42728105187416077], [0.0027720415964722633, 0.0027720415964722633, 0.011263053864240646, 0.012830871157348156, 0.9703620076179504], [0.5687693953514099, 0.015307983383536339, 0.037075724452733994, 0.037075724452733994, 0.3417711555957794], [0.7991164326667786, 0.02773553691804409, 0.03514714166522026, 0.1102653443813324, 0.02773553691804409], [0.0532691515982151, 0.03937993571162224, 0.4410226047039032, 0.4410226047039032, 0.025305699557065964], [0.09681486338376999, 0.0006734709022566676, 0.15051589906215668, 0.09681486338376999, 0.6551808714866638], [0.19202928245067596, 0.20865027606487274, 0.23750077188014984, 0.23750077188014984, 0.12431890517473221], [0.027630619704723358, 0.3996806740760803, 0.5242690443992615, 0.04204602912068367, 0.006373566575348377], [0.006926677189767361, 0.008314394392073154, 0.9677188396453857, 0.008725660853087902, 0.008314394392073154], [0.8845825791358948, 0.03466535732150078, 0.015700891613960266, 0.030385799705982208, 0.03466535732150078], [0.07480689883232117, 0.03153156116604805, 0.4183851480484009, 0.07480689883232117, 0.4004695415496826], [0.47586947679519653, 0.01666572131216526, 0.030730951577425003, 0.47586947679519653, 0.0008643412729725242], [0.014453713782131672, 0.22432400286197662, 0.1316797137260437, 0.014453713782131672, 0.6150888800621033], [0.5769540071487427, 0.35296630859375, 0.002726125530898571, 0.002726125530898571, 0.06462744623422623], [0.00469135120511055, 0.00469135120511055, 0.041283585131168365, 0.8110629916191101, 0.138270765542984], [0.4506775438785553, 0.027626175433397293, 0.4506775438785553, 0.060146868228912354, 0.010871898382902145], [0.017034003511071205, 0.06142741069197655, 0.05277836322784424, 0.05277836322784424, 0.8159818649291992], [0.18116514384746552, 0.080531045794487, 0.0004225471056997776, 0.0004225471056997776, 0.7374587655067444], [0.0103475172072649, 0.4557831287384033, 0.2627120614051819, 0.2627120614051819, 0.008445135317742825], [0.0007687417091801763, 0.13225789368152618, 0.018679967150092125, 0.13225789368152618, 0.7160355448722839], [0.0009521298343315721, 0.03264564275741577, 0.00400770315900445, 0.03264564275741577, 0.9297488927841187], [0.004750101827085018, 0.10058759152889252, 0.09306956082582474, 0.40079638361930847, 0.40079638361930847], [0.61568683385849, 0.00399133050814271, 0.3356926739215851, 0.022314632311463356, 0.022314632311463356], [0.9117488265037537, 0.08375784754753113, 0.0011472172336652875, 0.0016730688512325287, 0.0016730688512325287], [0.4611647129058838, 0.015850020572543144, 0.005949964746832848, 0.05587068572640419, 0.4611647129058838], [0.00758163258433342, 0.004670680966228247, 0.004670680966228247, 0.3924115300178528, 0.5906654596328735], [0.006715926341712475, 0.009408406913280487, 0.013147816061973572, 0.013147816061973572, 0.957580029964447], [0.14826643466949463, 0.06017560511827469, 0.6338363289833069, 0.009455235674977303, 0.14826643466949463], [0.00033269310370087624, 0.45627450942993164, 0.45627450942993164, 0.08584152162075043, 0.0012767571024596691], [0.013511939905583858, 0.7725386023521423, 0.013511939905583858, 0.18384398519992828, 0.01659359596669674], [0.29967400431632996, 0.29967400431632996, 0.06921546906232834, 0.164884552359581, 0.16655193269252777], [0.01767158694565296, 0.40980064868927, 0.016510600224137306, 0.2780085802078247, 0.2780085802078247], [7.775301492074504e-05, 0.487783282995224, 0.022885674610733986, 0.0014701191103085876, 0.487783282995224], [0.06574704498052597, 0.06574704498052597, 0.6311137080192566, 0.21531574428081512, 0.02207651175558567], [0.03393005207180977, 0.4447842240333557, 0.024504302069544792, 0.4447842240333557, 0.05199720710515976], [0.5900661945343018, 0.0001634288637433201, 0.1590227633714676, 0.2505841553211212, 0.0001634288637433201], [0.9443454146385193, 0.020461486652493477, 0.005711707286536694, 0.005711707286536694, 0.023769672960042953], [0.1840619146823883, 0.2114899456501007, 0.06985204666852951, 0.32310616970062256, 0.2114899456501007], [0.016965826973319054, 0.012632363475859165, 0.40719926357269287, 0.15600331127643585, 0.40719926357269287], [0.5063621401786804, 0.09181220084428787, 0.3771902322769165, 0.012317693792283535, 0.012317693792283535], [0.18469031155109406, 0.612930178642273, 0.016443898901343346, 0.18469031155109406, 0.0012453001691028476], [0.021357545629143715, 0.20362256467342377, 0.25129052996635437, 0.27243882417678833, 0.25129052996635437], [0.06336946040391922, 0.0074996501207351685, 0.03459519147872925, 0.46641281247138977, 0.428122878074646], [0.011668440885841846, 0.47879287600517273, 0.14023883640766144, 0.011668440885841846, 0.3576314151287079], [0.02354205586016178, 0.0002154803805751726, 0.4737061858177185, 0.4737061858177185, 0.028830070048570633], [0.002444662619382143, 0.002444662619382143, 0.060080740600824356, 0.1291862577199936, 0.805843710899353], [0.42118504643440247, 0.008110284805297852, 0.42118504643440247, 0.03754955157637596, 0.11197008937597275], [0.3208836019039154, 0.025398213416337967, 0.0047917417250573635, 0.3208836019039154, 0.32804280519485474], [0.0018402212299406528, 0.4954093396663666, 0.005143758840858936, 0.4954093396663666, 0.002197360387071967], [0.001528914668597281, 0.12462057173252106, 0.7620982527732849, 0.001528914668597281, 0.11022339016199112], [0.003661256516352296, 0.003586266189813614, 0.9871921539306641, 0.003586266189813614, 0.001974028069525957], [0.7598778605461121, 0.03507300466299057, 0.03507300466299057, 0.1308966726064682, 0.03907947614789009], [0.0014683249173685908, 0.006215304601937532, 0.2407417893409729, 0.0014683249173685908, 0.7501062154769897], [0.0022146846167743206, 0.1157117709517479, 0.02290593460202217, 0.4295837879180908, 0.4295837879180908], [0.006892337463796139, 0.5619214773178101, 0.001244502724148333, 0.42304933071136475, 0.006892337463796139], [0.05889745429158211, 0.05889745429158211, 0.03820675611495972, 0.06607727706432343, 0.7779210805892944], [0.0006494575645774603, 0.6106680631637573, 0.3648337125778198, 0.010059595108032227, 0.013789159245789051], [0.7167426943778992, 0.13843373954296112, 0.006258305162191391, 0.00013150027371011674, 0.13843373954296112], [0.02301427163183689, 0.3696461021900177, 0.3696461021900177, 0.002120902994647622, 0.2355727106332779], [0.10524211823940277, 0.42758727073669434, 0.03169527277350426, 0.007888072170317173, 0.42758727073669434], [0.22642488777637482, 0.26177042722702026, 0.24221323430538177, 0.02737816423177719, 0.24221323430538177], [0.12726840376853943, 0.08862976729869843, 0.027053257450461388, 0.086972177028656, 0.6700763702392578], [0.08509833365678787, 0.07985354214906693, 0.17269448935985565, 0.577255368232727, 0.08509833365678787], [0.4080345928668976, 0.00531374104321003, 0.09144064038991928, 0.08717641979455948, 0.4080345928668976], [0.24265149235725403, 0.36967962980270386, 0.24265149235725403, 0.04019768908619881, 0.10481971502304077], [0.29106616973876953, 0.005436775740236044, 0.008727171458303928, 0.11147622019052505, 0.5832937359809875], [0.14212466776371002, 0.04424662888050079, 0.1460142880678177, 0.14437566697597504, 0.5232387185096741], [0.3329908847808838, 0.00854040589183569, 0.5179904103279114, 0.00854040589183569, 0.13193783164024353], [0.00016870941908564419, 0.14731094241142273, 0.0278681218624115, 0.0278681218624115, 0.7967840433120728], [0.2323368936777115, 0.356132835149765, 0.05461100488901138, 0.0007863917271606624, 0.356132835149765], [0.00011977332178503275, 0.5453614592552185, 0.44803163409233093, 0.00636737747117877, 0.00011977332178503275], [0.13194453716278076, 0.025876132771372795, 0.11838291585445404, 0.6979202628135681, 0.025876132771372795], [0.3278902769088745, 0.13443298637866974, 0.011661242693662643, 0.13443298637866974, 0.39158254861831665], [0.003568931482732296, 0.003568931482732296, 0.007054606452584267, 0.2622925937175751, 0.7235148549079895], [0.8103926181793213, 0.03107663430273533, 0.03107663430273533, 0.09821178764104843, 0.029242336750030518], [0.3656213879585266, 0.3656213879585266, 0.22754409909248352, 0.03949333354830742, 0.0017198148416355252], [0.009129995480179787, 0.17911918461322784, 0.5857597589492798, 0.046871915459632874, 0.17911918461322784], [0.31185537576675415, 0.09160114824771881, 0.07952375710010529, 0.09160114824771881, 0.42541855573654175], [0.0064194295555353165, 0.8455235362052917, 0.11964801698923111, 0.021989569067955017, 0.0064194295555353165], [0.0616685226559639, 0.5126040577888489, 0.26434677839279175, 0.09971212595701218, 0.0616685226559639], [0.17577026784420013, 0.056238096207380295, 0.008798481896519661, 0.583422839641571, 0.17577026784420013], [0.2552393972873688, 0.47427883744239807, 0.001356733264401555, 0.013885678723454475, 0.2552393972873688], [0.002212833147495985, 0.002212833147495985, 0.004169279709458351, 0.9905741810798645, 0.0008309588301926851], [0.1187824234366417, 0.28135260939598083, 0.29758745431900024, 0.28135260939598083, 0.02092490717768669], [0.2156999558210373, 0.3804975748062134, 0.005777597427368164, 0.3804975748062134, 0.017527291551232338], [0.0015292855678126216, 0.0015292855678126216, 0.10115347057580948, 0.8753468990325928, 0.02044103667140007], [0.5399240851402283, 0.3776261806488037, 0.0024894140660762787, 0.07747095078229904, 0.0024894140660762787], [0.06333127617835999, 0.07591716200113297, 0.24451486766338348, 0.06333127617835999, 0.5529054403305054], [0.19078564643859863, 0.7442755699157715, 0.010829299688339233, 0.010829299688339233, 0.04328015819191933], [0.35202112793922424, 0.13865700364112854, 0.382572203874588, 0.03968983143568039, 0.08705992251634598], [0.03600112348794937, 0.0003428953350521624, 0.8382946848869324, 0.12501834332942963, 0.0003428953350521624], [0.06240074336528778, 0.007059041876345873, 0.03297211229801178, 0.007059041876345873, 0.8905090093612671], [0.2140549123287201, 0.2945348024368286, 0.016643695533275604, 0.23738330602645874, 0.23738330602645874], [0.4567727744579315, 0.013800724409520626, 0.21492378413677216, 0.09957895427942276, 0.21492378413677216], [0.32929620146751404, 0.004102444741874933, 0.3320137560367584, 0.005291439127177, 0.32929620146751404], [0.2635249197483063, 0.0006669681752100587, 0.7355738878250122, 0.00011714026186382398, 0.00011714026186382398], [0.08451638370752335, 0.13929173350334167, 0.15285800397396088, 0.08451638370752335, 0.5388174653053284], [0.04177249222993851, 0.3988930583000183, 0.05967488884925842, 0.3988930583000183, 0.10076647251844406], [0.09870017319917679, 0.8638772368431091, 0.0014585867756977677, 0.018580246716737747, 0.017383774742484093], [0.01396733894944191, 0.16608105599880219, 0.01396733894944191, 0.23697784543037415, 0.5690064430236816], [0.044368863105773926, 0.3378829061985016, 0.34531381726264954, 0.22806553542613983, 0.044368863105773926], [0.3680259585380554, 0.009510326199233532, 0.3680259585380554, 0.23408880829811096, 0.020348919555544853], [0.03920533135533333, 0.5893311500549316, 0.01943041756749153, 0.17601653933525085, 0.17601653933525085], [0.009209900163114071, 0.2829706072807312, 0.3102913200855255, 0.08723682165145874, 0.3102913200855255], [0.8194291591644287, 0.0762305036187172, 0.07262419909238815, 0.0226944237947464, 0.00902161467820406], [0.1888027787208557, 0.3126234710216522, 0.2695922255516052, 0.11449073255062103, 0.11449073255062103], [0.044268302619457245, 0.009767650626599789, 0.3382623791694641, 0.5827648639678955, 0.02493683062493801], [0.013030611909925938, 0.0012998075690120459, 0.005926302168518305, 0.005926302168518305, 0.9738169312477112], [0.04670211300253868, 0.010878898203372955, 0.48206672072410583, 0.04670211300253868, 0.41365018486976624], [0.3272445499897003, 0.3862656056880951, 0.00013252369535621256, 0.14317867159843445, 0.14317867159843445], [0.9848306179046631, 0.0036481586284935474, 0.009794038720428944, 0.0008636154816485941, 0.0008636154816485941], [0.4629003405570984, 0.0013695528032258153, 0.00042464776197448373, 0.07240501791238785, 0.4629003405570984], [0.8753835558891296, 0.03593958169221878, 0.0032490291632711887, 0.03593958169221878, 0.04948825761675835], [0.01945747248828411, 0.5613540410995483, 0.20605908334255219, 0.20605908334255219, 0.007070327643305063], [0.14127276837825775, 0.07470065355300903, 0.0483599528670311, 0.5943938493728638, 0.14127276837825775], [0.005022185388952494, 0.43825703859329224, 0.4674874544143677, 0.07862482964992523, 0.010608436539769173], [0.032599955797195435, 0.3882293403148651, 0.1576542854309082, 0.3882293403148651, 0.033287081867456436], [0.0008688333327881992, 0.7330359220504761, 5.406309719546698e-05, 0.005527823232114315, 0.2605133354663849], [0.009904902428388596, 0.009904902428388596, 0.007683678064495325, 0.6832942962646484, 0.289212167263031], [0.027908379212021828, 0.21482232213020325, 0.006380610167980194, 0.006380610167980194, 0.7445080876350403], [0.039203397929668427, 0.3543020188808441, 0.24894461035728455, 0.0032478738576173782, 0.3543020188808441], [0.07423824071884155, 0.3035004734992981, 0.012811670079827309, 0.3035004734992981, 0.3059491813182831], [0.14956390857696533, 0.11495810747146606, 0.48918643593788147, 0.11495810747146606, 0.13133350014686584], [0.03227146342396736, 0.9236922264099121, 0.03227146342396736, 0.002887105103582144, 0.008877670392394066], [0.3303329646587372, 0.15468667447566986, 0.2468675822019577, 0.021245265379548073, 0.2468675822019577], [0.321488618850708, 0.2828077971935272, 0.05915717035531998, 0.015057777054607868, 0.321488618850708], [0.09828177839517593, 0.8027687072753906, 0.09828177839517593, 0.0004503654781728983, 0.00021741518867202103], [0.08787232637405396, 0.08787232637405396, 0.07819253206253052, 0.13991984724998474, 0.6061428785324097], [0.047236453741788864, 0.00037150003481656313, 0.4263818860054016, 0.4263818860054016, 0.0996282696723938], [0.030659973621368408, 0.2785128653049469, 0.21546049416065216, 0.25990620255470276, 0.21546049416065216], [0.0110637741163373, 0.0110637741163373, 0.646397590637207, 0.32229894399642944, 0.009175888262689114], [0.0292615108191967, 0.9037987589836121, 0.03491731360554695, 0.0027608340606093407, 0.0292615108191967], [0.0924987941980362, 0.0924987941980362, 0.2860143482685089, 0.4738624691963196, 0.05512559041380882], [0.0031082273926585913, 0.024285877123475075, 0.26038169860839844, 0.26038169860839844, 0.45184245705604553], [0.3342069685459137, 0.0025672351475805044, 0.6177229285240173, 0.01632469892501831, 0.02917821891605854], [0.4471188187599182, 0.10109680891036987, 4.338999860920012e-05, 0.004622146487236023, 0.4471188187599182], [0.00853327102959156, 0.013599542900919914, 0.5624476671218872, 0.40182000398635864, 0.013599542900919914], [0.12478549778461456, 0.03360431641340256, 0.01718858815729618, 0.7908173203468323, 0.03360431641340256], [0.018049906939268112, 0.5175734758377075, 0.042289409786462784, 0.042289409786462784, 0.3797978162765503], [0.008307456970214844, 0.4881639778614044, 0.4881639778614044, 0.01486815046519041, 0.0004964449326507747], [0.0010988734429702163, 0.0010988734429702163, 0.992343008518219, 0.004554665181785822, 0.0009046149789355695], [0.18736928701400757, 0.03182685747742653, 0.012793800793588161, 0.5806407332420349, 0.18736928701400757], [0.0030013439245522022, 0.009051783941686153, 0.6306217908859253, 0.03275923430919647, 0.3245658874511719], [0.03182986006140709, 0.11614613980054855, 0.12252745777368546, 0.697666585445404, 0.03182986006140709], [0.0904524028301239, 0.00788023229688406, 0.00788023229688406, 0.2699422240257263, 0.6238448023796082], [0.39042866230010986, 0.25261572003364563, 0.006126605439931154, 0.17541448771953583, 0.17541448771953583], [0.1915145367383957, 0.1915145367383957, 0.41995668411254883, 0.12348870933055878, 0.07352553308010101], [0.017493214458227158, 0.0008279686444438994, 0.017493214458227158, 0.803669273853302, 0.16051635146141052], [0.054088447242975235, 0.054088447242975235, 0.5922282338142395, 0.0002257491578347981, 0.29936906695365906], [0.0029703634791076183, 0.03808233514428139, 0.029186874628067017, 0.34351271390914917, 0.5862476229667664], [0.04534326121211052, 0.43458813428878784, 0.01932617463171482, 0.06615433841943741, 0.43458813428878784], [0.29296913743019104, 0.10697533190250397, 0.18795950710773468, 0.06635130196809769, 0.34574469923973083], [0.45325711369514465, 0.005079306662082672, 0.0798042044043541, 0.008602216839790344, 0.45325711369514465], [0.19519317150115967, 0.23483382165431976, 0.0007880900520831347, 0.19519317150115967, 0.3739916682243347], [0.07100506126880646, 0.8227287530899048, 0.007185325026512146, 0.037106357514858246, 0.06197458505630493], [0.014798473566770554, 0.015513435006141663, 0.7705069780349731, 0.1843826323747635, 0.014798473566770554], [0.1549168825149536, 0.3542899489402771, 0.06796705722808838, 0.2679091691970825, 0.1549168825149536], [0.09287860244512558, 0.20202693343162537, 0.20202693343162537, 0.11410433799028397, 0.38896316289901733], [0.07019907236099243, 0.6546088457107544, 0.12155378609895706, 0.12155378609895706, 0.03208453208208084], [0.31801751255989075, 0.3229005038738251, 0.032277580350637436, 0.2945268452167511, 0.032277580350637436], [0.43836647272109985, 0.09215071052312851, 0.01772603765130043, 0.013390335254371166, 0.43836647272109985], [0.32207176089286804, 0.036818381398916245, 0.13048438727855682, 0.18855370581150055, 0.32207176089286804], [0.3261089324951172, 0.1316792070865631, 0.0011102885473519564, 0.1316792070865631, 0.4094223082065582], [0.07013534754514694, 0.055534329265356064, 0.055534329265356064, 0.8179928064346313, 0.000803112518042326], [0.002338469261303544, 0.09551966935396194, 0.0851273387670517, 0.7214948534965515, 0.09551966935396194], [0.5013524293899536, 0.13176454603672028, 0.0008316353778354824, 0.18302571773529053, 0.18302571773529053], [0.01250156108289957, 0.834518313407898, 0.07100072503089905, 0.010978651233017445, 0.07100072503089905], [0.060893263667821884, 0.03655856102705002, 0.005614445079118013, 0.004224366508424282, 0.8927093148231506], [0.28196796774864197, 2.213340121670626e-05, 2.213340121670626e-05, 0.4165520966053009, 0.3014356791973114], [0.0032843470107764006, 0.8630352020263672, 0.039686501026153564, 0.09070967137813568, 0.0032843470107764006], [0.06651531159877777, 0.05193103104829788, 0.203222393989563, 0.06651531159877777, 0.6118159890174866], [0.6017090678215027, 0.020918309688568115, 0.11545021086931229, 0.13096119463443756, 0.13096119463443756], [0.09774168580770493, 0.08090468496084213, 0.17376473546028137, 0.08090468496084213, 0.5666842460632324], [0.007257537916302681, 0.028499938547611237, 0.09322093427181244, 0.028499938547611237, 0.8425216674804688], [0.08385177701711655, 4.7971130697987974e-05, 0.08385177701711655, 0.1413014680147171, 0.6909470558166504], [0.2050505131483078, 0.7458423376083374, 0.02824987843632698, 0.010428634472191334, 0.010428634472191334], [0.08064060658216476, 0.26925063133239746, 0.15868210792541504, 0.38386669754981995, 0.10756003111600876], [0.026111485436558723, 0.41856372356414795, 0.41856372356414795, 0.10529394447803497, 0.03146715462207794], [0.02141161821782589, 0.06280720978975296, 0.02141161821782589, 0.6043551564216614, 0.29001447558403015], [0.8282637596130371, 0.010591204278171062, 0.13500632345676422, 0.015547587536275387, 0.010591204278171062], [0.38134050369262695, 0.023874754086136818, 0.132686048746109, 0.38134050369262695, 0.0807582437992096], [0.7152261734008789, 0.018684886395931244, 0.0023228097707033157, 0.018684886395931244, 0.2450813204050064], [0.1980835646390915, 0.04269733652472496, 0.04269733652472496, 0.6886479258537292, 0.027873754501342773], [0.05357636883854866, 0.44078993797302246, 5.350094215827994e-05, 0.06479020416736603, 0.44078993797302246], [0.0002857101208064705, 0.9664662480354309, 0.0002857101208064705, 0.021298959851264954, 0.01166341733187437], [0.035655729472637177, 0.29642605781555176, 0.02491171285510063, 0.32150328159332275, 0.32150328159332275], [0.06696296483278275, 0.03219623491168022, 0.029196178540587425, 0.029196178540587425, 0.8424484729766846], [0.03778713941574097, 0.46021386981010437, 0.025322578847408295, 0.46021386981010437, 0.01646255888044834], [0.45982858538627625, 0.03509822115302086, 0.1752319037914276, 0.15460945665836334, 0.1752319037914276], [0.06704841554164886, 0.4299003779888153, 0.4299003779888153, 0.07176487147808075, 0.0013859623577445745], [0.334722638130188, 0.4904538094997406, 0.01711416058242321, 0.010051200166344643, 0.14765815436840057], [0.38682639598846436, 0.008222455158829689, 0.20515717566013336, 0.012967617250978947, 0.38682639598846436], [0.20177428424358368, 0.056219592690467834, 0.2749638855457306, 0.056219592690467834, 0.4108226001262665], [0.6400701999664307, 0.06235048547387123, 0.20055583119392395, 0.06235048547387123, 0.03467299044132233], [0.03843502700328827, 0.3708418905735016, 0.3708418905735016, 0.12107693403959274, 0.09880425781011581], [0.006745646707713604, 0.06068021431565285, 0.40275222063064575, 0.2649109661579132, 0.2649109661579132], [0.01967671699821949, 0.29979169368743896, 0.002586101181805134, 0.29979169368743896, 0.3781537115573883], [0.08584991097450256, 0.8647856712341309, 0.024516504257917404, 0.0003314418427180499, 0.024516504257917404], [0.015903092920780182, 0.0014077399391680956, 0.26366499066352844, 0.7176164388656616, 0.0014077399391680956], [0.10767417401075363, 0.37313294410705566, 0.17954888939857483, 0.17954888939857483, 0.16009506583213806], [0.014416789636015892, 0.10706513375043869, 0.10706513375043869, 0.32514476776123047, 0.4463082551956177], [0.6283586621284485, 0.035028304904699326, 0.08592154085636139, 0.08592154085636139, 0.16476993262767792], [0.02900739759206772, 0.02900739759206772, 0.013718651607632637, 0.0007049338892102242, 0.9275615811347961], [0.10628596693277359, 0.049745090305805206, 0.34272560477256775, 0.1585177630186081, 0.34272560477256775], [0.5010267496109009, 0.12828649580478668, 0.18788370490074158, 0.05451654642820358, 0.12828649580478668], [0.33658459782600403, 0.33658459782600403, 0.25233009457588196, 0.060335174202919006, 0.014165477827191353], [0.024240640923380852, 0.12359452992677689, 0.2592412233352661, 0.00012784790305886418, 0.592795729637146], [0.0015497992280870676, 0.2729523479938507, 0.0015497992280870676, 0.6858552694320679, 0.03809279575943947], [0.0689304992556572, 0.4899466633796692, 0.15089619159698486, 0.0689304992556572, 0.22129619121551514], [0.5238621830940247, 0.006682255771011114, 0.05985327437520027, 0.20480117201805115, 0.20480117201805115], [0.07131008058786392, 0.6042630672454834, 0.019226526841521263, 0.15260016918182373, 0.15260016918182373], [0.03461705148220062, 0.016647573560476303, 0.27811548113822937, 0.03461705148220062, 0.6360028386116028], [0.00371226342394948, 0.14614887535572052, 0.6500253081321716, 0.05396471545100212, 0.14614887535572052], [0.4300743639469147, 0.07041547447443008, 0.05145956203341484, 0.01797628216445446, 0.4300743639469147], [0.9158557653427124, 0.005491076968610287, 0.0035709505900740623, 0.0035709505900740623, 0.07151126116514206], [0.3206002414226532, 0.017626894637942314, 0.007877853699028492, 0.3206002414226532, 0.3332947790622711], [0.08011271059513092, 0.1736251264810562, 0.42100682854652405, 0.1516302227973938, 0.1736251264810562], [0.04963293299078941, 0.004021679051220417, 0.0013836194993928075, 0.9435780644416809, 0.0013836194993928075], [0.031698644161224365, 0.4654058814048767, 0.3943893313407898, 0.05425305664539337, 0.05425305664539337], [0.04445061832666397, 0.17725247144699097, 0.7314388751983643, 0.04445061832666397, 0.002407418331131339], [0.13358955085277557, 0.13358955085277557, 0.2656753957271576, 0.0756414607167244, 0.39150410890579224], [0.3262203335762024, 0.052190110087394714, 0.02799987979233265, 0.5413995981216431, 0.052190110087394714], [0.9044702649116516, 6.913048855494708e-05, 0.030713077634572983, 0.030713077634572983, 0.034034475684165955], [0.02096281759440899, 0.18866854906082153, 0.02096281759440899, 0.615148663520813, 0.15425704419612885], [0.3699994385242462, 0.0713672935962677, 0.3699994385242462, 0.05033040791749954, 0.1383034735918045], [0.41986092925071716, 0.0574420765042305, 0.0022323387674987316, 0.41986092925071716, 0.10060374438762665], [0.3908321261405945, 0.020070871338248253, 0.2726964056491852, 0.020070871338248253, 0.2963298261165619], [0.4838045537471771, 0.00405947957187891, 0.23536406457424164, 0.00444042356684804, 0.27233147621154785], [0.95225590467453, 0.021240830421447754, 1.638133471715264e-05, 0.013243471272289753, 0.013243471272289753], [0.00015249470015987754, 0.6724594235420227, 0.09823098033666611, 0.2233479917049408, 0.005809049122035503], [0.0003818444092758, 0.11654423922300339, 0.7548903226852417, 0.011639314703643322, 0.11654423922300339], [0.07517335563898087, 0.008802954107522964, 0.07517335563898087, 0.023193540051579475, 0.8176568150520325], [0.25801026821136475, 0.06314841657876968, 0.25801026821136475, 0.4207529127597809, 7.811309478711337e-05], [0.13442012667655945, 0.018491217866539955, 0.018491217866539955, 0.790008544921875, 0.03858884796500206], [0.02570897527039051, 0.010417124256491661, 0.4792860448360443, 0.4792860448360443, 0.005301767960190773], [0.10340665280818939, 0.4174554646015167, 0.026533709838986397, 0.4174554646015167, 0.035148706287145615], [0.11481811851263046, 0.15037065744400024, 0.11481811851263046, 0.6087005138397217, 0.011292554438114166], [0.00041530406451784074, 0.012631764635443687, 0.9682995080947876, 0.0012723595136776567, 0.017381031066179276], [0.04877326637506485, 0.06542010605335236, 0.06542010605335236, 0.8190996646881104, 0.0012868230696767569], [0.03525862097740173, 0.027379073202610016, 0.1430647373199463, 0.6512328386306763, 0.1430647373199463], [0.24389231204986572, 0.014485800638794899, 0.20453861355781555, 0.20453861355781555, 0.3325446844100952], [0.001705835573375225, 0.1467001736164093, 0.04417745769023895, 0.4037083089351654, 0.4037083089351654], [0.18833433091640472, 0.0747198536992073, 0.3572991192340851, 0.3572991192340851, 0.022347567602992058], [0.6799591183662415, 0.029612330719828606, 0.25023096799850464, 0.03732767328619957, 0.002869936404749751], [0.21902284026145935, 0.34795716404914856, 0.1836460828781128, 0.21902284026145935, 0.03035108558833599], [0.3182584345340729, 0.32670605182647705, 0.3182584345340729, 0.030490117147564888, 0.006287008989602327], [0.04772801697254181, 0.35232388973236084, 0.07069089263677597, 0.17693333327770233, 0.35232388973236084], [0.006667443551123142, 0.0007379719172604382, 0.9548513889312744, 0.03306536376476288, 0.0046777925454080105], [0.014856169000267982, 0.23410989344120026, 0.6875123381614685, 0.016005592420697212, 0.047516074031591415], [0.09999397397041321, 0.4650898575782776, 0.10532964766025543, 0.10532964766025543, 0.22425690293312073], [0.13617274165153503, 0.44148901104927063, 0.0016918795881792903, 0.4189545512199402, 0.0016918795881792903], [0.3352859616279602, 0.018828077241778374, 0.3352859616279602, 0.0016313220839947462, 0.3089686930179596], [0.18893057107925415, 0.5070948600769043, 0.18893057107925415, 0.09223593771457672, 0.022808091714978218], [0.646608829498291, 0.0148712657392025, 0.11203095316886902, 0.0148712657392025, 0.2116176038980484], [0.4651605784893036, 0.00809862557798624, 0.003121278714388609, 0.003121278714388609, 0.5204982757568359], [0.0545453280210495, 0.0545453280210495, 0.5752540230751038, 0.14032472670078278, 0.17533066868782043], [0.15226155519485474, 0.0019434753339737654, 0.4582287073135376, 0.0019434753339737654, 0.38562285900115967], [0.7539504766464233, 0.03338651359081268, 0.03338651359081268, 0.0848555862903595, 0.09442099183797836], [0.00017668496002443135, 0.0023571273777633905, 0.0024766847491264343, 0.0024766847491264343, 0.9925128221511841], [0.2651594281196594, 0.4042399525642395, 0.04859175533056259, 0.016849499195814133, 0.2651594281196594], [0.000460550538264215, 0.0017030681483447552, 0.4942810535430908, 0.009274259209632874, 0.4942810535430908], [0.2741711437702179, 0.0036311023868620396, 0.44415876269340515, 0.2741711437702179, 0.0038679062854498625], [0.20309893786907196, 0.4424118399620056, 0.028031377121806145, 0.12335890531539917, 0.20309893786907196], [0.26987072825431824, 0.4112805426120758, 0.26987072825431824, 0.04316312074661255, 0.005814883392304182], [0.14248254895210266, 0.07992473989725113, 0.47642773389816284, 0.02226109430193901, 0.2789038419723511], [0.006370209623128176, 0.006370209623128176, 0.41005367040634155, 0.34458592534065247, 0.2326199859380722], [0.011318821460008621, 0.03349815309047699, 0.03349815309047699, 0.03470931202173233, 0.8869755864143372], [0.15290561318397522, 0.0657426193356514, 0.0029596497770398855, 0.15290561318397522, 0.6254864931106567], [0.038106005638837814, 0.06382671743631363, 0.6078407764434814, 0.1451132446527481, 0.1451132446527481], [0.08613218367099762, 0.8622363805770874, 0.025629425421357155, 0.025629425421357155, 0.00037260810495354235], [0.012415633536875248, 0.44071754813194275, 0.17829068005084991, 0.18428805470466614, 0.18428805470466614], [0.023027505725622177, 0.6261690855026245, 0.00406119879335165, 0.3237147629261017, 0.023027505725622177], [0.00016661557310726494, 0.00016661557310726494, 0.002246713265776634, 0.6905257105827332, 0.30689433217048645], [0.029589688405394554, 0.012114834040403366, 0.10851939767599106, 0.42488807439804077, 0.42488807439804077], [0.002090557711198926, 0.34688013792037964, 0.34688013792037964, 0.13497090339660645, 0.16917826235294342], [0.3542589247226715, 0.17423543334007263, 0.2218693345785141, 0.027766933664679527, 0.2218693345785141], [0.11821529269218445, 0.4979693293571472, 0.06691177189350128, 0.249991774559021, 0.06691177189350128], [0.1981307566165924, 0.07197527587413788, 0.1981307566165924, 0.47087985277175903, 0.060883257538080215], [0.005616024136543274, 0.5428592562675476, 0.0004837291198782623, 0.4454249441623688, 0.005616024136543274], [0.004844518844038248, 0.06943903863430023, 0.6834056973457336, 0.004844518844038248, 0.2374662458896637], [0.12020211666822433, 0.4604493975639343, 0.09931904822587967, 0.2207103967666626, 0.09931904822587967], [0.553284764289856, 0.010783586651086807, 0.010783586651086807, 0.291685551404953, 0.1334625482559204], [0.28083381056785583, 0.09406459331512451, 0.06169160455465317, 0.28257617354393005, 0.28083381056785583], [0.08323423564434052, 0.22281721234321594, 0.24980045855045319, 0.22281721234321594, 0.2213309109210968], [0.36788487434387207, 0.18638008832931519, 0.07771039009094238, 0.36788487434387207, 0.00013972837768960744], [2.8353926609270275e-05, 0.027195509523153305, 0.31541967391967773, 0.31541967391967773, 0.34193673729896545], [0.029391516000032425, 0.029391516000032425, 0.9163370132446289, 0.024227440357208252, 0.0006525159114971757], [0.11421553790569305, 0.11421553790569305, 0.3918425440788269, 0.3149438798427582, 0.06478250026702881], [0.29199129343032837, 0.02199527993798256, 0.04443847015500069, 0.02432425506412983, 0.6172507405281067], [0.00787301454693079, 0.12081560492515564, 0.2116043120622635, 0.00787301454693079, 0.6518340110778809], [0.14129415154457092, 0.21932245790958405, 0.2644704580307007, 0.23361876606941223, 0.14129415154457092], [0.5520523190498352, 0.3662095069885254, 0.006787387654185295, 0.0034243445843458176, 0.07152653485536575], [0.3400031626224518, 0.040294528007507324, 0.3400031626224518, 0.27885672450065613, 0.0008423646213486791], [0.8076246380805969, 0.00352762290276587, 0.00352762290276587, 0.08753089606761932, 0.09778928756713867], [0.13864460587501526, 0.0169308390468359, 0.23298655450344086, 0.37845152616500854, 0.23298655450344086], [0.0013315527467057109, 0.44451096653938293, 0.05165522173047066, 0.05799134820699692, 0.44451096653938293], [0.08274960517883301, 0.0029710608068853617, 0.08274960517883301, 0.29962483048439026, 0.531904935836792], [0.01855365000665188, 0.7241897583007812, 0.017119698226451874, 0.22301717102527618, 0.017119698226451874], [0.9832909107208252, 0.0031682434491813183, 1.792576404113788e-05, 0.010354612022638321, 0.0031682434491813183], [0.0014575693057850003, 0.4095248878002167, 0.3608599305152893, 0.2267000675201416, 0.0014575693057850003], [0.48615890741348267, 0.48615890741348267, 0.011744788847863674, 0.007546677254140377, 0.00839066132903099], [0.43575572967529297, 0.43575572967529297, 0.0964965969324112, 0.018078580498695374, 0.013913417235016823], [0.05298126861453056, 0.019656799733638763, 0.8171793818473816, 0.09052571654319763, 0.019656799733638763], [0.005664632190018892, 0.7127833962440491, 0.27325713634490967, 0.005664632190018892, 0.002630155300721526], [0.06317883729934692, 0.01983310468494892, 0.3879498541355133, 0.3879498541355133, 0.1410883516073227], [0.40806859731674194, 0.12045849859714508, 0.07834427058696747, 0.12045849859714508, 0.2726702094078064], [0.10361988097429276, 0.018625039607286453, 0.03878841921687126, 0.8203415870666504, 0.018625039607286453], [0.0864417627453804, 0.4276527166366577, 0.4276527166366577, 0.017895769327878952, 0.0403570756316185], [0.00205564615316689, 0.10572370141744614, 0.00205564615316689, 0.06324732303619385, 0.8269177675247192], [0.00021899212151765823, 0.29769182205200195, 0.29769182205200195, 0.33243101835250854, 0.0719662681221962], [0.3083195984363556, 0.10310205817222595, 0.3083195984363556, 0.020398106426000595, 0.2598606050014496], [0.03284628316760063, 0.16006799042224884, 0.03284628316760063, 0.20077170431613922, 0.5734677314758301], [0.23043017089366913, 0.0705871656537056, 0.049070414155721664, 0.5793250203132629, 0.0705871656537056], [0.39947178959846497, 0.004613425116986036, 0.39947178959846497, 0.0009798682294785976, 0.195463165640831], [0.07555778324604034, 0.002182622905820608, 0.07555778324604034, 0.006933219730854034, 0.8397685885429382], [0.9077405333518982, 0.03441479802131653, 0.012294923886656761, 0.03441479802131653, 0.011134901084005833], [0.001313795568421483, 0.40507638454437256, 0.27034667134284973, 0.27034667134284973, 0.05291641131043434], [0.20077931880950928, 0.026137270033359528, 0.6725226640701294, 0.026137270033359528, 0.07442347705364227], [0.7210021018981934, 0.07464121282100677, 0.19623510539531708, 0.004060770384967327, 0.004060770384967327], [0.057004984468221664, 0.7197436094284058, 0.15876175463199615, 0.007484648376703262, 0.057004984468221664], [0.02372475527226925, 0.936069667339325, 0.012496738694608212, 0.02372475527226925, 0.003984101116657257], [0.1674668937921524, 0.5805625319480896, 0.012774400413036346, 0.1674668937921524, 0.07172932475805283], [0.012794286012649536, 0.12475626170635223, 0.3619179427623749, 0.3619179427623749, 0.13861356675624847], [0.0022394047118723392, 0.012767041102051735, 0.9695194363594055, 0.0027070259675383568, 0.012767041102051735], [0.00032698686118237674, 0.3981662690639496, 0.1542799025774002, 0.011286911554634571, 0.43593987822532654], [0.01764584891498089, 0.4591040015220642, 0.05524492636322975, 0.4591040015220642, 0.008901163935661316], [0.646733283996582, 0.126547709107399, 0.012533231638371944, 0.126547709107399, 0.0876380130648613], [0.02161470241844654, 0.00017660287267062813, 0.9181928634643555, 0.030007941648364067, 0.030007941648364067], [0.154812753200531, 0.3340933918952942, 0.10751413553953171, 0.24876698851585388, 0.154812753200531], [0.04194033145904541, 0.2999613881111145, 0.13506793975830078, 0.04194033145904541, 0.4810900390148163], [0.031947482377290726, 0.061064522713422775, 0.023747488856315613, 0.3201596438884735, 0.563080906867981], [0.07488294690847397, 0.828991711139679, 0.017710987478494644, 0.07488294690847397, 0.0035314089618623257], [0.02062869630753994, 0.9714638590812683, 0.0019451966509222984, 0.0019451966509222984, 0.004017012659460306], [0.8262990713119507, 0.020670875906944275, 0.046169787645339966, 0.06069045141339302, 0.046169787645339966], [0.023773230612277985, 0.004455325193703175, 0.0340573787689209, 0.004455325193703175, 0.9332588315010071], [0.24486732482910156, 0.24486732482910156, 0.08492468297481537, 0.055972423404455185, 0.3693682551383972], [0.204107865691185, 0.35886919498443604, 0.04953084886074066, 0.204107865691185, 0.18338428437709808], [0.10622766613960266, 0.05381091311573982, 0.2209254801273346, 0.39811038970947266, 0.2209254801273346], [0.017447825521230698, 0.21029771864414215, 0.017447825521230698, 0.6791951060295105, 0.07561151683330536], [0.13191843032836914, 0.37925735116004944, 0.37925735116004944, 0.03183015435934067, 0.0777367427945137], [0.3003688454627991, 0.023093128576874733, 0.37614697217941284, 2.2261199774220586e-05, 0.3003688454627991], [0.011344648897647858, 0.6795170307159424, 0.01335859764367342, 0.0375744067132473, 0.258205384016037], [0.37063127756118774, 0.2538171112537384, 0.2538171112537384, 0.11877654492855072, 0.0029578960966318846], [0.4298935830593109, 0.028874848037958145, 0.495682954788208, 0.0227743461728096, 0.0227743461728096], [0.3513302803039551, 0.0017068162560462952, 0.2091764360666275, 0.21889321506023407, 0.21889321506023407], [0.42641139030456543, 0.12631559371948242, 0.0179539043456316, 0.42641139030456543, 0.002907761838287115], [0.49444490671157837, 0.2787793278694153, 0.15927687287330627, 0.03374946862459183, 0.03374946862459183], [0.1271081417798996, 0.03670292720198631, 0.1271081417798996, 0.09100345522165298, 0.6180773973464966], [0.005857903975993395, 0.49121004343032837, 0.0011384213576093316, 0.49121004343032837, 0.010583638213574886], [0.48956498503685, 0.00013348580978345126, 0.018916316330432892, 0.48956498503685, 0.001820275792852044], [0.0438503623008728, 0.017626339569687843, 0.13442085683345795, 0.6696816086769104, 0.13442085683345795], [0.015845661982893944, 0.10060673952102661, 0.10060673952102661, 0.7739630937576294, 0.00897781178355217], [0.006928742863237858, 0.006928742863237858, 0.3233114182949066, 0.5034846663475037, 0.15934646129608154], [0.06159258261322975, 0.6554942727088928, 0.008818162605166435, 0.2125023901462555, 0.06159258261322975], [0.023000862449407578, 0.467290997505188, 0.467290997505188, 0.0029509947635233402, 0.03946607932448387], [0.42348167300224304, 0.0038413465954363346, 0.42348167300224304, 0.0070401825942099094, 0.14215512573719025], [0.0017739380709826946, 0.07915449887514114, 0.6302305459976196, 0.23454880714416504, 0.054292209446430206], [0.33074814081192017, 0.32749491930007935, 0.0012605807278305292, 0.32749491930007935, 0.013001352548599243], [0.3943430185317993, 0.10368349403142929, 0.034923478960990906, 0.3633665144443512, 0.10368349403142929], [0.526563823223114, 0.0007741636363789439, 0.007168896961957216, 0.46471890807151794, 0.0007741636363789439], [0.09761089831590652, 0.815899133682251, 0.03746023401618004, 0.03746023401618004, 0.011569437570869923], [0.0567864291369915, 0.00932315643876791, 0.8455159664154053, 0.0441872738301754, 0.0441872738301754], [0.24495217204093933, 0.2189951390028, 0.008752611465752125, 0.30830493569374084, 0.2189951390028], [0.08532549440860748, 0.25158029794692993, 0.013557378202676773, 0.32476845383644104, 0.32476845383644104], [0.005501674022525549, 0.6237383484840393, 0.1726916879415512, 0.1726916879415512, 0.025376643985509872], [0.019903425127267838, 0.29179832339286804, 0.1084447056055069, 0.28992676734924316, 0.28992676734924316], [0.019762903451919556, 0.3996047377586365, 0.3996047377586365, 0.15866732597351074, 0.022360319271683693], [0.09489212930202484, 0.26287055015563965, 0.312457799911499, 0.312457799911499, 0.017321746796369553], [0.09162887185811996, 0.03094140999019146, 0.8263721466064453, 0.025528796017169952, 0.025528796017169952], [0.008811822161078453, 0.4856542646884918, 0.005071904975920916, 0.14316517114639282, 0.3572968542575836], [0.040167998522520065, 0.3582015335559845, 0.4633342921733856, 0.13413669168949127, 0.0041594491340219975], [0.005725773051381111, 0.005725773051381111, 0.9238502383232117, 0.002309253206476569, 0.062389083206653595], [0.8631097674369812, 0.060152310878038406, 0.02139788307249546, 0.027670037001371384, 0.027670037001371384], [0.05217801779508591, 0.2562096118927002, 0.2562096118927002, 0.32379892468452454, 0.11160381883382797], [0.1466122716665268, 0.13214950263500214, 0.4662875831127167, 0.1274753212928772, 0.1274753212928772], [0.040008749812841415, 0.0743742436170578, 0.017712006345391273, 0.0743742436170578, 0.7935307621955872], [0.7477440237998962, 0.16199901700019836, 0.004945852793753147, 0.04265553876757622, 0.04265553876757622], [0.18843217194080353, 0.03606810420751572, 0.18843217194080353, 0.5776283144950867, 0.009439249522984028], [0.1717948168516159, 0.2971418499946594, 0.0676492303609848, 0.2971418499946594, 0.16627225279808044], [0.0169682577252388, 0.004914308898150921, 0.004914308898150921, 0.3512725830078125, 0.6219305396080017], [0.06726615130901337, 0.0038423873484134674, 0.0038423873484134674, 0.00474921241402626, 0.9202998876571655], [0.005735768936574459, 0.4351201355457306, 0.11614683270454407, 0.007877177558839321, 0.4351201355457306], [0.002150460844859481, 0.002150460844859481, 0.39813554286956787, 0.012702872045338154, 0.5848606824874878], [0.05263635516166687, 0.7146822214126587, 0.00041141847032122314, 0.1796337217092514, 0.05263635516166687], [0.06695268303155899, 0.34442389011383057, 0.18970312178134918, 0.34442389011383057, 0.054496411234140396], [0.29108795523643494, 0.23140425980091095, 0.29108795523643494, 0.02949683926999569, 0.15692298114299774], [0.0036641417536884546, 0.05936131626367569, 0.29597535729408264, 0.32049956917762756, 0.32049956917762756], [0.006951445713639259, 0.4986966848373413, 0.3656919300556183, 0.06432995200157166, 0.06432995200157166], [0.09938262403011322, 0.1348678320646286, 0.0928947702050209, 0.0928947702050209, 0.5799600481987], [0.20201106369495392, 0.10488736629486084, 0.10488736629486084, 0.18127527832984924, 0.40693897008895874], [0.15238960087299347, 0.14727403223514557, 0.445713073015213, 0.13841146230697632, 0.11621179431676865], [5.813897951156832e-05, 0.5177813172340393, 5.813897951156832e-05, 0.4787101447582245, 0.003392248647287488], [0.0006171198328956962, 0.01947782188653946, 0.01947782188653946, 0.31527647376060486, 0.6451507806777954], [0.009718592278659344, 0.014951086603105068, 0.963180422782898, 0.003186678048223257, 0.008963173255324364], [0.9740139842033386, 0.00814548134803772, 0.0004139480006415397, 0.0004139480006415397, 0.01701260730624199], [0.7349960207939148, 0.12015068531036377, 0.12015068531036377, 0.0063583459705114365, 0.01834425888955593], [0.009708601050078869, 0.26689326763153076, 0.4543669521808624, 0.0021378963720053434, 0.26689326763153076], [0.001580913201905787, 0.4940583109855652, 0.003693175734952092, 0.006609364878386259, 0.4940583109855652], [0.7608754634857178, 0.2360910177230835, 0.0010455225128680468, 0.0018750468734651804, 0.00011288321547908708], [0.3229254484176636, 0.5362923741340637, 0.06977994740009308, 0.06977994740009308, 0.0012222706573083997], [0.033173345029354095, 0.160610631108284, 2.2773698219680227e-05, 0.6455826163291931, 0.160610631108284], [0.029217379167675972, 0.0001065891920006834, 0.029217379167675972, 0.9361351728439331, 0.005323468707501888], [0.7789933681488037, 0.003526433138176799, 0.10127445310354233, 0.10127445310354233, 0.014931324869394302], [0.2515420615673065, 0.4446122944355011, 0.0060929954051971436, 0.04621056467294693, 0.2515420615673065], [0.3392087519168854, 0.46815037727355957, 0.05943424254655838, 0.07377239316701889, 0.05943424254655838], [0.23916305601596832, 0.302090048789978, 0.1570647805929184, 0.14461728930473328, 0.1570647805929184], [0.622035562992096, 0.250091552734375, 0.046606484800577164, 0.034659869968891144, 0.046606484800577164], [0.27348628640174866, 0.22653312981128693, 0.25099724531173706, 0.22653312981128693, 0.02245020866394043], [0.07150757312774658, 0.00031402180320583284, 0.009671874344348907, 0.9181925654411316, 0.00031402180320583284], [0.04945288226008415, 0.8350346684455872, 0.04945288226008415, 5.6044569646473974e-05, 0.06600353866815567], [0.0516897514462471, 0.7585984468460083, 0.0516897514462471, 0.02157239429652691, 0.11644972115755081], [0.06527059525251389, 0.0859767347574234, 0.7210752367973328, 0.0859767347574234, 0.041700657457113266], [0.25369739532470703, 0.17954333126544952, 0.0016332123195752501, 0.35048186779022217, 0.21464422345161438], [0.270955353975296, 0.001202907063998282, 0.22778970003128052, 0.270955353975296, 0.2290966957807541], [0.09575013816356659, 0.02748374454677105, 0.3620741069316864, 0.02748374454677105, 0.4872083365917206], [0.01476309448480606, 0.01476309448480606, 0.0013420212781056762, 0.7256826162338257, 0.24344919621944427], [0.32535719871520996, 0.2675418555736542, 0.026410743594169617, 0.026410743594169617, 0.35427945852279663], [0.3135059177875519, 0.06771641969680786, 0.29046884179115295, 0.014802908524870872, 0.3135059177875519], [0.3066743314266205, 0.27152737975120544, 0.0824994370341301, 0.27152737975120544, 0.06777142733335495], [0.0064909327775239944, 0.05696652829647064, 0.9364793300628662, 3.161779750371352e-05, 3.161779750371352e-05], [0.48997488617897034, 0.3885878622531891, 0.0786171555519104, 0.03264091536402702, 0.010179216042160988], [0.394124299287796, 0.2088322639465332, 0.394124299287796, 0.0007234272197820246, 0.0021957396529614925], [0.2548965513706207, 0.23154859244823456, 0.3510168194770813, 0.12327355891466141, 0.03926445171236992], [0.056412313133478165, 0.04732510820031166, 0.056412313133478165, 0.012068472802639008, 0.8277818560600281], [0.011547614820301533, 0.11468049138784409, 0.43986400961875916, 0.31922733783721924, 0.11468049138784409], [0.15475091338157654, 0.3403297960758209, 0.08592158555984497, 0.3403297960758209, 0.07866795361042023], [0.013255699537694454, 0.35537615418434143, 0.03008457086980343, 0.013255699537694454, 0.5880279541015625], [0.09946344047784805, 0.5376115441322327, 0.07811037451028824, 0.18535116314888, 0.09946344047784805], [0.0015067481435835361, 0.04435832425951958, 0.47528374195098877, 0.47528374195098877, 0.003567522158846259], [0.06308965384960175, 0.013017243705689907, 0.027060043066740036, 0.6876294016838074, 0.20920364558696747], [0.24191446602344513, 0.01374878454953432, 0.1782989799976349, 0.1782989799976349, 0.38773876428604126], [0.032383136451244354, 0.14610305428504944, 0.032383136451244354, 0.05221313610672951, 0.7369176149368286], [0.0030994899570941925, 0.000415995717048645, 0.13522659242153168, 0.13522659242153168, 0.7260313034057617], [7.046331302262843e-05, 0.0012118895538151264, 0.4828770160675049, 0.03296365216374397, 0.4828770160675049], [0.916269063949585, 0.029430260881781578, 0.02316969819366932, 0.007961198687553406, 0.02316969819366932], [0.48083367943763733, 0.15141437947750092, 0.15141437947750092, 0.08777511119842529, 0.12856248021125793], [0.03924014791846275, 0.08137194067239761, 0.30504241585731506, 0.16836418211460114, 0.4059812128543854], [0.22369655966758728, 0.5409453511238098, 0.011640324257314205, 2.1247737095109187e-05, 0.22369655966758728], [0.36810654401779175, 0.12947794795036316, 0.36810654401779175, 0.07918599992990494, 0.055122990161180496], [0.10238427668809891, 0.37188756465911865, 0.14710868895053864, 0.14710868895053864, 0.23151086270809174], [0.04167357087135315, 0.04167357087135315, 0.420695960521698, 0.4681282937526703, 0.027828652411699295], [0.07372274249792099, 0.032531969249248505, 0.07372274249792099, 0.1402517706155777, 0.6797707676887512], [0.8106192350387573, 0.000707233848515898, 0.13062506914138794, 0.000707233848515898, 0.05734127014875412], [0.040219977498054504, 0.23331327736377716, 0.23331327736377716, 0.057043083012104034, 0.43611040711402893], [0.00820847973227501, 0.9252237677574158, 0.054863233119249344, 0.00820847973227501, 0.0034959909971803427], [0.14517363905906677, 0.054505959153175354, 0.002112851245328784, 0.3991037905216217, 0.3991037905216217], [0.023491857573390007, 0.032682277262210846, 0.787777841091156, 0.07802403718233109, 0.07802403718233109], [0.0005505778244696558, 0.0002707588719204068, 0.8324795961380005, 0.08334952592849731, 0.08334952592849731], [0.4218892455101013, 0.05947764217853546, 0.2972792387008667, 0.20520097017288208, 0.016152968630194664], [0.0014199767028912902, 0.02732567861676216, 0.27858346700668335, 0.6912508606910706, 0.0014199767028912902], [0.08905818313360214, 0.0233635101467371, 0.7963634729385376, 0.0021565959323197603, 0.08905818313360214], [0.07299277186393738, 0.07299277186393738, 0.44144207239151, 3.9943312003742903e-05, 0.4125324785709381], [0.005883768666535616, 0.0061392709612846375, 0.0061392709612846375, 0.9287243485450745, 0.05311333388090134], [0.1574970781803131, 0.20270629227161407, 0.24251987040042877, 0.20270629227161407, 0.19457048177719116], [0.0011011749738827348, 0.057874396443367004, 0.01915903575718403, 0.9027064442634583, 0.01915903575718403], [0.09316138178110123, 0.5845678448677063, 0.004775341600179672, 0.004775341600179672, 0.31272009015083313], [0.5859700441360474, 0.29327908158302307, 0.02703867293894291, 0.09329406172037125, 0.00041810725815594196], [0.030435774475336075, 0.026707777753472328, 0.030435774475336075, 0.7997993230819702, 0.11262135207653046], [0.36100447177886963, 0.11653149873018265, 0.46776282787323, 0.027350621297955513, 0.027350621297955513], [0.06700495630502701, 0.24267496168613434, 0.3021318316459656, 0.32118335366249084, 0.06700495630502701], [0.04461189731955528, 0.08185264468193054, 0.1945565640926361, 0.3394894599914551, 0.3394894599914551], [0.23230402171611786, 0.3327696919441223, 0.003772017080336809, 0.3327696919441223, 0.09838458895683289], [0.4330335557460785, 0.14579655230045319, 0.14579655230045319, 0.16650643944740295, 0.10886695235967636], [0.0003553865244612098, 0.08453108370304108, 0.08453108370304108, 0.017666524276137352, 0.8129159212112427], [0.03707830607891083, 0.3209727704524994, 0.3209727704524994, 0.02161409892141819, 0.29936203360557556], [0.037256889045238495, 0.2801140546798706, 0.657034695148468, 0.005058512091636658, 0.020535852760076523], [0.4770803153514862, 0.0027195168659090996, 0.04290366545319557, 0.4770803153514862, 0.00021615873265545815], [0.30992385745048523, 0.00989657174795866, 0.6397383809089661, 0.030544603243470192, 0.00989657174795866], [0.30362093448638916, 0.0898704081773758, 0.0898704081773758, 0.4571819603443146, 0.05945628508925438], [0.14782050251960754, 0.05982222408056259, 0.38435494899749756, 0.05982222408056259, 0.34818005561828613], [0.8335069417953491, 0.027194080874323845, 0.006484384648501873, 0.10562053322792053, 0.027194080874323845], [0.019510144367814064, 0.012037444859743118, 0.9385336637496948, 0.012037444859743118, 0.017881352454423904], [0.05633307248353958, 0.77588951587677, 0.05633307248353958, 0.07873502373695374, 0.03270924836397171], [0.030860964208841324, 0.021831722930073738, 0.02250421978533268, 0.030860964208841324, 0.89394211769104], [0.11681491136550903, 0.31069159507751465, 0.08918026834726334, 0.39413291215896606, 0.08918026834726334], [0.44774335622787476, 0.44774335622787476, 0.006929237861186266, 0.06748825311660767, 0.030095865949988365], [0.01510445773601532, 0.0152661744505167, 0.01510445773601532, 0.9543289542198181, 0.000195891028852202], [0.036736227571964264, 0.062441859394311905, 0.036736227571964264, 0.373719722032547, 0.4903658926486969], [0.019498905166983604, 0.0015128995291888714, 0.03722131997346878, 0.47088339924812317, 0.47088339924812317], [0.02972516044974327, 0.3110602796077728, 0.271056205034256, 0.11710219085216522, 0.271056205034256], [0.03074432909488678, 0.5275330543518066, 0.07075246423482895, 0.3002176880836487, 0.07075246423482895], [0.005380073096603155, 0.4837203621864319, 0.027020465582609177, 0.4837203621864319, 0.00015870307106524706], [0.3585381805896759, 0.0005277011659927666, 0.3061266541481018, 0.028680769726634026, 0.3061266541481018], [0.00012728641740977764, 0.00012728641740977764, 0.8758402466773987, 0.03195137530565262, 0.09195386618375778], [0.0016654585488140583, 0.21374812722206116, 0.7818285226821899, 0.0013789344811812043, 0.0013789344811812043], [0.44654545187950134, 0.08556947112083435, 0.018582651391625404, 0.44654545187950134, 0.002756988164037466], [0.06851206719875336, 0.1964905709028244, 0.6862168312072754, 0.023437941446900368, 0.025342602282762527], [0.021245790645480156, 0.19625942409038544, 0.01623992994427681, 0.19625942409038544, 0.5699954032897949], [0.00400119973346591, 0.03294740617275238, 0.821849524974823, 0.1372007429599762, 0.00400119973346591], [0.027817657217383385, 0.08183467388153076, 0.10330212861299515, 0.7592279314994812, 0.027817657217383385], [0.2570604383945465, 0.3534862697124481, 0.3534862697124481, 0.01412274967879057, 0.021844306960701942], [0.013848432339727879, 0.3333714008331299, 0.5821554064750671, 0.05677631497383118, 0.013848432339727879], [0.008819122798740864, 0.023155521601438522, 0.0018465288449078798, 0.6295120120048523, 0.3366667628288269], [0.010181359015405178, 0.010181359015405178, 0.26609471440315247, 0.4929301142692566, 0.22061249613761902], [0.0007343891193158925, 0.5378650426864624, 0.18202131986618042, 0.13968965411186218, 0.13968965411186218], [0.2549687922000885, 8.389583672396839e-05, 0.0007233069627545774, 0.2549687922000885, 0.4892551302909851], [0.12441595643758774, 0.012757486663758755, 0.2805270850658417, 0.5695419311523438, 0.012757486663758755], [0.0020965493749827147, 0.4199744462966919, 0.12135784327983856, 0.036596693098545074, 0.4199744462966919], [0.09677521884441376, 0.09677521884441376, 0.01989913359284401, 0.053302034735679626, 0.7332484126091003], [0.36144593358039856, 0.006704744417220354, 0.11246833950281143, 0.006704744417220354, 0.5126762390136719], [3.766013469430618e-05, 0.0006753832567483187, 3.766013469430618e-05, 0.9464426636695862, 0.052806705236434937], [0.10886334627866745, 0.10886334627866745, 0.33590394258499146, 0.013435804285109043, 0.43293359875679016], [0.24757227301597595, 0.15371334552764893, 0.27429434657096863, 0.27429434657096863, 0.050125736743211746], [0.0002897546801250428, 0.9747690558433533, 0.000981856370344758, 0.022977443411946297, 0.000981856370344758], [0.820010781288147, 0.08840690553188324, 0.001143894623965025, 0.0020314077846705914, 0.08840690553188324], [0.03510303050279617, 0.4085676372051239, 0.0013772742822766304, 0.14638438820838928, 0.4085676372051239], [0.22998669743537903, 0.026178017258644104, 0.6348416805267334, 0.08281558752059937, 0.026178017258644104], [0.07791461050510406, 0.6760189533233643, 0.02378820814192295, 0.02378820814192295, 0.19849003851413727], [0.2957977056503296, 0.2088695615530014, 0.2957977056503296, 0.18488676846027374, 0.0146482577547431], [0.03882024437189102, 0.34652480483055115, 0.34652480483055115, 0.15081338584423065, 0.11731679737567902], [0.06238570436835289, 0.22148220241069794, 0.3572377562522888, 0.3572377562522888, 0.0016565588302910328], [0.000322353356750682, 0.08543892949819565, 0.4448383152484894, 0.024562058970332146, 0.4448383152484894], [0.020439838990569115, 0.020439838990569115, 0.31724071502685547, 0.5427882671356201, 0.0990912914276123], [0.06162383779883385, 0.06279036402702332, 0.7805904746055603, 0.03220490366220474, 0.06279036402702332], [0.25614064931869507, 0.23337066173553467, 0.21175771951675415, 0.25614064931869507, 0.04259031265974045], [0.10806220769882202, 0.3866051137447357, 0.10522319376468658, 0.29204732179641724, 0.10806220769882202], [0.8784993290901184, 0.00011236144200665876, 0.04879484325647354, 0.00011236144200665876, 0.07248112559318542], [0.0015736265340819955, 0.05837085470557213, 0.7624816298484802, 0.1760002225637436, 0.0015736265340819955], [0.028385870158672333, 0.023409968242049217, 0.8325572609901428, 0.05782345309853554, 0.05782345309853554], [0.46396222710609436, 0.08722690492868423, 0.06585368514060974, 0.06585368514060974, 0.31710344552993774], [0.18652208149433136, 0.3457261621952057, 0.3457261621952057, 0.006717500276863575, 0.11530806869268417], [0.2419937551021576, 0.00747426925227046, 0.015249733813107014, 0.00747426925227046, 0.7278079390525818], [0.21656405925750732, 0.0007782502798363566, 0.16220515966415405, 0.21656405925750732, 0.403888463973999], [0.054803524166345596, 0.6573571562767029, 0.054803524166345596, 0.056765116751194, 0.17627064883708954], [0.2378746122121811, 0.6429533958435059, 0.07126223295927048, 0.02395489439368248, 0.02395489439368248], [0.0049735791981220245, 0.01855061575770378, 0.4414096474647522, 0.08821069449186325, 0.44685548543930054], [0.00021089348592795432, 0.25409528613090515, 0.08767207711935043, 0.00021089348592795432, 0.6578109264373779], [0.4634053707122803, 0.0014562042197212577, 0.0014562042197212577, 0.020418591797351837, 0.5132635831832886], [0.41075244545936584, 0.41075244545936584, 0.15304459631443024, 0.0027368362061679363, 0.02271376922726631], [0.1645883470773697, 0.012383265420794487, 0.04755842685699463, 0.6108816266059875, 0.1645883470773697], [0.7334877848625183, 0.024404317140579224, 0.024404317140579224, 0.08433878421783447, 0.13336478173732758], [0.006624241825193167, 0.45005980134010315, 0.014169277623295784, 0.45005980134010315, 0.07908688485622406], [0.11543147265911102, 0.41069018840789795, 0.13117766380310059, 0.13117766380310059, 0.21152304112911224], [0.7865068912506104, 0.03859835863113403, 0.029449354857206345, 0.029449354857206345, 0.11599602550268173], [0.004906127229332924, 0.747642993927002, 0.07183992117643356, 0.07183992117643356, 0.10377106815576553], [0.06899188458919525, 0.03035370446741581, 0.21123670041561127, 0.6590640544891357, 0.03035370446741581], [0.020760027691721916, 0.016253991052508354, 0.8875898122787476, 0.05914219096302986, 0.016253991052508354], [0.028530580922961235, 0.01678026095032692, 0.08235053718090057, 0.8438080549240112, 0.028530580922961235], [0.09487900882959366, 0.17445464432239532, 0.08472846448421478, 0.17445464432239532, 0.4714832305908203], [0.032020457088947296, 0.9020575284957886, 0.008750473149120808, 0.028585806488990784, 0.028585806488990784], [0.27175459265708923, 0.07084730267524719, 0.14184501767158508, 0.24379847943782806, 0.27175459265708923], [0.05253921076655388, 0.056921206414699554, 0.8597534894943237, 0.015393040142953396, 0.015393040142953396], [0.07853685319423676, 0.36527401208877563, 0.24467216432094574, 0.24467216432094574, 0.06684484332799911], [0.001234476687386632, 0.009025540202856064, 0.8689398765563965, 0.06040007248520851, 0.06040007248520851], [0.06596989929676056, 0.06596989929676056, 0.03570384904742241, 0.46283552050590515, 0.36952078342437744], [0.0065661584958434105, 0.0065661584958434105, 0.028159156441688538, 0.8902246952056885, 0.06848382204771042], [0.16627785563468933, 0.4241710305213928, 0.16627785563468933, 0.0006601313943974674, 0.24261309206485748], [0.09614478051662445, 0.3411150276660919, 0.3411150276660919, 0.019412750378251076, 0.20221242308616638], [0.12248523533344269, 0.09366805851459503, 0.0009082321776077151, 0.7820302248001099, 0.0009082321776077151], [0.25823986530303955, 0.1612972766160965, 0.2859364151954651, 0.25823986530303955, 0.036286551505327225], [0.0006645809626206756, 0.34795165061950684, 0.34795165061950684, 0.0006990287802182138, 0.30273300409317017], [0.02483365312218666, 0.2649777829647064, 0.32556483149528503, 0.05905892327427864, 0.32556483149528503], [0.0008475572103634477, 0.0008475572103634477, 0.06106472387909889, 0.49520862102508545, 0.4420316517353058], [0.04583583399653435, 0.9345910549163818, 0.007205654866993427, 0.006183743942528963, 0.006183743942528963], [0.40009868144989014, 0.11923718452453613, 0.40009868144989014, 0.005564241670072079, 0.07500122487545013], [0.25550979375839233, 0.30164292454719543, 0.12108925729990005, 0.30164292454719543, 0.020115068182349205], [0.01940849795937538, 0.049601927399635315, 0.011506227776408195, 0.9000748991966248, 0.01940849795937538], [0.026505840942263603, 0.013467826880514622, 0.36454200744628906, 0.23094232380390167, 0.36454200744628906], [0.0027322659734636545, 6.628082337556407e-05, 0.0005829342408105731, 0.9946126937866211, 0.0020058213267475367], [0.043827902525663376, 0.007802114821970463, 0.0028125126846134663, 0.9017296433448792, 0.043827902525663376], [0.0022402158938348293, 0.20843186974525452, 0.3671225607395172, 0.2111027091741562, 0.2111027091741562], [0.3942379653453827, 0.3942379653453827, 0.12473789602518082, 0.005139422602951527, 0.08164669573307037], [0.06152024120092392, 0.008791063912212849, 0.4586077928543091, 0.4586077928543091, 0.01247311383485794], [0.008358156308531761, 0.015457534231245518, 0.8901374340057373, 0.07058927416801453, 0.015457534231245518], [0.0007731185178272426, 0.4833405911922455, 0.03247714787721634, 6.853550439700484e-05, 0.4833405911922455], [0.31263267993927, 0.0012375744991004467, 0.34288129210472107, 0.0003671555023174733, 0.34288129210472107], [0.03006604127585888, 0.03006604127585888, 0.8653221130371094, 0.04243474081158638, 0.03211110085248947], [0.25190046429634094, 0.0077873594127595425, 0.6962519884109497, 0.022030092775821686, 0.022030092775821686], [0.28655290603637695, 0.0021221654023975134, 0.43749821186065674, 0.13691335916519165, 0.13691335916519165], [0.45285117626190186, 0.04335705563426018, 0.006352421827614307, 0.044588182121515274, 0.45285117626190186], [0.023863639682531357, 0.23017221689224243, 0.023863639682531357, 0.19101083278656006, 0.531089723110199], [0.6097580790519714, 0.05455965921282768, 0.26644590497016907, 0.05455965921282768, 0.014676706865429878], [0.15536433458328247, 0.01857648976147175, 0.15536433458328247, 0.025500593706965446, 0.6451942324638367], [0.16455553472042084, 0.06636813282966614, 0.0727003887295723, 0.16455553472042084, 0.5318204164505005], [0.011111564934253693, 0.47191908955574036, 0.025363976135849953, 0.47191908955574036, 0.019686274230480194], [0.7774178981781006, 0.033683065325021744, 0.08973828703165054, 0.08973828703165054, 0.00942245963960886], [0.010361107997596264, 0.3667568564414978, 0.011825492605566978, 0.3667568564414978, 0.24429963529109955], [0.012448866851627827, 0.005306771025061607, 0.45805415511131287, 0.06613603979349136, 0.45805415511131287], [0.34250110387802124, 0.0001482660445617512, 0.10103864222764969, 0.34250110387802124, 0.2138109654188156], [0.2364790141582489, 0.6828446984291077, 0.06350451707839966, 0.008585899136960506, 0.008585899136960506], [0.15971441566944122, 0.31481266021728516, 0.0376451350748539, 0.45018264651298523, 0.0376451350748539], [0.07437292486429214, 0.2821647822856903, 0.32592761516571045, 0.03536989912390709, 0.2821647822856903], [0.20602846145629883, 0.29023951292037964, 0.07890041172504425, 0.2458161860704422, 0.1790154129266739], [0.005072643514722586, 0.3213706910610199, 0.3213706910610199, 0.24190764129161835, 0.11027830839157104], [0.024273667484521866, 0.005175023805350065, 0.009904583916068077, 0.9507421255111694, 0.009904583916068077], [0.06604234874248505, 0.020038435235619545, 0.0006648644339293242, 0.0006648644339293242, 0.912589430809021], [0.6137430667877197, 0.0008136769174598157, 0.038251593708992004, 0.346377968788147, 0.0008136769174598157], [0.2897181510925293, 0.08667919039726257, 0.14210954308509827, 0.14210954308509827, 0.33938363194465637], [0.35953816771507263, 0.31212157011032104, 0.31212157011032104, 0.014116684906184673, 0.002102033933624625], [0.6758720278739929, 0.0466279536485672, 0.013679961673915386, 0.217192143201828, 0.0466279536485672], [0.2333458960056305, 0.2333458960056305, 0.04883468151092529, 0.03754586726427078, 0.4469277262687683], [0.07966695725917816, 0.5035259127616882, 0.2520725727081299, 0.07966695725917816, 0.08506764471530914], [0.2101733535528183, 0.014751185663044453, 0.2889614701271057, 0.2430570125579834, 0.2430570125579834], [0.008050561882555485, 0.05557087063789368, 0.8335392475128174, 0.008136717602610588, 0.09470261633396149], [0.32746535539627075, 0.13344193994998932, 0.2034161239862442, 0.32746535539627075, 0.0082111656665802], [0.09231382608413696, 0.18952539563179016, 0.14350934326648712, 0.18952539563179016, 0.3851260244846344], [0.23482640087604523, 0.6656985282897949, 0.01494421623647213, 0.01494421623647213, 0.06958665698766708], [0.10890871286392212, 0.20621682703495026, 0.4156206548213959, 0.06303699314594269, 0.20621682703495026], [0.140456423163414, 0.010670031420886517, 0.34940004348754883, 0.15007342398166656, 0.34940004348754883], [0.02258136123418808, 0.11064809560775757, 0.2647077441215515, 0.3250334560871124, 0.2770293653011322], [0.08003707975149155, 0.8578090071678162, 0.0008516010129824281, 0.03065117821097374, 0.03065117821097374], [0.26520398259162903, 0.01796145923435688, 0.6713218092918396, 0.01796145923435688, 0.027551304548978806], [0.39833202958106995, 0.28995728492736816, 0.01087974850088358, 0.2306966781616211, 0.0701342225074768], [0.47508639097213745, 0.047764018177986145, 0.029529379680752754, 0.39985623955726624, 0.047764018177986145], [0.007978307083249092, 0.007978307083249092, 0.8528621792793274, 0.027225997298955917, 0.1039552241563797], [0.010258614085614681, 0.01796579733490944, 0.9712216258049011, 0.00027698621852323413, 0.00027698621852323413], [0.2356940656900406, 0.3661770522594452, 0.022996624931693077, 0.3661770522594452, 0.008955175057053566], [6.59696088405326e-05, 0.012545215897262096, 0.1018756628036499, 6.59696088405326e-05, 0.8854472041130066], [0.8146501183509827, 0.024835607036948204, 0.04355302453041077, 0.07340814173221588, 0.04355302453041077], [0.4146582782268524, 0.17801709473133087, 0.024984018877148628, 0.19117029011249542, 0.19117029011249542], [0.8976469039916992, 0.006562278605997562, 0.03149399906396866, 0.03280283510684967, 0.03149399906396866], [0.030864514410495758, 0.001677097985520959, 0.001677097985520959, 0.0010226656449958682, 0.9647586345672607], [0.0013311677612364292, 0.22158627212047577, 0.3879093527793884, 0.0012638353509828448, 0.3879093527793884], [0.9258432388305664, 3.5047632991336286e-05, 0.04492030292749405, 3.5047632991336286e-05, 0.02916637994349003], [0.02156510390341282, 0.08240073919296265, 0.023820284754037857, 0.7898131012916565, 0.08240073919296265], [0.03289739415049553, 0.9274508953094482, 0.03081439435482025, 4.9224581744056195e-06, 0.008832301944494247], [0.01952936314046383, 0.21929042041301727, 0.3805730640888214, 3.41248232871294e-05, 0.3805730640888214], [0.05936382710933685, 0.01758824847638607, 0.01758824847638607, 0.6912415027618408, 0.2142181694507599], [0.2531992495059967, 0.2531992495059967, 0.46889954805374146, 0.01991054229438305, 0.004791385028511286], [0.004110897425562143, 0.004110897425562143, 0.007967176847159863, 0.45670032501220703, 0.527110755443573], [0.4876241981983185, 0.04845241457223892, 0.41444674134254456, 0.04845241457223892, 0.0010242083808407187], [0.5003169178962708, 0.27063071727752686, 0.11058660596609116, 0.007879133336246014, 0.11058660596609116], [0.09818488359451294, 0.797267496585846, 0.09818488359451294, 0.0017069777240976691, 0.0046557290479540825], [0.5700227618217468, 0.16556786000728607, 0.06625654548406601, 0.16556786000728607, 0.03258493170142174], [0.8757727146148682, 0.0006409792113117874, 0.01601291447877884, 0.09156052768230438, 0.01601291447877884], [0.12152869999408722, 0.8486435413360596, 0.00611111568287015, 0.00611111568287015, 0.017605455592274666], [0.12322918325662613, 0.31686946749687195, 0.24841953814029694, 0.18825259804725647, 0.12322918325662613], [0.08894145488739014, 0.12557488679885864, 0.09427188336849213, 0.6022703647613525, 0.08894145488739014], [0.6508259177207947, 0.013813929632306099, 0.013813929632306099, 0.2683740556240082, 0.05317215248942375], [0.15039393305778503, 0.0331253707408905, 0.6845658421516418, 0.04809984564781189, 0.08381496369838715], [0.3591364026069641, 0.3591364026069641, 0.1463814675807953, 0.07797172665596008, 0.057374004274606705], [0.44432806968688965, 0.010236560367047787, 0.44432806968688965, 0.08785771578550339, 0.013249595649540424], [0.06725633144378662, 0.05899656563997269, 0.4989798665046692, 0.18738363683223724, 0.18738363683223724], [0.0830160602927208, 0.00124178861733526, 0.00124178861733526, 0.007709585130214691, 0.9067907333374023], [0.012724978849291801, 0.4437647759914398, 0.4437647759914398, 0.02720913663506508, 0.07253638654947281], [0.8461933135986328, 0.12180887162685394, 0.005903652869164944, 0.001113900332711637, 0.02498026192188263], [0.5498981475830078, 0.09892778098583221, 0.038069821894168854, 0.09892778098583221, 0.21417641639709473], [7.57987581891939e-05, 2.6472049285075627e-05, 0.49338439106941223, 0.013129008002579212, 0.49338439106941223], [0.22787059843540192, 0.5434983372688293, 0.11227143555879593, 0.0040882183238863945, 0.11227143555879593], [0.7241649627685547, 0.15328814089298248, 0.046232957392930984, 0.012137043289840221, 0.06417691707611084], [0.0029746172949671745, 0.0038340198807418346, 0.35099464654922485, 0.35099464654922485, 0.29120200872421265], [0.040544964373111725, 0.4630320966243744, 0.4152225852012634, 0.04060017690062523, 0.04060017690062523], [0.0110539011657238, 0.0110539011657238, 0.030964631587266922, 0.9109082818031311, 0.036019276827573776], [0.08079095929861069, 0.3894203007221222, 0.16876757144927979, 0.20701231062412262, 0.1540088802576065], [0.002791524399071932, 0.33036744594573975, 0.3876228332519531, 0.26485252380371094, 0.014365676790475845], [0.24298976361751556, 0.24298976361751556, 0.015450824983417988, 0.07582453638315201, 0.4227450489997864], [0.04338287562131882, 0.358794629573822, 0.5539147853851318, 0.0005248181987553835, 0.04338287562131882], [0.9311577081680298, 0.03229396417737007, 0.01827111840248108, 0.01827111840248108, 6.0941579249629285e-06], [0.1704302281141281, 0.2255280315876007, 0.2255280315876007, 0.270755410194397, 0.10775831341743469], [0.04056167975068092, 0.036537814885377884, 0.05615176633000374, 0.036537814885377884, 0.8302109241485596], [0.013617717660963535, 0.03780246526002884, 0.2797567546367645, 0.2797567546367645, 0.38906633853912354], [0.009780151769518852, 0.24005533754825592, 0.1956266462802887, 0.3589112162590027, 0.1956266462802887], [0.3190522789955139, 0.3190522789955139, 0.3600304126739502, 1.8265838662046008e-05, 0.0018467806512489915], [0.0006405416643247008, 0.42871224880218506, 0.0016900975024327636, 0.42871224880218506, 0.14024493098258972], [0.4822993874549866, 0.1147562563419342, 0.12044370919466019, 0.1147562563419342, 0.167744442820549], [0.22742517292499542, 0.3708137571811676, 0.0912095233798027, 0.08312636613845825, 0.22742517292499542], [0.4497576951980591, 0.07449523359537125, 0.3830418884754181, 0.018210018053650856, 0.07449523359537125], [0.00846748985350132, 0.07828652113676071, 0.011786761693656445, 0.8896723985671997, 0.011786761693656445], [0.12714515626430511, 0.006175535265356302, 0.3875812292098999, 0.3875812292098999, 0.09151692688465118], [0.413735568523407, 0.0006137121235951781, 0.413735568523407, 0.0036559421569108963, 0.1682591587305069], [0.050899483263492584, 0.050899483263492584, 0.8581182360649109, 0.03307941555976868, 0.007003335747867823], [0.33541351556777954, 0.010630658827722073, 0.010630658827722073, 0.562514066696167, 0.08081112056970596], [0.029827307909727097, 0.033504586666822433, 0.029827307909727097, 0.02003728598356247, 0.8868034482002258], [0.016643349081277847, 0.0008218590519391, 0.47474104166030884, 0.47474104166030884, 0.033052630722522736], [0.08387856185436249, 0.001966002630069852, 0.001966002630069852, 0.8904699683189392, 0.021719463169574738], [0.04089273884892464, 0.000981199205853045, 0.04089273884892464, 0.41109970211982727, 0.5061336159706116], [0.3897712230682373, 0.044565316289663315, 0.1366751790046692, 0.0392170175909996, 0.3897712230682373], [0.22877328097820282, 0.07094903290271759, 0.12871131300926208, 0.3427931070327759, 0.22877328097820282], [5.148469426785596e-05, 0.49198591709136963, 0.49198591709136963, 0.0052539510652422905, 0.010722676292061806], [0.005636724643409252, 0.0008815479231998324, 0.013218196108937263, 0.0008815479231998324, 0.9793819189071655], [0.0016790421213954687, 0.9778353571891785, 0.0014136943500488997, 0.0016790421213954687, 0.017392873764038086], [0.04522014036774635, 0.821609616279602, 0.04522014036774635, 0.06445116549730301, 0.023499013856053352], [0.054541680961847305, 0.008698300458490849, 0.10215195268392563, 0.7272676825523376, 0.10734042525291443], [0.015063049271702766, 0.00047653564251959324, 0.00047653564251959324, 0.045484043657779694, 0.938499927520752], [0.4533163905143738, 0.08197791129350662, 0.008629034273326397, 0.4533163905143738, 0.002760285045951605], [0.09412360936403275, 0.03994022682309151, 0.7373698949813843, 0.03444269299507141, 0.09412360936403275], [0.5572630763053894, 0.3162134289741516, 0.002152014523744583, 0.124327652156353, 4.3809457565657794e-05], [0.013160333037376404, 0.8974858522415161, 0.026524558663368225, 0.036304716020822525, 0.026524558663368225], [0.022879036143422127, 0.6041390895843506, 0.33000922203063965, 0.0200936459004879, 0.022879036143422127], [0.0001205789449159056, 0.01743442751467228, 0.01769312284886837, 0.8132594227790833, 0.1514923870563507], [0.21657967567443848, 0.09821738302707672, 0.00014307415403891355, 0.333907812833786, 0.35115206241607666], [0.2619272768497467, 0.09068869799375534, 0.013555394485592842, 0.3719013035297394, 0.2619272768497467], [0.14274513721466064, 0.0009741621906869113, 0.00021057621052023023, 0.713325023651123, 0.14274513721466064], [0.050902463495731354, 0.16142840683460236, 0.22825001180171967, 0.050902463495731354, 0.5085166692733765], [0.33516326546669006, 0.33516326546669006, 0.06918516755104065, 0.2593504786491394, 0.001137788058258593], [0.09080611914396286, 0.5842777490615845, 0.09080611914396286, 0.017410865053534508, 0.21669907867908478], [0.04647547006607056, 0.4702971875667572, 0.04647547006607056, 0.4306798279285431, 0.006072035524994135], [0.0007121930248104036, 0.00040732300840318203, 0.3781595826148987, 0.24256137013435364, 0.3781595826148987], [0.180591881275177, 0.180591881275177, 0.2141609489917755, 0.4048084616661072, 0.01984674297273159], [0.019008170813322067, 0.4411996901035309, 0.4411996901035309, 0.08752264827489853, 0.01106982585042715], [0.12476369738578796, 0.12476369738578796, 0.28626760840415955, 0.016320638358592987, 0.44788432121276855], [0.0013939861673861742, 0.17554941773414612, 0.029773026704788208, 0.029773026704788208, 0.7635104656219482], [0.1713649034500122, 0.342925101518631, 0.1713649034500122, 0.0797487199306488, 0.234596386551857], [0.08098365366458893, 0.4705831706523895, 0.08098365366458893, 0.36383214592933655, 0.003617312526330352], [0.08376231044530869, 0.005060979165136814, 0.8943243622779846, 0.005060979165136814, 0.011791371740400791], [0.32441750168800354, 0.1785709410905838, 0.0941108912229538, 0.1785709410905838, 0.22432975471019745], [0.07997041940689087, 0.17280608415603638, 0.07997041940689087, 0.25315845012664795, 0.41409459710121155], [0.2989242374897003, 0.03818245232105255, 0.28482818603515625, 0.09323695302009583, 0.28482818603515625], [0.026720702648162842, 0.3923508822917938, 0.18641866743564606, 0.002158790361136198, 0.3923508822917938], [0.5499995350837708, 0.14374905824661255, 0.2527887523174286, 0.02673131786286831, 0.02673131786286831], [0.05135967582464218, 0.7390212416648865, 0.004443300422281027, 0.004443300422281027, 0.20073245465755463], [0.2527187466621399, 0.0031507036183029413, 0.0031507036183029413, 0.49012619256973267, 0.25085359811782837], [0.15659351646900177, 0.1085374504327774, 0.22217930853366852, 0.25634488463401794, 0.25634488463401794], [0.013212013058364391, 0.9031748175621033, 0.0004698457778431475, 0.0699312686920166, 0.013212013058364391], [0.014352274127304554, 0.02712322026491165, 0.002444696146994829, 0.02712322026491165, 0.9289565682411194], [0.7032220959663391, 0.17920394241809845, 0.0498594231903553, 0.01785510778427124, 0.0498594231903553], [0.05229063332080841, 0.5875007510185242, 0.16480958461761475, 0.16480958461761475, 0.030589470639824867], [0.0239811223000288, 0.32835444808006287, 0.2867007553577423, 0.2867007553577423, 0.07426288723945618], [0.00043631286825984716, 0.10265538096427917, 0.10265538096427917, 0.00536385690793395, 0.7888891100883484], [0.5658556222915649, 0.2973330020904541, 0.02332935854792595, 0.02332935854792595, 0.09015275537967682], [0.4971769452095032, 0.05043825879693031, 0.0661531537771225, 0.3200785219669342, 0.0661531537771225], [0.16660176217556, 0.03244007006287575, 0.7033643126487732, 0.0033522576559334993, 0.09424155950546265], [0.002396631520241499, 0.26313316822052, 0.0756695345044136, 0.26313316822052, 0.39566755294799805], [0.9336661100387573, 0.01200141292065382, 0.01200141292065382, 0.001932100742124021, 0.04039889574050903], [0.5548878908157349, 0.04216877371072769, 0.02134302631020546, 0.02134302631020546, 0.36025723814964294], [0.49199214577674866, 0.012536793015897274, 0.003463244531303644, 0.49199214577674866, 1.5715133486082777e-05], [0.026501350104808807, 0.0496031790971756, 0.699792206287384, 0.0496031790971756, 0.17450006306171417], [0.532458484172821, 0.00013191261678002775, 0.03018462471663952, 0.03018462471663952, 0.40704038739204407], [0.05437527224421501, 0.8582848310470581, 0.027318498119711876, 0.005646217614412308, 0.05437527224421501], [0.05391571670770645, 0.772121787071228, 0.00457229046151042, 0.05391571670770645, 0.11547452211380005], [0.24806265532970428, 0.0720643475651741, 0.41606855392456055, 0.0720643475651741, 0.19174006581306458], [0.6176496148109436, 0.13936981558799744, 0.13936981558799744, 0.025928454473614693, 0.07768228650093079], [0.5788266062736511, 0.01653660461306572, 0.03506225347518921, 0.01653660461306572, 0.35303795337677], [0.12413254380226135, 0.12413254380226135, 0.709557294845581, 0.00616666954010725, 0.03601094335317612], [0.415128231048584, 0.10701162368059158, 0.013939323835074902, 0.415128231048584, 0.04879258573055267], [0.14432722330093384, 0.0004998825024813414, 0.6338515281677246, 0.14432722330093384, 0.07699404656887054], [0.01247365027666092, 0.10213591158390045, 0.4392926096916199, 0.006805233657360077, 0.4392926096916199], [0.5945244431495667, 0.27783408761024475, 0.051566824316978455, 0.03803733363747597, 0.03803733363747597], [0.19575384259223938, 0.08477721363306046, 0.02289690636098385, 0.08477721363306046, 0.6117948293685913], [0.35742709040641785, 0.004562659189105034, 0.0017861123196780682, 0.2787969708442688, 0.35742709040641785], [0.18311932682991028, 0.005188595503568649, 0.02170804888010025, 0.6068646907806396, 0.18311932682991028], [0.4188312292098999, 0.4188312292098999, 0.0008277911692857742, 0.1535647064447403, 0.007945092394948006], [0.010874760337173939, 0.12011092156171799, 0.08898108452558517, 0.3900165855884552, 0.3900165855884552], [0.0658760815858841, 0.1414945274591446, 0.1414945274591446, 0.31557920575141907, 0.3355555832386017], [0.07938698679208755, 0.1732376664876938, 0.18618853390216827, 0.37499821186065674, 0.18618853390216827], [0.0018993098055943847, 0.16642051935195923, 0.000640188402030617, 0.000640188402030617, 0.830399751663208], [0.0007840296602807939, 0.39180296659469604, 0.0773068517446518, 0.5300241708755493, 8.19375054561533e-05], [0.0015073029790073633, 0.0015073029790073633, 0.06338774412870407, 0.34606122970581055, 0.5875363349914551], [0.2566951811313629, 0.2566951811313629, 0.1186806857585907, 0.035825494676828384, 0.3321034014225006], [0.07824850082397461, 0.7472026944160461, 0.06014444679021835, 0.07824850082397461, 0.03615583851933479], [0.2869509756565094, 0.00950141716748476, 0.029490210115909576, 0.2869509756565094, 0.38710641860961914], [0.1927071213722229, 0.41900166869163513, 0.1927071213722229, 0.17171801626682281, 0.0238660741597414], [0.33576247096061707, 0.22412952780723572, 0.0034922463819384575, 0.21248626708984375, 0.22412952780723572], [0.20157532393932343, 0.20157532393932343, 0.4599982798099518, 0.030709806829690933, 0.10614129155874252], [0.3010944128036499, 0.12535788118839264, 0.28180089592933655, 0.28180089592933655, 0.009945928119122982], [0.9850226044654846, 0.0002984034363180399, 1.6064186638686806e-05, 0.014646842144429684, 1.6064186638686806e-05], [0.40902966260910034, 0.08916769921779633, 0.40902966260910034, 0.009195989929139614, 0.08357693254947662], [0.09941644966602325, 0.009101158007979393, 0.09941644966602325, 0.24473580718040466, 0.5473301410675049], [0.06039976328611374, 0.3106949031352997, 0.31322047114372253, 0.31322047114372253, 0.0024644334334880114], [0.13516412675380707, 0.00893073994666338, 0.3493313193321228, 0.1572425216436386, 0.3493313193321228], [0.05669897794723511, 0.7967132329940796, 0.05953068286180496, 0.05953068286180496, 0.027526332065463066], [0.00576193118467927, 0.05997235327959061, 3.7938327295705676e-05, 0.9341898560523987, 3.7938327295705676e-05], [0.26839160919189453, 0.30515894293785095, 0.07304321974515915, 0.08501454442739487, 0.26839160919189453], [0.002235889434814453, 0.3102822005748749, 0.04145544022321701, 0.3357442617416382, 0.3102822005748749], [0.06504973769187927, 0.6737011075019836, 0.06504973769187927, 0.003239827696233988, 0.19295957684516907], [0.00016561834490858018, 0.9677289128303528, 0.01283117476850748, 0.00016561834490858018, 0.019108695909380913], [0.11747917532920837, 0.1865120828151703, 0.508195698261261, 0.11747917532920837, 0.07033386081457138], [0.2533179223537445, 0.06510323286056519, 0.007667905185371637, 0.007667905185371637, 0.6662430167198181], [0.8353068232536316, 0.005746106151491404, 0.06591856479644775, 0.02711002342402935, 0.06591856479644775], [0.006070864852517843, 0.08935153484344482, 0.006070864852517843, 0.7689498066902161, 0.12955687940120697], [0.029952988028526306, 0.17063294351100922, 0.17063294351100922, 0.14137966930866241, 0.48740145564079285], [0.11233648657798767, 0.05870620906352997, 0.7676758170127869, 0.0025752559304237366, 0.05870620906352997], [0.19818146526813507, 0.19818146526813507, 0.11776448786258698, 0.37484973669052124, 0.11102284491062164], [0.007902286946773529, 0.0719984695315361, 0.8359172940254211, 0.042090944945812225, 0.042090944945812225], [0.45449426770210266, 0.02223740890622139, 0.45449426770210266, 0.0003288447915110737, 0.06844522058963776], [0.33613795042037964, 0.00211312435567379, 0.3082121014595032, 0.33613795042037964, 0.017398905009031296], [0.049509283155202866, 0.03025357984006405, 0.5861412882804871, 0.16704794764518738, 0.16704794764518738], [0.4278479516506195, 0.00196680030785501, 0.4278479516506195, 0.12344639748334885, 0.01889089122414589], [0.01065131276845932, 0.006600438617169857, 0.9725974202156067, 0.006600438617169857, 0.0035504091065376997], [0.30269068479537964, 0.30269068479537964, 0.33853644132614136, 0.00885689165443182, 0.047225311398506165], [0.02199796959757805, 0.0368366613984108, 0.02199796959757805, 0.062439367175102234, 0.8567280173301697], [0.2719356119632721, 0.03675716370344162, 0.00912086758762598, 0.2719356119632721, 0.41025078296661377], [0.48866453766822815, 0.48866453766822815, 0.008801218122243881, 0.01117763016372919, 0.0026920337695628405], [0.23117436468601227, 0.036716528236866, 0.002759641734883189, 0.36467471718788147, 0.36467471718788147], [0.819421648979187, 0.08753234148025513, 0.00548766041174531, 2.5958555852412246e-05, 0.08753234148025513], [0.057093385607004166, 0.2172154188156128, 0.2172154188156128, 0.01082539651542902, 0.4976503849029541], [0.03523103520274162, 0.6761723756790161, 0.03523103520274162, 0.05307583138346672, 0.20028968155384064], [0.08140166848897934, 0.192179337143898, 0.192179337143898, 0.5280574560165405, 0.006182212848216295], [0.04847662150859833, 0.04903745651245117, 0.008707125671207905, 0.845302164554596, 0.04847662150859833], [0.0019232381600886583, 0.0019232381600886583, 0.03537653014063835, 0.9578537344932556, 0.0029232576489448547], [0.310648113489151, 0.310648113489151, 0.37114593386650085, 0.00014856875350233167, 0.007409357465803623], [0.8988549709320068, 0.0020825755782425404, 0.008708853274583817, 0.08164475858211517, 0.008708853274583817], [0.0402522087097168, 0.4061136245727539, 0.051735058426856995, 0.4061136245727539, 0.0957854762673378], [0.7310231328010559, 0.04517003521323204, 0.020541636273264885, 0.04517003521323204, 0.1580951064825058], [0.21533723175525665, 0.21533723175525665, 0.1259424388408661, 0.2839190363883972, 0.1594640612602234], [0.00821093562990427, 0.9734473824501038, 0.00821093562990427, 0.002782112918794155, 0.007348593324422836], [0.025805287063121796, 0.539759635925293, 0.12006042152643204, 0.19431427121162415, 0.12006042152643204], [0.002252083271741867, 0.37636077404022217, 0.37636077404022217, 0.08952789008617401, 0.15549850463867188], [0.5770740509033203, 0.02961994893848896, 0.0917702317237854, 0.15076793730258942, 0.15076793730258942], [0.009219572879374027, 0.29466772079467773, 0.4685679078102112, 0.11377239972352982, 0.11377239972352982], [0.13430003821849823, 9.725530981086195e-05, 0.5117248892784119, 0.23771993815898895, 0.1161579117178917], [0.02525298297405243, 0.4442521035671234, 0.08460888266563416, 0.4442521035671234, 0.001633939566090703], [8.62540618982166e-05, 2.159061659767758e-05, 0.0016903718933463097, 2.159061659767758e-05, 0.9981801509857178], [0.20518213510513306, 0.17057986557483673, 0.21863004565238953, 0.23502804338932037, 0.17057986557483673], [0.006083153188228607, 0.026522910222411156, 0.7263014912605286, 0.23500928282737732, 0.006083153188228607], [0.02134884148836136, 0.8348323702812195, 0.12043311446905136, 0.02134884148836136, 0.0020367582328617573], [0.8258767127990723, 0.010996309109032154, 0.025372980162501335, 0.1123809665441513, 0.025372980162501335], [0.2846031188964844, 0.061335206031799316, 0.36912283301353455, 0.2846031188964844, 0.00033574432018212974], [0.5105553865432739, 0.1535603404045105, 0.1535603404045105, 0.005765018984675407, 0.1765589416027069], [0.13740754127502441, 0.1854141503572464, 0.13740754127502441, 0.16312742233276367, 0.3766433596611023], [0.13183973729610443, 0.05049753561615944, 0.008614260703325272, 0.13183973729610443, 0.6772087812423706], [0.08941049873828888, 0.5661171078681946, 0.21552661061286926, 0.06447289884090424, 0.06447289884090424], [0.2859703600406647, 0.35998958349227905, 0.0008715973817743361, 0.17658422887325287, 0.17658422887325287], [0.00038037527701817453, 0.10970720648765564, 0.0018883449956774712, 0.0018883449956774712, 0.8861356973648071], [0.03234800696372986, 0.012082795612514019, 0.012082795612514019, 0.051057662814855576, 0.8924287557601929], [0.11045115441083908, 0.057936787605285645, 0.0011380190262570977, 0.0011380190262570977, 0.8293359875679016], [0.13702858984470367, 0.01023451890796423, 0.37970978021621704, 0.37970978021621704, 0.09331731498241425], [0.031610555946826935, 0.744626522064209, 0.024800719693303108, 0.024800719693303108, 0.17416147887706757], [0.019226688891649246, 0.7918615341186523, 0.14869198203086853, 0.019226688891649246, 0.02099318988621235], [0.046862367540597916, 0.44747194647789, 0.0008126326138153672, 0.05738111585378647, 0.44747194647789], [0.003805682295933366, 0.2881116271018982, 0.3001749813556671, 0.3001749813556671, 0.10773277282714844], [0.07121209055185318, 0.07121209055185318, 0.5453193187713623, 0.2859500050544739, 0.026306478306651115], [0.4391888380050659, 0.4391888380050659, 0.04939482361078262, 0.01708502694964409, 0.055142469704151154], [0.4553675949573517, 0.008504297584295273, 0.0005101477727293968, 0.4553675949573517, 0.08025035262107849], [0.6813039183616638, 3.855704562738538e-05, 3.855704562738538e-05, 0.04619332775473595, 0.27242565155029297], [0.13559137284755707, 0.34251782298088074, 0.3756752014160156, 0.13559137284755707, 0.010624216869473457], [0.9908630847930908, 0.004483995959162712, 0.0012326297583058476, 0.0017101900884881616, 0.0017101900884881616], [0.20337913930416107, 0.3712438941001892, 0.20337913930416107, 0.21233133971691132, 0.009666415862739086], [0.008994488045573235, 0.28919512033462524, 0.5504043698310852, 0.008994488045573235, 0.14241154491901398], [0.45615339279174805, 0.00666039576753974, 0.030014730989933014, 0.05101808160543442, 0.45615339279174805], [0.3196634352207184, 0.26548880338668823, 0.1492292881011963, 0.0001297050475841388, 0.26548880338668823], [0.026242908090353012, 0.24543403089046478, 0.026242908090353012, 0.04522270709276199, 0.6568573117256165], [0.02049044333398342, 0.010066075250506401, 0.897722601890564, 0.010066075250506401, 0.06165480613708496], [0.9510905146598816, 0.012959673069417477, 0.004328208509832621, 0.012959673069417477, 0.018661901354789734], [0.07279771566390991, 0.022667555138468742, 0.00817857589572668, 0.024234581738710403, 0.8721215128898621], [0.29121682047843933, 0.09654559940099716, 0.26984578371047974, 0.33231469988822937, 0.010077082552015781], [0.1134185791015625, 0.006516533438116312, 0.8444658517837524, 0.0023063544649630785, 0.03329269587993622], [0.00048469967441633344, 0.391317754983902, 0.391317754983902, 0.038912925869226456, 0.17796696722507477], [0.005175253842025995, 0.0009665038087405264, 0.6311030387878418, 0.29107072949409485, 0.07168449461460114], [0.0437784418463707, 0.33875253796577454, 0.2568325996398926, 0.33875253796577454, 0.021883893758058548], [0.008627081289887428, 0.6906178593635559, 0.04085535556077957, 0.008627081289887428, 0.25127261877059937], [0.4404550790786743, 0.10326606780290604, 0.4404550790786743, 0.011653258465230465, 0.004170494619756937], [0.4309442341327667, 0.27232834696769714, 0.27232834696769714, 0.013208121992647648, 0.01119096390902996], [0.008074370212852955, 0.008074370212852955, 0.040167149156332016, 0.47946760058403015, 0.4642164707183838], [0.10211740434169769, 0.3851185739040375, 0.23399566113948822, 0.04477272927761078, 0.23399566113948822], [0.003758898936212063, 0.02357751876115799, 0.02357751876115799, 0.705716073513031, 0.24336998164653778], [0.027402466163039207, 0.15440733730793, 0.05717300623655319, 0.7336146831512451, 0.027402466163039207], [0.33867037296295166, 0.12357623130083084, 0.22882522642612457, 0.18535195291042328, 0.12357623130083084], [0.23921072483062744, 0.08159637451171875, 0.3300463557243347, 0.01910020038485527, 0.3300463557243347], [0.05125666409730911, 0.37160587310791016, 9.826891619013622e-05, 0.5257825255393982, 0.05125666409730911], [0.45607516169548035, 0.45607516169548035, 0.044320929795503616, 0.008197583258152008, 0.035331159830093384], [0.0687694102525711, 0.024066835641860962, 0.04945197328925133, 0.0687694102525711, 0.7889424562454224], [0.0007811374380253255, 0.037844959646463394, 0.04359906539320946, 0.8741757273674011, 0.04359906539320946], [0.20633743703365326, 0.26269984245300293, 0.06765514612197876, 0.20060773193836212, 0.26269984245300293], [0.4782446324825287, 0.13361230492591858, 0.17235605418682098, 0.13361230492591858, 0.08217477053403854], [0.48993703722953796, 0.011030440218746662, 0.006071250885725021, 0.0030242218635976315, 0.48993703722953796], [0.1639685034751892, 0.0002947155444417149, 0.7252817153930664, 0.0002947155444417149, 0.11016040295362473], [0.00032332478440366685, 0.054650817066431046, 0.017055967822670937, 0.91091388463974, 0.017055967822670937], [0.32620683312416077, 0.004167581908404827, 0.27679282426834106, 0.11603990942239761, 0.27679282426834106], [0.20693263411521912, 0.003380958456546068, 0.20693263411521912, 0.5822939276695251, 0.0004597785300575197], [0.0259004645049572, 0.0259004645049572, 0.9371949434280396, 0.008832190185785294, 0.0021718700882047415], [0.005950876511633396, 0.3337445557117462, 0.03998197987675667, 0.310161292552948, 0.310161292552948], [0.09943674504756927, 0.39768800139427185, 0.09943674504756927, 0.05830054357647896, 0.34513795375823975], [0.015330027788877487, 0.0063507454469799995, 0.9627450108528137, 0.015330027788877487, 0.0002442083787173033], [0.3319514989852905, 0.22589288651943207, 0.0013007051311433315, 0.21496199071407318, 0.22589288651943207], [0.6446263790130615, 0.0021839009132236242, 0.002590413670986891, 0.34841543436050415, 0.0021839009132236242], [0.3666451573371887, 0.3666451573371887, 0.05514538288116455, 0.061388447880744934, 0.15017586946487427], [0.004295156802982092, 0.009350232779979706, 0.8952247500419617, 0.009350232779979706, 0.0817796066403389], [0.17355477809906006, 0.006088143214583397, 0.17355477809906006, 0.048515237867832184, 0.598287045955658], [0.1853150576353073, 0.13891401886940002, 0.04784004017710686, 0.4890168011188507, 0.13891401886940002], [0.05899035558104515, 0.058053888380527496, 0.43494561314582825, 0.43494561314582825, 0.01306457445025444], [0.0009426090400665998, 0.0025186478160321712, 0.9792264699935913, 0.014793634414672852, 0.0025186478160321712], [0.4751933515071869, 0.04563435539603233, 0.002624653512611985, 0.0013542446540668607, 0.4751933515071869], [0.04056072607636452, 0.4629363417625427, 0.004598212894052267, 0.004598212894052267, 0.48730653524398804], [0.35162365436553955, 0.23188801109790802, 0.41402730345726013, 0.001230505178682506, 0.001230505178682506], [0.37327197194099426, 0.09789489954710007, 0.1493702083826065, 0.006190984509885311, 0.37327197194099426], [0.5550881028175354, 0.025439465418457985, 0.014229089953005314, 0.3798038065433502, 0.025439465418457985], [0.2747214138507843, 0.5968508720397949, 0.1166732907295227, 0.0058772023767232895, 0.0058772023767232895], [0.10102752596139908, 0.054817527532577515, 0.06229151412844658, 0.10102752596139908, 0.6808359622955322], [0.45837289094924927, 0.05674441158771515, 0.45837289094924927, 0.0060031902976334095, 0.02050653100013733], [0.27525416016578674, 0.27525416016578674, 0.05395415797829628, 0.0942874327301979, 0.3012501001358032], [0.060780808329582214, 0.007856438867747784, 0.06940896064043045, 0.060780808329582214, 0.8011729717254639], [0.009398610331118107, 0.0026973208878189325, 0.9646022915840149, 0.0027723575476557016, 0.020529352128505707], [0.03860068321228027, 0.03454824164509773, 0.4016585350036621, 0.12353400141000748, 0.4016585350036621], [0.23879843950271606, 0.3984189033508301, 0.23879843950271606, 0.12294232845306396, 0.0010419205063953996], [0.41342124342918396, 0.38128766417503357, 0.010585174895823002, 0.18412072956562042, 0.010585174895823002], [0.2887856662273407, 0.0034620887599885464, 0.351757675409317, 0.004236821085214615, 0.351757675409317], [0.3493006229400635, 0.063301220536232, 0.08944679796695709, 0.14865073561668396, 0.3493006229400635], [0.5517430901527405, 0.33831459283828735, 0.049673523753881454, 0.049673523753881454, 0.01059527974575758], [0.019305197522044182, 0.005542424041777849, 0.4179784953594208, 0.4179784953594208, 0.13919539749622345], [0.4256606101989746, 0.03623697906732559, 0.025081025436520576, 0.4256606101989746, 0.08736072480678558], [0.7482592463493347, 0.0025295980740338564, 0.0025295980740338564, 0.15229035913944244, 0.09439126402139664], [0.7563876509666443, 0.011208750307559967, 0.011208750307559967, 0.1593199372291565, 0.06187489628791809], [0.04509161785244942, 0.44789060950279236, 0.18064354360103607, 0.18064354360103607, 0.14573070406913757], [0.004005979280918837, 0.09334767609834671, 0.892309308052063, 0.004005979280918837, 0.006331029813736677], [0.0017385859973728657, 0.5989593863487244, 0.0017385859973728657, 0.04731515794992447, 0.3502482771873474], [0.053768862038850784, 0.053768862038850784, 0.2508082389831543, 0.032617826014757156, 0.6090362071990967], [0.6272439360618591, 0.0014958834508433938, 1.944195173564367e-05, 0.0014958834508433938, 0.3697448968887329], [0.7805062532424927, 0.010860237292945385, 0.006245001684874296, 0.006245001684874296, 0.19614355266094208], [0.7771637439727783, 0.0033942912705242634, 0.040873777121305466, 0.08928412199020386, 0.08928412199020386], [0.002668790053576231, 0.16560953855514526, 0.016892610117793083, 0.002668790053576231, 0.8121601939201355], [0.135506734251976, 0.12993554770946503, 0.11191167682409286, 0.5107343196868896, 0.11191167682409286], [0.8920396566390991, 0.10373752564191818, 0.003562517464160919, 0.0003301893884781748, 0.0003301893884781748], [0.012839563190937042, 0.1921042799949646, 0.06358766555786133, 0.3657342493534088, 0.3657342493534088], [0.30572766065597534, 0.08748827129602432, 0.30572766065597534, 0.00415789196267724, 0.2968984544277191], [0.016872724518179893, 0.24977633357048035, 0.24977633357048035, 0.03536519780755043, 0.44820934534072876], [0.14789307117462158, 0.6019946932792664, 0.010238139890134335, 0.14789307117462158, 0.09198101609945297], [0.12126622349023819, 0.43512067198753357, 0.019795186817646027, 0.2119089514017105, 0.2119089514017105], [0.15776360034942627, 0.008934546262025833, 0.5556762218475342, 0.2686910629272461, 0.008934546262025833], [0.002810498932376504, 0.002810498932376504, 0.0019662685226649046, 0.5761239528656006, 0.416288822889328], [0.7355334758758545, 0.21527422964572906, 0.013487692922353745, 0.02221699245274067, 0.013487692922353745], [0.059535734355449677, 0.0006690967129543424, 0.14822065830230713, 0.14822065830230713, 0.6433538794517517], [0.11157097667455673, 0.03393198549747467, 0.06694106757640839, 0.7206149101257324, 0.06694106757640839], [0.3405213952064514, 0.0015850174240767956, 0.3405213952064514, 0.009830264374613762, 0.30754202604293823], [0.41228187084198, 0.1731681525707245, 0.0003238768258597702, 0.0019441766198724508, 0.41228187084198], [0.7036581635475159, 0.1101609393954277, 0.1101609393954277, 0.07590466737747192, 0.00011535517842276022], [0.44054654240608215, 0.14671818912029266, 0.40904098749160767, 1.386814983561635e-05, 0.0036804107949137688], [0.03254152461886406, 0.042861513793468475, 5.9550544392550364e-05, 0.9244778156280518, 5.9550544392550364e-05], [0.018998119980096817, 0.6348648071289062, 0.17190109193325043, 0.17190109193325043, 0.0023349400144070387], [0.0006067918729968369, 0.000490271660964936, 0.0006067918729968369, 0.00037611296284012496, 0.9979199767112732], [0.39263010025024414, 0.39263010025024414, 0.13057701289653778, 0.015223275870084763, 0.06893951445817947], [0.4405374228954315, 0.4405374228954315, 0.04799880459904671, 0.07091253995895386, 1.3705472156289034e-05], [0.546963632106781, 0.1807754635810852, 0.03810540586709976, 0.053380075842142105, 0.1807754635810852], [0.1434038132429123, 0.00861631240695715, 6.748582381987944e-05, 0.0024677193723618984, 0.8454446196556091], [0.014912664890289307, 0.014912664890289307, 0.027234740555286407, 0.03192533180117607, 0.9110146164894104], [0.6926643252372742, 0.014794970862567425, 0.02335631661117077, 0.18843263387680054, 0.08075176924467087], [0.35906651616096497, 0.08497103303670883, 0.10681617259979248, 0.35906651616096497, 0.09007974714040756], [0.031178252771496773, 0.0069909305311739445, 0.6886482834815979, 0.24200430512428284, 0.031178252771496773], [0.32089176774024963, 0.32089176774024963, 0.0037307722959667444, 0.002052588388323784, 0.35243308544158936], [0.17321422696113586, 0.192743718624115, 0.2274370938539505, 0.20330247282981873, 0.20330247282981873], [0.03539397194981575, 0.27832263708114624, 0.3091210722923279, 0.3579198122024536, 0.01924251578748226], [0.00026713820989243686, 0.04189009591937065, 0.711632251739502, 0.00026713820989243686, 0.24594338238239288], [0.3282773494720459, 0.13978801667690277, 0.006815727800130844, 0.5183031558990479, 0.006815727800130844], [0.28611424565315247, 0.004923858214169741, 0.28611424565315247, 0.10179875046014786, 0.32104894518852234], [0.01336746197193861, 0.001029192702844739, 0.015054245479404926, 0.01336746197193861, 0.9571816921234131], [0.2416587918996811, 0.0070846485905349255, 0.4353492856025696, 0.07424844801425934, 0.2416587918996811], [0.2345762848854065, 0.1045178696513176, 0.5970742702484131, 0.03191576898097992, 0.03191576898097992], [0.0022766010370105505, 0.11055289208889008, 0.7532153725624084, 0.11055289208889008, 0.0234022606164217], [0.36457380652427673, 0.005049095023423433, 0.0010720841819420457, 0.624255895614624, 0.005049095023423433], [0.6976341605186462, 0.05006431043148041, 0.03982473537325859, 0.03982473537325859, 0.17265203595161438], [0.3258422613143921, 0.3258422613143921, 0.0006709104054607451, 0.13527467846870422, 0.2123698741197586], [0.2950277328491211, 0.0024214633740484715, 0.10706750303506851, 0.48841580748558044, 0.10706750303506851], [0.06320807337760925, 0.0008000122616067529, 0.49408844113349915, 0.0008000122616067529, 0.44110339879989624], [0.11759642511606216, 0.19088272750377655, 0.13351097702980042, 0.11759642511606216, 0.44041335582733154], [0.0013595736818388104, 0.0013595736818388104, 0.7672019004821777, 0.09632997959852219, 0.13374899327754974], [0.02134816162288189, 0.02134816162288189, 0.05806779861450195, 0.07398354262113571, 0.8252524137496948], [0.008866394869983196, 0.2181241363286972, 0.5716962218284607, 0.19244687259197235, 0.008866394869983196], [0.03346807509660721, 0.18878893554210663, 0.1030907854437828, 0.1030907854437828, 0.5715613961219788], [0.2601505219936371, 0.06933990120887756, 0.04434628784656525, 0.3660127520561218, 0.2601505219936371], [0.4013972580432892, 0.007457082625478506, 0.436117559671402, 0.14757104218006134, 0.007457082625478506], [0.7569687366485596, 0.10016293078660965, 0.10016293078660965, 0.012937331572175026, 0.029768042266368866], [0.08868349343538284, 0.025552211329340935, 0.6209086775779724, 0.17617209255695343, 0.08868349343538284], [0.026591118425130844, 0.38230186700820923, 0.38230186700820923, 0.1643342524766922, 0.04447095841169357], [0.04233241453766823, 0.14629389345645905, 0.3672958314418793, 0.3672958314418793, 0.07678203284740448], [0.0724623054265976, 0.06646855175495148, 0.1269972324371338, 0.6616095900535583, 0.0724623054265976], [0.44280683994293213, 0.47094231843948364, 0.007690345868468285, 0.007690345868468285, 0.07087025046348572], [0.14585459232330322, 0.5924391746520996, 0.1871437132358551, 0.03728125989437103, 0.03728125989437103], [0.00047942803939804435, 0.19937527179718018, 0.3935498595237732, 0.013045543804764748, 0.3935498595237732], [0.3416401147842407, 0.05881005525588989, 0.3416401147842407, 0.16020230948925018, 0.09770742803812027], [0.33885663747787476, 0.010650302283465862, 0.019433995708823204, 0.2922024726867676, 0.33885663747787476], [0.1314694732427597, 0.014313986524939537, 0.028767472133040428, 0.7966815829277039, 0.028767472133040428], [0.1166473999619484, 0.0008640253799967468, 0.42026931047439575, 0.1166473999619484, 0.3455718755722046], [0.4868629574775696, 0.001978357322514057, 0.023118996992707253, 0.4868629574775696, 0.0011767586693167686], [0.408204048871994, 0.0019912535790354013, 0.13945913314819336, 0.04214147478342056, 0.408204048871994], [0.6914218068122864, 0.1521882861852646, 0.0007235317607410252, 0.00347804999910295, 0.1521882861852646], [0.40694019198417664, 0.025457212701439857, 0.15682457387447357, 0.0038378150202333927, 0.40694019198417664], [0.026842407882213593, 0.3908795118331909, 0.01756610907614231, 0.17383244633674622, 0.3908795118331909], [0.0157958772033453, 0.01046538446098566, 0.01046538446098566, 0.48429951071739197, 0.4789738059043884], [0.15063510835170746, 0.2165345549583435, 0.232510045170784, 0.18378572165966034, 0.2165345549583435], [0.8441788554191589, 0.0373038575053215, 0.06790324300527573, 0.013310049660503864, 0.0373038575053215], [0.007416085340082645, 0.26247382164001465, 0.4309154748916626, 0.036720775067806244, 0.26247382164001465], [0.0008971964125521481, 0.4951547086238861, 0.4951547086238861, 0.00796351209282875, 0.000829931756015867], [0.08121813088655472, 0.9074070453643799, 0.0005114394007250667, 0.010351888835430145, 0.0005114394007250667], [0.11748386919498444, 0.08545253425836563, 0.00041369081009179354, 0.6791660189628601, 0.11748386919498444], [0.019000211730599403, 0.40895694494247437, 0.04154882952570915, 0.26524701714515686, 0.26524701714515686], [0.20474709570407867, 0.3838278651237488, 0.015022466890513897, 0.3813800811767578, 0.015022466890513897], [0.03755704686045647, 0.09504539519548416, 0.00428886478766799, 0.4315544068813324, 0.4315544068813324], [0.364865779876709, 0.18255329132080078, 0.04191986471414566, 0.364865779876709, 0.045795291662216187], [0.10450568795204163, 0.13089269399642944, 0.04070756584405899, 0.36194702982902527, 0.36194702982902527], [0.3768441081047058, 0.1991392821073532, 0.1991392821073532, 0.0015609784750267863, 0.22331635653972626], [0.08259941637516022, 0.04198240116238594, 0.1277688890695572, 0.7056668996810913, 0.04198240116238594], [8.582500595366582e-05, 0.16767774522304535, 0.0020060688257217407, 0.16767774522304535, 0.6625525951385498], [0.009900666773319244, 0.23747190833091736, 0.5057139992713928, 0.23747190833091736, 0.009441548958420753], [0.19212932884693146, 0.390727162361145, 0.390727162361145, 0.023711809888482094, 0.0027045628521591425], [0.10222969204187393, 0.030966877937316895, 0.3850005567073822, 0.3850005567073822, 0.0968022421002388], [0.7551448345184326, 0.027523191645741463, 0.06460072100162506, 0.06460072100162506, 0.08813054859638214], [0.5008397102355957, 0.0016562137752771378, 0.25221508741378784, 0.12264446914196014, 0.12264446914196014], [0.04021146893501282, 0.5118551850318909, 0.4012065529823303, 0.04021146893501282, 0.006515344604849815], [0.038596443831920624, 0.17670823633670807, 0.027973873540759087, 0.027973873540759087, 0.7287476062774658], [0.0012187586398795247, 0.017512965947389603, 0.9533078670501709, 0.0012187586398795247, 0.026741674169898033], [0.01800713501870632, 0.01800713501870632, 0.06805196404457092, 0.8277238011360168, 0.06821005046367645], [0.0003915090055670589, 0.19550804793834686, 0.44801729917526245, 0.16057507693767548, 0.19550804793834686], [0.06370759010314941, 0.14518004655838013, 0.2237005978822708, 0.0030259336344897747, 0.5643858313560486], [0.269124835729599, 0.2197222113609314, 0.13329540193080902, 0.13329540193080902, 0.24456211924552917], [0.2139929085969925, 0.04485693573951721, 0.2139929085969925, 0.0043828459456563, 0.5227743983268738], [0.0301673486828804, 0.0066691176034510136, 0.4576598107814789, 0.4576598107814789, 0.047843944281339645], [0.08885203301906586, 0.3511764705181122, 0.42039209604263306, 0.050727419555187225, 0.08885203301906586], [0.2421187162399292, 0.14873701333999634, 0.21881288290023804, 0.2421187162399292, 0.14821265637874603], [0.03045501746237278, 0.019608650356531143, 5.778037666459568e-05, 0.9389358758926392, 0.010942701250314713], [0.030957026407122612, 0.016698168590664864, 0.07161404192447662, 0.07161404192447662, 0.809116780757904], [0.10499514639377594, 0.28741636872291565, 0.4889633357524872, 0.059312604367733, 0.059312604367733], [0.039579298347234726, 0.039579298347234726, 0.02400067262351513, 0.007878636941313744, 0.8889621496200562], [0.4674581289291382, 0.0011720494367182255, 0.06288570165634155, 0.4674581289291382, 0.0010259714908897877], [0.074168860912323, 0.15043027698993683, 0.01944890059530735, 0.3779759705066681, 0.3779759705066681], [0.5120230913162231, 0.18534965813159943, 0.0009903949685394764, 0.11628719419240952, 0.18534965813159943], [0.017452090978622437, 0.08710312098264694, 0.017452090978622437, 0.12094826251268387, 0.7570444345474243], [0.35995423793792725, 0.052678242325782776, 0.0031685170251876116, 0.22424477338790894, 0.35995423793792725], [0.01747865416109562, 0.0003996984160039574, 0.4880055785179138, 0.006110453978180885, 0.4880055785179138], [0.8726059794425964, 0.049721673130989075, 0.006266551557928324, 0.021684182807803154, 0.049721673130989075], [0.07757561653852463, 0.0014024103293195367, 0.4537453055381775, 0.4537453055381775, 0.013531383126974106], [0.0077612800523638725, 0.01395501010119915, 0.01395501010119915, 0.6494562029838562, 0.31487250328063965], [0.019167691469192505, 0.019167691469192505, 0.32760947942733765, 0.03060855343937874, 0.6034466028213501], [0.2202019840478897, 0.4080652594566345, 0.028849497437477112, 0.12268125265836716, 0.2202019840478897], [0.09989676624536514, 0.027102401480078697, 0.30447256565093994, 0.027102401480078697, 0.541425883769989], [0.9594255685806274, 0.0026391211431473494, 0.00711112329736352, 0.00711112329736352, 0.023713048547506332], [0.07739366590976715, 0.5308052897453308, 0.19363857805728912, 0.004523906856775284, 0.19363857805728912], [0.11161928623914719, 0.013127253390848637, 0.4296959638595581, 0.4324302077293396, 0.013127253390848637], [0.08289200067520142, 0.11930850893259048, 0.11930850893259048, 0.2783487141132355, 0.40014219284057617], [0.1930602341890335, 0.10474363714456558, 0.1930602341890335, 0.0038892519660294056, 0.505246639251709], [0.007237490266561508, 0.8158246874809265, 0.060252729803323746, 0.060252729803323746, 0.05643231049180031], [0.620456337928772, 0.2092113047838211, 0.05680426210165024, 0.05672387033700943, 0.05680426210165024], [0.4394090175628662, 0.4394090175628662, 0.0008697552257217467, 0.11973132193088531, 0.0005808778805658221], [0.0024335116613656282, 0.05500450357794762, 0.004521473776549101, 0.05500450357794762, 0.8830360174179077], [0.6817360520362854, 0.06926379352807999, 0.24860048294067383, 0.00019980584329459816, 0.00019980584329459816], [0.6091719269752502, 0.07419569790363312, 0.07419569790363312, 0.24087747931480408, 0.0015591355040669441], [0.10163247585296631, 0.0008742604404687881, 0.0008742604404687881, 0.8774529099464417, 0.01916603557765484], [0.039989493787288666, 0.0034816660918295383, 0.09359782934188843, 0.0034816660918295383, 0.8594493269920349], [0.05067335069179535, 0.00894780084490776, 0.09324425458908081, 0.8381867408752441, 0.00894780084490776], [0.2438431829214096, 0.32998064160346985, 0.159150168299675, 0.10787584632635117, 0.159150168299675], [0.11829986423254013, 0.24929679930210114, 0.24929679930210114, 0.314424067735672, 0.06868252903223038], [0.0007351926760748029, 0.004550074692815542, 0.4742613732814789, 0.4742613732814789, 0.04619194194674492], [0.15706993639469147, 0.32103005051612854, 0.06576621532440186, 0.1351037472486496, 0.32103005051612854], [0.016616763547062874, 0.43244874477386475, 0.10283306241035461, 0.015652602538466454, 0.43244874477386475], [0.0018260024953633547, 0.08826722204685211, 0.0018260024953633547, 0.048297904431819916, 0.8597827553749084], [0.40034180879592896, 0.40034180879592896, 0.003728572279214859, 0.04680639132857323, 0.14878138899803162], [0.06876051425933838, 0.0005311950226314366, 0.09597290307283401, 0.8039599061012268, 0.030775457620620728], [0.0003031013475265354, 0.6456327438354492, 0.0005234594573266804, 0.0005234594573266804, 0.35301733016967773], [0.7104231119155884, 0.058860573917627335, 0.17177732288837433, 7.839899626560509e-05, 0.058860573917627335], [0.0546346940100193, 0.0546346940100193, 0.8695351481437683, 0.00012404161680024117, 0.02107151597738266], [0.034903112798929214, 0.20125463604927063, 0.29489243030548096, 0.17405737936496735, 0.29489243030548096], [0.0176650770008564, 0.11062891781330109, 0.376655638217926, 0.1183946505188942, 0.376655638217926], [0.003744213841855526, 0.016370531171560287, 0.3847636878490448, 0.5787510871887207, 0.016370531171560287], [0.5231131911277771, 0.4357968270778656, 0.002072989707812667, 0.019508497789502144, 0.019508497789502144], [0.26464372873306274, 0.09159022569656372, 0.2959122359752655, 0.05194157361984253, 0.2959122359752655], [0.0635126456618309, 0.04951087012887001, 0.42541366815567017, 0.0635126456618309, 0.3980501592159271], [0.016839243471622467, 0.003022183431312442, 0.9800507426261902, 4.389294554130174e-05, 4.389294554130174e-05], [0.877816915512085, 0.07583882659673691, 0.018438143655657768, 0.018438143655657768, 0.00946797989308834], [0.056300293654203415, 0.056300293654203415, 0.09418729692697525, 0.13780853152275085, 0.6554036140441895], [0.04857216030359268, 0.46827712655067444, 0.012803889811038971, 0.46827712655067444, 0.0020696762949228287], [0.20965291559696198, 0.001070610131137073, 0.44960564374923706, 0.130017951130867, 0.20965291559696198], [0.2664493918418884, 0.0018880759598687291, 0.36257457733154297, 0.36257457733154297, 0.0065133096650242805], [0.4002155661582947, 0.14985980093479156, 0.2938736379146576, 0.006191215477883816, 0.14985980093479156], [0.26006487011909485, 0.0027623367495834827, 0.7336456775665283, 0.0007647015154361725, 0.0027623367495834827], [0.9744807481765747, 0.008093021810054779, 0.008337540552020073, 0.0009956841822713614, 0.008093021810054779], [0.09764595329761505, 0.27041468024253845, 0.2984374463558197, 0.2984374463558197, 0.035064470022916794], [0.534259021282196, 0.1497666835784912, 0.04559456557035446, 0.1206129938364029, 0.1497666835784912], [0.11857101321220398, 2.0668143406510353e-05, 0.7202143669128418, 0.08059699088335037, 0.08059699088335037], [0.10463383793830872, 0.30816397070884705, 0.30816397070884705, 0.27690401673316956, 0.002134238136932254], [0.023839132860302925, 0.6899958252906799, 0.023839132860302925, 0.20391525328159332, 0.05841064453125], [0.4462435245513916, 0.4462435245513916, 0.07511137425899506, 0.03231411427259445, 8.745601371629164e-05], [0.07612919062376022, 0.33194008469581604, 0.04068690910935402, 0.21930372714996338, 0.33194008469581604], [0.6078789830207825, 0.03304717689752579, 0.30821558833122253, 0.03304717689752579, 0.01781102828681469], [0.08714707940816879, 0.5393972396850586, 0.19332218170166016, 0.09298640489578247, 0.08714707940816879], [0.10676737874746323, 0.567489504814148, 0.014094233512878418, 0.10676737874746323, 0.20488153398036957], [0.13039058446884155, 0.0983213484287262, 0.0983213484287262, 0.1267417073249817, 0.5462249517440796], [0.07789397984743118, 0.09975778311491013, 0.10657978802919388, 0.6091886162757874, 0.10657978802919388], [0.01335282064974308, 0.13028261065483093, 0.13028261065483093, 0.6867143511772156, 0.03936763480305672], [0.3178035020828247, 0.26813721656799316, 0.09594254195690155, 0.00031321810092777014, 0.3178035020828247], [0.7809900641441345, 0.016690783202648163, 0.016690783202648163, 0.08577330410480499, 0.09985499829053879], [0.062311142683029175, 0.02533593215048313, 0.444027841091156, 0.444027841091156, 0.024297188967466354], [0.8529645800590515, 0.012697994709014893, 0.000280236970866099, 0.13262693583965302, 0.0014302160125225782], [0.642979085445404, 0.04117615520954132, 0.14909248054027557, 0.017659762874245644, 0.14909248054027557], [0.434813529253006, 0.03159462288022041, 0.434813529253006, 0.007581470999866724, 0.09119685739278793], [0.38571682572364807, 0.08256549388170242, 0.14822573959827423, 0.14822573959827423, 0.23526625335216522], [8.136651558743324e-06, 0.0021094295661896467, 0.3280632197856903, 0.3417559564113617, 0.3280632197856903], [0.4287645220756531, 0.4287645220756531, 0.007536175660789013, 0.007230866234749556, 0.12770392000675201], [0.014957873150706291, 0.004277929663658142, 0.9656189680099487, 0.014957873150706291, 0.00018739388906396925], [0.004107180051505566, 0.9452917575836182, 0.010551054030656815, 0.004107180051505566, 0.03594270348548889], [0.07945922017097473, 0.004747618921101093, 0.9121755361557007, 0.00105739152058959, 0.0025602837558835745], [0.8539316058158875, 0.0001443989749532193, 0.1281151920557022, 0.01766440086066723, 0.0001443989749532193], [0.1132916584610939, 0.7574335932731628, 0.01481789629906416, 0.0572284460067749, 0.0572284460067749], [0.005929436534643173, 0.005929436534643173, 0.6317350268363953, 0.34968632459640503, 0.006719809025526047], [0.20555263757705688, 0.0026633066590875387, 0.5852043032646179, 0.20555263757705688, 0.0010270669590681791], [0.008363662287592888, 0.7226304411888123, 0.16787509620189667, 0.050565384328365326, 0.050565384328365326], [0.0703895092010498, 0.0703895092010498, 0.12285152077674866, 0.730374813079834, 0.005994652397930622], [0.061197832226753235, 0.2151300311088562, 0.551676332950592, 0.08599794656038284, 0.08599794656038284], [0.01612045243382454, 0.01612045243382454, 0.04813551530241966, 0.9166299700737, 0.002993595087900758], [0.07010359317064285, 0.07010359317064285, 0.046966321766376495, 0.7340893149375916, 0.07873716950416565], [0.21517695486545563, 0.09746783971786499, 0.06454824656248093, 0.21517695486545563, 0.4076300859451294], [0.002682218560948968, 0.34588754177093506, 0.26194119453430176, 0.043601494282484055, 0.34588754177093506], [0.006481103599071503, 0.02734912373125553, 0.7433574795722961, 0.11140613257884979, 0.11140613257884979], [0.024432724341750145, 0.3432462215423584, 0.26849544048309326, 0.31612247228622437, 0.04770314693450928], [0.5463441014289856, 0.0011899902019649744, 0.032057393342256546, 0.0011899902019649744, 0.419218510389328], [0.7919554710388184, 0.1859123855829239, 0.012931011617183685, 0.004600508138537407, 0.004600508138537407], [0.18226821720600128, 0.05236787348985672, 0.6514685153961182, 0.10641088336706161, 0.007484571076929569], [0.004124654922634363, 0.49468448758125305, 0.16028368473052979, 0.004124654922634363, 0.3367825448513031], [0.23732414841651917, 0.24686449766159058, 0.4098398983478546, 0.02835230715572834, 0.07761920988559723], [0.00010455952724441886, 0.024546373635530472, 0.40869295597076416, 0.0047194091603159904, 0.5619366765022278], [0.005456738639622927, 0.281608909368515, 0.003240808378905058, 0.6830564737319946, 0.026637069880962372], [0.001758240512572229, 0.0014705696376040578, 0.47480738162994385, 0.0471564345061779, 0.47480738162994385], [0.13864462077617645, 0.14649470150470734, 0.14649470150470734, 0.00025366529007442296, 0.568112313747406], [0.22021009027957916, 0.01679539866745472, 0.7455384135246277, 0.0006607220857404172, 0.01679539866745472], [0.001543358783237636, 0.010244131088256836, 0.4907877445220947, 0.4907877445220947, 0.006637034006416798], [0.0011707503581419587, 0.21951717138290405, 0.0011707503581419587, 0.03146611899137497, 0.7466752529144287], [0.15679681301116943, 0.1128431111574173, 0.1128431111574173, 0.4523908793926239, 0.1651260256767273], [0.3624098598957062, 0.14714214205741882, 0.14714214205741882, 0.1732921600341797, 0.17001375555992126], [0.20176619291305542, 0.19672158360481262, 0.1976546049118042, 0.20209144055843353, 0.20176619291305542], [0.008751027286052704, 0.01624264568090439, 0.7440490126609802, 0.11547864973545074, 0.11547864973545074], [0.23648075759410858, 0.0325087234377861, 0.2208886742591858, 0.2208886742591858, 0.28923314809799194], [0.005395372398197651, 0.23597781360149384, 0.37884730100631714, 0.37884730100631714, 0.0009321596589870751], [0.5156811475753784, 0.01752910204231739, 0.011746305041015148, 0.011746305041015148, 0.4432971775531769], [0.7327392101287842, 0.05121736228466034, 0.05121736228466034, 0.16060492396354675, 0.004221165087074041], [0.018150782212615013, 0.24574428796768188, 0.018150782212615013, 0.7177582383155823, 0.00019586490816436708], [0.7765638828277588, 0.12015040218830109, 0.01655781827867031, 0.01655781827867031, 0.0701700821518898], [0.24061672389507294, 0.02783757634460926, 0.004484077449887991, 0.36353081464767456, 0.36353081464767456], [0.025196878239512444, 0.4629133343696594, 0.000697701470926404, 0.04827880859375, 0.4629133343696594], [0.00012931812671013176, 0.7909690737724304, 0.007651558145880699, 0.007651558145880699, 0.19359850883483887], [0.08347736299037933, 0.11584717035293579, 0.041156645864248276, 0.11584717035293579, 0.6436716914176941], [0.4070304334163666, 0.12266043573617935, 0.00024143861082848161, 0.4070304334163666, 0.06303732097148895], [0.04391811043024063, 0.47116953134536743, 0.15690390765666962, 0.15690390765666962, 0.1711045801639557], [0.061166442930698395, 0.004345557186752558, 0.004345557186752558, 0.009271555580198765, 0.9208709001541138], [0.43569493293762207, 0.20680595934391022, 0.1087057888507843, 0.14008748531341553, 0.1087057888507843], [0.5851275324821472, 0.07733031362295151, 0.04885019361972809, 0.1443459540605545, 0.1443459540605545], [0.0010818032315000892, 0.4868197441101074, 0.014324725605547428, 0.0010818032315000892, 0.49669191241264343], [0.03314582258462906, 0.0010027753887698054, 0.005382918752729893, 0.959465742111206, 0.0010027753887698054], [0.12385912984609604, 0.015038075856864452, 0.015038075856864452, 0.8453684449195862, 0.0006962317856959999], [0.0002900133840739727, 0.5432780981063843, 0.08598499000072479, 0.37015679478645325, 0.0002900133840739727], [0.029401404783129692, 0.09894280880689621, 0.029401404783129692, 0.007653549779206514, 0.8346007466316223], [0.023132482543587685, 0.0014750874834135175, 0.03772041201591492, 0.2945074439048767, 0.6431645750999451], [0.7390785813331604, 0.11568843573331833, 0.00175547378603369, 0.11568843573331833, 0.02778906561434269], [0.14568127691745758, 0.5352774262428284, 0.0918898656964302, 0.11357567459344864, 0.11357567459344864], [0.016033049672842026, 0.045421600341796875, 0.15276455879211426, 0.7697476744651794, 0.016033049672842026], [0.21565507352352142, 0.011652250774204731, 0.17843620479106903, 0.5826042294502258, 0.011652250774204731], [0.25258001685142517, 0.019442817196249962, 0.04055564105510712, 0.019442817196249962, 0.6679786443710327], [0.053293462842702866, 0.32615411281585693, 0.30615121126174927, 0.008249975740909576, 0.30615121126174927], [0.04262629896402359, 0.003887798869982362, 0.44141021370887756, 0.07066543400287628, 0.44141021370887756], [0.15711136162281036, 0.05698943883180618, 0.01104468759149313, 0.6177431344985962, 0.15711136162281036], [0.04505821689963341, 0.012085904367268085, 0.000441196549218148, 0.012085904367268085, 0.9303287863731384], [0.45855239033699036, 0.45855239033699036, 0.015603996813297272, 0.012291519902646542, 0.054999709129333496], [0.0025309354532510042, 0.21427662670612335, 0.014520850032567978, 0.014520850032567978, 0.7541507482528687], [0.01009528711438179, 0.020344188436865807, 0.9224022030830383, 0.020344188436865807, 0.026814088225364685], [0.03624362498521805, 0.028458423912525177, 0.7417198419570923, 0.09678909182548523, 0.09678909182548523], [0.20894403755664825, 0.041345082223415375, 0.37000805139541626, 0.37000805139541626, 0.00969471875578165], [0.7452809810638428, 0.004181371070444584, 0.002242811257019639, 0.2460520714521408, 0.002242811257019639], [0.15895605087280273, 0.023195218294858932, 0.09057695418596268, 0.023195218294858932, 0.7040765881538391], [0.25408506393432617, 0.5828985571861267, 0.034324221312999725, 0.06434610486030579, 0.06434610486030579], [0.05447159335017204, 0.14298927783966064, 0.1584623157978058, 0.05447159335017204, 0.5896051526069641], [0.8427977561950684, 0.0029858406633138657, 0.012277086265385151, 0.13895352184772491, 0.0029858406633138657], [0.0242562647908926, 0.0242562647908926, 0.6148516535758972, 0.001269398839212954, 0.33536645770072937], [0.36210519075393677, 0.03213698789477348, 0.005438345484435558, 0.5770004391670227, 0.02331906370818615], [0.043937958776950836, 0.12215780466794968, 0.010583465918898582, 0.41166040301322937, 0.41166040301322937], [0.006307817995548248, 0.2225024551153183, 0.2225024551153183, 0.5212684869766235, 0.027418823912739754], [0.03456129506230354, 0.03456129506230354, 0.24733340740203857, 0.5908691883087158, 0.09267482906579971], [0.147373229265213, 0.4011511504650116, 0.4011511504650116, 0.02040083147585392, 0.029923608526587486], [0.06545527279376984, 0.24554727971553802, 0.24554727971553802, 0.08789056539535522, 0.35555964708328247], [0.5991086959838867, 0.06786958873271942, 0.12730549275875092, 0.07841069251298904, 0.12730549275875092], [0.10615955293178558, 0.040329527109861374, 0.002827174961566925, 0.8478565812110901, 0.002827174961566925], [0.0004059172933921218, 0.13822788000106812, 0.7218407392501831, 0.13822788000106812, 0.0012976290890946984], [0.0005058205570094287, 0.06641912460327148, 0.19446368515491486, 0.19446368515491486, 0.5441476702690125], [0.08312350511550903, 0.40924376249313354, 0.14148427546024323, 0.2830249071121216, 0.08312350511550903], [0.07603101432323456, 0.05079761520028114, 0.07603101432323456, 0.5272654891014099, 0.2698749303817749], [0.2817670404911041, 0.5932118892669678, 0.029039425775408745, 0.029039425775408745, 0.0669422596693039], [0.014851939864456654, 0.002198366215452552, 0.8342398405075073, 0.07435491681098938, 0.07435491681098938], [0.3403531014919281, 0.2016606479883194, 0.3403531014919281, 0.013376642018556595, 0.1042565107345581], [0.9881872534751892, 0.0003336273948661983, 0.004629164468497038, 0.0022208516020327806, 0.004629164468497038], [0.06064377725124359, 0.33963048458099365, 0.19853125512599945, 0.33963048458099365, 0.06156395748257637], [0.008570530451834202, 0.2855689823627472, 0.2601214349269867, 0.2855689823627472, 0.1601700335741043], [0.0669916495680809, 0.19031237065792084, 0.008826910518109798, 0.5435566902160645, 0.19031237065792084], [0.544199526309967, 0.4332725703716278, 0.00980251096189022, 0.00636270409449935, 0.00636270409449935], [0.018331537023186684, 0.08904298394918442, 0.4461345076560974, 0.0003565539082046598, 0.4461345076560974], [0.16269560158252716, 0.16269560158252716, 0.001836674753576517, 0.6082292795181274, 0.06454283744096756], [0.4507046043872833, 0.4629532992839813, 0.023763762786984444, 0.023763762786984444, 0.03881464898586273], [0.3628690242767334, 0.14656472206115723, 0.2442367523908615, 0.002092761220410466, 0.2442367523908615], [0.4256632626056671, 0.019833434373140335, 0.4256632626056671, 0.0026311601977795362, 0.12620888650417328], [0.11288709193468094, 0.11288709193468094, 0.1279820203781128, 0.2845304608345032, 0.36171337962150574], [0.22812850773334503, 0.013497217558324337, 0.013497217558324337, 0.7169243693351746, 0.02795267477631569], [0.3968217074871063, 0.20212064683437347, 0.0023134287912398577, 0.3968217074871063, 0.0019224632997065783], [0.2223873883485794, 0.2223873883485794, 0.04971878603100777, 0.3195277154445648, 0.1859787553548813], [0.4313492774963379, 0.040468525141477585, 0.012714588083326817, 0.08411835134029388, 0.4313492774963379], [0.04074247553944588, 0.4286065697669983, 0.04598229005932808, 0.05606207996606827, 0.4286065697669983], [0.21151752769947052, 0.3053523004055023, 0.3053523004055023, 0.009670596569776535, 0.16810724139213562], [0.4806639552116394, 0.0012262359960004687, 0.4806639552116394, 0.00024082258460111916, 0.037204962223768234], [0.003314615460112691, 0.01859126053750515, 0.01859126053750515, 0.9580508470535278, 0.0014520614640787244], [0.004594889003783464, 0.0791066512465477, 0.0791066512465477, 0.8338451981544495, 0.0033465339802205563], [0.49314379692077637, 0.10832033306360245, 0.01626642979681492, 0.19113467633724213, 0.19113467633724213], [0.1757843941450119, 0.014778858982026577, 0.1757843941450119, 0.4388667643070221, 0.19478559494018555], [0.2044311761856079, 0.29645776748657227, 0.24662648141384125, 0.24662648141384125, 0.005858059506863356], [0.004609657451510429, 0.4185096323490143, 0.09622037410736084, 0.09622037410736084, 0.38444000482559204], [0.22252877056598663, 0.22252877056598663, 0.11652330309152603, 0.28305763006210327, 0.15536151826381683], [0.15195034444332123, 0.3706015348434448, 0.27838560938835144, 0.15195034444332123, 0.04711213707923889], [0.45317381620407104, 0.15339168906211853, 0.15339168906211853, 0.05468391999602318, 0.18535897135734558], [0.6222788095474243, 0.23716981709003448, 0.04802083224058151, 0.04802083224058151, 0.04450972378253937], [0.05567175894975662, 0.035173431038856506, 0.2870057225227356, 0.33514338731765747, 0.2870057225227356], [0.21300187706947327, 0.1541229635477066, 0.21300187706947327, 0.2578212022781372, 0.16205212473869324], [0.11864466965198517, 0.07437657564878464, 0.07675246894359589, 0.07675246894359589, 0.6534738540649414], [0.016425717622041702, 0.1638047695159912, 0.24937333166599274, 0.1638047695159912, 0.40659141540527344], [0.20234036445617676, 0.20234036445617676, 0.22254392504692078, 0.13966064155101776, 0.23311464488506317], [0.4678500294685364, 0.0003312134649604559, 0.0059121763333678246, 0.058056533336639404, 0.4678500294685364], [0.005431787110865116, 0.023903511464595795, 0.027222387492656708, 0.9434328675270081, 9.441613656235859e-06], [0.13438214361667633, 0.6055383086204529, 0.05028547719120979, 0.1595085859298706, 0.05028547719120979], [0.00014197558630257845, 0.007258554920554161, 0.4954374432563782, 0.4954374432563782, 0.001724584843032062], [0.0006530869868583977, 0.004614145494997501, 0.004614145494997501, 0.07275300472974777, 0.917365550994873], [0.23591943085193634, 0.34470993280410767, 0.0011348429834470153, 0.34470993280410767, 0.07352588325738907], [0.6542885899543762, 0.10416842997074127, 0.08182157576084137, 0.08182157576084137, 0.07789981365203857], [0.0953180268406868, 0.008377215825021267, 0.6982971429824829, 0.0953180268406868, 0.10268956422805786], [0.4487433135509491, 0.26819896697998047, 0.013484193943440914, 0.0013745824107900262, 0.26819896697998047], [0.0019938081968575716, 0.2729913294315338, 0.2729913294315338, 0.17590850591659546, 0.27611497044563293], [0.05316827446222305, 0.026937110349535942, 0.28299206495285034, 0.3539104759693146, 0.28299206495285034], [0.01817476935684681, 0.3112458288669586, 0.2604776918888092, 0.3112458288669586, 0.09885583817958832], [0.10140533000230789, 0.03067881427705288, 0.03067881427705288, 0.8128427863121033, 0.0243943240493536], [0.001670247525908053, 0.001670247525908053, 0.7114295959472656, 0.2345389723777771, 0.05069088935852051], [0.372472882270813, 0.19696733355522156, 0.05350508913397789, 0.0045818001963198185, 0.372472882270813], [0.1840842366218567, 0.14706191420555115, 0.6207833886146545, 0.024035224691033363, 0.024035224691033363], [0.26782047748565674, 0.01908685453236103, 0.353083074092865, 0.006926500238478184, 0.353083074092865], [0.05319740250706673, 0.8502877354621887, 0.05319740250706673, 0.04293149709701538, 0.000385997467674315], [0.6355901956558228, 0.0009009265340864658, 0.0009009265340864658, 0.03007586859166622, 0.33253204822540283], [0.008060039021074772, 0.0008130319183692336, 0.04348846897482872, 0.0008130319183692336, 0.946825385093689], [0.6172853112220764, 0.0893593430519104, 0.2775706350803375, 0.00789235346019268, 0.00789235346019268], [0.035638537257909775, 0.19386105239391327, 0.3711487352848053, 0.028202969580888748, 0.3711487352848053], [0.13328921794891357, 0.07179958373308182, 0.02511715143918991, 0.011780903674662113, 0.7580130696296692], [0.321798712015152, 0.2738596498966217, 0.2738596498966217, 0.0051482063718140125, 0.1253337562084198], [0.19941438734531403, 0.3309839963912964, 0.059582117944955826, 0.19941438734531403, 0.21060508489608765], [0.40934520959854126, 0.40934520959854126, 0.15906912088394165, 0.0003351079358253628, 0.021905362606048584], [0.11800748854875565, 0.11800748854875565, 0.5111110210418701, 0.23299463093280792, 0.01987936720252037], [0.038258664309978485, 0.6158162355422974, 0.3003547787666321, 0.038258664309978485, 0.007311617955565453], [0.30625492334365845, 0.12283962219953537, 0.0014229787047952414, 0.30625492334365845, 0.26322758197784424], [0.4617879092693329, 0.17792916297912598, 0.17792916297912598, 0.1766539067029953, 0.005699848290532827], [0.423749178647995, 0.423749178647995, 0.08553535491228104, 0.009996849112212658, 0.0569695420563221], [0.007625334430485964, 0.2885833978652954, 0.2369784414768219, 0.22983436286449432, 0.2369784414768219], [0.00852087140083313, 0.5086172223091125, 0.354229599237442, 0.00852087140083313, 0.12011143565177917], [0.22626401484012604, 0.039315346628427505, 0.3489081561565399, 0.22626401484012604, 0.159248486161232], [0.05193047598004341, 0.01029517687857151, 0.07217496633529663, 0.7934244275093079, 0.07217496633529663], [0.3646785020828247, 0.03240125626325607, 0.22240275144577026, 0.015839001163840294, 0.3646785020828247], [0.123507559299469, 0.123507559299469, 0.35328179597854614, 0.00124411191791296, 0.39845898747444153], [0.473226934671402, 0.04557812213897705, 0.006361633073538542, 0.0016064507653936744, 0.473226934671402], [1.3426333680399694e-05, 0.043805573135614395, 0.467072457075119, 0.467072457075119, 0.02203609235584736], [0.022514628246426582, 0.22066347301006317, 0.11628403514623642, 0.22066347301006317, 0.419874370098114], [0.018675614148378372, 0.0023330210242420435, 0.10048987716436386, 0.0023330210242420435, 0.876168429851532], [0.04947648569941521, 0.44102054834365845, 0.0858536884188652, 0.0858536884188652, 0.33779555559158325], [0.00012500808225013316, 0.0012233752058818936, 0.0026934079360216856, 0.49797913432121277, 0.49797913432121277], [0.4656459391117096, 0.0011453904444351792, 0.005803507752716541, 0.4656459391117096, 0.06175927817821503], [0.2323889136314392, 0.2323889136314392, 0.09570346772670746, 0.007058640941977501, 0.4324599802494049], [0.06757882237434387, 0.3417501449584961, 0.3417501449584961, 0.02484768070280552, 0.22407321631908417], [0.14387598633766174, 0.04000592231750488, 0.04000592231750488, 0.17891956865787506, 0.5971925854682922], [0.002550063654780388, 0.002550063654780388, 0.02262594923377037, 0.906468391418457, 0.06580546498298645], [0.2420545369386673, 0.010575682856142521, 0.203018456697464, 0.203018456697464, 0.34133288264274597], [0.15192799270153046, 0.09591378271579742, 0.0006270669400691986, 0.014510554261505604, 0.7370206117630005], [0.2442988157272339, 0.752936601638794, 0.0008608683128841221, 0.0008608683128841221, 0.0010429311078041792], [0.13761021196842194, 0.4075486958026886, 0.03901698812842369, 0.008275452069938183, 0.4075486958026886], [0.009929069317877293, 0.04224717989563942, 0.3585897386074066, 0.04224717989563942, 0.5469868183135986], [0.3127492070198059, 0.3127492070198059, 0.03199539706110954, 0.21742485463619232, 0.12508131563663483], [0.1258377879858017, 0.0063880933448672295, 0.6933862566947937, 0.16799969971179962, 0.0063880933448672295], [0.023742584511637688, 0.0014392745215445757, 0.023742584511637688, 0.0001219582263729535, 0.9509537220001221], [0.04276919364929199, 0.04838451370596886, 0.04276919364929199, 0.40232938528060913, 0.4637477695941925], [0.10777163505554199, 0.052113015204668045, 0.23272767663002014, 0.37466001510620117, 0.23272767663002014], [0.0009386288002133369, 0.11249755322933197, 0.003818721044808626, 0.0009386288002133369, 0.8818065524101257], [0.8016541004180908, 0.001052612904459238, 0.014505203813314438, 0.17770355939865112, 0.005084526725113392], [0.23062488436698914, 0.10718550533056259, 0.09216786175966263, 0.46283629536628723, 0.10718550533056259], [0.657039999961853, 0.008086062967777252, 0.3121761381626129, 0.008086062967777252, 0.014611768536269665], [0.18864767253398895, 0.3938474953174591, 0.3938474953174591, 9.594166476745158e-05, 0.0235613863915205], [0.6207874417304993, 0.3287796676158905, 0.02445334941148758, 0.0015262886881828308, 0.02445334941148758], [0.01591629721224308, 0.42636606097221375, 0.03953603655099869, 0.42636606097221375, 0.09181558340787888], [0.006299138534814119, 0.39552727341651917, 0.024496344849467278, 0.5673781633377075, 0.006299138534814119], [0.31967657804489136, 0.29911911487579346, 0.0003090969694312662, 0.31967657804489136, 0.06121867150068283], [0.0756310448050499, 0.3802146911621094, 0.28819501399993896, 0.18032822012901306, 0.0756310448050499], [0.03435825929045677, 0.07129979133605957, 0.165179044008255, 0.03435825929045677, 0.6948046088218689], [0.008138270117342472, 0.30296605825424194, 0.6800421476364136, 0.008138270117342472, 0.0007152633043006063], [0.851390540599823, 0.0010946535039693117, 0.004453247878700495, 0.0010946535039693117, 0.14196684956550598], [0.07651309669017792, 0.16433122754096985, 0.16433122754096985, 0.46336469054222107, 0.13145972788333893], [0.7706983685493469, 0.051907315850257874, 0.07620075345039368, 0.051907315850257874, 0.04928620532155037], [0.5270664691925049, 0.06277035176753998, 0.25668227672576904, 0.0907105877995491, 0.06277035176753998], [0.0012516160495579243, 0.41312238574028015, 0.0012516160495579243, 0.4300994873046875, 0.15427491068840027], [0.05916257202625275, 0.16954371333122253, 0.020245874300599098, 0.5815041065216064, 0.16954371333122253], [0.5169321298599243, 0.1451549232006073, 0.1451549232006073, 0.05119456723332405, 0.14156347513198853], [0.0008201002492569387, 0.3164134919643402, 0.3506963551044464, 0.3164134919643402, 0.015656577423214912], [0.21276412904262543, 0.02668522484600544, 0.6588627099990845, 0.02668522484600544, 0.07500269263982773], [0.5794872045516968, 0.17923279106616974, 0.10609768331050873, 0.02908462844789028, 0.10609768331050873], [0.11281118541955948, 0.21203568577766418, 0.49309587478637695, 0.06924610584974289, 0.11281118541955948], [0.006870930083096027, 0.05491165816783905, 0.8955932259559631, 0.00026978651294484735, 0.04235443100333214], [0.100258968770504, 0.26576459407806396, 0.0014886260032653809, 0.3162439167499542, 0.3162439167499542], [0.21819628775119781, 0.5425105094909668, 0.020921627059578896, 0.21819628775119781, 0.00017532137280795723], [0.4264647364616394, 0.06413634866476059, 0.08102697134017944, 0.06413634866476059, 0.36423563957214355], [4.785873898072168e-05, 0.002005218993872404, 0.49864938855171204, 0.0006482636672444642, 0.49864938855171204], [0.1156114712357521, 0.009946014732122421, 0.1156114712357521, 0.7379284501075745, 0.020902590826153755], [0.4133576452732086, 0.0008755709859542549, 0.0017917025834321976, 0.17061747610569, 0.4133576452732086], [0.00035267212660983205, 0.01717122085392475, 0.0005237867590039968, 0.0005237867590039968, 0.9814286231994629], [0.22761131823062897, 0.5304383635520935, 0.0007274919771589339, 0.22761131823062897, 0.013611537404358387], [0.00022402752074413002, 0.10831790417432785, 0.8689080476760864, 0.02232595719397068, 0.00022402752074413002], [0.022714383900165558, 0.015105890110135078, 0.015105890110135078, 0.28461554646492004, 0.6624582409858704], [0.9452425837516785, 0.009163823910057545, 0.014227834530174732, 0.009163823910057545, 0.02220185101032257], [0.42312091588974, 0.09428008645772934, 0.09428008645772934, 0.008295887149870396, 0.3800230026245117], [0.46252521872520447, 0.004865678958594799, 0.46252521872520447, 0.01614653319120407, 0.0539373904466629], [0.18481241166591644, 0.18887822329998016, 0.42359429597854614, 0.017902636900544167, 0.18481241166591644], [0.0821467712521553, 0.0821467712521553, 0.20030485093593597, 0.03611166030168533, 0.5992898941040039], [0.0175924189388752, 0.33398494124412537, 0.33398494124412537, 0.31194818019866943, 0.0024895428214222193], [0.3658837676048279, 0.0028804605826735497, 0.5822464823722839, 0.0028804605826735497, 0.04610881954431534], [0.03834459185600281, 0.18207009136676788, 0.583384096622467, 0.03834459185600281, 0.15785664319992065], [0.015918845310807228, 0.3404194414615631, 0.3404194414615631, 0.0819980725646019, 0.2212441861629486], [0.0037726720329374075, 0.12083522975444794, 0.3772301971912384, 0.24908094108104706, 0.24908094108104706], [0.017654268071055412, 0.3696700632572174, 0.03786159306764603, 0.2051440179347992, 0.3696700632572174], [0.003700238186866045, 0.03021610900759697, 0.46804380416870117, 0.029996037483215332, 0.46804380416870117], [0.5645177364349365, 0.09847766160964966, 0.10118264704942703, 0.1256801187992096, 0.11014176160097122], [0.46320462226867676, 0.248775914311409, 0.03719005361199379, 0.0020533958449959755, 0.248775914311409], [0.3684675991535187, 0.23413318395614624, 0.23413318395614624, 0.031331371515989304, 0.13193461298942566], [0.010430318303406239, 0.05095093697309494, 0.39230024814605713, 0.4953675866127014, 0.05095093697309494], [0.017656393349170685, 0.26031365990638733, 0.07674409449100494, 0.07674409449100494, 0.5685417056083679], [0.03420906141400337, 0.01974157616496086, 0.01974157616496086, 0.48675334453582764, 0.4395544230937958], [0.6282985210418701, 0.00014538342657033354, 0.019797438755631447, 0.00014538342657033354, 0.35161328315734863], [0.06069638207554817, 0.2556748390197754, 0.2556748390197754, 0.27421292662620544, 0.15374106168746948], [0.02871408686041832, 0.021178720518946648, 0.0021902911830693483, 0.9410157799720764, 0.006901170592755079], [0.5288500785827637, 0.009252944961190224, 0.0014181598089635372, 0.009252944961190224, 0.4512258768081665], [0.003256379859521985, 0.003256379859521985, 0.7402921319007874, 0.03378884866833687, 0.21940627694129944], [0.002732998225837946, 0.3070838749408722, 0.22941045463085175, 0.2313622087240219, 0.22941045463085175], [0.39210763573646545, 0.4473680853843689, 0.008965062908828259, 0.14259423315525055, 0.008965062908828259], [0.3680945634841919, 0.03290223702788353, 0.060521580278873444, 0.17038710415363312, 0.3680945634841919], [0.2934343218803406, 0.04045705497264862, 0.2680532932281494, 0.2934343218803406, 0.10462100803852081], [0.008566207252442837, 0.050405941903591156, 0.469292551279068, 0.469292551279068, 0.002442685654386878], [0.004227795172482729, 0.010256200097501278, 0.004227795172482729, 0.9795443415641785, 0.0017438475042581558], [0.01615726202726364, 0.0036491183564066887, 0.9547834396362305, 0.009252899326384068, 0.01615726202726364], [0.06687570363283157, 0.8495727181434631, 0.061171043664216995, 0.011190295219421387, 0.011190295219421387], [0.0678519681096077, 0.0020847367122769356, 0.690431535243988, 0.1717798113822937, 0.0678519681096077], [0.011194737628102303, 0.0012931950623169541, 0.01691657491028309, 0.4852977395057678, 0.4852977395057678], [0.06247619539499283, 0.49626514315605164, 0.3410450220108032, 0.06247619539499283, 0.03773745149374008], [0.10510815680027008, 0.04090424254536629, 0.5069078803062439, 0.17353984713554382, 0.17353984713554382], [0.00048573993262834847, 0.03042774833738804, 0.011555657722055912, 0.011555657722055912, 0.9459753036499023], [0.010557926259934902, 0.844989001750946, 0.0007820763858035207, 0.010557926259934902, 0.1331130862236023], [0.0766076147556305, 0.0766076147556305, 0.4785636365413666, 0.14156574010849, 0.22665540874004364], [0.326957106590271, 0.17284363508224487, 0.326957106590271, 0.017674528062343597, 0.15556764602661133], [0.0015343541745096445, 0.3368043899536133, 0.13043229281902313, 0.5296946167945862, 0.0015343541745096445], [0.001963753253221512, 0.001963753253221512, 0.004544381517916918, 0.09216761589050293, 0.8993604183197021], [0.03800268471240997, 0.39039701223373413, 0.015485669486224651, 0.39039701223373413, 0.16571763157844543], [0.40717485547065735, 0.14797906577587128, 0.40717485547065735, 0.03150557354092598, 0.006165686529129744], [0.9219849109649658, 0.00593995675444603, 0.05828946828842163, 0.00689283013343811, 0.00689283013343811], [0.35285741090774536, 0.35285741090774536, 0.0038231220096349716, 0.22084151208400726, 0.06962049007415771], [0.034811485558748245, 0.12652228772640228, 0.41775059700012207, 0.0031651132740080357, 0.41775059700012207], [0.1257491409778595, 0.176364004611969, 0.00924632977694273, 0.5122765302658081, 0.176364004611969], [0.0005044457502663136, 0.09607857465744019, 0.0005044457502663136, 0.0010676047531887889, 0.9018449187278748], [0.10966676473617554, 0.3643856942653656, 0.10966676473617554, 0.06571410596370697, 0.35056668519973755], [0.9616435170173645, 0.001336670946329832, 6.885381299071014e-05, 0.00042804545955732465, 0.03652280941605568], [0.1052137166261673, 0.42797720432281494, 0.03708076477050781, 0.42797720432281494, 0.0017511380137875676], [8.392511517740786e-05, 0.2806544005870819, 0.43580037355422974, 0.00280686654150486, 0.2806544005870819], [0.004316668026149273, 0.3306768834590912, 0.32828545570373535, 0.3306768834590912, 0.006044092122465372], [0.0912344679236412, 0.24667403101921082, 0.24667403101921082, 0.326572984457016, 0.08884449303150177], [0.5332838296890259, 0.03561762347817421, 0.0038640236016362906, 0.39161694049835205, 0.03561762347817421], [0.10665600001811981, 0.10665600001811981, 0.1630803644657135, 0.4849472641944885, 0.13866041600704193], [0.020441053435206413, 0.030429163947701454, 0.6077092885971069, 0.102891705930233, 0.238528773188591], [0.2582007050514221, 0.18346603214740753, 0.2929745614528656, 0.2582007050514221, 0.007157977670431137], [0.8404005169868469, 0.03480425849556923, 0.038238927721977234, 0.0483173131942749, 0.038238927721977234], [0.005172146949917078, 0.48333802819252014, 0.48333802819252014, 0.016481801867485046, 0.011669967323541641], [0.08855828642845154, 0.3126142919063568, 0.1810220181941986, 0.3126142919063568, 0.10519114881753922], [0.10824618488550186, 0.3516151010990143, 0.009937621653079987, 0.023871947079896927, 0.5063291192054749], [0.437486469745636, 0.004707880783826113, 0.036921046674251556, 0.08339819312095642, 0.437486469745636], [0.6398595571517944, 0.300793319940567, 0.044206976890563965, 0.008881825022399426, 0.006258352659642696], [0.15226148068904877, 0.38764452934265137, 0.056093744933605194, 0.01635570637881756, 0.38764452934265137], [0.2212224155664444, 0.01527950819581747, 0.31465426087379456, 0.31465426087379456, 0.13418953120708466], [0.16135719418525696, 0.0497819148004055, 0.019115425646305084, 0.17493630945682526, 0.5948092341423035], [0.012950525619089603, 0.009278600104153156, 0.3087250590324402, 0.659767210483551, 0.009278600104153156], [0.04715566709637642, 0.4536875784397125, 0.024482043460011482, 0.02098715491592884, 0.4536875784397125], [0.032247692346572876, 0.032247692346572876, 0.2209140807390213, 0.3746354877948761, 0.33995509147644043], [0.045699842274188995, 0.005629998631775379, 0.4740832448005676, 0.0005036499351263046, 0.4740832448005676], [0.0005805122782476246, 0.046772852540016174, 0.780949056148529, 0.0005805122782476246, 0.17111703753471375], [0.0009381076088175178, 0.000126280530821532, 0.49943286180496216, 0.49943286180496216, 6.99672382324934e-05], [0.0030315418262034655, 0.24887818098068237, 0.25871896743774414, 0.2306523323059082, 0.25871896743774414], [0.42295295000076294, 0.42295295000076294, 0.0465020053088665, 0.06284666806459427, 0.04474543035030365], [0.12850543856620789, 0.10323233157396317, 0.20568522810935974, 0.10323233157396317, 0.45934468507766724], [0.07256830483675003, 0.6575272679328918, 0.10045482218265533, 0.06899479776620865, 0.10045482218265533], [0.0038388471584767103, 0.022481709718704224, 0.0038388471584767103, 0.021403837949037552, 0.9484368562698364], [0.3381813168525696, 0.021364377811551094, 0.021364377811551094, 0.3610120415687561, 0.2580778896808624], [0.001129570067860186, 0.04497874155640602, 0.4765644669532776, 0.4765644669532776, 0.0007627954473719001], [0.7925304770469666, 0.10341311246156693, 9.976771980291232e-05, 0.0005434845224954188, 0.10341311246156693], [0.059369903057813644, 0.6750581860542297, 0.01817804016172886, 0.22921575605869293, 0.01817804016172886], [0.07637878507375717, 0.028241880238056183, 0.08976531028747559, 0.08976531028747559, 0.7158488035202026], [0.03642762824892998, 0.01993667520582676, 0.4608476459980011, 0.03642762824892998, 0.4463604688644409], [0.01640676148235798, 0.4850839376449585, 0.4233774244785309, 0.06721295416355133, 0.00791892409324646], [0.1932823359966278, 0.5626226663589478, 0.0046047549694776535, 0.0462079718708992, 0.1932823359966278], [0.09635967016220093, 0.4196142852306366, 0.04479709267616272, 0.09635967016220093, 0.342869371175766], [0.27743324637413025, 0.34115785360336304, 0.0225700531154871, 0.0225700531154871, 0.336268812417984], [0.001962872687727213, 0.001962872687727213, 0.09282955527305603, 0.3034568727016449, 0.5997878909111023], [0.49305400252342224, 0.006581125780940056, 0.49305400252342224, 0.004962814971804619, 0.0023480041418224573], [0.17537017166614532, 0.05719924345612526, 0.07797379791736603, 0.34472841024398804, 0.34472841024398804], [0.06812284886837006, 0.017101775854825974, 0.8659820556640625, 0.024396665394306183, 0.024396665394306183], [0.0280934888869524, 0.034316111356019974, 0.0280934888869524, 0.8071014881134033, 0.10239540040493011], [0.27079087495803833, 0.006139953155070543, 0.006139953155070543, 0.7113476991653442, 0.0055815232917666435], [0.7213661670684814, 0.01301945187151432, 0.23202012479305267, 0.016797084361314774, 0.016797084361314774], [0.13146434724330902, 0.012028681114315987, 0.4230206310749054, 0.4230206310749054, 0.010465740226209164], [0.06995142996311188, 0.0012394001241773367, 0.46212679147720337, 0.004555446095764637, 0.46212679147720337], [0.0011857337085530162, 0.0011857337085530162, 0.04054999724030495, 0.044525451958179474, 0.9125531315803528], [0.5209408402442932, 0.12917044758796692, 0.04881873354315758, 0.1505350023508072, 0.1505350023508072], [0.0001915462635224685, 0.47343504428863525, 0.011493544094264507, 0.47343504428863525, 0.04144488275051117], [0.34100741147994995, 0.34100741147994995, 0.1507243812084198, 0.02768356166779995, 0.1395772099494934], [0.968693733215332, 0.0003833658993244171, 0.0026102589908987284, 0.027929265052080154, 0.0003833658993244171], [0.4482801854610443, 0.10141655057668686, 0.4482801854610443, 0.00035766942892223597, 0.0016653751954436302], [0.004178766626864672, 0.29787078499794006, 0.02697170525789261, 0.485780268907547, 0.18519848585128784], [0.10245878994464874, 0.13097380101680756, 0.010186494328081608, 0.010186494328081608, 0.7461943626403809], [0.02696489356458187, 0.6711224317550659, 0.02696489356458187, 0.23179146647453308, 0.043156277388334274], [0.43839171528816223, 0.019366908818483353, 0.17112129926681519, 0.18556006252765656, 0.18556006252765656], [0.39246082305908203, 0.10214465856552124, 0.48675763607025146, 0.009318430908024311, 0.009318430908024311], [7.724276656517759e-05, 7.724276656517759e-05, 0.1182621642947197, 0.8750574588775635, 0.0065259733237326145], [0.13441027700901031, 0.12894006073474884, 0.3645246624946594, 0.007600230630487204, 0.3645246624946594], [0.0867798700928688, 0.7988473176956177, 0.0867798700928688, 0.011363480240106583, 0.016229458153247833], [0.021146079525351524, 0.1099158525466919, 0.08436212688684464, 0.7002138495445251, 0.08436212688684464], [0.46564945578575134, 0.01487926859408617, 0.039205800741910934, 0.014616011641919613, 0.46564945578575134], [0.03378654643893242, 0.004164800513535738, 0.03378654643893242, 0.9170299172401428, 0.01123216561973095], [0.4631308615207672, 0.008621702902019024, 0.03634849190711975, 0.4631308615207672, 0.0287680234760046], [0.00883827731013298, 0.8610290288925171, 0.00883827731013298, 0.11616430431604385, 0.00513014430180192], [0.0382547602057457, 0.0382547602057457, 0.05172203108668327, 0.7166915535926819, 0.15507681667804718], [0.13040630519390106, 0.047114282846450806, 0.4481813311576843, 0.3271837532520294, 0.047114282846450806], [0.14904028177261353, 0.02787940576672554, 0.38329359889030457, 0.29074645042419434, 0.14904028177261353], [0.2159041315317154, 0.493850439786911, 0.2159041315317154, 0.07357457280158997, 0.0007666778983548284], [0.04421231895685196, 0.0011776681058108807, 0.7643100023269653, 0.11700946092605591, 0.07329051941633224], [0.02504359744489193, 0.5147725343704224, 0.3370036482810974, 0.09813658893108368, 0.02504359744489193], [0.42272689938545227, 0.42272689938545227, 0.11768188327550888, 0.024027112871408463, 0.012837088666856289], [0.6581998467445374, 0.15452474355697632, 0.03024863451719284, 0.0025020225439220667, 0.15452474355697632], [0.009545767679810524, 0.0891130119562149, 0.46843236684799194, 0.19333416223526, 0.23957470059394836], [0.21011343598365784, 0.21627917885780334, 0.2443009912967682, 0.08500541746616364, 0.2443009912967682], [0.019184349104762077, 0.8362432718276978, 0.09125629812479019, 0.04738643765449524, 0.00592963770031929], [0.02944405935704708, 0.7582873106002808, 0.02944405935704708, 0.05119317024946213, 0.13163143396377563], [0.11488855630159378, 0.22626005113124847, 0.4596061706542969, 0.09962262958288193, 0.09962262958288193], [0.3928660452365875, 0.10673926025629044, 0.00022152859310153872, 0.1073070764541626, 0.3928660452365875], [4.6128152462188154e-05, 0.1660415381193161, 0.4138396680355072, 0.4138396680355072, 0.006232945714145899], [0.0002750290441326797, 0.0002750290441326797, 0.38714849948883057, 0.6051075458526611, 0.007193855941295624], [0.08413491398096085, 0.14147798717021942, 0.2428262084722519, 0.14147798717021942, 0.39008283615112305], [0.3453143537044525, 0.3453143537044525, 0.1539447158575058, 0.001451799995265901, 0.1539747416973114], [0.08625458180904388, 0.01580231450498104, 0.032892536371946335, 0.03949708864092827, 0.8255535364151001], [0.0020041540265083313, 0.05485883355140686, 0.0539587065577507, 0.0024537486024200916, 0.8867245316505432], [0.530143141746521, 0.17865338921546936, 0.002346962923184037, 0.2865094840526581, 0.002346962923184037], [0.0019049857510253787, 0.38635149598121643, 0.021145880222320557, 0.021145880222320557, 0.5694518089294434], [0.009607626125216484, 0.011013195849955082, 0.011013195849955082, 0.9005153179168701, 0.06785059720277786], [0.0829320102930069, 0.018855374306440353, 0.7250920534133911, 0.018855374306440353, 0.15426521003246307], [0.0007748915231786668, 0.4351961612701416, 0.4351961612701416, 0.08224648982286453, 0.0465863011777401], [0.09394585341215134, 0.015196390450000763, 0.030439047142863274, 0.43020936846733093, 0.43020936846733093], [0.11834798753261566, 0.6077645421028137, 0.11071156710386276, 0.11071156710386276, 0.05246436595916748], [0.44934237003326416, 0.008990224450826645, 0.44934237003326416, 0.0633736252784729, 0.028951525688171387], [0.035424232482910156, 0.013055544346570969, 0.6623137593269348, 0.013055544346570969, 0.2761509120464325], [0.01928756944835186, 0.15188756585121155, 0.761304497718811, 0.04823280870914459, 0.01928756944835186], [0.00036592985270544887, 0.32938462495803833, 0.1218637228012085, 0.31478598713874817, 0.23359975218772888], [0.19742725789546967, 0.42555516958236694, 0.046351246535778046, 0.19742725789546967, 0.13323912024497986], [0.09575853496789932, 0.1316431313753128, 0.33724841475486755, 0.3037067651748657, 0.1316431313753128], [0.23316609859466553, 0.30075299739837646, 0.13421984016895294, 0.30075299739837646, 0.031108079478144646], [0.16683954000473022, 0.0003370365593582392, 0.6003215312957764, 0.0003370365593582392, 0.23216485977172852], [0.010678501799702644, 0.04863841086626053, 0.026147672906517982, 0.457267701625824, 0.457267701625824], [0.01517637912184, 0.4284515678882599, 0.12764787673950195, 0.4284515678882599, 0.00027258344925940037], [0.018694648519158363, 0.4538099467754364, 0.4538099467754364, 0.03105449490249157, 0.042630910873413086], [0.09894873946905136, 0.002527456497773528, 0.03922215476632118, 0.09894873946905136, 0.7603529095649719], [0.46266552805900574, 0.03504451736807823, 0.03835466876626015, 0.0012697718339040875, 0.46266552805900574], [0.002111893380060792, 0.002111893380060792, 0.010457128286361694, 0.9667127132415771, 0.018606411293148994], [0.015620915219187737, 0.3641623556613922, 0.1579384058713913, 0.015620915219187737, 0.4466574192047119], [0.11517517268657684, 0.034441713243722916, 0.034441713243722916, 0.10902128368616104, 0.7069200277328491], [0.5493097305297852, 0.016377422958612442, 0.3658842444419861, 0.016377422958612442, 0.05205121263861656], [0.3825972378253937, 0.03201586753129959, 0.1860695332288742, 0.3825972378253937, 0.016720086336135864], [0.021140048280358315, 0.027490191161632538, 0.9504329562187195, 0.0004683781589847058, 0.0004683781589847058], [0.04419872909784317, 0.4333500266075134, 0.4333500266075134, 0.0002804873511195183, 0.08882073312997818], [0.08844691514968872, 0.8188822865486145, 5.618694194708951e-05, 0.04630729556083679, 0.04630729556083679], [0.08008609712123871, 0.24198459088802338, 0.1846960335969925, 0.24198459088802338, 0.25124868750572205], [0.0012730011949315667, 0.40096938610076904, 0.07683709263801575, 0.07683709263801575, 0.44408342242240906], [0.013158305548131466, 9.936284914147109e-05, 0.01203139964491129, 0.9626795053482056, 0.01203139964491129], [0.1884607970714569, 0.0014546476304531097, 0.1884607970714569, 0.40409600734710693, 0.21752779185771942], [0.0041889045387506485, 0.07001916319131851, 0.07867620885372162, 0.7770966291427612, 0.07001916319131851], [0.8273587822914124, 0.00030661109485663474, 0.009594994597136974, 0.00030661109485663474, 0.16243305802345276], [0.012042548507452011, 0.26189088821411133, 0.3493335545063019, 0.3493335545063019, 0.027399498969316483], [0.046196579933166504, 0.45769402384757996, 0.02394154481589794, 0.44822636246681213, 0.02394154481589794], [5.3397012379718944e-05, 5.3397012379718944e-05, 0.48904481530189514, 0.46644753217697144, 0.044400885701179504], [0.010654847137629986, 0.08755698800086975, 0.11865375190973282, 0.6644806861877441, 0.11865375190973282], [0.4559588134288788, 0.002073293086141348, 0.4559588134288788, 0.052316535264253616, 0.03369254618883133], [0.24160222709178925, 0.18243390321731567, 0.20916548371315002, 0.1576329618692398, 0.20916548371315002], [0.15313108265399933, 0.3446987271308899, 0.00984280463308096, 0.3391963541507721, 0.15313108265399933], [0.45631706714630127, 0.45631706714630127, 0.06963304430246353, 0.016025710850954056, 0.001707201823592186], [0.1499701291322708, 0.45207422971725464, 0.012191671878099442, 0.012191671878099442, 0.37357231974601746], [0.03930193558335304, 0.1833149641752243, 0.1833149641752243, 0.49919068813323975, 0.0948774516582489], [0.15128393471240997, 0.2924134135246277, 0.2924134135246277, 0.006974336225539446, 0.2569149434566498], [0.0525968112051487, 0.23091715574264526, 0.465257465839386, 0.23091715574264526, 0.020311418920755386], [0.49072951078414917, 0.006606497801840305, 0.004983112215995789, 0.006951321382075548, 0.49072951078414917], [0.44720563292503357, 0.0006564782233908772, 0.10345999896526337, 0.0014722178457304835, 0.44720563292503357], [0.09907672554254532, 0.06038432940840721, 0.46758773922920227, 0.31256693601608276, 0.06038432940840721], [0.29177093505859375, 0.3312112092971802, 0.08462432771921158, 0.0006226693512871861, 0.29177093505859375], [0.27412137389183044, 0.4110444486141205, 0.007630310487002134, 0.15360194444656372, 0.15360194444656372], [0.1305059939622879, 0.7739098072052002, 0.0008271136321127415, 0.0007188466261141002, 0.094038225710392], [0.20388935506343842, 0.052164968103170395, 0.0010642014676705003, 0.20388935506343842, 0.5389920473098755], [0.0004572633479256183, 0.0004572633479256183, 0.696264922618866, 0.2590107321739197, 0.04380985349416733], [0.4578869044780731, 0.008266374468803406, 0.06317174434661865, 0.012788075953722, 0.4578869044780731], [0.8375087380409241, 0.001134431455284357, 0.1485108733177185, 0.001134431455284357, 0.011711642146110535], [0.8616490960121155, 0.008910764008760452, 0.06201859191060066, 0.0054029254242777824, 0.06201859191060066], [0.007942253723740578, 0.10394447296857834, 0.10394447296857834, 0.23659397661685944, 0.5475748777389526], [0.43811678886413574, 0.43811678886413574, 0.028195012360811234, 0.09160614013671875, 0.003965271171182394], [0.35285767912864685, 0.055234845727682114, 0.1482873409986496, 0.38838520646095276, 0.055234845727682114], [0.003969607409089804, 0.12481283396482468, 0.3767433762550354, 0.166489377617836, 0.32798483967781067], [0.0048346128314733505, 0.6493849754333496, 0.01535741612315178, 0.1652115285396576, 0.1652115285396576], [0.48927852511405945, 0.24108639359474182, 0.027427034452557564, 0.0011216674465686083, 0.24108639359474182], [0.3634500205516815, 0.0055958908051252365, 0.12557832896709442, 0.3634500205516815, 0.14192572236061096], [0.045844439417123795, 0.007762514520436525, 0.3550470471382141, 0.1834765076637268, 0.40786945819854736], [0.5055472254753113, 0.013659922406077385, 0.1391504555940628, 0.20249195396900177, 0.1391504555940628], [0.008023969829082489, 0.008023969829082489, 0.5295767784118652, 0.41616198420524597, 0.03821336105465889], [0.5136005282402039, 0.16641870141029358, 0.15867410600185394, 0.15867410600185394, 0.002632502233609557], [0.032646164298057556, 0.01818750984966755, 0.032646164298057556, 0.09761646389961243, 0.8189036250114441], [0.22891712188720703, 0.05040052905678749, 0.35711097717285156, 0.22891712188720703, 0.1346542239189148], [0.012351224198937416, 0.008826171979308128, 0.7132971286773682, 0.009649529121816158, 0.25587594509124756], [0.0697987973690033, 0.020446401089429855, 0.20649543404579163, 0.098650723695755, 0.6046086549758911], [0.047559645026922226, 0.0002296040765941143, 0.07292860746383667, 0.047559645026922226, 0.8317225575447083], [0.08740699291229248, 0.4140373170375824, 0.21865078806877136, 0.08740699291229248, 0.19249795377254486], [0.020637741312384605, 0.007061963900923729, 0.6345189809799194, 0.18311837315559387, 0.15466295182704926], [2.6982284907717258e-05, 0.000769719947129488, 0.6982606053352356, 0.000769719947129488, 0.30017295479774475], [0.494392454624176, 0.15450818836688995, 0.14806893467903137, 0.15450818836688995, 0.048522137105464935], [0.32722973823547363, 0.2545703947544098, 0.07404481619596481, 0.2545703947544098, 0.08958472311496735], [0.4910886883735657, 0.07428093254566193, 0.18615610897541046, 0.062318261712789536, 0.18615610897541046], [0.07122884690761566, 0.5711699724197388, 0.09733103960752487, 0.13013508915901184, 0.13013508915901184], [0.04131288826465607, 0.4770440459251404, 0.004383189138025045, 0.04131288826465607, 0.4359470307826996], [0.19390912353992462, 0.023200420662760735, 0.06444115191698074, 0.5245401859283447, 0.19390912353992462], [0.00021110556554049253, 0.6748929023742676, 0.06833105534315109, 0.25635382533073425, 0.00021110556554049253], [0.34739741683006287, 0.23347905278205872, 0.011557351797819138, 0.34739741683006287, 0.060168858617544174], [0.30613380670547485, 0.062435030937194824, 0.062435030937194824, 0.10078515857458115, 0.46821096539497375], [0.24501465260982513, 0.2656165659427643, 0.28260338306427, 0.10338268429040909, 0.10338268429040909], [0.011159862391650677, 0.006253463681787252, 0.43567022681236267, 0.1112462729215622, 0.43567022681236267], [0.5663022994995117, 0.12113186717033386, 0.13041211664676666, 0.13041211664676666, 0.051741596311330795], [0.1934008002281189, 0.06089530885219574, 0.7365255951881409, 0.004589139949530363, 0.004589139949530363], [0.02119435928761959, 0.35932454466819763, 0.06798302382230759, 0.1866806000471115, 0.36481747031211853], [0.0035946033895015717, 0.0037752618081867695, 0.05084173381328583, 0.043724726885557175, 0.8980636596679688], [0.034341465681791306, 0.034341465681791306, 0.09605331718921661, 0.5873828530311584, 0.24788090586662292], [0.0011772052384912968, 0.9651830792427063, 0.016285507008433342, 0.016285507008433342, 0.0010686373570933938], [0.6457138657569885, 0.004793122410774231, 0.28544095158576965, 0.05925895273685455, 0.004793122410774231], [0.5926288366317749, 0.0036121762823313475, 0.0036121762823313475, 0.006927314214408398, 0.3932194411754608], [0.00292884255759418, 0.2328656166791916, 0.00292884255759418, 0.7143979072570801, 0.046878863126039505], [0.4859795570373535, 0.006446947809308767, 0.4859795570373535, 0.019411426037549973, 0.00218254909850657], [0.08576951920986176, 0.5022931098937988, 0.3026530146598816, 0.08576951920986176, 0.02351483516395092], [0.0005254967836663127, 0.0005254967836663127, 0.15975970029830933, 0.6719357967376709, 0.1672535091638565], [0.15608792006969452, 0.22317659854888916, 0.2485673427581787, 0.14899155497550964, 0.22317659854888916], [0.030862215906381607, 0.015178468078374863, 0.7665651440620422, 0.17221574485301971, 0.015178468078374863], [0.00790675263851881, 0.0004823952913284302, 0.00790675263851881, 0.8288466930389404, 0.15485742688179016], [0.005548219196498394, 0.4852057695388794, 0.020211832597851753, 0.4852057695388794, 0.0038284705951809883], [0.425351083278656, 0.425351083278656, 0.0036280767526477575, 0.14524522423744202, 0.0004245140007697046], [0.3869782090187073, 0.16285307705402374, 0.3869782090187073, 0.006774271838366985, 0.05641622468829155], [0.17391374707221985, 0.026450660079717636, 0.3219430446624756, 0.15574954450130463, 0.3219430446624756], [0.194004625082016, 0.08481328189373016, 0.4771372973918915, 0.050040144473314285, 0.194004625082016], [0.016308365389704704, 0.6471047401428223, 0.05288071930408478, 0.23082546889781952, 0.05288071930408478], [0.07852602005004883, 0.026854626834392548, 0.19039909541606903, 0.625694215297699, 0.07852602005004883], [0.0006348623428493738, 0.0006348623428493738, 0.2628242075443268, 0.26765239238739014, 0.4682537019252777], [0.3421075940132141, 0.00661378214135766, 0.03944029659032822, 0.26973065733909607, 0.3421075940132141], [0.03983455151319504, 0.7338471412658691, 0.11459313333034515, 0.03983455151319504, 0.07189058512449265], [0.5087134838104248, 0.21116119623184204, 0.1393039971590042, 0.001517311087809503, 0.1393039971590042], [0.6259888410568237, 0.07732780277729034, 0.057792529463768005, 0.07732780277729034, 0.16156302392482758], [0.12776319682598114, 0.12776319682598114, 0.01593123748898506, 0.03835306316614151, 0.6901893019676208], [0.4210573136806488, 6.792918429709971e-05, 0.4210573136806488, 0.15781138837337494, 6.0546176428033505e-06], [0.08932135999202728, 0.010181915014982224, 0.02486727386713028, 0.010181915014982224, 0.8654475212097168], [0.5520378947257996, 0.34788134694099426, 0.019501518458127975, 0.019501518458127975, 0.0610777847468853], [2.4835691874613985e-05, 0.027428876608610153, 2.4835691874613985e-05, 0.9141958355903625, 0.058325543999671936], [0.33754462003707886, 0.08391762524843216, 0.42419829964637756, 0.07042182236909866, 0.08391762524843216], [0.008705062791705132, 0.008705062791705132, 0.5606864094734192, 0.39112311601638794, 0.030780266970396042], [0.007481010165065527, 0.8727836012840271, 0.10353013128042221, 0.008724144659936428, 0.007481010165065527], [0.0069524082355201244, 0.22474616765975952, 0.19536054134368896, 0.22474616765975952, 0.34819477796554565], [0.00036318754428066313, 0.2592814862728119, 0.3704458177089691, 0.11062812805175781, 0.2592814862728119], [0.21005302667617798, 0.011623146012425423, 0.03205937519669533, 0.7142050862312317, 0.03205937519669533], [0.5707846879959106, 0.1809435933828354, 0.1809435933828354, 0.046611152589321136, 0.020716967061161995], [0.4692811965942383, 0.005279340781271458, 0.014284295961260796, 0.014284295961260796, 0.49687090516090393], [0.5342644453048706, 0.0015283009270206094, 0.0015283009270206094, 0.3392082154750824, 0.12347080558538437], [8.67539711180143e-05, 0.04360930994153023, 0.0404374860227108, 0.457933247089386, 0.457933247089386], [0.009153819642961025, 0.857955813407898, 0.09770762175321579, 0.026028912514448166, 0.009153819642961025], [0.02057022787630558, 0.12306807935237885, 0.033340759575366974, 0.4115104675292969, 0.4115104675292969], [0.0050430032424628735, 0.03863975778222084, 0.0008298049797303975, 0.9546576142311096, 0.0008298049797303975], [0.0980401337146759, 0.006846311967819929, 0.22544866800308228, 0.44421619176864624, 0.22544866800308228], [0.049824658781290054, 0.4188538193702698, 0.26986783742904663, 0.1307268589735031, 0.1307268589735031], [0.7849558591842651, 0.1530190408229828, 0.04113885760307312, 0.010443110950291157, 0.010443110950291157], [0.14734114706516266, 0.37332844734191895, 0.37332844734191895, 0.08700267225503922, 0.01899932697415352], [0.9864715933799744, 0.00020493585907388479, 0.0017234609695151448, 0.00020493585907388479, 0.01139505859464407], [0.06054897606372833, 0.0013250219635665417, 0.9214076995849609, 0.008359120227396488, 0.008359120227396488], [0.02625373937189579, 0.2175295054912567, 0.12432783842086792, 0.4143593907356262, 0.2175295054912567], [0.3950671851634979, 0.001955288928002119, 0.3950671851634979, 0.20746418833732605, 0.0004461026983335614], [0.01821458712220192, 0.09273218363523483, 0.07206591963768005, 0.7804407477378845, 0.03654658421874046], [0.20231667160987854, 0.00020097533706575632, 0.3314955234527588, 0.2636701166629791, 0.20231667160987854], [0.05676222965121269, 0.3691108822822571, 0.5684519410133362, 0.0028374537359923124, 0.0028374537359923124], [0.39540255069732666, 0.15992918610572815, 0.34614336490631104, 0.04926244914531708, 0.04926244914531708], [0.008436014875769615, 0.2061527669429779, 0.004563907627016306, 0.5746945738792419, 0.2061527669429779], [0.7969580888748169, 0.0015391646884381771, 0.0036143045872449875, 0.19634926319122314, 0.0015391646884381771], [0.6194130182266235, 0.19339559972286224, 0.10793470591306686, 0.03962833061814308, 0.03962833061814308], [0.01686173491179943, 0.003059940878301859, 0.06862279027700424, 0.455727756023407, 0.455727756023407], [0.09440850466489792, 0.0939917042851448, 0.028681466355919838, 0.6885098218917847, 0.09440850466489792], [0.041604526340961456, 0.041604526340961456, 0.23851336538791656, 0.5526115298271179, 0.125666081905365], [0.0009239130304194987, 0.0004350223462097347, 0.9705379605293274, 0.014051542617380619, 0.014051542617380619], [0.1008538082242012, 0.039898570626974106, 0.009679417125880718, 0.23665542900562286, 0.6129127740859985], [0.012330806814134121, 0.0055695790797472, 0.22235339879989624, 0.0055695790797472, 0.7541766166687012], [0.10760533064603806, 0.005754765123128891, 0.005754765123128891, 0.5760179162025452, 0.3048672676086426], [0.10015556216239929, 0.289167582988739, 0.10015556216239929, 0.18579664826393127, 0.32472461462020874], [0.5589403510093689, 0.14381425082683563, 0.0016336840344592929, 0.0019332936499267817, 0.2936784625053406], [0.28985029458999634, 0.0281180739402771, 0.6079751253128052, 0.0281180739402771, 0.04593845456838608], [0.3673199713230133, 0.5351653099060059, 0.08868837356567383, 0.004413170740008354, 0.004413170740008354], [0.004722670651972294, 0.2136092334985733, 0.5079599618911743, 0.06009886786341667, 0.2136092334985733], [0.12288694828748703, 0.2025255709886551, 0.09427494555711746, 0.2025255709886551, 0.3777870237827301], [0.1656476855278015, 0.26564982533454895, 0.0012377267703413963, 0.3018149435520172, 0.26564982533454895], [0.38660818338394165, 0.40869203209877014, 0.08018060028553009, 0.04433854669332504, 0.08018060028553009], [0.0023107919842004776, 0.850221574306488, 0.12263375520706177, 0.022523198276758194, 0.0023107919842004776], [0.009462305344641209, 0.41862741112709045, 0.009462305344641209, 0.48294126987457275, 0.07950670272111893], [0.002365047112107277, 0.000888783426489681, 0.10478011518716812, 0.44598302245140076, 0.44598302245140076], [0.7803500890731812, 0.001062491093762219, 0.09218458831310272, 0.03421827778220177, 0.09218458831310272], [0.40549492835998535, 0.010099945589900017, 0.026951303705573082, 0.026951303705573082, 0.5305024981498718], [0.000332127878209576, 0.29604747891426086, 0.40243932604789734, 0.29604747891426086, 0.0051335603930056095], [0.017169952392578125, 0.01627356931567192, 0.6557775139808655, 0.01627356931567192, 0.29450541734695435], [0.12540645897388458, 0.7452734112739563, 0.0004074154421687126, 0.12540645897388458, 0.0035063393879681826], [0.16543087363243103, 0.3958433270454407, 0.3958433270454407, 0.03835894167423248, 0.004523514304310083], [0.10040257126092911, 0.10040257126092911, 0.4947645366191864, 0.013664469122886658, 0.2907658517360687], [0.006506844889372587, 0.018185053020715714, 0.4872816503047943, 0.0007447946118190885, 0.4872816503047943], [0.43386662006378174, 0.0001261151337530464, 0.08407934010028839, 0.43386662006378174, 0.04806126281619072], [0.13677799701690674, 0.14303834736347198, 0.04712573438882828, 0.5362799763679504, 0.13677799701690674], [0.20058594644069672, 0.20058594644069672, 0.10547236353158951, 0.44494032859802246, 0.04841531813144684], [0.0695788785815239, 0.0695788785815239, 0.4549068510532379, 0.2904951274394989, 0.11544027179479599], [0.2218603640794754, 0.10562197118997574, 0.1506379097700119, 0.30001935362815857, 0.2218603640794754], [0.11856307089328766, 0.17747332155704498, 0.20368264615535736, 0.29659825563430786, 0.20368264615535736], [0.9031474590301514, 0.01608695276081562, 0.06405657529830933, 0.0006220506620593369, 0.01608695276081562], [0.03233688697218895, 0.34131744503974915, 0.013622662983834743, 0.34131744503974915, 0.27140557765960693], [0.001142985885962844, 0.08784852176904678, 0.00046315568033605814, 0.08784852176904678, 0.8226968050003052], [0.0006962669431231916, 0.00024909296189434826, 0.9937248826026917, 0.005080684553831816, 0.00024909296189434826], [0.07968762516975403, 0.0183902308344841, 0.00021866821043659002, 0.8220158219337463, 0.07968762516975403], [0.004625140223652124, 0.40052512288093567, 0.027190687134861946, 0.004625140223652124, 0.563033938407898], [0.42290550470352173, 0.400441437959671, 0.16655439138412476, 0.005049337632954121, 0.005049337632954121], [0.045489925891160965, 0.0019164502155035734, 0.1311960071325302, 0.4106987714767456, 0.4106987714767456], [0.10903815180063248, 0.1245165765285492, 0.4434848427772522, 0.19844384491443634, 0.1245165765285492], [0.16679851710796356, 0.09822586923837662, 0.09822586923837662, 0.4899574816226959, 0.14679230749607086], [0.054637543857097626, 0.10976219177246094, 0.07254184037446976, 0.10976219177246094, 0.653296172618866], [0.2942965030670166, 0.04123072698712349, 0.0095883933827281, 0.2942965030670166, 0.36058786511421204], [0.322081059217453, 0.21437080204486847, 0.322081059217453, 0.0007813961710780859, 0.14068563282489777], [0.11555830389261246, 6.631584983551875e-05, 0.017877768725156784, 0.436073362827301, 0.4304242432117462], [0.20892234146595, 0.04077257961034775, 0.007849312387406826, 0.7016832828521729, 0.04077257961034775], [0.404634565114975, 0.05867592617869377, 0.3154519200325012, 0.11061877757310867, 0.11061877757310867], [0.017088348045945168, 0.05649878457188606, 0.18272127211093903, 0.7266032695770264, 0.017088348045945168], [0.0793454721570015, 0.16308318078517914, 0.166072279214859, 0.42542678117752075, 0.166072279214859], [0.05386535823345184, 0.007917593233287334, 0.8176115155220032, 0.007917593233287334, 0.11268800497055054], [0.0019605623092502356, 0.042203281074762344, 0.009317571297287941, 0.473259299993515, 0.473259299993515], [0.0753662958741188, 0.10672443360090256, 0.3072760999202728, 0.0753662958741188, 0.4352668821811676], [0.02427217923104763, 0.6532994508743286, 0.0880591869354248, 0.1463100016117096, 0.0880591869354248], [0.1546279937028885, 0.6232092380523682, 0.023811787366867065, 0.1546279937028885, 0.043723028153181076], [0.42843297123908997, 0.4333401322364807, 0.05399046093225479, 0.042118191719055176, 0.042118191719055176], [0.30544158816337585, 0.3415599763393402, 0.30544158816337585, 0.010993314906954765, 0.03656351938843727], [0.9784409999847412, 0.004498255904763937, 0.00852284487336874, 0.00852284487336874, 1.5045269719848875e-05], [0.182905375957489, 0.182905375957489, 0.07638443261384964, 0.508895754814148, 0.04890909045934677], [0.470516175031662, 0.04644520953297615, 0.04644520953297615, 0.0416349321603775, 0.3949584662914276], [0.8441007137298584, 0.04671420902013779, 0.04834309592843056, 0.04671420902013779, 0.014127777889370918], [0.033058252185583115, 0.03468789905309677, 0.02528439089655876, 0.02528439089655876, 0.8816850185394287], [0.2076834738254547, 0.2737499177455902, 0.038485217839479446, 0.4415961802005768, 0.038485217839479446], [0.35311415791511536, 0.1502474695444107, 0.025684433057904243, 0.35311415791511536, 0.11783983558416367], [0.012289156205952168, 0.23945394158363342, 0.012289156205952168, 0.7190762162208557, 0.016891509294509888], [0.18611043691635132, 0.18611043691635132, 0.18943604826927185, 0.32980284094810486, 0.10854020714759827], [0.8925917744636536, 0.00412673968821764, 0.0016640610992908478, 0.09749072045087814, 0.00412673968821764], [0.05313362926244736, 0.21765847504138947, 0.0016388717340305448, 0.0016388717340305448, 0.7259301543235779], [0.01715935580432415, 0.17786109447479248, 0.002080725971609354, 0.800818145275116, 0.002080725971609354], [0.2667195796966553, 0.06846991181373596, 0.41528329253196716, 0.2148875892162323, 0.03463961184024811], [0.05675005167722702, 0.04072604700922966, 0.01571980118751526, 0.4434020519256592, 0.4434020519256592], [0.7494113445281982, 0.22484181821346283, 0.013116841204464436, 0.008869078941643238, 0.0037607860285788774], [0.013739158399403095, 0.3562565743923187, 0.0005146160838194191, 0.2732330560684204, 0.3562565743923187], [0.0018224710365757346, 0.022078290581703186, 0.007991492748260498, 0.9601161479949951, 0.007991492748260498], [0.05926571786403656, 0.33845487236976624, 0.05977904051542282, 0.4827212393283844, 0.05977904051542282], [0.01009292621165514, 0.9107275009155273, 0.039777375757694244, 0.01009292621165514, 0.02930925041437149], [0.31176671385765076, 0.08366799354553223, 0.2401815801858902, 0.31176671385765076, 0.05261700972914696], [0.02480785921216011, 0.4472724497318268, 0.047607313841581345, 0.4472724497318268, 0.03303996101021767], [0.001813687151297927, 0.21143491566181183, 0.21143491566181183, 0.566416323184967, 0.00890021026134491], [0.7959388494491577, 0.12008015811443329, 0.0031146486289799213, 0.040433187037706375, 0.040433187037706375], [0.6921944618225098, 0.008575470186769962, 0.021924473345279694, 0.2553810477256775, 0.021924473345279694], [0.0005597456474788487, 0.1464104950428009, 0.15310975909233093, 0.6993602514266968, 0.0005597456474788487], [0.37843289971351624, 0.07830702513456345, 0.1679120510816574, 0.07830702513456345, 0.2970409691333771], [0.49434584379196167, 0.015175603330135345, 0.2688645124435425, 0.11080699414014816, 0.11080699414014816], [0.27115052938461304, 0.12701667845249176, 0.04052324593067169, 0.43429285287857056, 0.12701667845249176], [0.32008522748947144, 0.12251488119363785, 0.2501894235610962, 0.18469563126564026, 0.12251488119363785], [0.4147644639015198, 0.03602929413318634, 0.4147644639015198, 0.12319225072860718, 0.011249562725424767], [0.1374012529850006, 0.6741239428520203, 0.1374012529850006, 0.02768876776099205, 0.02338482439517975], [0.24968494474887848, 0.33869966864585876, 0.33869966864585876, 0.001119222491979599, 0.0717964842915535], [0.009454119019210339, 0.019854336977005005, 0.2524162232875824, 0.019854336977005005, 0.6984209418296814], [0.01004826556891203, 0.35469603538513184, 0.01004826556891203, 0.5530651211738586, 0.07214229553937912], [0.025221744552254677, 0.27353060245513916, 0.27353060245513916, 0.006163101643323898, 0.42155393958091736], [0.5853722095489502, 0.0047058542259037495, 0.1386333554983139, 0.0047058542259037495, 0.26658278703689575], [0.03784945234656334, 0.01287746150046587, 0.050220370292663574, 0.050220370292663574, 0.848832368850708], [0.005895458161830902, 0.14399714767932892, 0.6482092142105103, 0.05790099874138832, 0.14399714767932892], [0.3023551404476166, 0.1293332576751709, 0.2573336064815521, 0.3023551404476166, 0.008622836321592331], [0.07672340422868729, 0.40415534377098083, 0.08393129706382751, 0.08393129706382751, 0.35125866532325745], [0.17421294748783112, 0.08099398761987686, 0.041213106364011765, 0.041213106364011765, 0.6623669266700745], [0.008079092018306255, 0.28209027647972107, 0.28209027647972107, 0.40909555554389954, 0.018644757568836212], [0.0027019947301596403, 0.05568186938762665, 0.8425278067588806, 0.05568186938762665, 0.043406449258327484], [0.0033209272660315037, 0.00939003936946392, 0.00939003936946392, 0.9670618772506714, 0.01083709392696619], [0.38498634099960327, 0.36220523715019226, 0.1657308042049408, 0.06537938863039017, 0.02169824205338955], [0.37026482820510864, 0.06396624445915222, 0.1374167799949646, 0.3643859028816223, 0.06396624445915222], [0.06108725443482399, 0.06108725443482399, 0.7488438487052917, 0.09784311801195145, 0.03113851696252823], [0.20783740282058716, 0.1696743220090866, 0.05261164531111717, 1.4396890946954954e-05, 0.5698622465133667], [0.022637395188212395, 0.025629397481679916, 0.438642680644989, 0.438642680644989, 0.074447862803936], [0.05020403861999512, 0.4295300841331482, 0.002605362795293331, 0.5150551795959473, 0.002605362795293331], [0.6843288540840149, 0.0001905020180856809, 0.0001905020180856809, 0.312910258769989, 0.0023798905313014984], [0.22153624892234802, 0.35166817903518677, 0.001230095513164997, 0.07389739900827408, 0.35166817903518677], [0.3105110824108124, 0.3105110824108124, 7.319205178646371e-05, 0.19717131555080414, 0.18173331022262573], [0.1898173689842224, 0.45927488803863525, 0.1178039014339447, 0.0432865135371685, 0.1898173689842224], [0.05808890610933304, 0.12009052187204361, 0.04015779122710228, 0.7235739231109619, 0.05808890610933304], [0.20561231672763824, 0.5094031095504761, 0.20561231672763824, 0.031200790777802467, 0.04817148298025131], [0.12027858197689056, 0.7733207941055298, 0.013495766557753086, 0.013495766557753086, 0.07940909266471863], [0.1818687915802002, 0.5504621267318726, 0.1818687915802002, 0.003636433044448495, 0.08216390013694763], [0.0008509574690833688, 0.025897949934005737, 0.8505085110664368, 0.0008509574690833688, 0.12189160287380219], [0.8784658312797546, 0.009044477716088295, 0.028505781665444374, 0.07493949681520462, 0.009044477716088295], [0.0011236965656280518, 0.38390567898750305, 0.03170950710773468, 0.03170950710773468, 0.5515516400337219], [0.22793029248714447, 0.004750757943838835, 0.2696101665496826, 0.2696101665496826, 0.22809860110282898], [0.014251602813601494, 0.816202700138092, 0.07849393039941788, 0.07849393039941788, 0.01255781203508377], [0.1594645082950592, 0.09385033696889877, 0.1594645082950592, 0.3324338495731354, 0.25478675961494446], [0.015131860971450806, 0.7989019751548767, 0.06953758746385574, 0.04689100757241249, 0.06953758746385574], [0.07504750788211823, 0.6514942646026611, 0.07812638580799103, 0.07504750788211823, 0.12028432637453079], [0.10235217213630676, 0.6489319205284119, 0.0038222954608500004, 0.0038222954608500004, 0.24107131361961365], [0.25142017006874084, 0.09462197124958038, 0.5304053425788879, 0.028930585831403732, 0.09462197124958038], [0.0023998848628252745, 0.0001505803520558402, 0.9934073686599731, 0.0023998848628252745, 0.0016422271728515625], [0.054082103073596954, 0.02703753486275673, 0.054082103073596954, 0.7095266580581665, 0.15527160465717316], [0.07690936326980591, 0.6929871439933777, 0.1123303472995758, 0.1123303472995758, 0.005442752968519926], [0.29870402812957764, 0.000993607915006578, 0.2369847446680069, 0.23165880143642426, 0.23165880143642426], [0.020341860130429268, 0.38556399941444397, 0.17145736515522003, 0.38556399941444397, 0.03707275912165642], [0.0018701939843595028, 0.8381137251853943, 0.022121960297226906, 0.0018701939843595028, 0.13602395355701447], [0.5658797025680542, 0.052144452929496765, 0.002953633898869157, 0.052144452929496765, 0.32687774300575256], [0.23726564645767212, 0.007835239171981812, 0.4291081726551056, 0.23726564645767212, 0.08852531760931015], [0.06772680580615997, 0.682765781879425, 0.03511638939380646, 0.03511638939380646, 0.1792745590209961], [0.1211463063955307, 0.37259146571159363, 0.27981963753700256, 0.105296291410923, 0.1211463063955307], [0.010956315323710442, 0.2908129394054413, 0.29521873593330383, 0.29521873593330383, 0.10779324918985367], [0.023112459108233452, 0.3917122781276703, 0.03394287824630737, 0.1595200002193451, 0.3917122781276703], [0.06080789491534233, 0.21995998919010162, 0.5913493037223816, 0.06080789491534233, 0.0670749694108963], [0.20929646492004395, 0.12684814631938934, 0.012966400943696499, 0.6379225850105286, 0.012966400943696499], [0.0023104799911379814, 0.9671211838722229, 0.006432338152080774, 0.0023104799911379814, 0.02182541787624359], [0.5769657492637634, 0.10680090636014938, 0.07558469474315643, 0.10680090636014938, 0.13384777307510376], [0.8750928640365601, 0.006057363469153643, 0.0027024198789149523, 0.11344493925571442, 0.0027024198789149523], [0.04673483967781067, 0.16022679209709167, 0.39626961946487427, 0.0004990625311620533, 0.39626961946487427], [0.09683316946029663, 0.04901822656393051, 0.1935179978609085, 0.46711260080337524, 0.1935179978609085], [0.8596298694610596, 0.00719981687143445, 0.09514595568180084, 0.030824437737464905, 0.00719981687143445], [0.4192863404750824, 0.05188046023249626, 5.383388270274736e-05, 0.26438969373703003, 0.26438969373703003], [0.021886827424168587, 0.021886827424168587, 0.020660022273659706, 0.008027064613997936, 0.9275392889976501], [0.03825562819838524, 0.4636874198913574, 0.0005515242810361087, 0.4636874198913574, 0.03381804749369621], [0.7156638503074646, 2.7319565560901538e-05, 0.08444315940141678, 0.19983835518360138, 2.7319565560901538e-05], [0.06985776871442795, 0.18779753148555756, 0.4327481687068939, 0.23973873257637024, 0.06985776871442795], [0.23224571347236633, 0.3062060475349426, 0.10293830931186676, 0.3062060475349426, 0.05240386724472046], [0.05248809605836868, 0.03179723769426346, 0.7816826105117798, 0.081543929874897, 0.05248809605836868], [0.00024114825646393, 0.3266279101371765, 0.00024114825646393, 0.1373150795698166, 0.5355746746063232], [0.0018304954282939434, 0.10893414169549942, 0.0008387758862227201, 0.8875578045845032, 0.0008387758862227201], [0.18393288552761078, 0.18393288552761078, 0.05198123678565025, 1.7931030015461147e-05, 0.5801350474357605], [0.10878537595272064, 0.4110730290412903, 0.0008470803732052445, 0.4110730290412903, 0.06822150200605392], [9.570382098900154e-05, 0.46560460329055786, 0.04053454473614693, 0.028160525485873222, 0.46560460329055786], [0.09844140708446503, 0.018562106415629387, 0.28607675433158875, 0.5783576369285583, 0.018562106415629387], [0.5649887323379517, 0.34781044721603394, 0.05562686547636986, 0.015786968171596527, 0.015786968171596527], [0.8393462896347046, 0.0039446079172194, 0.14689907431602478, 0.005865493789315224, 0.0039446079172194], [0.09325483441352844, 0.027948718518018723, 0.8401668667793274, 0.010680890642106533, 0.027948718518018723], [0.6003736257553101, 0.09576594084501266, 0.13904857635498047, 0.13904857635498047, 0.0257632564753294], [0.10973071306943893, 0.3032219409942627, 0.46035343408584595, 0.10973071306943893, 0.016963224858045578], [0.004968353547155857, 0.6408233642578125, 0.004968353547155857, 0.08985675126314163, 0.2593831717967987], [0.15419916808605194, 0.1781495213508606, 0.32604163885116577, 0.32604163885116577, 0.015568063594400883], [0.013123300857841969, 0.40860041975975037, 0.0835672989487648, 0.4815857410430908, 0.013123300857841969], [0.08830644190311432, 0.014116027392446995, 0.8664776682853699, 0.014116027392446995, 0.01698385365307331], [0.021021755412220955, 0.14010290801525116, 0.15942810475826263, 0.33894282579421997, 0.34050440788269043], [0.4146505296230316, 0.011727211996912956, 0.2836405336856842, 0.006341225001960993, 0.2836405336856842], [0.014309427700936794, 0.007569394540041685, 0.4041667580604553, 0.1697877049446106, 0.4041667580604553], [0.02657555602490902, 0.8894296884536743, 0.03237329423427582, 0.02504587359726429, 0.02657555602490902], [0.0067047677002847195, 0.885705292224884, 0.0067047677002847195, 0.0008179405122064054, 0.10006719082593918], [0.445220023393631, 0.004120373632758856, 0.004120373632758856, 0.36937078833580017, 0.17716848850250244], [0.05958840996026993, 0.046120718121528625, 0.05958840996026993, 0.8204482793807983, 0.014254159294068813], [0.0844917744398117, 0.3399476408958435, 0.03777135908603668, 0.03033755160868168, 0.5074516534805298], [0.8785296678543091, 0.017428865656256676, 0.06552544981241226, 0.017428865656256676, 0.021087167784571648], [0.8685146570205688, 0.0909811481833458, 0.004037830047309399, 0.036417942494153976, 4.8328594857594e-05], [0.19046851992607117, 0.024480529129505157, 9.003221202874556e-05, 0.3924804925918579, 0.3924804925918579], [0.026061631739139557, 0.16302648186683655, 0.026061631739139557, 0.004042383749037981, 0.7808079123497009], [0.5867515206336975, 0.03912684693932533, 0.03912684693932533, 0.3281414210796356, 0.0068533397279679775], [0.08106043934822083, 0.2795397639274597, 0.00014818178897257894, 0.6259565949440002, 0.013294984586536884], [0.24168594181537628, 0.32017070055007935, 0.032981693744659424, 0.32017070055007935, 0.0849909782409668], [0.3695926368236542, 0.22720572352409363, 0.10674504935741425, 0.22720572352409363, 0.06925085186958313], [0.003707093885168433, 0.003707093885168433, 0.7616695761680603, 0.02410893701016903, 0.20680733025074005], [0.12339072674512863, 0.0277051143348217, 0.23687608540058136, 0.37515196204185486, 0.23687608540058136], [0.3770524859428406, 0.22001338005065918, 0.3770524859428406, 0.017919931560754776, 0.007961801253259182], [0.12092941999435425, 0.3042839467525482, 0.21817933022975922, 0.3042839467525482, 0.05232337489724159], [0.006213911809027195, 0.006705753039568663, 0.006705753039568663, 0.009831742383539677, 0.9705429077148438], [0.481670081615448, 0.16607822477817535, 0.025731027126312256, 0.3007896840572357, 0.025731027126312256], [0.4858156442642212, 0.00017429303261451423, 0.4858156442642212, 0.008418933488428593, 0.019775452092289925], [0.47419285774230957, 0.15154343843460083, 0.12423069030046463, 0.09848953038454056, 0.15154343843460083], [1.546882231195923e-05, 0.007258138153702021, 0.29024115204811096, 0.6952270269393921, 0.007258138153702021], [0.03781041502952576, 0.3658280074596405, 0.011951563879847527, 0.3658280074596405, 0.21858201920986176], [0.23277823626995087, 0.23277823626995087, 0.007474028039723635, 0.48337870836257935, 0.04359075799584389], [0.3795367479324341, 0.0005311279091984034, 0.17703470587730408, 0.06336057186126709, 0.3795367479324341], [0.7198745608329773, 0.11226994544267654, 0.11226994544267654, 0.05239228159189224, 0.0031933223363012075], [0.12284581363201141, 0.13011565804481506, 0.044286735355854034, 0.13011565804481506, 0.5726361274719238], [0.731086254119873, 0.0032297142315655947, 0.014387356117367744, 0.23690927028656006, 0.014387356117367744], [0.11653033643960953, 0.31859394907951355, 0.42537423968315125, 0.022971132770180702, 0.11653033643960953], [0.21038609743118286, 0.22410814464092255, 3.2877822377486154e-05, 0.3413647711277008, 0.22410814464092255], [0.12361327558755875, 0.3931005299091339, 0.3991971015930176, 0.028076685965061188, 0.05601244792342186], [0.49368926882743835, 0.0005177569692023098, 0.49368926882743835, 0.011967700906097889, 0.00013598088116850704], [0.012844249606132507, 0.012844249606132507, 0.0012510347878560424, 0.9610573053359985, 0.01200324110686779], [0.0004864018119405955, 0.1105969026684761, 0.0019127208506688476, 0.4435020089149475, 0.4435020089149475], [0.029422683641314507, 0.005645441357046366, 0.4824548661708832, 0.4824548661708832, 2.2113263185019605e-05], [0.35280290246009827, 0.2679644525051117, 0.0001726151822367683, 0.026257168501615524, 0.35280290246009827], [0.018849631771445274, 0.0008229879313148558, 0.013654125854372978, 0.9478235244750977, 0.018849631771445274], [0.04525604099035263, 0.48249179124832153, 0.3206489086151123, 0.04525604099035263, 0.10634714365005493], [0.03880150988698006, 0.14421330392360687, 0.32158559560775757, 0.4565981328487396, 0.03880150988698006], [0.2028183490037918, 0.38182371854782104, 0.12654919922351837, 0.2028183490037918, 0.08599038422107697], [0.1503530591726303, 0.27023014426231384, 0.27023014426231384, 0.1184174194931984, 0.19076921045780182], [0.043601956218481064, 0.009317077696323395, 0.043601956218481064, 0.4063098430633545, 0.49716916680336], [0.00728140352293849, 0.4113924503326416, 0.20815105736255646, 0.20815105736255646, 0.16502396762371063], [0.31873783469200134, 0.003105034353211522, 0.3521842360496521, 0.007235144264996052, 0.31873783469200134], [0.06626813113689423, 0.25072282552719116, 0.2735821008682251, 0.25072282552719116, 0.15870408713817596], [0.12424661964178085, 0.04882228374481201, 0.021109838038682938, 0.7569990158081055, 0.04882228374481201], [0.0038659542333334684, 0.19060887396335602, 0.006326933391392231, 0.7953322529792786, 0.0038659542333334684], [0.5130082368850708, 0.17442195117473602, 0.06398291885852814, 0.17442195117473602, 0.07416491955518723], [0.7340328097343445, 0.0212611872702837, 0.0212611872702837, 0.019674789160490036, 0.2037699967622757], [0.004799600690603256, 0.014834647998213768, 0.23017507791519165, 0.5200155973434448, 0.23017507791519165], [0.006761110853403807, 0.4225168824195862, 0.054307106882333755, 0.09389806538820267, 0.4225168824195862], [0.07611598819494247, 0.054918769747018814, 0.3787914514541626, 0.3787914514541626, 0.11138234287500381], [0.005893753841519356, 0.035364940762519836, 0.04949366673827171, 0.7109603881835938, 0.19828730821609497], [0.5718883275985718, 0.02682783454656601, 0.08640694618225098, 0.1574384570121765, 0.1574384570121765], [0.0030740387737751007, 0.4775477647781372, 0.4775477647781372, 0.01873127557337284, 0.023099202662706375], [0.09657836705446243, 0.03785217925906181, 0.7351973056793213, 0.03785217925906181, 0.09251999855041504], [0.11963483691215515, 0.275733083486557, 0.09329362213611603, 0.2356053739786148, 0.275733083486557], [0.01948448270559311, 0.4501597583293915, 0.07119179517030716, 0.4501597583293915, 0.009004272520542145], [0.08187275379896164, 0.30274033546447754, 0.12469985336065292, 0.30274033546447754, 0.18794672191143036], [0.00376434950158, 0.6275091767311096, 0.00376434950158, 0.13167056441307068, 0.23329152166843414], [0.03345261141657829, 0.3687291145324707, 0.059831079095602036, 0.3687291145324707, 0.1692580282688141], [0.001321782823652029, 0.001321782823652029, 0.38420283794403076, 0.6080304980278015, 0.00512302853167057], [0.443782240152359, 0.443782240152359, 0.0049654110334813595, 0.09701401740312576, 0.010456089861690998], [0.016918476670980453, 0.11978401988744736, 0.5791206359863281, 0.2672584056854248, 0.016918476670980453], [0.0021053289528936148, 0.0031422737520188093, 0.028987271711230278, 0.482882559299469, 0.482882559299469], [0.11137474328279495, 0.0018842850113287568, 0.11137474328279495, 0.006280878093093634, 0.7690852284431458], [0.028947919607162476, 0.41381382942199707, 0.0012072300305590034, 0.27801549434661865, 0.27801549434661865], [0.030807962641119957, 0.07915476709604263, 0.42760100960731506, 0.42760100960731506, 0.034835293889045715], [0.0023385321255773306, 0.6282138228416443, 0.047110944986343384, 0.21664808690547943, 0.10568860918283463], [0.9736744165420532, 0.011934936046600342, 0.0015294523909687996, 0.0009262886014766991, 0.011934936046600342], [0.2804073989391327, 0.07645346969366074, 0.2804073989391327, 0.02671670727431774, 0.336014986038208], [0.010635402984917164, 0.9366329312324524, 0.0026415667962282896, 0.0474485382437706, 0.0026415667962282896], [0.16041161119937897, 0.5606187582015991, 0.07574209570884705, 0.16041161119937897, 0.04281593859195709], [0.004966899286955595, 0.019286619499325752, 0.41744154691696167, 0.1408633142709732, 0.41744154691696167], [0.9272676110267639, 0.003997165709733963, 0.003997165709733963, 0.012333495542407036, 0.05240453779697418], [0.006282810587435961, 0.03170723468065262, 0.017780913040041924, 0.9125217199325562, 0.03170723468065262], [0.21208555996418, 0.030919451266527176, 0.4276077151298523, 0.030919451266527176, 0.29846784472465515], [0.3947582542896271, 0.04422589763998985, 0.3947582542896271, 0.033168159425258636, 0.13308951258659363], [0.01860019564628601, 0.002545516239479184, 0.006951462477445602, 0.48595142364501953, 0.48595142364501953], [0.00926903821527958, 0.02119101583957672, 0.9224417805671692, 0.02590719424188137, 0.02119101583957672], [0.7020455002784729, 0.005968521349132061, 0.12153007090091705, 0.12153007090091705, 0.04892581328749657], [0.038148343563079834, 0.25560688972473145, 0.011206275783479214, 0.038148343563079834, 0.6568902134895325], [0.0018749069422483444, 0.29154661297798157, 0.29154661297798157, 0.026592815294861794, 0.38843902945518494], [0.056454066187143326, 0.01280862744897604, 0.16067592799663544, 0.006078365258872509, 0.7639830708503723], [0.009143097326159477, 0.26508140563964844, 0.3765963315963745, 0.26508140563964844, 0.08409784734249115], [0.08805245906114578, 0.4447137117385864, 0.36451828479766846, 0.014663035981357098, 0.08805245906114578], [0.02670319564640522, 0.02670319564640522, 0.32713520526885986, 0.4799267053604126, 0.1395316869020462], [0.038392916321754456, 0.2817615568637848, 0.31144222617149353, 0.056961070746183395, 0.31144222617149353], [0.035605911165475845, 0.2819505035877228, 0.2965925931930542, 0.2965925931930542, 0.0892583578824997], [0.03374781087040901, 0.009519034996628761, 0.38439810276031494, 0.03374781087040901, 0.538587212562561], [0.4551785886287689, 0.1549893617630005, 0.0672277957201004, 0.1676148921251297, 0.1549893617630005], [0.4918603301048279, 0.03853759914636612, 0.23455442488193512, 0.23455442488193512, 0.0004931719158776104], [0.21247009932994843, 0.03754755109548569, 0.21247009932994843, 0.1256948858499527, 0.41181737184524536], [0.2410580962896347, 0.3000629246234894, 0.00837814249098301, 0.1504378765821457, 0.3000629246234894], [0.001485516200773418, 0.02652578428387642, 0.39486071467399597, 0.40296807885169983, 0.17415988445281982], [0.014194282703101635, 0.13364608585834503, 0.014413995668292046, 0.7706559300422668, 0.06708969175815582], [0.444957435131073, 0.444957435131073, 0.002691172296181321, 0.002465722616761923, 0.10492829978466034], [0.0160380732268095, 2.762798612820916e-05, 0.0160380732268095, 0.41953691840171814, 0.5483593344688416], [0.48317432403564453, 0.026444870978593826, 0.004718751180917025, 0.48317432403564453, 0.0024877043906599283], [0.09803002327680588, 0.022013241425156593, 0.005766022484749556, 0.4370953440666199, 0.4370953440666199], [0.932935893535614, 0.004231549799442291, 0.002070273505523801, 0.05555978789925575, 0.005202540662139654], [0.0036901263520121574, 0.046973612159490585, 0.0036106158513575792, 0.046973612159490585, 0.8987520933151245], [0.37555116415023804, 0.0042533488012850285, 0.007196187973022461, 0.37555116415023804, 0.23744817078113556], [0.0072354963049292564, 0.033056098967790604, 0.6908707618713379, 0.23578155040740967, 0.033056098967790604], [0.03320314735174179, 0.03320314735174179, 0.7516569495201111, 0.14927978813648224, 0.03265692666172981], [0.04863109439611435, 0.04863109439611435, 0.0032613049261271954, 0.23362958431243896, 0.6658470034599304], [0.7136964201927185, 0.027613027021288872, 0.0907241553068161, 0.027613027021288872, 0.14035333693027496], [0.49419352412223816, 0.012044033035635948, 0.245794415473938, 0.0021735215559601784, 0.245794415473938], [0.0160494577139616, 0.30229395627975464, 0.07795407623052597, 0.3018512725830078, 0.3018512725830078], [0.8580358624458313, 0.011212102137506008, 0.02864331193268299, 0.05105435848236084, 0.05105435848236084], [0.007670782506465912, 0.04296882823109627, 0.07143303751945496, 0.007670782506465912, 0.8702566027641296], [0.4706234037876129, 0.0037600621581077576, 0.04246960207819939, 0.4706234037876129, 0.012523581273853779], [0.021627727895975113, 0.010419635102152824, 0.4211426079273224, 0.4211426079273224, 0.12566740810871124], [0.005238081328570843, 2.1623587599606253e-05, 2.1623587599606253e-05, 0.532943844795227, 0.4617747962474823], [0.16779078543186188, 0.009339860640466213, 0.27509579062461853, 0.27267777919769287, 0.27509579062461853], [0.035321857780218124, 0.4695879817008972, 0.018988683819770813, 0.006513523869216442, 0.4695879817008972], [0.055993109941482544, 0.1397019475698471, 0.055993109941482544, 0.03164278343319893, 0.7166690826416016], [0.017695264890789986, 0.042242974042892456, 0.34641334414482117, 0.008199923671782017, 0.5854485034942627], [0.45494478940963745, 0.07146958261728287, 0.12717075645923615, 0.27494531869888306, 0.07146958261728287], [0.4201391041278839, 0.265671044588089, 0.031621769070625305, 0.016896994784474373, 0.265671044588089], [0.05640869960188866, 0.3316158056259155, 0.23713763058185577, 0.3316158056259155, 0.043222032487392426], [0.01729901134967804, 0.01729901134967804, 0.14209522306919098, 0.12291362881660461, 0.7003931999206543], [0.6878919005393982, 7.024037768132985e-05, 7.024037768132985e-05, 0.17731551826000214, 0.1346520632505417], [0.07847076654434204, 0.29931631684303284, 0.4416968822479248, 0.09025803208351135, 0.09025803208351135], [0.009191147051751614, 0.022652436047792435, 0.8720550537109375, 0.009191147051751614, 0.086910180747509], [0.3325484097003937, 0.43414872884750366, 0.004565591458231211, 0.006226916331797838, 0.22251038253307343], [0.5758351683616638, 0.006225018296390772, 0.0673971027135849, 0.0673971027135849, 0.2831456959247589], [0.008558995090425014, 0.008558995090425014, 0.03648914024233818, 0.21874961256980896, 0.7276432514190674], [0.0865953117609024, 0.07714678347110748, 0.7562289237976074, 0.07714678347110748, 0.002882177708670497], [0.006825407966971397, 0.006825407966971397, 0.038925234228372574, 0.940142035484314, 0.00728190690279007], [0.6549209952354431, 0.12755481898784637, 0.009365974925458431, 0.08060337603092194, 0.12755481898784637], [0.004107241053134203, 0.6527186036109924, 0.3176858127117157, 0.012744143605232239, 0.012744143605232239], [0.38366934657096863, 0.2067524939775467, 0.2067524939775467, 0.20005641877651215, 0.00276929815299809], [0.026914183050394058, 0.0007182395202107728, 0.46694618463516235, 0.46694618463516235, 0.038475193083286285], [0.026562748476862907, 0.8344902396202087, 0.026562748476862907, 0.08886043727397919, 0.02352386713027954], [0.005339149385690689, 0.40362825989723206, 0.40362825989723206, 0.17933370172977448, 0.008070617914199829], [0.043996360152959824, 0.0019403939368203282, 0.04691425338387489, 0.4535744786262512, 0.4535744786262512], [0.16394291818141937, 0.03380816429853439, 0.7692971229553223, 0.01647591032087803, 0.01647591032087803], [0.12215366959571838, 0.16876021027565002, 0.16876021027565002, 0.472507119178772, 0.06781875342130661], [0.000865117646753788, 0.001436973107047379, 0.0075911907479166985, 0.001436973107047379, 0.988669753074646], [5.1549504860304296e-05, 0.05352184176445007, 0.15357781946659088, 0.7025678157806396, 0.0902809426188469], [0.2028477042913437, 0.1737840175628662, 0.3115622401237488, 0.0002438375959172845, 0.3115622401237488], [0.006239387206733227, 0.6369526982307434, 0.11823765188455582, 0.12033261358737946, 0.11823765188455582], [4.027820978080854e-05, 4.027820978080854e-05, 0.007368022110313177, 0.005167003255337477, 0.9873844385147095], [0.017769398167729378, 0.017769398167729378, 0.7432947158813477, 0.2118820995092392, 0.009284386411309242], [0.00014516073861159384, 0.2312958538532257, 0.7464870810508728, 0.011035967618227005, 0.011035967618227005], [0.45894482731819153, 0.0016405020141974092, 0.0016405020141974092, 0.5341811776161194, 0.003592965193092823], [0.090044766664505, 0.3715570569038391, 0.3715570569038391, 0.0842045322060585, 0.08263660967350006], [0.507966935634613, 0.1773865818977356, 0.1773865818977356, 0.12754373252391815, 0.00971613172441721], [0.01413167268037796, 0.4655056297779083, 0.04696476832032204, 0.4655056297779083, 0.007892247289419174], [0.7247924208641052, 0.08095233887434006, 9.491737000644207e-05, 0.11320797353982925, 0.08095233887434006], [0.5750992894172668, 0.02393265627324581, 0.18994782865047455, 0.18994782865047455, 0.021072369068861008], [0.4529663622379303, 0.0002797238703351468, 0.5073068737983704, 0.0002797238703351468, 0.03916730731725693], [0.006987517233937979, 0.7729425430297852, 0.027783939614892006, 0.16450199484825134, 0.027783939614892006], [0.0597013458609581, 0.05594591051340103, 0.3763023614883423, 0.1317480504512787, 0.3763023614883423], [0.06642308831214905, 0.06642308831214905, 0.20486804842948914, 0.019663026556372643, 0.6426227688789368], [0.25776052474975586, 0.4115242063999176, 0.006098198238760233, 0.31851890683174133, 0.006098198238760233], [0.0033439588733017445, 0.3776361346244812, 0.17049121856689453, 0.07089251279830933, 0.3776361346244812], [0.34757348895072937, 0.024039115756750107, 0.012320022098720074, 0.34757348895072937, 0.2684938907623291], [0.3899818956851959, 0.14638571441173553, 0.05832890048623085, 0.14638571441173553, 0.25891777873039246], [0.03823886066675186, 0.7889842987060547, 0.11795955896377563, 0.03823886066675186, 0.016578394919633865], [0.0043627433478832245, 0.14898982644081116, 0.0043627433478832245, 0.571839451789856, 0.27044519782066345], [6.393896910594776e-05, 0.005485274363309145, 0.42361316084861755, 0.14722445607185364, 0.42361316084861755], [0.004091383423656225, 0.4450068771839142, 0.004091383423656225, 0.004470509942620993, 0.5423398613929749], [0.009497751481831074, 0.08643529564142227, 0.004958295729011297, 0.8896108865737915, 0.009497751481831074], [0.1792304664850235, 0.0004968843422830105, 0.01782170683145523, 0.1792304664850235, 0.6232205033302307], [0.3213685154914856, 0.014160720631480217, 0.19216182827949524, 0.19216182827949524, 0.28014710545539856], [0.0020515816286206245, 0.0017810204299166799, 0.46489840745925903, 0.46489840745925903, 0.06637062132358551], [0.07573095709085464, 0.4063705801963806, 0.2494729608297348, 0.2494729608297348, 0.018952511250972748], [0.012637685984373093, 0.8350057601928711, 0.07301624864339828, 0.012637685984373093, 0.0667026937007904], [0.003348936792463064, 0.07743141800165176, 0.0068682110868394375, 0.0068682110868394375, 0.9054832458496094], [5.190792944631539e-05, 0.10621624439954758, 0.26847073435783386, 0.35679036378860474, 0.26847073435783386], [0.054679445922374725, 0.39113348722457886, 0.16304738819599152, 6.173121164465556e-06, 0.39113348722457886], [0.05088818818330765, 0.05088818818330765, 0.689839780330658, 0.15656305849552155, 0.05182085186243057], [0.0018293861066922545, 0.08359679579734802, 0.020582400262355804, 0.020582400262355804, 0.8734090924263], [0.45488089323043823, 0.01593203656375408, 0.021618951112031937, 0.0526871532201767, 0.45488089323043823], [0.015329528599977493, 0.9643322825431824, 0.002436993410810828, 0.002436993410810828, 0.015464176423847675], [0.21137964725494385, 0.23386205732822418, 0.21137964725494385, 0.26313433051109314, 0.08024432510137558], [0.18891625106334686, 0.5407639741897583, 0.18891625106334686, 0.07374792546033859, 0.007655589375644922], [0.163800910115242, 0.02574644610285759, 0.2882847785949707, 0.5053958296775818, 0.016772037371993065], [0.1693534255027771, 0.0024101021699607372, 0.1693534255027771, 0.18685723841190338, 0.47202587127685547], [0.00769254844635725, 0.26090893149375916, 0.23297938704490662, 0.23297938704490662, 0.2654397487640381], [0.31160420179367065, 0.09763612598180771, 0.26487910747528076, 0.014276372268795967, 0.31160420179367065], [0.46745651960372925, 0.013485580682754517, 0.007878069765865803, 0.25558990240097046, 0.25558990240097046], [0.03874298557639122, 0.3967464864253998, 8.595612598583102e-05, 0.16767804324626923, 0.3967464864253998], [0.23943644762039185, 0.12718433141708374, 0.30812227725982666, 0.21699215471744537, 0.10826483368873596], [0.22972798347473145, 0.09880303591489792, 0.22972798347473145, 0.4400852620601654, 0.0016556227346882224], [0.024029148742556572, 0.5615411996841431, 0.2619193196296692, 0.024029148742556572, 0.12848122417926788], [0.30016475915908813, 0.01739869825541973, 0.30016475915908813, 0.37409523129463196, 0.008176538161933422], [0.2523873448371887, 0.2804384231567383, 0.17526473104953766, 0.03952217847108841, 0.2523873448371887], [0.005494763143360615, 0.6115289330482483, 0.1875816285610199, 0.1875816285610199, 0.007813052274286747], [0.3375268578529358, 0.1236511692404747, 0.1102747991681099, 0.3375268578529358, 0.09102023392915726], [0.7660766243934631, 0.0430157408118248, 0.1428438425064087, 0.0050480784848332405, 0.0430157408118248], [0.03785154968500137, 0.03785154968500137, 0.00013155593478586525, 0.029195468872785568, 0.8949698805809021], [0.12226516753435135, 0.10910121351480484, 0.1660376936197281, 0.12226516753435135, 0.4803306460380554], [0.10016079992055893, 0.000856344064231962, 0.02319786697626114, 0.009554744698107243, 0.866230309009552], [0.14626671373844147, 0.01284581609070301, 0.41352900862693787, 0.41352900862693787, 0.013829407282173634], [0.1776506006717682, 0.05262267589569092, 0.4969662129878998, 0.1776506006717682, 0.0951099544763565], [0.0976225733757019, 0.14940334856510162, 0.014693167991936207, 0.5888776183128357, 0.14940334856510162], [0.25628623366355896, 0.35447439551353455, 0.06271235644817352, 0.25628623366355896, 0.0702408030629158], [0.04280983656644821, 0.04280983656644821, 0.5896357893943787, 0.2927546203136444, 0.031989965587854385], [0.5743635892868042, 0.2520345151424408, 0.12883974611759186, 0.010731681250035763, 0.034030452370643616], [0.12268701195716858, 0.0009648737031966448, 0.7502564787864685, 0.12268701195716858, 0.0034046315122395754], [0.20244406163692474, 0.3454078435897827, 0.07196635007858276, 0.03477387875318527, 0.3454078435897827], [0.010394399054348469, 0.3509816825389862, 0.050813693553209305, 0.23682858049869537, 0.3509816825389862], [0.2023652195930481, 0.11142094433307648, 0.008012613281607628, 0.2023652195930481, 0.47583603858947754], [0.0018639527261257172, 0.0018639527261257172, 0.9726075530052185, 0.005767599679529667, 0.017896967008709908], [0.012685748748481274, 0.012685748748481274, 0.950330376625061, 0.00010787030623760074, 0.024190185591578484], [0.012516363523900509, 0.43243342638015747, 0.23115625977516174, 0.3113776743412018, 0.012516363523900509], [0.003334569977596402, 0.23445509374141693, 6.29710266366601e-05, 0.026574401184916496, 0.7355729937553406], [0.005895639304071665, 0.09665936976671219, 0.4433933198451996, 0.4433933198451996, 0.0106583246961236], [0.07605261355638504, 0.07605261355638504, 0.08372853696346283, 0.7522048354148865, 0.011961374431848526], [0.01070245448499918, 0.7785247564315796, 0.15665219724178314, 0.043418191373348236, 0.01070245448499918], [0.5289188623428345, 0.4497215151786804, 0.016255922615528107, 0.0025518517941236496, 0.0025518517941236496], [0.022626953199505806, 0.23988783359527588, 0.30562883615493774, 0.12622755765914917, 0.30562883615493774], [0.17518241703510284, 0.22342447936534882, 0.22342447936534882, 0.18291890621185303, 0.1950497180223465], [0.11527854949235916, 0.3439652621746063, 0.10163293778896332, 0.09515797346830368, 0.3439652621746063], [0.4293889105319977, 0.000885635323356837, 0.1119571328163147, 0.028379404917359352, 0.4293889105319977], [0.006927387323230505, 0.0842880979180336, 0.300606906414032, 0.3040888011455536, 0.3040888011455536], [0.00921582616865635, 0.005524348001927137, 0.01873043365776539, 0.9477989077568054, 0.01873043365776539], [0.10403800010681152, 0.03136870265007019, 0.10403800010681152, 0.24500076472759247, 0.5155544877052307], [0.015475906431674957, 0.22943846881389618, 0.22943846881389618, 0.14957886934280396, 0.3760682940483093], [0.6031603217124939, 0.07725899666547775, 0.0004364147607702762, 0.0004364147607702762, 0.31870782375335693], [0.039050932973623276, 0.00037974107544869184, 0.3275429308414459, 0.31651315093040466, 0.31651315093040466], [0.25883564352989197, 0.27471423149108887, 0.4446934461593628, 0.004021238535642624, 0.01773545891046524], [0.2553892135620117, 0.25506535172462463, 0.053883373737335205, 0.007835115306079388, 0.4278268814086914], [0.10673942416906357, 0.018748372793197632, 0.6129703521728516, 0.13077092170715332, 0.13077092170715332], [0.12760882079601288, 0.043111659586429596, 0.25185495615005493, 0.2887122929096222, 0.2887122929096222], [0.016708413138985634, 0.8822599649429321, 0.0967804491519928, 0.002125601517036557, 0.002125601517036557], [0.008968919515609741, 0.9599456787109375, 0.008968919515609741, 0.010350469499826431, 0.01176596898585558], [0.0795908197760582, 0.5328755378723145, 0.14186272025108337, 0.0795908197760582, 0.1660800576210022], [0.29794973134994507, 0.010271739214658737, 0.332877516746521, 0.026023495942354202, 0.332877516746521], [0.45947712659835815, 0.0002521059359423816, 0.13095462322235107, 0.40906399488449097, 0.0002521059359423816], [0.11511809378862381, 0.820802628993988, 0.028178835287690163, 0.01795019768178463, 0.01795019768178463], [0.023964272812008858, 0.01536908932030201, 0.01536908932030201, 0.46866241097450256, 0.4766350984573364], [0.0008542725117877126, 0.0736827552318573, 0.0008542725117877126, 0.8337459564208984, 0.09086280316114426], [0.001235834788531065, 0.1662437617778778, 0.15986384451389313, 0.5127926468849182, 0.15986384451389313], [0.06018069386482239, 0.4621674418449402, 0.005690964870154858, 0.4621674418449402, 0.009793427772819996], [0.0012784503633156419, 0.4930330216884613, 0.0008006967254914343, 0.01185471098870039, 0.4930330216884613], [0.3620883822441101, 0.21453845500946045, 0.0023421163205057383, 0.058942705392837524, 0.3620883822441101], [0.05911348760128021, 0.06447722762823105, 0.05911348760128021, 0.7825135588645935, 0.03478218987584114], [0.001720822649076581, 0.0035379331093281507, 0.001720822649076581, 0.9805106520652771, 0.012509816326200962], [0.17451070249080658, 0.379008948802948, 0.061612796038389206, 0.21035686135292053, 0.17451070249080658], [0.094574935734272, 0.24468234181404114, 0.24468234181404114, 0.313689649105072, 0.1023707166314125], [0.12742844223976135, 0.3560013473033905, 0.052171800285577774, 0.23219919204711914, 0.23219919204711914], [0.36441344022750854, 0.11645001173019409, 0.11960390955209732, 0.11645001173019409, 0.2830825746059418], [0.016322458162903786, 0.0772939920425415, 0.20316125452518463, 0.0772939920425415, 0.6259283423423767], [0.009228309616446495, 0.04329633712768555, 0.009228309616446495, 0.24431942403316498, 0.6939276456832886], [0.017774023115634918, 0.3403431475162506, 0.03503258898854256, 0.3403431475162506, 0.266507089138031], [0.17443707585334778, 0.0403798408806324, 0.068308986723423, 0.068308986723423, 0.6485649943351746], [0.15877608954906464, 0.15877608954906464, 0.1749676614999771, 0.03571141138672829, 0.4717687666416168], [0.0795821025967598, 0.09093355387449265, 0.7119872570037842, 0.09093355387449265, 0.02656349167227745], [0.04626947641372681, 0.04848780110478401, 0.28556370735168457, 0.04626947641372681, 0.5734096169471741], [0.031198648735880852, 0.031198648735880852, 0.35626620054244995, 0.5457956194877625, 0.03554084151983261], [0.15099753439426422, 0.28622984886169434, 0.11288131773471832, 0.15099753439426422, 0.2988937497138977], [0.0167855117470026, 0.9112527966499329, 0.015635935589671135, 0.015635935589671135, 0.04068976268172264], [0.573482871055603, 0.006011974532157183, 0.006011974532157183, 0.014606713317334652, 0.39988648891448975], [0.4449504017829895, 0.00014687670045532286, 0.4086282253265381, 0.00014687670045532286, 0.1461276113986969], [0.03370029479265213, 0.03370029479265213, 0.03837084025144577, 0.22160035371780396, 0.6726282238960266], [0.042335689067840576, 0.35960766673088074, 0.15976513922214508, 0.042335689067840576, 0.3959558308124542], [0.4893856346607208, 0.0036214450374245644, 0.015938319265842438, 0.0016690139891579747, 0.4893856346607208], [0.38494160771369934, 0.055904820561409, 0.04117603600025177, 0.13303595781326294, 0.38494160771369934], [0.112425297498703, 0.022308064624667168, 0.8255072832107544, 0.017451319843530655, 0.022308064624667168], [0.7523196339607239, 0.008232572115957737, 0.04800357297062874, 0.04800357297062874, 0.14344064891338348], [0.05683334916830063, 0.325418084859848, 0.3840392827987671, 0.05683334916830063, 0.17687587440013885], [0.00551298214122653, 0.006619876250624657, 0.38693904876708984, 0.2139890491962433, 0.38693904876708984], [0.024438204243779182, 0.884965717792511, 0.02547278441488743, 0.04068511724472046, 0.024438204243779182], [0.3891178071498871, 0.011390799656510353, 0.0038730662781745195, 0.20650051534175873, 0.3891178071498871], [0.05924580991268158, 0.6487734317779541, 0.036243047565221786, 0.19649185240268707, 0.05924580991268158], [0.05666971951723099, 0.028610235080122948, 0.5042026042938232, 0.20525872707366943, 0.20525872707366943], [0.043418969959020615, 0.10716275870800018, 0.3994210958480835, 0.05057608336210251, 0.3994210958480835], [0.6755256056785583, 0.06796404719352722, 0.23856300115585327, 0.01404083613306284, 0.003906552214175463], [0.015613920986652374, 0.12315370887517929, 0.12315370887517929, 0.20260345935821533, 0.5354751944541931], [0.6586908102035522, 0.26760438084602356, 0.02885022573173046, 0.01600433513522148, 0.02885022573173046], [0.538318932056427, 0.13411752879619598, 0.006914571858942509, 0.31373435258865356, 0.006914571858942509], [0.08142002671957016, 0.7963252663612366, 0.04079802334308624, 3.6685651139123365e-05, 0.08142002671957016], [0.10022957623004913, 0.00664325850084424, 0.05216078460216522, 0.8024771213531494, 0.03848918527364731], [0.0633237212896347, 0.0007485126261599362, 0.9204312562942505, 0.0007485126261599362, 0.014747945591807365], [0.004677803721278906, 5.223460175329819e-05, 0.3540128767490387, 0.2872442305088043, 0.3540128767490387], [0.06950679421424866, 0.13964392244815826, 0.39159679412841797, 0.007655581459403038, 0.39159679412841797], [0.19436989724636078, 0.008997826837003231, 0.7853162288665771, 0.0023182330187410116, 0.008997826837003231], [0.04836822673678398, 0.04836822673678398, 0.5446874499320984, 0.12859050929546356, 0.22998559474945068], [0.2435886114835739, 0.27115562558174133, 0.002561550121754408, 0.24134710431098938, 0.24134710431098938], [0.9258725643157959, 0.0006246269913390279, 0.026715870946645737, 0.0006246269913390279, 0.046162284910678864], [0.005701710935682058, 0.019702808931469917, 0.005701710935682058, 0.1554912030696869, 0.813402533531189], [0.6215370893478394, 0.26058509945869446, 0.00018252576410304755, 0.10936371982097626, 0.008331541903316975], [0.06446560472249985, 0.05116836354136467, 0.12946757674217224, 0.20065607130527496, 0.5542423725128174], [0.008248298428952694, 0.07800299674272537, 0.3509296774864197, 0.3509296774864197, 0.21188940107822418], [0.8009198904037476, 0.09061449021100998, 0.0032491076271981, 0.0032491076271981, 0.10196740925312042], [0.27896934747695923, 0.27896934747695923, 0.12107697874307632, 0.30169883370399475, 0.019285529851913452], [0.014879613183438778, 0.09505569189786911, 0.8316720128059387, 0.05220363661646843, 0.006189101841300726], [0.01803099736571312, 0.08106168359518051, 0.01803099736571312, 0.16220982372760773, 0.7206665277481079], [0.1028846725821495, 0.05438627302646637, 0.057034194469451904, 0.6828101873397827, 0.1028846725821495], [0.3645111620426178, 0.40793171525001526, 0.10765969753265381, 0.10765969753265381, 0.012237746268510818], [0.3417373597621918, 0.0032310346141457558, 0.26140153408050537, 0.0518927164375782, 0.3417373597621918], [0.20999306440353394, 0.1761833131313324, 0.17852747440338135, 0.20999306440353394, 0.22530320286750793], [0.009291508235037327, 0.39413881301879883, 0.5834997892379761, 0.006534943822771311, 0.006534943822771311], [0.001467083697207272, 0.001467083697207272, 0.899898886680603, 0.01492377184331417, 0.0822431817650795], [0.0008680532919242978, 0.4036463797092438, 0.0008680532919242978, 0.13865458965301514, 0.4559629261493683], [0.03141295164823532, 0.0035854310262948275, 0.47516873478889465, 0.47516873478889465, 0.014664198271930218], [0.5777894854545593, 0.003807408967986703, 0.11424174904823303, 0.003807408967986703, 0.30035400390625], [0.0044471812434494495, 0.7774224877357483, 0.11166199296712875, 0.0044471812434494495, 0.10202118754386902], [0.03153722360730171, 0.2483207881450653, 0.2483207881450653, 0.006744584999978542, 0.46507665514945984], [0.19232438504695892, 0.22615300118923187, 0.13092198967933655, 0.22444762289524078, 0.22615300118923187], [0.06780771911144257, 0.3294925391674042, 0.08887308835983276, 0.18433412909507751, 0.3294925391674042], [0.00044395338045433164, 0.0005537453689612448, 0.9555912613868713, 0.042967163026332855, 0.00044395338045433164], [4.594627534970641e-05, 0.058872248977422714, 0.058872248977422714, 0.8383122682571411, 0.04389718919992447], [0.27134740352630615, 0.6297321915626526, 0.03672216460108757, 0.03672216460108757, 0.025476034730672836], [0.3369639217853546, 0.3213980495929718, 0.12422898411750793, 0.12422898411750793, 0.09318004548549652], [0.40283203125, 0.0489211305975914, 0.40283203125, 0.14167103171348572, 0.0037437856663018465], [0.017363157123327255, 0.35344427824020386, 0.35344427824020386, 0.01675243116915226, 0.258995920419693], [0.10773597657680511, 0.1914002150297165, 0.1914002150297165, 0.04211289808154106, 0.46735066175460815], [0.06389735639095306, 0.3832305669784546, 0.5268827080726624, 0.012994671240448952, 0.012994671240448952], [0.2826893925666809, 0.1390691101551056, 0.07904751598834991, 0.24959696829319, 0.24959696829319], [0.27965041995048523, 0.01224827766418457, 0.4034864604473114, 0.01224827766418457, 0.2923665940761566], [0.31153225898742676, 0.13554517924785614, 0.0004603902925737202, 0.37595874071121216, 0.17650340497493744], [0.019964754581451416, 0.051590580493211746, 0.42582380771636963, 0.42582380771636963, 0.0767970159649849], [0.818532407283783, 0.06432842463254929, 0.03879128396511078, 0.06432842463254929, 0.01401941291987896], [0.5441907644271851, 0.20179200172424316, 0.01128204632550478, 0.04094311222434044, 0.20179200172424316], [0.29430216550827026, 0.29430216550827026, 0.04074318706989288, 0.3341694176197052, 0.03648311272263527], [0.08310442417860031, 0.08310442417860031, 0.3205665051937103, 0.10440319031476974, 0.4088214933872223], [0.002571946708485484, 0.45851966738700867, 0.07996537536382675, 0.45851966738700867, 0.00042335843318141997], [0.0010039262706413865, 0.0718897357583046, 0.744421124458313, 0.0718897357583046, 0.11079540103673935], [0.3346051275730133, 0.3346051275730133, 0.2980274260044098, 0.006771514192223549, 0.025990799069404602], [0.4973200261592865, 0.1452893763780594, 0.35376906394958496, 0.001810764311812818, 0.001810764311812818], [0.002759003546088934, 0.16398589313030243, 0.6197037696838379, 0.002759003546088934, 0.21079231798648834], [0.2896905839443207, 0.06745230406522751, 0.028711853548884392, 0.2896905839443207, 0.3244546055793762], [0.0034204949624836445, 0.35559314489364624, 0.300790011882782, 0.300790011882782, 0.03940635547041893], [0.30242809653282166, 0.06638628989458084, 0.30242809653282166, 0.3254793882369995, 0.003278122516348958], [0.35830312967300415, 0.009706687182188034, 0.26874014735221863, 0.09450982511043549, 0.26874014735221863], [0.0006699165096506476, 0.41407451033592224, 0.16296137869358063, 0.008219633251428604, 0.41407451033592224], [0.2138502150774002, 0.2138502150774002, 0.5060855746269226, 0.06372184306383133, 0.0024921202566474676], [0.007210324518382549, 0.042855970561504364, 0.8366804122924805, 0.042855970561504364, 0.07039733976125717], [0.06874755024909973, 0.08790463209152222, 0.07674175500869751, 0.08790463209152222, 0.6787015199661255], [0.3190390169620514, 0.01398302149027586, 0.060947954654693604, 0.28699105978012085, 0.3190390169620514], [0.012392083182930946, 0.012392083182930946, 0.20938390493392944, 0.053563911467790604, 0.7122679352760315], [0.11632133275270462, 0.7160370945930481, 0.0801219567656517, 0.0801219567656517, 0.007397683337330818], [0.39691784977912903, 0.12551629543304443, 0.4774307310581207, 6.755336653441191e-05, 6.755336653441191e-05], [0.04774824157357216, 0.08272535353899002, 0.6975181102752686, 0.11638596653938293, 0.055622398853302], [0.3039913773536682, 0.0046959202736616135, 0.3232162296772003, 0.3039913773536682, 0.0641050860285759], [0.06016429513692856, 0.0012722618412226439, 0.06016429513692856, 0.4992392361164093, 0.3791598975658417], [0.01683357171714306, 0.47379666566848755, 0.47379666566848755, 0.03268207237124443, 0.0028909374959766865], [0.10033368319272995, 0.42687422037124634, 0.024483639746904373, 0.021434197202324867, 0.42687422037124634], [0.04714815691113472, 0.0528191477060318, 0.0528191477060318, 0.45125648379325867, 0.3959570527076721], [0.11780425906181335, 0.6336854100227356, 0.0497613325715065, 0.0497613325715065, 0.14898772537708282], [0.07449376583099365, 0.15890087187290192, 0.37857332825660706, 0.37857332825660706, 0.009458743967115879], [0.012208261527121067, 0.6832571625709534, 0.23904664814472198, 0.05327966809272766, 0.012208261527121067], [0.00015722133684903383, 0.01183861680328846, 0.00015722133684903383, 0.008290406316518784, 0.979556679725647], [0.0012440310092642903, 0.8510702252388, 0.145514115691185, 0.0010858256136998534, 0.0010858256136998534], [0.005330218467861414, 0.48194509744644165, 0.0027374797500669956, 0.5072497129440308, 0.0027374797500669956], [0.012261590920388699, 0.005185169167816639, 0.7575249075889587, 0.2127668261528015, 0.012261590920388699], [0.0034165927208960056, 0.032798219472169876, 0.46768617630004883, 0.46768617630004883, 0.02841280959546566], [0.11701451987028122, 0.16974887251853943, 0.5433303117752075, 0.16974887251853943, 0.0001574409252498299], [0.4408825933933258, 0.1009235680103302, 0.013056673109531403, 0.004254524130374193, 0.4408825933933258], [0.19498397409915924, 0.07229641079902649, 0.28632795810699463, 0.19498397409915924, 0.2514076828956604], [0.1740640252828598, 0.013324079103767872, 0.005617609713226557, 0.1740640252828598, 0.6329302191734314], [0.03557206317782402, 0.13663631677627563, 0.06004440039396286, 0.06004440039396286, 0.7077028155326843], [0.0680403858423233, 0.4345704913139343, 0.018799442797899246, 0.044019151479005814, 0.4345704913139343], [0.2446197271347046, 0.35235396027565, 0.010030749253928661, 0.04064154624938965, 0.35235396027565], [0.3564199209213257, 0.15396371483802795, 0.06184680759906769, 0.2532777488231659, 0.1744917780160904], [0.2073642462491989, 0.1296282708644867, 0.3109135031700134, 0.2073642462491989, 0.1447298228740692], [0.28500133752822876, 0.38050732016563416, 0.1407923400402069, 0.19039703905582428, 0.0033019455149769783], [0.008966843597590923, 0.1430816799402237, 0.6985929012298584, 0.0062768664211034775, 0.1430816799402237], [0.042460810393095016, 0.003206276334822178, 0.07696307450532913, 0.003206276334822178, 0.8741634488105774], [0.009388800710439682, 0.491671621799469, 0.23333629965782166, 0.03226706385612488, 0.23333629965782166], [0.10601957887411118, 0.004854429513216019, 0.7045241594314575, 0.07858222723007202, 0.10601957887411118], [0.13643574714660645, 0.25952965021133423, 0.24068982899188995, 0.12265493720769882, 0.24068982899188995], [0.006544824689626694, 0.6118098497390747, 0.05402058735489845, 0.32107990980148315, 0.006544824689626694], [0.07017973065376282, 0.7917216420173645, 0.04853808507323265, 0.04154268652200699, 0.0480179600417614], [0.018455950543284416, 0.07226906716823578, 0.07226906716823578, 0.22439096868038177, 0.6126148700714111], [0.3744050860404968, 0.19820638000965118, 0.3744050860404968, 0.00031381932785734534, 0.052669599652290344], [0.00786298606544733, 0.00786298606544733, 0.009919513948261738, 0.038860905915498734, 0.935493528842926], [0.21236009895801544, 0.6773980855941772, 0.021281816065311432, 0.08886188268661499, 9.802978456718847e-05], [0.7991214394569397, 0.04773586988449097, 0.04400968551635742, 0.04400968551635742, 0.0651232898235321], [0.05426586791872978, 0.7632802128791809, 0.1218109130859375, 0.05426586791872978, 0.006377201061695814], [0.6014863848686218, 0.0012917077401652932, 0.34629878401756287, 0.04963136464357376, 0.0012917077401652932], [0.492574006319046, 0.012189642526209354, 0.00032451696461066604, 0.492574006319046, 0.0023377800825983286], [0.024072473868727684, 0.5302278995513916, 0.07335961610078812, 0.07335961610078812, 0.29898038506507874], [0.23770232498645782, 0.09186436235904694, 0.20806492865085602, 0.23770232498645782, 0.22466608881950378], [0.251557320356369, 0.3245841860771179, 0.06649230420589447, 0.251557320356369, 0.10580886900424957], [0.2938859164714813, 0.27216142416000366, 0.06464551389217377, 0.2938859164714813, 0.07542119175195694], [0.08423087000846863, 0.3012828528881073, 0.3012828528881073, 0.061750106513500214, 0.25145334005355835], [0.08953701704740524, 0.00558537058532238, 0.022834856063127518, 0.8592078685760498, 0.022834856063127518]]\n",
      "[[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC: 100%|██████████████████████████████| 12649/12649 [00:06<00:00, 2005.54it/s]\n",
      "AUC: 100%|████████████████████████████| 12649/12649 [00:00<00:00, 100388.95it/s]\n",
      "AUC: 100%|█████████████████████████████| 12649/12649 [00:00<00:00, 38443.77it/s]\n",
      "AUC: 100%|█████████████████████████████| 12649/12649 [00:00<00:00, 37280.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MetricEvaluator class>: \n",
      " {\n",
      "    \"auc\": 0.5380860147047197,\n",
      "    \"mrr\": 0.5045668959338024,\n",
      "    \"ndcg@5\": 0.6256726770845469,\n",
      "    \"ndcg@10\": 0.6256726770845469\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "BATCH_SIZE_TEST = 10\n",
    "\n",
    "dataset.setup_test_data(dataset_path = DATAPATH, datasplit = DATASET, history_size = HISTORY_SIZE, columns = COLS, fraction = FRACTION, seed = SEED, candidate_size=CANDITATE_SIZE)\n",
    "\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=dataset.df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "pred_test = []\n",
    "labels_test = []\n",
    "with torch.no_grad():\n",
    "    for iteration, (data, labels) in enumerate(test_dataloader):\n",
    "        his_input_title, pred_input_title, timestamps = data\n",
    "\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pred_input_title, his_input_title)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        for i in range(outputs.size(0)):\n",
    "            pred_test.append(outputs[i].tolist())\n",
    "            labels_test.append(labels[i].tolist())\n",
    "\n",
    "        print(f\"Test iteration {iteration + 1}/{len(test_dataloader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    print(\"Test loss:\", test_loss)\n",
    "\n",
    "print(pred_test)\n",
    "print(labels_test)\n",
    "\n",
    "from from_ebrec.evaluation import MetricEvaluator\n",
    "from from_ebrec.evaluation import AucScore, MrrScore, NdcgScore\n",
    "metrics = MetricEvaluator(\n",
    "    labels = labels_test,\n",
    "    predictions= pred_test,\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()\n",
    "print(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 predictions vs labels:\n",
      "Article 0\n",
      "0.070 vs 0.000\n",
      "0.011 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.070 vs 0.000\n",
      "0.848 vs 1.000\n",
      "\n",
      "Article 1\n",
      "0.000 vs 0.000\n",
      "0.015 vs 1.000\n",
      "0.057 vs 0.000\n",
      "0.928 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 2\n",
      "0.267 vs 0.000\n",
      "0.106 vs 0.000\n",
      "0.106 vs 0.000\n",
      "0.372 vs 0.000\n",
      "0.150 vs 1.000\n",
      "\n",
      "Article 3\n",
      "0.000 vs 1.000\n",
      "0.274 vs 0.000\n",
      "0.030 vs 0.000\n",
      "0.666 vs 0.000\n",
      "0.030 vs 0.000\n",
      "\n",
      "Article 4\n",
      "0.268 vs 0.000\n",
      "0.032 vs 0.000\n",
      "0.061 vs 1.000\n",
      "0.032 vs 0.000\n",
      "0.607 vs 0.000\n",
      "\n",
      "Article 5\n",
      "0.826 vs 0.000\n",
      "0.029 vs 0.000\n",
      "0.035 vs 1.000\n",
      "0.081 vs 0.000\n",
      "0.029 vs 0.000\n",
      "\n",
      "Article 6\n",
      "0.134 vs 0.000\n",
      "0.134 vs 0.000\n",
      "0.102 vs 1.000\n",
      "0.013 vs 0.000\n",
      "0.618 vs 0.000\n",
      "\n",
      "Article 7\n",
      "0.542 vs 1.000\n",
      "0.212 vs 0.000\n",
      "0.212 vs 0.000\n",
      "0.017 vs 0.000\n",
      "0.016 vs 0.000\n",
      "\n",
      "Article 8\n",
      "0.108 vs 0.000\n",
      "0.130 vs 0.000\n",
      "0.380 vs 0.000\n",
      "0.380 vs 0.000\n",
      "0.001 vs 1.000\n",
      "\n",
      "Article 9\n",
      "0.144 vs 0.000\n",
      "0.442 vs 0.000\n",
      "0.244 vs 1.000\n",
      "0.025 vs 0.000\n",
      "0.144 vs 0.000\n",
      "\n",
      "Article 10\n",
      "0.001 vs 0.000\n",
      "0.023 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.973 vs 1.000\n",
      "0.003 vs 0.000\n",
      "\n",
      "Article 11\n",
      "0.026 vs 0.000\n",
      "0.353 vs 1.000\n",
      "0.290 vs 0.000\n",
      "0.043 vs 0.000\n",
      "0.290 vs 0.000\n",
      "\n",
      "Article 12\n",
      "0.458 vs 0.000\n",
      "0.036 vs 0.000\n",
      "0.048 vs 0.000\n",
      "0.001 vs 1.000\n",
      "0.458 vs 0.000\n",
      "\n",
      "Article 13\n",
      "0.032 vs 1.000\n",
      "0.453 vs 0.000\n",
      "0.002 vs 0.000\n",
      "0.060 vs 0.000\n",
      "0.453 vs 0.000\n",
      "\n",
      "Article 14\n",
      "0.468 vs 0.000\n",
      "0.212 vs 0.000\n",
      "0.212 vs 0.000\n",
      "0.108 vs 0.000\n",
      "0.000 vs 1.000\n",
      "\n",
      "Article 15\n",
      "0.270 vs 0.000\n",
      "0.265 vs 0.000\n",
      "0.192 vs 0.000\n",
      "0.265 vs 0.000\n",
      "0.008 vs 1.000\n",
      "\n",
      "Article 16\n",
      "0.000 vs 0.000\n",
      "0.003 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.341 vs 0.000\n",
      "0.655 vs 0.000\n",
      "\n",
      "Article 17\n",
      "0.240 vs 0.000\n",
      "0.042 vs 1.000\n",
      "0.240 vs 0.000\n",
      "0.282 vs 0.000\n",
      "0.195 vs 0.000\n",
      "\n",
      "Article 18\n",
      "0.135 vs 0.000\n",
      "0.044 vs 0.000\n",
      "0.135 vs 0.000\n",
      "0.067 vs 1.000\n",
      "0.620 vs 0.000\n",
      "\n",
      "Article 19\n",
      "0.043 vs 0.000\n",
      "0.340 vs 0.000\n",
      "0.122 vs 1.000\n",
      "0.155 vs 0.000\n",
      "0.340 vs 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_to_print = 20\n",
    "print(\"Top %d predictions vs labels:\" % number_to_print)\n",
    "labels = dataset.df_test[\"labels\"].to_list()\n",
    "for i in range(number_to_print):\n",
    "    print(f\"Article {i}\")\n",
    "    for j in range(len(pred_test[i])):\n",
    "        print(f\"{pred_test[i][j]:.3f} vs {labels[i][j]:.3f}\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[46360  4236]\n",
      " [10252  2397]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Flatten the data for analysis\n",
    "predicted_probabilities = [prob for article in pred_test for prob in article]\n",
    "true_values = [val for article in labels[:len(pred_test)] for val in article]\n",
    "\n",
    "\n",
    "# Set a threshold (commonly 0.5) to classify probabilities as 0 or 1\n",
    "threshold = 0.5\n",
    "predicted_classes = [1 if p >= threshold else 0 for p in predicted_probabilities]\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_values, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate AUC and ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(true_values, predicted_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve with AUC value explicitly highlighted\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label=\"Random Guess\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKHOLE = False\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # fixes problem with graph\n",
    "\n",
    "\n",
    "if BLACKHOLE:\n",
    "    workspace_path = os.path.expandvars('$BLACKHOLE')\n",
    "    sys.path.append(workspace_path+'/DeepLearning/02456_news_project/src')\n",
    "    DATAPATH = Path(workspace_path+\"/DeepLearning/ebnerd_data\").expanduser()\n",
    "else:\n",
    "    DATAPATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "\n",
    "DATASET = \"ebnerd_demo\"\n",
    "#DATASET = \"ebnerd_small\"\n",
    "#DATASET = \"ebnerd_large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "\n",
    "#print(\"torch version:\", torch.__version__)\n",
    "\n",
    "# Check gpu availability\n",
    "\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(device)\n",
    "\n",
    "# Test:\n",
    "#print(torch.zeros(1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id                                 article_ids_inview  \\\n",
      "14146  1877949  [9765941, 9774527, 9738729, 9755800, 9774392, ...   \n",
      "11545   900378      [9775915, 9775900, 9775990, 9775673, 9775964]   \n",
      "7134    675902  [9771330, 9769497, 9767903, 9458293, 9233208, ...   \n",
      "7125    244367  [9775703, 9775894, 9775800, 9775785, 9775809, ...   \n",
      "3192    317862      [9774015, 9774404, 9774403, 9774527, 9774626]   \n",
      "...        ...                                                ...   \n",
      "18572  1178523      [9738729, 9769581, 9774383, 9774527, 9774532]   \n",
      "22991  1602581  [9775722, 9775325, 9774541, 9775697, 9775648, ...   \n",
      "20740  1279122  [9532638, 9778220, 9510890, 9717791, 9647575, ...   \n",
      "7729   1397437  [9758882, 9770997, 9767697, 9709817, 9770729, ...   \n",
      "20326   168638  [9772448, 9772858, 9772805, 9769624, 9772830, ...   \n",
      "\n",
      "      article_ids_clicked     impression_time  \n",
      "14146           [9774517] 2023-05-21 11:12:19  \n",
      "11545           [9775673] 2023-05-22 13:35:20  \n",
      "7134            [9771237] 2023-05-18 17:15:52  \n",
      "7125            [9775800] 2023-05-22 11:04:07  \n",
      "3192            [9774404] 2023-05-21 12:29:21  \n",
      "...                   ...                 ...  \n",
      "18572           [9774527] 2023-05-21 14:34:57  \n",
      "22991           [9775701] 2023-05-22 08:54:48  \n",
      "20740           [9779007] 2023-05-24 21:47:53  \n",
      "7729            [9770729] 2023-05-18 07:40:49  \n",
      "20326           [9772805] 2023-05-19 17:59:04  \n",
      "\n",
      "[247 rows x 4 columns]\n",
      "       article_id                                             title  \\\n",
      "0         3037230        Ishockey-spiller: Jeg troede jeg skulle dø   \n",
      "1         3044020                  Prins Harry tvunget til dna-test   \n",
      "2         3057622                       Rådden kørsel på blå plader   \n",
      "3         3073151                         Mærsk-arvinger i livsfare   \n",
      "4         3193383                    Skød svigersøn gennem babydyne   \n",
      "...           ...                                               ...   \n",
      "11772     9803492    Vilde billeder: Vulkan i udbrud i ferieparadis   \n",
      "11773     9803505               Flyvende Antonsen knuser topspiller   \n",
      "11774     9803525  Dansk skuespiller: - Jeg nægtede, at jeg var syg   \n",
      "11775     9803560       Så slemt er det: 14.000 huse er oversvømmet   \n",
      "11776     9803607       Aktion mod svindlere: Seks personer anholdt   \n",
      "\n",
      "                                                subtitle  \n",
      "0      ISHOCKEY: Ishockey-spilleren Sebastian Harts h...  \n",
      "1      Hoffet tvang Prins Harry til at tage dna-test ...  \n",
      "2      Kan ikke straffes: Udenlandske diplomater i Da...  \n",
      "3      FANGET I FLODBØLGEN: Skibsrederens oldebørn må...  \n",
      "4      44-årig kvinde tiltalt for drab på ekssvigersø...  \n",
      "...                                                  ...  \n",
      "11772        Der er gang i vulkanen på Hawaiis største ø  \n",
      "11773  Verdens nummer syv, Chou Tien-Chen, fik ikke e...  \n",
      "11774  Julie R. Ølgaard fik akut kejsersnit og fødte ...  \n",
      "11775  Tusindvis af huse står under vand i Kherson-re...  \n",
      "11776  Flere kvinder er ifølge politiet blevet svindl...  \n",
      "\n",
      "[11777 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int32 columns for key 'article_ids_inview'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m parquet_reader \u001b[38;5;241m=\u001b[39m Reader(dataset_path \u001b[38;5;241m=\u001b[39m DATAPATH, data_set \u001b[38;5;241m=\u001b[39m DATASET)\n\u001b[0;32m      5\u001b[0m behaviours, history, articles \u001b[38;5;241m=\u001b[39m parquet_reader\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m nrms_data \u001b[38;5;241m=\u001b[39m NRMSDataset(behaviours, history, articles, \u001b[38;5;241m0.01\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\Dev\\deep_learning\\02456_news_project\\src\\torch_nerd\\dataset.py:35\u001b[0m, in \u001b[0;36mNRMSDataset.__init__\u001b[1;34m(self, behaviours, history, articles, fraction)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(articles)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Merge the dataframes based on the article ids, i.e. expand the inview articles and clicked articles to include the title and subtitle\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m behaviours \u001b[38;5;241m=\u001b[39m behaviours\u001b[38;5;241m.\u001b[39mmerge(articles, left_on\u001b[38;5;241m=\u001b[39mcs\u001b[38;5;241m.\u001b[39mDEFAULT_INVIEW_ARTICLES_COL, right_on\u001b[38;5;241m=\u001b[39mcs\u001b[38;5;241m.\u001b[39mDEFAULT_ARTICLE_ID_COL, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m behaviours \u001b[38;5;241m=\u001b[39m behaviours\u001b[38;5;241m.\u001b[39mmerge(articles, left_on\u001b[38;5;241m=\u001b[39mcs\u001b[38;5;241m.\u001b[39mDEFAULT_CLICKED_ARTICLES_COL, right_on\u001b[38;5;241m=\u001b[39mcs\u001b[38;5;241m.\u001b[39mDEFAULT_ARTICLE_ID_COL, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_inview\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_clicked\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(behaviours)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10833\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10834\u001b[0m         right,\n\u001b[0;32m  10835\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m  10836\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m  10837\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m  10838\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m  10839\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m  10840\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m  10841\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m  10842\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m  10843\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m  10844\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m  10845\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10846\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[0;32m    173\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    174\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    175\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    176\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    177\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    178\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    179\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    180\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    181\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1508\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1504\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1505\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1506\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1507\u001b[0m     ):\n\u001b[1;32m-> 1508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int32 columns for key 'article_ids_inview'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "from parquets import Reader\n",
    "from dataset import NRMSDataset\n",
    "\n",
    "parquet_reader = Reader(dataset_path = DATAPATH, data_set = DATASET)\n",
    "behaviours, history, articles = parquet_reader.read(\"train\")\n",
    "\n",
    "nrms_data = NRMSDataset(behaviours, history, articles, 0.0001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

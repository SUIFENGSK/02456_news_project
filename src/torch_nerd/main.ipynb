{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T15:54:00.716569Z",
     "start_time": "2024-11-24T15:53:58.081981Z"
    }
   },
   "outputs": [],
   "source": [
    "BLACKHOLE = False\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "if BLACKHOLE:\n",
    "    workspace_path = os.path.expandvars('$BLACKHOLE')\n",
    "    sys.path.append(workspace_path+'/DeepLearning/02456_news_project/src')\n",
    "    DATAPATH = Path(workspace_path+\"/DeepLearning/ebnerd_data\").expanduser()\n",
    "else:\n",
    "    DATAPATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "\n",
    "DATASET = \"ebnerd_demo\"\n",
    "# DATASET = \"ebnerd_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1+cu124\n",
      "cuda\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "\n",
    "# Check gpu availability\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.zeros(1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T15:54:27.963083Z",
     "start_time": "2024-11-24T15:54:27.955803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSModel(\n",
      "  (word2vec_embedding): Embedding(100, 300)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (news_encoder): Sequential(\n",
      "    (0): Embedding(100, 300)\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): SelfAttention(\n",
      "      (query_layer): Linear(in_features=64, out_features=512, bias=True)\n",
      "      (key_layer): Linear(in_features=64, out_features=512, bias=True)\n",
      "      (value_layer): Linear(in_features=64, out_features=512, bias=True)\n",
      "    )\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): AttentionLayer2(\n",
      "      (attention_weight): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (user_encoder): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=512, bias=True)\n",
      "    (1): SelfAttention(\n",
      "      (query_layer): Linear(in_features=64, out_features=512, bias=True)\n",
      "      (key_layer): Linear(in_features=64, out_features=512, bias=True)\n",
      "      (value_layer): Linear(in_features=64, out_features=512, bias=True)\n",
      "    )\n",
      "    (2): AttentionLayer2(\n",
      "      (attention_weight): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check if the model can be loaded\n",
    "from nrms import NRMSModel\n",
    "from hyperparameters import HyperParameters\n",
    "\n",
    "# hparams contains the hyperparameters of the model:\n",
    "# They are:\n",
    "# vocab_size: int\n",
    "# word_embedding_dim: int\n",
    "# dropout: float\n",
    "\n",
    "\n",
    "hparams = HyperParameters(\n",
    "    vocab_size=100, \n",
    "    word_embedding_dim=300, \n",
    "    dropout=0.1, \n",
    "    head_num=8,\n",
    "    head_dim=64,\n",
    "    attention_hidden_dim=512,\n",
    "    title_size=20\n",
    ")\n",
    "\n",
    "word2vec_embedding = torch.randn(hparams.vocab_size, hparams.word_embedding_dim)\n",
    "\n",
    "model = NRMSModel(hparams=hparams, word2vec_embedding=word2vec_embedding)\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO HERFRA OG NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T16:48:11.267790Z",
     "start_time": "2024-11-24T16:48:09.343653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌─────────┬──────────────────────┬─────────────────────┬─────────────────────┬─────────────────────┐\n",
      "│ user_id ┆ impression_time_fixe ┆ scroll_percentage_f ┆ article_id_fixed    ┆ read_time_fixed     │\n",
      "│ ---     ┆ d                    ┆ ixed                ┆ ---                 ┆ ---                 │\n",
      "│ u32     ┆ ---                  ┆ ---                 ┆ list[i32]           ┆ list[f32]           │\n",
      "│         ┆ list[datetime[μs]]   ┆ list[f32]           ┆                     ┆                     │\n",
      "╞═════════╪══════════════════════╪═════════════════════╪═════════════════════╪═════════════════════╡\n",
      "│ 13538   ┆ [2023-04-27          ┆ [100.0, 35.0, …     ┆ [9738663, 9738569,  ┆ [17.0, 12.0, …      │\n",
      "│         ┆ 10:17:43, 2023-04-…  ┆ 100.0]              ┆ … 9769366]          ┆ 16.0]               │\n",
      "│ 58608   ┆ [2023-04-27          ┆ [37.0, 61.0, …      ┆ [9739362, 9739179,  ┆ [2.0, 24.0, … 0.0]  │\n",
      "│         ┆ 18:48:09, 2023-04-…  ┆ null]               ┆ … 9770333]          ┆                     │\n",
      "│ 95507   ┆ [2023-04-27          ┆ [60.0, 100.0, …     ┆ [9739035, 9738646,  ┆ [18.0, 29.0, … 0.0] │\n",
      "│         ┆ 15:20:28, 2023-04-…  ┆ null]               ┆ … 9769450]          ┆                     │\n",
      "│ 106588  ┆ [2023-04-27          ┆ [24.0, 57.0, …      ┆ [9738292, 9738216,  ┆ [9.0, 15.0, … 33.0] │\n",
      "│         ┆ 08:29:09, 2023-04-…  ┆ 100.0]              ┆ … 9747803]          ┆                     │\n",
      "│ 617963  ┆ [2023-04-27          ┆ [100.0, 100.0, …    ┆ [9739035, 9739088,  ┆ [45.0, 29.0, …      │\n",
      "│         ┆ 14:42:25, 2023-04-…  ┆ 90.0]               ┆ … 9770798]          ┆ 22.0]               │\n",
      "└─────────┴──────────────────────┴─────────────────────┴─────────────────────┴─────────────────────┘\n",
      "shape: (5, 17)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ impressio ┆ article_i ┆ impressio ┆ read_time ┆ … ┆ is_subscr ┆ session_i ┆ next_read ┆ next_scr │\n",
      "│ n_id      ┆ d         ┆ n_time    ┆ ---       ┆   ┆ iber      ┆ d         ┆ _time     ┆ oll_perc │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ f32       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ entage   │\n",
      "│ u32       ┆ i32       ┆ datetime[ ┆           ┆   ┆ bool      ┆ u32       ┆ f32       ┆ ---      │\n",
      "│           ┆           ┆ μs]       ┆           ┆   ┆           ┆           ┆           ┆ f32      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 48401     ┆ null      ┆ 2023-05-2 ┆ 21.0      ┆ … ┆ false     ┆ 21        ┆ 16.0      ┆ 27.0     │\n",
      "│           ┆           ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 21:06:50  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 152513    ┆ 9778745   ┆ 2023-05-2 ┆ 30.0      ┆ … ┆ false     ┆ 298       ┆ 2.0       ┆ 48.0     │\n",
      "│           ┆           ┆ 4         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 07:31:26  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 155390    ┆ null      ┆ 2023-05-2 ┆ 45.0      ┆ … ┆ false     ┆ 401       ┆ 215.0     ┆ 100.0    │\n",
      "│           ┆           ┆ 4         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 07:30:33  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 214679    ┆ null      ┆ 2023-05-2 ┆ 33.0      ┆ … ┆ false     ┆ 1357      ┆ 40.0      ┆ 47.0     │\n",
      "│           ┆           ┆ 3         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 05:25:40  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 214681    ┆ null      ┆ 2023-05-2 ┆ 21.0      ┆ … ┆ false     ┆ 1358      ┆ 5.0       ┆ 49.0     │\n",
      "│           ┆           ┆ 3         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 05:31:54  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from data_handler import NewsDataset\n",
    "\n",
    "# test\n",
    "dataset = NewsDataset(dataset_path=DATAPATH.joinpath(DATASET))\n",
    "\n",
    "print(dataset.df_history_train.head())\n",
    "\n",
    "print(dataset.df_behaviors_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NewsDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use the dataloader to separate the data into batches / validation / test sets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 4\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:163\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:172\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_source)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NewsDataset' has no len()"
     ]
    }
   ],
   "source": [
    "# Use the dataloader to separate the data into batches / validation / test sets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "from train import train\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    hparams=hparams,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

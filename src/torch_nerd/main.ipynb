{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:35:00.052795Z",
     "start_time": "2024-12-02T19:35:00.044836Z"
    }
   },
   "outputs": [],
   "source": [
    "BLACKHOLE = False\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # fixes problem with graph\n",
    "\n",
    "\n",
    "if BLACKHOLE:\n",
    "    workspace_path = os.path.expandvars('$BLACKHOLE')\n",
    "    sys.path.append(workspace_path+'/DeepLearning/02456_news_project/src')\n",
    "    DATAPATH = Path(workspace_path+\"/DeepLearning/ebnerd_data\").expanduser()\n",
    "else:\n",
    "    DATAPATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "\n",
    "DATASET = \"ebnerd_demo\"\n",
    "#DATASET = \"ebnerd_small\"\n",
    "#DATASET = \"ebnerd_large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:35:03.923111Z",
     "start_time": "2024-12-02T19:35:02.050814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1+cu124\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "\n",
    "# Check gpu availability\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Test:\n",
    "#print(torch.zeros(1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:35:04.714345Z",
     "start_time": "2024-12-02T19:35:03.927607Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.data_handler import NewsDataset\n",
    "import from_ebrec._constants as cs\n",
    "\n",
    "SEED = 42\n",
    "HISTORY_SIZE = 200\n",
    "CANDITATE_SIZE = 5\n",
    "\n",
    "COLS = [\n",
    "    cs.DEFAULT_USER_COL,\n",
    "    cs.DEFAULT_IMPRESSION_ID_COL,\n",
    "    cs.DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    cs.DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    cs.DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "\n",
    "#FRACTION = 0.001\n",
    "FRACTION = 0.01\n",
    "#FRACTION = 0.1\n",
    "#FRACTION = 1\n",
    "\n",
    "# test\n",
    "dataset = NewsDataset()\n",
    "\n",
    "dataset.setup_df(dataset_path = DATAPATH, datasplit = DATASET, history_size = HISTORY_SIZE, columns = COLS, fraction = FRACTION, seed = SEED, candidate_size=CANDITATE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:36:32.190522Z",
     "start_time": "2024-12-02T19:35:07.517602Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers as huggingface\n",
    "from from_ebrec._nlp import get_transformers_word_embeddings\n",
    "from from_ebrec._polars import concat_str_columns\n",
    "from from_ebrec._articles import convert_text2encoding_with_transformers\n",
    "from from_ebrec._articles import create_article_id_to_value_mapping\n",
    "\n",
    "dataset.setup_articles_data(dataset_path = DATAPATH.joinpath(DATASET))\n",
    "\n",
    "df_articles = dataset.df_articles\n",
    "\n",
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-large\"\n",
    "TEXT_COLUMNS_TO_USE = [cs.DEFAULT_SUBTITLE_COL, cs.DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = huggingface.AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = huggingface.AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH)\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_articles, value_col=token_col_title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "1 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "2 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "3 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "4 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "5 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "6 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "7 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "8 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "9 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "10 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "11 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "12 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "13 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "14 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "15 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "16 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "17 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "18 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "19 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "20 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "21 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "22 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "23 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "24 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "25 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "26 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "27 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "28 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "29 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "30 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "31 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "32 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "33 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "34 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "35 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "36 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "37 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "38 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "39 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "40 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "41 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "42 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "43 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "44 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "45 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "46 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "47 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "48 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "49 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "50 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "51 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "52 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "53 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "54 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "55 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "56 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "57 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "58 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "59 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "60 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "61 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "62 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "63 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "64 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "65 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "66 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "67 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "68 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "69 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "70 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "71 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "72 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "73 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "74 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "75 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "76 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "77 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "78 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "79 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "80 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "81 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "82 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "83 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "84 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "85 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "86 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "87 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "88 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "89 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "90 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "91 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "92 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "93 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "94 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "95 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "96 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "97 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "98 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "99 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "100 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "101 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "102 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "103 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "104 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "105 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "106 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "107 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "108 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "109 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "110 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "111 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "112 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "113 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "114 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "115 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "116 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "117 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "118 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "119 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "120 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "121 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "122 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "123 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "124 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "125 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "126 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "127 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "128 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "129 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "130 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "131 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "132 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "133 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "134 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "135 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "136 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "137 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "138 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "139 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "140 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "141 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "142 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "143 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "144 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "145 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "146 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "147 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "148 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "149 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "150 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "151 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "152 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "153 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "154 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "155 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "156 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "157 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "158 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "159 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "160 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "161 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "162 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "163 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "164 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "165 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "166 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "167 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "168 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "169 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "170 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "171 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "172 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "173 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "174 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "175 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "176 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "177 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "178 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "179 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "180 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "181 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "182 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "183 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "184 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "185 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "186 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "187 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "188 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "189 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "190 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "191 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "192 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "193 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "194 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "195 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "196 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "197 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "198 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "199 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "200 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "201 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "202 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "203 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "204 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "205 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "206 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "207 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "208 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "209 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "210 torch.Size([200, 30]) torch.Size([5, 30])\n",
      "211 torch.Size([200, 30]) torch.Size([5, 30])\n"
     ]
    }
   ],
   "source": [
    "from src.torch_nerd.dataset import NRMSDataLoader\n",
    "\n",
    "\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors= dataset.df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column= cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    ")\n",
    "for iteration, (data, labels) in enumerate(train_dataloader):\n",
    "        # Unpacking of batch\n",
    "        his_input_title, pred_input_title, timestamps = data\n",
    "        print(iteration, his_input_title.shape, pred_input_title.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:37:07.203670Z",
     "start_time": "2024-12-02T19:37:07.189798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSModel(\n",
      "  (news_encoder): NewsEncoder(\n",
      "    (embedding): Embedding(250002, 1024)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (positional_encoder): PositionEncoder(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (dense_layers): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=20, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "      (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "      (7): Dropout(p=0.2, inplace=False)\n",
      "      (8): Linear(in_features=20, out_features=1024, bias=True)\n",
      "      (9): ReLU()\n",
      "      (10): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (11): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (att_layer): AttLayer2(\n",
      "      (attention_projection): Linear(in_features=1024, out_features=200, bias=True)\n",
      "      (query_vector): Linear(in_features=200, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (user_encoder): UserEncoder(\n",
      "    (news_encoder): NewsEncoder(\n",
      "      (embedding): Embedding(250002, 1024)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (positional_encoder): PositionEncoder(\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (self_attention): SelfAttention(\n",
      "        (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (dense_layers): Sequential(\n",
      "        (0): Linear(in_features=1024, out_features=20, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.2, inplace=False)\n",
      "        (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "        (5): ReLU()\n",
      "        (6): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "        (7): Dropout(p=0.2, inplace=False)\n",
      "        (8): Linear(in_features=20, out_features=1024, bias=True)\n",
      "        (9): ReLU()\n",
      "        (10): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (11): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (att_layer): AttLayer2(\n",
      "        (attention_projection): Linear(in_features=1024, out_features=200, bias=True)\n",
      "        (query_vector): Linear(in_features=200, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (att_layer): AttLayer2(\n",
      "      (attention_projection): Linear(in_features=1024, out_features=200, bias=True)\n",
      "      (query_vector): Linear(in_features=200, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (click_predictor): ClickPredictor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nrms import NRMSModel\n",
    "from hyperparameters import hparams_nrms\n",
    "\n",
    "hparams = hparams_nrms()\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# PARAMETERS\n",
    "hparams.title_size = MAX_TITLE_LENGTH\n",
    "hparams.history_size = HISTORY_SIZE\n",
    "hparams.batch_size = BATCH_SIZE\n",
    "hparams.candidate_size = CANDITATE_SIZE\n",
    "\n",
    "# MODEL ARCHITECTURE\n",
    "hparams.head_num = 32\n",
    "hparams.head_dim = 32\n",
    "hparams.attention_hidden_dim = 200\n",
    "hparams.linear_hidden_dim = 20\n",
    "hparams.embedding_dim = word2vec_embedding.shape[1]\n",
    "\n",
    "hparams.use_positional_encoding = True\n",
    "\n",
    "hparams.use_time_embedding = False\n",
    "hparams.time_dim = 1\n",
    "hparams.time_embedding_dim = 32\n",
    "\n",
    "# MODEL OPTIMIZER:\n",
    "hparams.optimizer = \"adam\"\n",
    "hparams.loss = \"mse_loss\"\n",
    "hparams.dropout = 0.2\n",
    "hparams.learning_rate = 1e-4\n",
    "\n",
    "model = NRMSModel(hparams=hparams, word2vec_embedding=word2vec_embedding)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:37:12.471614Z",
     "start_time": "2024-12-02T19:37:12.005116Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "if hparams.loss == \"cross_entropy_loss\":\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "elif hparams.loss == \"mse_loss\":\n",
    "    criterion = nn.MSELoss()\n",
    "else:\n",
    "    raise ValueError(f\"Loss function {hparams.loss} not supported\")\n",
    "\n",
    "if hparams.optimizer == \"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hparams_nrms.learning_rate)\n",
    "else:\n",
    "    raise ValueError(f\"Optimizer {hparams.optimizer} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.torch_nerd.dataset import NRMSDataLoader\n",
    "\n",
    "\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors= dataset.df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column= cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors= dataset.df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column= cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:55:05.405907Z",
     "start_time": "2024-12-02T19:43:30.189951Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(pred_input_title, his_input_title)\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\Dev\\deep_learning\\02456_news_project\\src\\torch_nerd\\nrms.py:113\u001b[0m, in \u001b[0;36mNRMSModel.forward\u001b[1;34m(self, candidates, history, candidate_timestamps, history_timestamps)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, candidates, history, candidate_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, history_timestamps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):           \n\u001b[1;32m--> 113\u001b[0m     user_representation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_encoder(history, history_timestamps)  \u001b[38;5;66;03m# u in the paper\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     news_representations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(candidates\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_num \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mto(candidates\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;66;03m# candidate_size, head_num * head_dim\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(candidates\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]): \u001b[38;5;66;03m# for each candidate news encode the news\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\Dev\\deep_learning\\02456_news_project\\src\\torch_nerd\\nrms.py:83\u001b[0m, in \u001b[0;36mUserEncoder.forward\u001b[1;34m(self, history, timestamps)\u001b[0m\n\u001b[0;32m     81\u001b[0m         history_representations[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder(history[i], timestamps[i])  \u001b[38;5;66;03m# Shape: (head_num * head_dim)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m         history_representations[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder(history[i]) \u001b[38;5;66;03m# Shape: (head_num * head_dim)\u001b[39;00m\n\u001b[0;32m     84\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention(history_representations,\n\u001b[0;32m     85\u001b[0m                         history_representations, history_representations) \u001b[38;5;66;03m# Shape: (history_size, head_num * head_dim)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_layer(y) \u001b[38;5;66;03m# Shape: (head_num * head_dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\Dev\\deep_learning\\02456_news_project\\src\\torch_nerd\\nrms.py:59\u001b[0m, in \u001b[0;36mNewsEncoder.forward\u001b[1;34m(self, sequences_input_title, timestamps)\u001b[0m\n\u001b[0;32m     57\u001b[0m     embedded_sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([embedded_sequences, time_embedded], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Shape: (title_size, embedding_dim + time_embedding_dim)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embedded_sequences) \u001b[38;5;66;03m# Shape: (title_size, embedding_dim)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention(y, y, y)  \u001b[38;5;66;03m# Shape: (title_size, head_num * head_dim)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_layers(y)  \u001b[38;5;66;03m# Shape: (title_size, head_num * head_dim)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_layer(y) \u001b[38;5;66;03m# Shape: (head_num * head_dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\Dev\\deep_learning\\02456_news_project\\src\\torch_nerd\\layers.py:69\u001b[0m, in \u001b[0;36mSelfAttention.forward\u001b[1;34m(self, query, key, value)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    query, key, value: Tensors of shape (seq_len, input_dim)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Tensor of shape (seq_len, head_nums * head_dim)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Extract the sequence length from the input shape\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m seq_len, _ \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Project the inputs into the attention subspace\u001b[39;00m\n\u001b[0;32m     72\u001b[0m Q_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_proj(query)  \u001b[38;5;66;03m# (seq_len, head_nums * head_dim)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "# Move model to GPU if available\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "train_loss_history, val_loss_history = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    for iteration, (data, labels) in enumerate(train_dataloader):\n",
    "        # Unpacking of batch\n",
    "        his_input_title, pred_input_title, timestamps = data\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(pred_input_title, his_input_title)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}, Train iteration {iteration + 1}/{len(train_dataloader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for iteration, (data, labels) in enumerate(val_dataloader):\n",
    "            his_input_title, pred_input_title, timestamps = data\n",
    "\n",
    "            his_input_title = his_input_title.to(device)\n",
    "            pred_input_title = pred_input_title.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(pred_input_title, his_input_title)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}, Val iteration {iteration + 1}/{len(val_dataloader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    val_loss /= len(val_dataloader)\n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:55:34.910285Z",
     "start_time": "2024-12-02T19:55:34.366285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(val_loss_history, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:57:36.521266Z",
     "start_time": "2024-12-02T19:57:23.446145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test iteration 1/3: Loss = 0.1644\n",
      "Test iteration 2/3: Loss = 0.1637\n",
      "Test iteration 3/3: Loss = 0.1549\n",
      "Test loss: 0.16101658840974173\n",
      "[[0.20164380967617035, 0.28199493885040283, 0.15401583909988403, 0.18117274343967438, 0.18117274343967438], [0.19225075840950012, 0.21605895459651947, 0.212760791182518, 0.19225075840950012, 0.18667876720428467], [0.2663115859031677, 0.19358716905117035, 0.14849354326725006, 0.1963164359331131, 0.19529126584529877], [0.1727498322725296, 0.1727498322725296, 0.17899218201637268, 0.23382772505283356, 0.24168038368225098], [0.17470574378967285, 0.23126834630966187, 0.19002074003219604, 0.1872689574956894, 0.21673625707626343], [0.18230225145816803, 0.305752158164978, 0.305752158164978, 0.1025451198220253, 0.10364826023578644], [0.16690358519554138, 0.1747727394104004, 0.18999284505844116, 0.3014271855354309, 0.16690358519554138], [0.2755585014820099, 0.21645011007785797, 0.15526752173900604, 0.15526752173900604, 0.19745634496212006], [0.20091310143470764, 0.1966475397348404, 0.1966475397348404, 0.19020111858844757, 0.21559065580368042], [0.1999339908361435, 0.1792832463979721, 0.1792832463979721, 0.23597374558448792, 0.205525740981102], [0.2858583629131317, 0.10452231019735336, 0.2858583629131317, 0.142206609249115, 0.18155436217784882], [0.15816166996955872, 0.18081451952457428, 0.23219259083271027, 0.15816166996955872, 0.2706695795059204], [0.20069171488285065, 0.17151638865470886, 0.24329409003257751, 0.24329409003257751, 0.14120371639728546], [0.15137027204036713, 0.20507720112800598, 0.2233125865459442, 0.20507720112800598, 0.2151627093553543], [0.21425284445285797, 0.19825468957424164, 0.20315252244472504, 0.21425284445285797, 0.170087069272995], [0.23737971484661102, 0.20711421966552734, 0.20264235138893127, 0.16232164204120636, 0.19054216146469116], [0.321813702583313, 0.19064903259277344, 0.20430222153663635, 0.1416175365447998, 0.1416175365447998], [0.18263578414916992, 0.16878874599933624, 0.22652699053287506, 0.21199946105480194, 0.21004898846149445], [0.18727487325668335, 0.18727487325668335, 0.24020713567733765, 0.23654983937740326, 0.14869324862957], [0.15245957672595978, 0.15982533991336823, 0.4061442017555237, 0.14078545570373535, 0.14078545570373535], [0.17679853737354279, 0.17679853737354279, 0.15800972282886505, 0.2918815016746521, 0.19651168584823608], [0.17469412088394165, 0.17365695536136627, 0.17365695536136627, 0.27200743556022644, 0.20598450303077698], [0.1570405513048172, 0.23305082321166992, 0.1570405513048172, 0.25614476203918457, 0.1967233121395111], [0.1323513686656952, 0.30512940883636475, 0.15504108369350433, 0.10234873741865158, 0.30512940883636475], [0.12081802636384964, 0.17202486097812653, 0.4416963458061218, 0.12081802636384964, 0.14464272558689117]]\n",
      "[[0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC: 100%|| 25/25 [00:00<00:00, 1388.73it/s]\n",
      "AUC: 100%|| 25/25 [00:00<?, ?it/s]\n",
      "AUC: 100%|| 25/25 [00:00<00:00, 12499.42it/s]\n",
      "AUC: 100%|| 25/25 [00:00<00:00, 12486.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MetricEvaluator class>: \n",
      " {\n",
      "    \"auc\": 0.54,\n",
      "    \"mrr\": 0.5293333333333333,\n",
      "    \"ndcg@5\": 0.6437216712429763,\n",
      "    \"ndcg@10\": 0.6437216712429763\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "BATCH_SIZE_TEST = 10\n",
    "\n",
    "dataset.setup_test_data(dataset_path = DATAPATH, datasplit = DATASET, history_size = HISTORY_SIZE, columns = COLS, fraction = FRACTION, seed = SEED, candidate_size=CANDITATE_SIZE)\n",
    "\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=dataset.df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "pred_test = []\n",
    "labels_test = []\n",
    "with torch.no_grad():  \n",
    "    for iteration, (data, labels) in enumerate(test_dataloader):\n",
    "        his_input_title, pred_input_title, timestamps = data\n",
    "\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pred_input_title, his_input_title) \n",
    "        loss = criterion(outputs, labels)                 \n",
    "        test_loss += loss.item()\n",
    "\n",
    "        for i in range(outputs.size(0)):\n",
    "            pred_test.append(outputs[i].tolist())\n",
    "            labels_test.append(labels[i].tolist())\n",
    "\n",
    "        print(f\"Test iteration {iteration + 1}/{len(test_dataloader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    print(\"Test loss:\", test_loss)\n",
    "        \n",
    "print(pred_test)\n",
    "print(labels_test)\n",
    "\n",
    "from from_ebrec.evaluation import MetricEvaluator\n",
    "from from_ebrec.evaluation import AucScore, MrrScore, NdcgScore\n",
    "metrics = MetricEvaluator(\n",
    "    labels = labels_test,\n",
    "    predictions= pred_test,\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()\n",
    "print(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T19:57:39.522290Z",
     "start_time": "2024-12-02T19:57:39.515921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 predictions vs labels:\n",
      "Article 0\n",
      "0.202 vs 0.000\n",
      "0.282 vs 0.000\n",
      "0.154 vs 1.000\n",
      "0.181 vs 0.000\n",
      "0.181 vs 0.000\n",
      "\n",
      "Article 1\n",
      "0.192 vs 0.000\n",
      "0.216 vs 1.000\n",
      "0.213 vs 0.000\n",
      "0.192 vs 0.000\n",
      "0.187 vs 0.000\n",
      "\n",
      "Article 2\n",
      "0.266 vs 0.000\n",
      "0.194 vs 0.000\n",
      "0.148 vs 0.000\n",
      "0.196 vs 1.000\n",
      "0.195 vs 0.000\n",
      "\n",
      "Article 3\n",
      "0.173 vs 0.000\n",
      "0.173 vs 0.000\n",
      "0.179 vs 1.000\n",
      "0.234 vs 0.000\n",
      "0.242 vs 0.000\n",
      "\n",
      "Article 4\n",
      "0.175 vs 0.000\n",
      "0.231 vs 0.000\n",
      "0.190 vs 0.000\n",
      "0.187 vs 1.000\n",
      "0.217 vs 0.000\n",
      "\n",
      "Article 5\n",
      "0.182 vs 1.000\n",
      "0.306 vs 0.000\n",
      "0.306 vs 0.000\n",
      "0.103 vs 0.000\n",
      "0.104 vs 0.000\n",
      "\n",
      "Article 6\n",
      "0.167 vs 0.000\n",
      "0.175 vs 0.000\n",
      "0.190 vs 1.000\n",
      "0.301 vs 0.000\n",
      "0.167 vs 0.000\n",
      "\n",
      "Article 7\n",
      "0.276 vs 0.000\n",
      "0.216 vs 1.000\n",
      "0.155 vs 0.000\n",
      "0.155 vs 0.000\n",
      "0.197 vs 0.000\n",
      "\n",
      "Article 8\n",
      "0.201 vs 0.000\n",
      "0.197 vs 0.000\n",
      "0.197 vs 0.000\n",
      "0.190 vs 0.000\n",
      "0.216 vs 1.000\n",
      "\n",
      "Article 9\n",
      "0.200 vs 1.000\n",
      "0.179 vs 0.000\n",
      "0.179 vs 0.000\n",
      "0.236 vs 0.000\n",
      "0.206 vs 0.000\n",
      "\n",
      "Article 10\n",
      "0.286 vs 0.000\n",
      "0.105 vs 1.000\n",
      "0.286 vs 0.000\n",
      "0.142 vs 0.000\n",
      "0.182 vs 0.000\n",
      "\n",
      "Article 11\n",
      "0.158 vs 0.000\n",
      "0.181 vs 0.000\n",
      "0.232 vs 0.000\n",
      "0.158 vs 0.000\n",
      "0.271 vs 1.000\n",
      "\n",
      "Article 12\n",
      "0.201 vs 0.000\n",
      "0.172 vs 0.000\n",
      "0.243 vs 0.000\n",
      "0.243 vs 0.000\n",
      "0.141 vs 1.000\n",
      "\n",
      "Article 13\n",
      "0.151 vs 0.000\n",
      "0.205 vs 0.000\n",
      "0.223 vs 1.000\n",
      "0.205 vs 0.000\n",
      "0.215 vs 0.000\n",
      "\n",
      "Article 14\n",
      "0.214 vs 0.000\n",
      "0.198 vs 1.000\n",
      "0.203 vs 0.000\n",
      "0.214 vs 0.000\n",
      "0.170 vs 0.000\n",
      "\n",
      "Article 15\n",
      "0.237 vs 1.000\n",
      "0.207 vs 0.000\n",
      "0.203 vs 0.000\n",
      "0.162 vs 0.000\n",
      "0.191 vs 0.000\n",
      "\n",
      "Article 16\n",
      "0.322 vs 1.000\n",
      "0.191 vs 0.000\n",
      "0.204 vs 0.000\n",
      "0.142 vs 0.000\n",
      "0.142 vs 0.000\n",
      "\n",
      "Article 17\n",
      "0.183 vs 0.000\n",
      "0.169 vs 1.000\n",
      "0.227 vs 0.000\n",
      "0.212 vs 0.000\n",
      "0.210 vs 0.000\n",
      "\n",
      "Article 18\n",
      "0.187 vs 0.000\n",
      "0.187 vs 0.000\n",
      "0.240 vs 0.000\n",
      "0.237 vs 0.000\n",
      "0.149 vs 1.000\n",
      "\n",
      "Article 19\n",
      "0.152 vs 0.000\n",
      "0.160 vs 1.000\n",
      "0.406 vs 0.000\n",
      "0.141 vs 0.000\n",
      "0.141 vs 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_to_print = 20\n",
    "print(\"Top %d predictions vs labels:\" % number_to_print)\n",
    "labels = dataset.df_test[\"labels\"].to_list()\n",
    "for i in range(number_to_print):\n",
    "    print(f\"Article {i}\")\n",
    "    for j in range(len(pred_test[i])):\n",
    "        print(f\"{pred_test[i][j]:.3f} vs {labels[i][j]:.3f}\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T20:00:03.253083Z",
     "start_time": "2024-12-02T20:00:03.080295Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Flatten the data for analysis\n",
    "predicted_probabilities = [prob for article in pred_test for prob in article]\n",
    "true_values = [val for article in labels[:len(pred_test)] for val in article]\n",
    "\n",
    "\n",
    "# Set a threshold (commonly 0.5) to classify probabilities as 0 or 1\n",
    "threshold = 0.5\n",
    "predicted_classes = [1 if p >= threshold else 0 for p in predicted_probabilities]\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_values, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate AUC and ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(true_values, predicted_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve with AUC value explicitly highlighted\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label=\"Random Guess\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKHOLE = False\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # fixes problem with graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1+cu124\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "\n",
    "# Check gpu availability\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Test:\n",
    "#print(torch.zeros(1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSModel(\n",
      "  (news_encoder): NewsEncoder(\n",
      "    (embedding): Embedding(1000, 100)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (self_attention): SelfAttention(\n",
      "      (query_proj): Linear(in_features=100, out_features=256, bias=True)\n",
      "      (key_proj): Linear(in_features=100, out_features=256, bias=True)\n",
      "      (value_proj): Linear(in_features=100, out_features=256, bias=True)\n",
      "    )\n",
      "    (dense_layers): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=200, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "      (4): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "      (7): Dropout(p=0.2, inplace=False)\n",
      "      (8): Linear(in_features=200, out_features=256, bias=True)\n",
      "      (9): ReLU()\n",
      "      (10): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (11): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (att_layer): AttLayer2(\n",
      "      (attention_projection): Linear(in_features=256, out_features=1000, bias=True)\n",
      "      (query_vector): Linear(in_features=1000, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (user_encoder): UserEncoder(\n",
      "    (title_encoder): NewsEncoder(\n",
      "      (embedding): Embedding(1000, 100)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (self_attention): SelfAttention(\n",
      "        (query_proj): Linear(in_features=100, out_features=256, bias=True)\n",
      "        (key_proj): Linear(in_features=100, out_features=256, bias=True)\n",
      "        (value_proj): Linear(in_features=100, out_features=256, bias=True)\n",
      "      )\n",
      "      (dense_layers): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=200, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.2, inplace=False)\n",
      "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (5): ReLU()\n",
      "        (6): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        (7): Dropout(p=0.2, inplace=False)\n",
      "        (8): Linear(in_features=200, out_features=256, bias=True)\n",
      "        (9): ReLU()\n",
      "        (10): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (11): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (att_layer): AttLayer2(\n",
      "        (attention_projection): Linear(in_features=256, out_features=1000, bias=True)\n",
      "        (query_vector): Linear(in_features=1000, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (query_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (key_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (att_layer): AttLayer2(\n",
      "      (attention_projection): Linear(in_features=256, out_features=1000, bias=True)\n",
      "      (query_vector): Linear(in_features=1000, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (click_predictor): ClickPredictor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nrms import NRMSModel\n",
    "from hyperparameters import hparams_nrms\n",
    "import numpy as np\n",
    "\n",
    "hparams = hparams_nrms()\n",
    "\n",
    "MAX_TITLE_LENGTH = 10\n",
    "HISTORY_SIZE = 50\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "word2vec_embedding = np.random.rand(1000, 100)\n",
    "\n",
    "# PARAMETERS\n",
    "hparams.title_size = MAX_TITLE_LENGTH\n",
    "hparams.history_size = HISTORY_SIZE\n",
    "\n",
    "# MODEL ARCHITECTURE\n",
    "hparams.head_num = 16\n",
    "hparams.head_dim = 16\n",
    "hparams.attention_hidden_dim = 1000\n",
    "hparams.linear_hidden_dim = 200\n",
    "\n",
    "hparams.use_positional_encoding = False\n",
    "hparams.use_learned_positions = False\n",
    "\n",
    "# MODEL OPTIMIZER:\n",
    "hparams.optimizer = \"adam\"\n",
    "hparams.loss = \"cross_entropy_loss\"\n",
    "hparams.dropout = 0.2\n",
    "hparams.learning_rate = 1e-4\n",
    "\n",
    "model = NRMSModel(hparams=hparams, word2vec_embedding=word2vec_embedding, debug=True)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "if hparams.loss == \"cross_entropy_loss\":\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "elif hparams.loss == \"mse_loss\":\n",
    "    criterion = nn.MSELoss()\n",
    "else:\n",
    "    raise ValueError(f\"Loss function {hparams.loss} not supported\")\n",
    "\n",
    "if hparams.optimizer == \"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hparams_nrms.learning_rate)\n",
    "else:\n",
    "    raise ValueError(f\"Optimizer {hparams.optimizer} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 10)\n",
      "(64, 5, 10)\n",
      "(64, 5)\n",
      "torch.Size([64, 50])\n",
      "torch.Size([64, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(label_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label_data)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1295\u001b[0m         target,\n\u001b[0;32m   1296\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   1297\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index,\n\u001b[0;32m   1298\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[0;32m   1299\u001b[0m         label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing,\n\u001b[0;32m   1300\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\andre\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3481\u001b[0m     target,\n\u001b[0;32m   3482\u001b[0m     weight,\n\u001b[0;32m   3483\u001b[0m     _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction),\n\u001b[0;32m   3484\u001b[0m     ignore_index,\n\u001b[0;32m   3485\u001b[0m     label_smoothing,\n\u001b[0;32m   3486\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "NPRATIO = 4\n",
    "\n",
    "# Move model to GPU if available\n",
    "model.to(device)\n",
    "\n",
    "# Define the shapes of the input data\n",
    "his_input_title_shape = (HISTORY_SIZE, MAX_TITLE_LENGTH)\n",
    "pred_input_title_shape = (NPRATIO + 1, MAX_TITLE_LENGTH)\n",
    "label_shape = (NPRATIO + 1,)\n",
    "vocab_size = word2vec_embedding.shape[0]\n",
    "\n",
    "# Generate some random input data for input_1 with values between 0 and 1\n",
    "his_input_title = np.random.randint(0, vocab_size, (BATCH_SIZE, *his_input_title_shape))\n",
    "\n",
    "# Generate some random input data for input_2 with values between 0 and 1\n",
    "pred_input_title = np.random.randint(\n",
    "    0, vocab_size, (BATCH_SIZE, *pred_input_title_shape)\n",
    ")\n",
    "\n",
    "# Generate some random label data with values between 0 and 1\n",
    "label_data = np.zeros((BATCH_SIZE, *label_shape), dtype=int)\n",
    "for row in label_data:\n",
    "    row[np.random.choice(label_shape[0])] = 1\n",
    "\n",
    "# Print the shapes of the input data to verify they match the model's input layers\n",
    "print(his_input_title.shape) \n",
    "print(pred_input_title.shape)\n",
    "print(label_data.shape)\n",
    "\n",
    "# Convert the input data to PyTorch tensors\n",
    "his_input_title = torch.from_numpy(his_input_title).long().to(device)\n",
    "pred_input_title = torch.from_numpy(pred_input_title).long().to(device)\n",
    "label_data = torch.from_numpy(label_data).long().to(device)\n",
    "\n",
    "# Zero the gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(his_input_title, pred_input_title)\n",
    "\n",
    "print(outputs.shape)\n",
    "print(label_data.shape)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(outputs, label_data)\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Update the weights\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(val_loss_history, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (25, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>list[i8]</td></tr></thead><tbody><tr><td>337540</td><td>384241557</td><td>2023-05-26&nbsp;13:18:10</td><td>[9776259,&nbsp;9776087,&nbsp;…&nbsp;9780039]</td><td>[9782421]</td><td>[9465878,&nbsp;9782487,&nbsp;…&nbsp;9778796]</td><td>[0,&nbsp;0,&nbsp;…&nbsp;0]</td></tr><tr><td>2027502</td><td>337476478</td><td>2023-05-26&nbsp;12:24:51</td><td>[9775568,&nbsp;9775809,&nbsp;…&nbsp;9778902]</td><td>[9782290]</td><td>[9782057,&nbsp;9782133,&nbsp;…&nbsp;9782103]</td><td>[0,&nbsp;0,&nbsp;…&nbsp;0]</td></tr><tr><td>1498918</td><td>488477676</td><td>2023-05-25&nbsp;10:14:30</td><td>[9775331,&nbsp;9775256,&nbsp;…&nbsp;9779577]</td><td>[9780496]</td><td>[9780547,&nbsp;9780648,&nbsp;…&nbsp;9780561]</td><td>[0,&nbsp;0,&nbsp;…&nbsp;0]</td></tr><tr><td>2199061</td><td>312844535</td><td>2023-05-27&nbsp;17:59:44</td><td>[9772038,&nbsp;9772088,&nbsp;…&nbsp;9780039]</td><td>[9781998]</td><td>[9784444,&nbsp;9417521,&nbsp;…&nbsp;9784138]</td><td>[0,&nbsp;0,&nbsp;…&nbsp;0]</td></tr><tr><td>1047938</td><td>112604512</td><td>2023-05-27&nbsp;17:37:00</td><td>[0,&nbsp;0,&nbsp;…&nbsp;9779813]</td><td>[9783850]</td><td>[9277736,&nbsp;9784430,&nbsp;…&nbsp;9779370]</td><td>[0,&nbsp;0,&nbsp;…&nbsp;0]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>750497</td><td>306815361</td><td>2023-05-27&nbsp;16:22:16</td><td>[9774020,&nbsp;9774297,&nbsp;…&nbsp;9779511]</td><td>[9783858]</td><td>[9615540,&nbsp;9783075,&nbsp;…&nbsp;9621194]</td><td>[0,&nbsp;0,&nbsp;…&nbsp;0]</td></tr><tr><td>1674815</td><td>218662677</td><td>2023-05-28&nbsp;05:40:18</td><td>[0,&nbsp;0,&nbsp;…&nbsp;9779674]</td><td>[9782884]</td><td>[9783790,&nbsp;9782884,&nbsp;…&nbsp;9784803]</td><td>[0,&nbsp;1,&nbsp;…&nbsp;0]</td></tr><tr><td>1153721</td><td>281369856</td><td>2023-05-31&nbsp;19:20:54</td><td>[9776341,&nbsp;9774559,&nbsp;…&nbsp;9779517]</td><td>[9790645]</td><td>[9790532,&nbsp;9790682,&nbsp;…&nbsp;9790645]</td><td>[0,&nbsp;0,&nbsp;…&nbsp;1]</td></tr><tr><td>2415367</td><td>490055973</td><td>2023-05-30&nbsp;18:03:17</td><td>[9778198,&nbsp;9775596,&nbsp;…&nbsp;9779007]</td><td>[9788251]</td><td>[9788404,&nbsp;9788251,&nbsp;…&nbsp;9788621]</td><td>[0,&nbsp;1,&nbsp;…&nbsp;0]</td></tr><tr><td>1078413</td><td>407646922</td><td>2023-05-26&nbsp;18:26:09</td><td>[9766452,&nbsp;9766042,&nbsp;…&nbsp;9779737]</td><td>[9780283]</td><td>[9780283,&nbsp;9783181,&nbsp;…&nbsp;9782219]</td><td>[1,&nbsp;0,&nbsp;…&nbsp;0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (25, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ impression_i ┆ impression_t ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      │\n",
       "│ ---     ┆ d            ┆ ime          ┆ ixed         ┆ clicked      ┆ inview       ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ u32          ┆ datetime[μs] ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 337540  ┆ 384241557    ┆ 2023-05-26   ┆ [9776259,    ┆ [9782421]    ┆ [9465878,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 13:18:10     ┆ 9776087, …   ┆              ┆ 9782487, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9780039]     ┆              ┆ 9778796]     ┆             │\n",
       "│ 2027502 ┆ 337476478    ┆ 2023-05-26   ┆ [9775568,    ┆ [9782290]    ┆ [9782057,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 12:24:51     ┆ 9775809, …   ┆              ┆ 9782133, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9778902]     ┆              ┆ 9782103]     ┆             │\n",
       "│ 1498918 ┆ 488477676    ┆ 2023-05-25   ┆ [9775331,    ┆ [9780496]    ┆ [9780547,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 10:14:30     ┆ 9775256, …   ┆              ┆ 9780648, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9779577]     ┆              ┆ 9780561]     ┆             │\n",
       "│ 2199061 ┆ 312844535    ┆ 2023-05-27   ┆ [9772038,    ┆ [9781998]    ┆ [9784444,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 17:59:44     ┆ 9772088, …   ┆              ┆ 9417521, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9780039]     ┆              ┆ 9784138]     ┆             │\n",
       "│ 1047938 ┆ 112604512    ┆ 2023-05-27   ┆ [0, 0, …     ┆ [9783850]    ┆ [9277736,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 17:37:00     ┆ 9779813]     ┆              ┆ 9784430, …   ┆             │\n",
       "│         ┆              ┆              ┆              ┆              ┆ 9779370]     ┆             │\n",
       "│ …       ┆ …            ┆ …            ┆ …            ┆ …            ┆ …            ┆ …           │\n",
       "│ 750497  ┆ 306815361    ┆ 2023-05-27   ┆ [9774020,    ┆ [9783858]    ┆ [9615540,    ┆ [0, 0, … 0] │\n",
       "│         ┆              ┆ 16:22:16     ┆ 9774297, …   ┆              ┆ 9783075, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9779511]     ┆              ┆ 9621194]     ┆             │\n",
       "│ 1674815 ┆ 218662677    ┆ 2023-05-28   ┆ [0, 0, …     ┆ [9782884]    ┆ [9783790,    ┆ [0, 1, … 0] │\n",
       "│         ┆              ┆ 05:40:18     ┆ 9779674]     ┆              ┆ 9782884, …   ┆             │\n",
       "│         ┆              ┆              ┆              ┆              ┆ 9784803]     ┆             │\n",
       "│ 1153721 ┆ 281369856    ┆ 2023-05-31   ┆ [9776341,    ┆ [9790645]    ┆ [9790532,    ┆ [0, 0, … 1] │\n",
       "│         ┆              ┆ 19:20:54     ┆ 9774559, …   ┆              ┆ 9790682, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9779517]     ┆              ┆ 9790645]     ┆             │\n",
       "│ 2415367 ┆ 490055973    ┆ 2023-05-30   ┆ [9778198,    ┆ [9788251]    ┆ [9788404,    ┆ [0, 1, … 0] │\n",
       "│         ┆              ┆ 18:03:17     ┆ 9775596, …   ┆              ┆ 9788251, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9779007]     ┆              ┆ 9788621]     ┆             │\n",
       "│ 1078413 ┆ 407646922    ┆ 2023-05-26   ┆ [9766452,    ┆ [9780283]    ┆ [9780283,    ┆ [1, 0, … 0] │\n",
       "│         ┆              ┆ 18:26:09     ┆ 9766042, …   ┆              ┆ 9783181, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9779737]     ┆              ┆ 9782219]     ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.setup_test_data(dataset_path = DATAPATH, datasplit = DATASET, history_size = HISTORY_SIZE, columns = COLS, fraction = FRACTION, seed = SEED)\n",
    "\n",
    "dataset.df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 25/25 [00:00<00:00, 152.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[   262  16471  35992 ...     17  11269  81708]\n",
      " [  1575 126957  58483 ...  82739    261  72468]\n",
      " [ 60592  49049 149727 ...  22772    172  73896]\n",
      " ...\n",
      " [  1310   7400  38552 ...      1      1      1]\n",
      " [128354    990   1991 ...     11  52454  28302]\n",
      " [   357  26073 187073 ...  15198  33532   8520]]\n",
      "pred_input_title: (1, 12, 30) Value in first row: [[  2206    449  14936  59040     90      9     66  53631     60  78552\n",
      "     603    588   4475  12912     56      5  19507      7   2811  24314\n",
      "     139  82739      7  17474     17 144282    203  11504    242     34]\n",
      " [  3311 102570  68315  62738     14    109   8599   1505    563  14936\n",
      "    6259    109  76968      5   1111  33532 102570    171 142404    261\n",
      "   69480     19      4    495    149    203  62614    254  92674  56233]\n",
      " [161436   4935      4  62172  73119   3196     60  59215     72    545\n",
      "      17  97809     12  57687  14663   5761   1063 136709     67    745\n",
      "      17  24906    128  41275     18    261    203  64712    588    168]\n",
      " [  1310     72   8796     17     22      6  80988     17 117288  78685\n",
      "       5  23243     33     72   1379   7619  23243     17 117288  78685\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [111347 140852     18  19095     56    604      6 134893     56    588\n",
      "    6530  20636      4    122    182  58026     99  25005   6474    100\n",
      "     149  96634 209550      5   6609  14650 144589    109      4     99]\n",
      " [  9865  16723    186 125082     18     17     91  67259  40005      7\n",
      "    8749    420  12366     71   6919     82    261    149  96634 210300\n",
      "   97537    824      6  98705     20    168  74224  45804  19314   6316]\n",
      " [ 26729   3263    100   9653 167304    261  45555     60    104  16977\n",
      "     109  55598    478  19513    182   2430     86   2472   5331      5\n",
      "    9578    805     72    142  28295     18    100     99  66450     13]\n",
      " [ 99442  21139   1681  30003     22 175351 152035   5256  27633   2811\n",
      "   96634  12969   5095 163933  21836      5  78287   3683   2752  52454\n",
      "      42  59138    139  92265  13527      7  17042 113877    159 143662]\n",
      " [    87  98510     72     22    193     66   1042  61634      4    122\n",
      "    3491      6 154759    100  20870 119018      4  20714   5129 127063\n",
      "   18721   5129  60005  49547   1042 113059 114541      7 194636     17]\n",
      " [ 62151     92 114306  56159 106094   7136    182  54302  58134  44759\n",
      "      19    124  25538  49520   4896    588    540    191 128705      4\n",
      "     453  40003     72    332    555    128  67722   5037     34     33]\n",
      " [212803  26530  21816    182  15763  52849    261    880   2993      4\n",
      "     124   1926    545    182   5423     17   1360   1368      4     60\n",
      "     149    285     22   2355  62011    100   6079   3683  16148   1360]\n",
      " [    20    579      4    881   2060  14009      4    285   2536  16323\n",
      "      18    645 105791   1368  31182      4    453    777  95652   4196\n",
      "   14872  19576  24337     17 202312   6474    100     17  12574      4]]\n",
      "batch_y: torch.Size([1, 12]), values: tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "Batch 1 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 45152     13  14299 ...   3196    348    416]\n",
      " [207975      7  48267 ...    124  23092    261]\n",
      " [ 46406  16749 152035 ...  16799  28779     56]\n",
      " ...\n",
      " [   345    555 105920 ...     12  82739  43144]\n",
      " [   384   7797  44109 ...    242  54494  12227]\n",
      " [ 56159 106094   7136 ...      1      1      1]]\n",
      "pred_input_title: (1, 17, 30) Value in first row: [[  3145  58675   3986  40118     13  37749  11816   8079   1289    824\n",
      "  106133    645  14949  27303  28290  32226  41311   2811  44517      5\n",
      "    1111    122     72 109057     13      6  19611   1515  24315  54569]\n",
      " [   930 113095    592  72542  52849     67   4602     17  26819      4\n",
      "     285    332   3080  83085 144380     18    100  44296   7334     60\n",
      "  123845      4  16237  85888     18 183804     13  99602  83085 205700]\n",
      " [ 20261    306   9173     85  12981     39  61100     72  20714  11001\n",
      "       4   8793     22    600  84265    545 113885    109  47367  63844\n",
      "      17 183828  16148  21113  89827     12  72621     56    545 100339]\n",
      " [ 99442  21139   1681  30003     22 175351 152035   5256  27633   2811\n",
      "   96634  12969   5095 163933  21836      5  78287   3683   2752  52454\n",
      "      42  59138    139  92265  13527      7  17042 113877    159 143662]\n",
      " [   579   7400  77261   1950     19   9370      4    124   1953  21562\n",
      "    1134   2965    416    112  49240    124 147407 119949     17  37757\n",
      "  128283  37757 128283    142 155462    600 147407 119949      1      1]\n",
      " [  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "     182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "    1111    122     72  32376     82  54392   6799    495   3728  10750]\n",
      " [ 40902    182    315  11736  59049 107005    872      7  86317     17\n",
      "   22805    139  32555 192940    720   5756  86317    139  32555      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [119154    285    168   4949  33640     99   9881      5   1111    315\n",
      "    1873  47173      7    242  25267   9014  45327     25 100500     22\n",
      "   47621     17    168  61706  85805      9   8551      5   3183    149]\n",
      " [   636     86 164689 186044   6106     60   7400   7980    139  43084\n",
      "       4   4271  70338     42  45122 140069  30719      5    353   3390\n",
      "     353   5771     72   4610  97809   5084    353   5771     72    242]\n",
      " [  1310     72   9342    171     22   1202    128      6  86654     18\n",
      "    1959   3405     19  24700  71661    261     47  18700 201591      4\n",
      "     122     17 183828  45849  11783  33618  35365     86 149746    128]\n",
      " [  2548   1823    588     82  12447    124  73213      9  19057   1192\n",
      "   79650     17 234702     60    139  39046    820   3080    391  15639\n",
      "     615  13557  27303 195000  21407 160235   7400    600    391  15639]\n",
      " [   345 211694   5077      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [  1910    116    182  38552    126    139     17  25531 152262     60\n",
      "   16237    315  14355   1505  28398     90 115456      4   2683    777\n",
      "      72  33618 148372     86    139     99  82729  92265  13527   1910]\n",
      " [   563  13528      9  35121  18413  63905  47640   2752  35121  80928\n",
      "      17     22   9782 160197     60      6 220281     17    168  24906\n",
      "     645 163662     33 124946    538    285     17 130579    645  22805]\n",
      " [  6478      9  78147  87193  24299   3491      6  68413     18    109\n",
      "    7897      7  16401    261    880  11269  12018    100  95445     86\n",
      "     261 143622      4    122   9790  32502     13   2057    171     99]\n",
      " [   357   3059     47   1368  27194  45555  25779    109 128139  27472\n",
      "    1953     99    765  79329     22  34777     13    109     22   2412\n",
      "    1277     56 102733      4   2328  38016     33    285    109   2130]\n",
      " [ 14949  46231    379    182 106686   4842 108829  38692    587  27331\n",
      "       7    139  81264  46231    379      9  18066    416 106686    139\n",
      "   67722      1      1      1      1      1      1      1      1      1]]\n",
      "batch_y: torch.Size([1, 17]), values: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 2 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 23243  48820      7 ...    261  41993      7]\n",
      " [206612  61952    112 ...  77395   1226     99]\n",
      " [   579    203  11504 ...      4  13440   1926]\n",
      " ...\n",
      " [  1326  19787  57440 ...    456 141840      1]\n",
      " [ 50715     18  14936 ...      1      1      1]\n",
      " [  8301    332 136617 ...   1004    149  44075]]\n",
      "pred_input_title: (1, 5, 30) Value in first row: [[ 14978 107005    872  81134     17   5178  33683      4     99    777\n",
      "     545   3963  65609   1661  15821 114341     60  21309   3278    139\n",
      "  114805     17  56558    341   3405  19738    112    128  15821   2179]\n",
      " [ 60222     13     60  16471 216404     72  19538    645 101767    261\n",
      "   11476  16471   7042 160492      5  45152     13      6  57350 131670\n",
      "       7    109  31143  16471   7042 160492 186592      7      1      1]\n",
      " [   579 126957  11862    139   8451     72    109     82  58558   3675\n",
      "    4527     18  30896     18  17019      4  49355    149    588 123949\n",
      "       7  13440  10384  82412   6664 123949   1872  72468  96634  61634]\n",
      " [  9626  86875    126  49355    109  59084 129238  26470 129956  12018\n",
      "     128  80632  24658  68413      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [179892   1063    765     22 195383    171  34627  19285    109  14949\n",
      "  101864      4     60    315  99579 124895  93264   1015    171     82\n",
      "     242   6752  76576   1276     25     17  11862    139     10      9]]\n",
      "batch_y: torch.Size([1, 5]), values: tensor([[0., 0., 0., 1., 0.]])\n",
      "Batch 3 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 58066  43254     17 ... 191691  12563      7]\n",
      " [  7868    387   2357 ...      1      1      1]\n",
      " [   242  90278     76 ...    168     72 173293]\n",
      " ...\n",
      " [ 26076      9   1098 ...  57280     12   3810]\n",
      " [ 26076      9   1098 ...  57280     12   3810]\n",
      " [   357  26073 187073 ...  15198  33532   8520]]\n",
      "pred_input_title: (1, 24, 30) Value in first row: [[138719 123373    100 123949      7 150884  28274 170467    170 232043\n",
      "   81134    139     22 194151  26359      4     99 144282     17  82739\n",
      "     203  34872   1368  31182      5   4311      7   2320   6704      4]\n",
      " [ 76188  16446     56     60  52436   3491  70893    126     20     60\n",
      "     139 117673   1630  27820    126     12 107503    115   3005     93\n",
      "       9 109694     32  58923      7   5945      9   1478    162    282]\n",
      " [ 12574     72     82  19096     18  43067 108167    261 144568  32594\n",
      "      13 192940  10703     33   1953  62172  13635  32594     13      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [ 11246    334   1409     53   2319    519   8848     73  81134     17\n",
      "      82   5178  33683      4     99 142092      9  40042    182 159548\n",
      "    2563   3564  74686   7334     17  59657    171 174857    528   6850]\n",
      " [151927    515    107  55449    182    545     22  30469 138972    532\n",
      "   47405      5   1840     72      4   8928  30003     86  69538   1873\n",
      "    9929    139     99   5015    128      4  18597      8 114805   2752]\n",
      " [  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "     182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "    1111    122     72  32376     82  54392   6799    495   3728  10750]\n",
      " [ 10453 109563    112    880  81170    109  50029   4498      5  21519\n",
      "     171     22   2993      7  10204  33328    141   5557   1953   4539\n",
      "    5919    139   8167  16145  52982     12     20  47824  18097     33]\n",
      " [ 32897   1151   7400  64475  76758  12964   6581  30395  51580    139\n",
      "   53752      4   2328      8   1134  78969     90 149746 186592     42\n",
      "    3787   9458     17 241096  85283   6763      9  38669 109881      1]\n",
      " [ 45095  52849     67 138251   1111   8831      7      9    192     34\n",
      "   40777    126     17     22  28995    223    645    100      6 171233\n",
      "      13      4  23606   1205 107919     13  45095 103899    603    139]\n",
      " [   579   4343  27820     72    315     12  73753 242312     13      6\n",
      "  101956   3135     32  16148   4669   1368     12   1429     72 242312\n",
      "   36656  71705  10266      1      1      1      1      1      1      1]\n",
      " [  1775   5178  12924      9   3667  50399   5426      4    122   7400\n",
      "   75818  75281   1824    261  82217  18700     42      4     72  14872\n",
      "     588    495 107736      4    124  58558   3675   3428    126 232756]\n",
      " [  5533   1466   2432   8695  43289   7997   1042    160   7373     17\n",
      "    6520   1015      5   8268  26328   1015 238753     42    128  71016\n",
      "       7 107430      4  32226 144546     13   1466     67    171  52809]\n",
      " [ 85287     56 215253     19     17 112923     33  60804    112  57513\n",
      "   55028  12018      4     60    149    520    315   1872    139      4\n",
      "      99  75212    169  82261   9120  33759    168 136058 182291    341]\n",
      " [ 45421  73657 100332      7  48267     60   4804  12655    571  37214\n",
      "      72    139 111241   1226  59980  58948   1277   1953     22    100\n",
      "   11951  22019    112  76529    588     22   2160   6850 149746   5535]\n",
      " [   908     19   2186   1950    820    285    128    139     99  26508\n",
      "   44517    149 184194  40118     13  74991  18097     17  18413     92\n",
      "       4     48 104951   3491  38552    126  97670    908     19   2186]\n",
      " [138087  19824    285    149 174854     13   8753    109    149 174854\n",
      "      13  16077     17    845  30319      4   2328   1550    820   1872\n",
      "   24705  18066    588  30622   1067   7639  15912   2415      7  67623]\n",
      " [130189     13 142209   7274    182   1953 109881     33    261   7370\n",
      "       6 115061      9      7  21552  76688  80330  14014  13069 111059\n",
      "    1067  29630    920  11124  79650     17   7370      6 115061      9]\n",
      " [ 57501  79949   1015     60  86653  41409  12121  48467   3428   4196\n",
      "       4     99      8   3271  54106    128    171 133657   3196     17\n",
      "    2663   1053      5     87  25429  72328     22  13822 106262   1937]\n",
      " [   345    112   6121  77339  59277    112 134252   1379  41494  27805\n",
      "   93198      4     60    845  30319  17075  54568    112   2536  55924\n",
      "     139   7822   3263   4792  87998    131   5518    109   1550   1042]\n",
      " [207975      7  48267    182  15763   4475   1096  39607  26343     17\n",
      "   92549    261  57513  46466     17  24906    128  88761     18  31931\n",
      "    1405  48267   1873 128989    171  52238  24347   5386   1226  31931]\n",
      " [ 39170 157282  36323 146874   1191 180801     60 121739  70189  22513\n",
      "      19     72  80459     13     17  52945  43769      4    233  14907\n",
      "      56    168 116850   7829  11214     56     12  52945 131720     42]\n",
      " [ 14355   1505  28398     13   9162   1144   2355   2936    139     99\n",
      "   20252   1809  26583     56   1953    880  93487      7  27633      5\n",
      "    1326    545    495  74138   3916  43144    777  32790   2432    109]\n",
      " [  2777  77306 203350   3491     17 154759   6530  18951 242988    100\n",
      "      99   3568   3405    372    168  14134      4    122   9038  52238\n",
      "   56603  25257      5   1429     72  22378  36069   5408      4     60]\n",
      " [ 52945  43769      6 132546    100   4541   4642     17  18413     92\n",
      "     149 116850  74991  18097   1953     22  58671      9      7   1334\n",
      "      42    109  43040  36012    645  15161  77399  52945  43769     72]]\n",
      "batch_y: torch.Size([1, 24]), values: tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0.]])\n",
      "Batch 4 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[     0      0      0 ...      0      0      0]\n",
      " [     0      0      0 ...      0      0      0]\n",
      " [     0      0      0 ...      0      0      0]\n",
      " ...\n",
      " [  8694     39   5828 ...  28949    109  93387]\n",
      " [   384   7797  44109 ...    242  54494  12227]\n",
      " [104324    180   1353 ...   3667     12  23037]]\n",
      "pred_input_title: (1, 9, 30) Value in first row: [[ 32221   1264   2076    927  25335  24708   4574  33791  35548    109\n",
      "      99   1712    128     17    242    571    934   5436     25      4\n",
      "     453    777   5054   7830   1712  98628    100  28280     20     40]\n",
      " [ 45095  52849     67 138251   1111   8831      7      9    192     34\n",
      "   40777    126     17     22  28995    223    645    100      6 171233\n",
      "      13      4  23606   1205 107919     13  45095 103899    603    139]\n",
      " [  2777  77306 203350   3491     17 154759   6530  18951 242988    100\n",
      "      99   3568   3405    372    168  14134      4    122   9038  52238\n",
      "   56603  25257      5   1429     72  22378  36069   5408      4     60]\n",
      " [   242  19279     98     70  18919     25     72 124664    100   1100\n",
      "       4   1100     60  32376   2563   1100      5 111347 140852     18\n",
      "     182  52214 147691  62728     86      5    503    745    604    262]\n",
      " [   345    112   6121  77339  59277    112 134252   1379  41494  27805\n",
      "   93198      4     60    845  30319  17075  54568    112   2536  55924\n",
      "     139   7822   3263   4792  87998    131   5518    109   1550   1042]\n",
      " [ 52945  43769      6 132546    100   4541   4642     17  18413     92\n",
      "     149 116850  74991  18097   1953     22  58671      9      7   1334\n",
      "      42    109  43040  36012    645  15161  77399  52945  43769     72]\n",
      " [  3145 144137     12   5976     71   5084   1202  16237      4   5916\n",
      "   88034  53437      9 128743  16673  22201      4     48    149   1630\n",
      "    6474      4     99     22  88034  53437      9  25389    285   1239]\n",
      " [   262    182  34592    261     40   1357      4    453   2328   4610\n",
      "  185502      8  29935    109     99 180046   1100  51169   9872     56\n",
      "      32    579   1873    115   2752  45190     17    604    579 185502]\n",
      " [ 10453 109563    112    880  81170    109  50029   4498      5  21519\n",
      "     171     22   2993      7  10204  33328    141   5557   1953   4539\n",
      "    5919    139   8167  16145  52982     12     20  47824  18097     33]]\n",
      "batch_y: torch.Size([1, 9]), values: tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "Batch 5 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 36558      9     60 ... 120807   1803   1063]\n",
      " [   262 181272     13 ...    149 184151    124]\n",
      " [   159  27808   6660 ...     12   3805    109]\n",
      " ...\n",
      " [ 45567   5077  47640 ...   5129    588   1832]\n",
      " [  1429  44177   8395 ...   1144     17  34592]\n",
      " [   357  26073 187073 ...  15198  33532   8520]]\n",
      "pred_input_title: (1, 19, 30) Value in first row: [[124895  10300     11 199719      7 130970    285     99    308    372\n",
      "    1053  14251      5    579  63926     13   2563    671   9427    124\n",
      "    1226     82   9790   1229   7112      4     60   3564     85  13440]\n",
      " [   360  18026     33   3443     60 124664    588  20807   5044     12\n",
      "     242  67369  28581   1466      5   7325   2601     25     12   1429\n",
      "     182   1872  25445  79507     42    100   6616     18  21366      1]\n",
      " [  2888  69589 124847     19    100  44339   1368   7400    168  55378\n",
      "      13   4516   2198    282 207745     18    128  80652 129238  26470\n",
      "    2949  80632 124847    109  47621  15198  83822     60  48968      1]\n",
      " [ 51549    186  91568     56  16237      4     99  47508     88 127874\n",
      "     588  70658     60  51669   7400  33855     13     99 136464    171\n",
      "    1587   1368    540 127874     17    494  10534     12    262   7400]\n",
      " [   436      9  23044    126    182  39819  45661    820   1872    139\n",
      "   79668      4    122  63299 137184    126     17     82  34703      4\n",
      "     124      8  80604    545   3271 155263      5   3810    315    203]\n",
      " [  3658     67    241  16466     60      8 114598   3986  53306    261\n",
      "   16965   4028  20358  50971    112    845  30319  16326  43957    128\n",
      "     228   6947   1746  10674  15267   6639   8710   4034    109   8395]\n",
      " [ 74191   1679     33  33276    262    294  33752   1063      6  40272\n",
      "   16294    128   5879    171  14953    474    126    139 222717  26163\n",
      "     126     17    387   2357      4    453  40003     72    332    555]\n",
      " [   579     72   5859   5252   5159  77076     33      4  64475      8\n",
      "  100592   1205  40340     56      4    124 111347 140852     18    182\n",
      "  132178  17532  12912     33     17  80513  87775   1212      5 242962]\n",
      " [   930 114821    257  41946      6 123373      4  45122  51032   5222\n",
      "  160235      4  45299    285  63199   3019  62247   2517    109    335\n",
      "       5    618      5      4   5054    777    765     22 109728   1772]\n",
      " [ 14949  27303   1015  44177  19538    100  30749  14098      4    122\n",
      "   33759  87210      6 108396   2198     67  44517     17  26521  19175\n",
      "       5  84163  59657    604  57544     12  12264   5077  50250   6423]\n",
      " [ 10250    202   7154      4  67013   2721     60  18493   3491  47640\n",
      "  118995  51580   1872    139     22  71274 141120    109 197331 183535\n",
      "    1419  71274     18    139 105722  20956     17     75 100038      1]\n",
      " [ 53752     72  62172  32556 136449  93055  27649      4     60  12882\n",
      "      72  88192     91  55413    236  69589 126374     18   5178    100\n",
      "     807  72083      5  54132  49355  77395     33    588    290 107241]\n",
      " [    87  24906    128  27535  68211    109   2926  12909    241   4633\n",
      "    1226  73165     72   4475   7799   1515     60   4568 127874  20714\n",
      "  106393     18 140785    100  74723      7  53693      6 175434  19963]\n",
      " [  1310   1823    139     99   1712 106750      6 125162     42 150884\n",
      "   33850    139 111241   1379  44339  18951  36416      4   2328    332\n",
      "      72   4610 144589    109 146923 143027 101133    603  75399    600]\n",
      " [   579  13594  11816   3019 120088      4     48     22  14134    109\n",
      "    1803     67     22  74103 180877      9  46320    933      6 198499\n",
      "      17  18118    449   1272    310   2822   7799    271 177242    720]\n",
      " [ 15161   7370      7    170  14936   1760 139947     17  72392   2918\n",
      "  146012     42    109     99 108609 139140     17  23100   2278      4\n",
      "      60    149  21340 124726   2776    109  57134 105712    341   3405]\n",
      " [   579  16987     42     22  20459  38670  52210 148689   1224  26992\n",
      "    3135      4    122     72   7980    139  12841     20    453    168\n",
      "   95934      5   1004    149     22  13247 164354     32    579     72]\n",
      " [  4804  80864  52454 100592   1205  38352 157945     13   3491  53396\n",
      "   75818    139     99    348    416    372    149 126957  46390      7\n",
      "    1336    275  23698  11872      7    262    603   1202     12 153080]\n",
      " [  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "     182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "    1111    122     72  32376     82  54392   6799    495   3728  10750]]\n",
      "batch_y: torch.Size([1, 19]), values: tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]])\n",
      "Batch 6 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[  2471   2061  26181 ...      1      1      1]\n",
      " [  1371  19209     42 ...   5165     13    182]\n",
      " [ 82528  12964   6581 ... 241096  85283   6763]\n",
      " ...\n",
      " [   345    555 105920 ...     12  82739  43144]\n",
      " [  6470 193220    182 ...    177  14936   3667]\n",
      " [   357   1053  48951 ...     82  19787   4140]]\n",
      "pred_input_title: (1, 14, 30) Value in first row: [[    20   1731     72 220770     99  36433     99   3963 146614      6\n",
      "  185705     60   1712    495 203653      4     99    668  88607     42\n",
      "    2057   2536      8  71039      4   2328    668   5054   5015    139]\n",
      " [  1575  12532  82217 222717 186592      7   6799    315    100      6\n",
      "  164108    261  55301  14486  22201  99602  11214     13     12   5879\n",
      "   45667    820    109  26232 197681     99    765    186  78131   8816]\n",
      " [   357  77199    171     99  45890   1357    149  82217  53630  80430\n",
      "  145187   6474    139    615  19110  76924   1134    315    139    261\n",
      "  167754     17  43953    126    853 116389  12832   1236  41946  20387]\n",
      " [   357   4442      9  48951  81493  14134     72   1144   3263    100\n",
      "  105282  70534  49392      4   1953     99    777  68315   2752    139\n",
      "      22  24830  14134  10729  13384  11380  39607   4207    109  32216]\n",
      " [ 87094      4  12403     60    100  54305  26343      5 111347 140852\n",
      "      18  16861   1466    149   4343 156257    645  80431   1444  50443\n",
      "      56    579  67394   7334    109  46771     33     12    503   7247]\n",
      " [  7948  16666     71   1679   5054    765  80513    107  40530   2264\n",
      "     139     99    233  65856    272    149  22370    112  36103      4\n",
      "     122     17  25620   3491    261  85771   2811   2057      5    579]\n",
      " [ 10592  12620    126    139 200178    106  33678    261  35892     19\n",
      "     100   9018 211694     18  57501  79949   1015     20      6  76037\n",
      "   33683    126   2328  45712   7190  57280     33  81134    171   1661]\n",
      " [130189     13   8667   4371      7 140232     13  86052     72     47\n",
      "     261   1360  65578  20627      4   5101   4475   2528  92992      7\n",
      "     495   2264   1953    142  53631   4804  92992      7  65578   1953]\n",
      " [ 14355   1505  28398     13     72  21351    261     99  33617      4\n",
      "      99   2902  24273   7465  14580      7    182      6 157597   1144\n",
      "   14355   1505  28398     13  16673  11783    109    681     92      9]\n",
      " [ 15745  85371    141      4 111347 140852    933 105367  34940   4597\n",
      "       4   3278  49043    109  19115 152371      7  82729    107     60\n",
      "     308  18966  85371    141     12   5919   3667    109  73149      1]\n",
      " [  1572    555     72  20714   1144   3263    100  14134   3041    275\n",
      "       4    233  14907     56  73104   2646      7  16749 141120     12\n",
      "     717  20627 242312     60  14134    142  78131      1      1      1]\n",
      " [  8301    115     72   7799    271    109    241   4633 140069    170\n",
      "   84322  15366  12909   1134    115  47640  19080  48490    275     86\n",
      "    1466    128 229588   5252   3423    188  54261      9    161    232]\n",
      " [ 38458     86  34609  24383    483     72  34608  78147   4699     86\n",
      "     588  81129  14437      5    786    203     40    149 122757 110937\n",
      "     128  25257     17 215467    604   4699     86      6 132546  10574]\n",
      " [107578      6 132546   3974  19175   1953 182291    645   8321     17\n",
      "      22 183293  22688      4    122  25779    261 126550      7     17\n",
      "  106393      7  10237      7   1716   2971     42   6620 107578      6]]\n",
      "batch_y: torch.Size([1, 14]), values: tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 7 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[  4843    334   1872 ...      4   8928   2528]\n",
      " [  1310    203   3082 ...     71     12  58066]\n",
      " [  1310     72   3082 ...  11364     17  53752]\n",
      " ...\n",
      " [   360  18026     33 ...      1      1      1]\n",
      " [ 12339    177 123507 ...     13   2924      9]\n",
      " [  8301    332 136617 ...   1004    149  44075]]\n",
      "pred_input_title: (1, 9, 30) Value in first row: [[   276  50371      9  88946  20345    568     12    873  19611     39\n",
      "      67     60    770  17454   3263      6  25183  13576    182  13245\n",
      "      18    109   2428      7      4  63039  18097      4 175894      4]\n",
      " [ 80799     67      9    919  18066   2154   1015      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [  7244      7   8749  40272     42      4  19893 126507      4    182\n",
      "    2394    429      9  35414    126    747  11476 141918     56    261\n",
      "   28235     25      7 105367  23134    242 113469   1409     25  19893]\n",
      " [  2888  24792  66373     60  44192     17  30038    126    109  86373\n",
      "   15492     22  34608  48951  14134     82  18413      5   2548      6\n",
      "  123645      7    100 141120     19      4   2328     22  22958  48951]\n",
      " [   717   1011     18      9  16200    261   1803     67      4     99\n",
      "   59657   3271  28117    382  17376      5  16148 178745     72 105791\n",
      "   64736     17 154759      6  23920  24347   1679      4     60  32630]\n",
      " [123251      7  99656  13282   1630   5097    182  11958     18     87\n",
      "   29065   2752  40427     22  93054  11364  43764   2811  10070     92\n",
      "     391    513 151314   1953  45772   1872  30239 123251   6534     56]\n",
      " [100700  73359    182  15763  29727     33    139     99   1712 184195\n",
      "   51169   2528      4   3916    777    285   1360  12216   1368      5\n",
      "    2548   1226   3728      4     99    149    203   1712   3817      6]\n",
      " [ 35583  14949   1015     72  43040  36140  36140    261  19985      5\n",
      "    2548   3491   8017  18891   1379     22  93487      4   3491  52478\n",
      "    3198    109  17986    126     60    182    315  36903  67018   1264]\n",
      " [ 24289     33    109    168  96634  46941     13    182  10296   5423\n",
      "   13259  13069    495  30896      4    124    168     72    315      5\n",
      "     579    203    807  72083  24911     13  10765     13    261      5]]\n",
      "batch_y: torch.Size([1, 9]), values: tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 8 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 39096    379 232043 ...    308   1297    139]\n",
      " [ 14355   1505  28398 ...  62046    149    139]\n",
      " [ 82739    182   8282 ...  87713    192 105920]\n",
      " ...\n",
      " [ 52888      7  58483 ...  33276    262    294]\n",
      " [   527 187631    350 ...     95   4249   2193]\n",
      " [128354    990   1991 ...     11  52454  28302]]\n",
      "pred_input_title: (1, 6, 30) Value in first row: [[  4804 221502  93487      7 154982     56 132199     42    604     82\n",
      "    1528      4   2328    115    128   5015 202787    203    308    372\n",
      "     233    139    209  14251    109    209  93016    209  14251    109]\n",
      " [  8302   6468  94412    720     17  22473   6581  30501   4271  70338\n",
      "      42   3817  62769     60  77330  94674      4     99    122   4949\n",
      "    3477    182  13069  15198   1235   7274  94674    261  72468    681]\n",
      " [  1310     72   3082 114105    109      4   2328   3728  10776   3196\n",
      "     182  10922     18    109  43067  64006   3196     17  68883     60\n",
      "   10740      4     48      8   3271  51294   1357   7247 156344  58698]\n",
      " [  3145 144137     12   5976     71   5084   1202  16237      4   5916\n",
      "   88034  53437      9 128743  16673  22201      4     48    149   1630\n",
      "    6474      4     99     22  88034  53437      9  25389    285   1239]\n",
      " [   262  96634 148372   3434 129357   6704     40  36140    261  43084\n",
      "       9 113877     33     17     83  91621      4     60     22    261\n",
      "       8   2536   4343     72  25121   1952   3509    645   2752  26899]\n",
      " [ 38827    820  49043    109  22378    182 126198  17955   2795  42461\n",
      "     171   5879     60      8    100   2955   3986  99602     17   1784\n",
      "       9     11      9   2729    519   5879      9     66  58653  51652]]\n",
      "batch_y: torch.Size([1, 6]), values: tensor([[0., 0., 1., 0., 0., 0.]])\n",
      "Batch 9 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[  1310     72   9342 ...    214     60  25971]\n",
      " [  1310     72   9342 ...    214     60  25971]\n",
      " [  3868    168 157721 ...     13     99 170589]\n",
      " ...\n",
      " [  1529   2480    872 ...    579     72    682]\n",
      " [   262   6530   7223 ...     60     40   1144]\n",
      " [ 42926   1314   2465 ... 175471   2811  55329]]\n",
      "pred_input_title: (1, 7, 30) Value in first row: [[ 84752    126     17  61408   1379  59779     56      4  97045  11783\n",
      "      60 173686   1674  11783  33925     60  20636      4  64475    600\n",
      "   16568  58593     56   3438    139    361   1368   7400   5044   1463]\n",
      " [  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "     182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "    1111    122     72  32376     82  54392   6799    495   3728  10750]\n",
      " [  2609   1390     72   2536      6 242511     18     17     23  12409\n",
      "   36752  89180   2811 164658      4   5101    122  21992      7    109\n",
      "      99  50169  22945  17591     71   1015  75399      6 242511     18]\n",
      " [  1775  34703    261  50605     13 134906      4    122    203  11504\n",
      "      82   8010  53370    100   1379  42373   6581   5665  68211      4\n",
      "      72  20714   1379 145667 150564     18  26040     56  19692   3787]\n",
      " [   357  10189    645   3509 193307  52985   6799    495 107736    124\n",
      "   10658  97101    872  44192    109    100  78475    126  30038  41952\n",
      "      60   4475   2528   1872  56606     67  16941  26343   3810   2633]\n",
      " [158017    362  65318   6063  19716      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [ 62394   2208  25681     17  15161    605     25      7 141918  10254\n",
      "      60  80876     56    182 154157 101416  33618  35992      5 130189\n",
      "      13 121739     33    285    149  63688   5077  15161    605      9]]\n",
      "batch_y: torch.Size([1, 7]), values: tensor([[0., 0., 0., 1., 0., 0., 0.]])\n",
      "Batch 10 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 79231    712   8599 ...    139  45833    400]\n",
      " [199613  46466    182 ...      1      1      1]\n",
      " [ 16148   4317  50775 ... 205463     42 104776]\n",
      " ...\n",
      " [   357   3082  13036 ...    128  21861  39046]\n",
      " [  8301    332 136617 ...   1004    149  44075]\n",
      " [  1004  51213  18043 ...    100     22  52311]]\n",
      "pred_input_title: (1, 8, 30) Value in first row: [[   353    837   3196  77170  28949    139  73104  15270  79329  67623\n",
      "      17   3438   3267  39607     18 190890      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [  1575   3787  30205  44860   1134  85085    139  37304  76539     17\n",
      "  221450      4   2328    168  24607      7     99  11504 154915 178614\n",
      "      72    149  16026     12  56657    149     38      1      1      1]\n",
      " [  1840  81134   1360  20636    171      4   5916    149 152460    100\n",
      "     745     99    765   1100    128 146592    353    145      4   7714\n",
      "      60  21612    145     12  54132     72   1100    128 100618    100]\n",
      " [ 92937    563  56856  71832  12711     56    149 105083     13 123684\n",
      "       5   9578  41575 132048    182 167261    126   1144   2752    109\n",
      "   25257      4    453    563  56856  71832 156896    720     99 118804]\n",
      " [   579   3491     82      6  40080  14872    588   6275   1151    100\n",
      "    1391    162     17 138550      4   5101  93264 165501     17 200178\n",
      "     116 121376  22201      5   1840    203    115  42049  27820   1151]\n",
      " [ 48861  27646      7   1909     24    708   1746  84537  61514    124\n",
      "   18782   2811  37205  12746      4  20363    777     60 183841  22184\n",
      "   45772 138290    126  14434      9   2434  49690   3405    520     24]\n",
      " [182907    203     62     11    571  21825     82 175351 193717  62182\n",
      "     588   3438  50281    592     20    453    149     72    545   2633\n",
      "     109  18118    449   1272  96870      4    109   1081   1505     62]\n",
      " [  5900   1587  94412  59950     42     60  54903     13  40099   1991\n",
      "   26837     17   1368     13   1824     20    604     72     22  37505\n",
      "  132110    109  53705  25681      4    122    315     72  23286     17]]\n",
      "batch_y: torch.Size([1, 8]), values: tensor([[0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "Batch 11 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[164017  46466  17110 ...   4841  21493  87884]\n",
      " [  4265 163335    823 ...  36903  14964   2907]\n",
      " [  4061      7  44767 ...     48     72    149]\n",
      " ...\n",
      " [  1575  82217   6079 ...      1      1      1]\n",
      " [104324    180   1353 ...   3667     12  23037]\n",
      " [128354    990   1991 ...     11  52454  28302]]\n",
      "pred_input_title: (1, 11, 30) Value in first row: [[207975      7  48267    182  15763   4475   1096  39607  26343     17\n",
      "   92549    261  57513  46466     17  24906    128  88761     18  31931\n",
      "    1405  48267   1873 128989    171  52238  24347   5386   1226  31931]\n",
      " [ 10255   2082    112 133857      7    100    177  14936    112    112\n",
      "   11269  12018     23 217315     42    315      4     99    777     72\n",
      "  129500    139  53185    242   2472     99    100  61711   3787  60016]\n",
      " [138719 123373    100 123949      7 150884  28274 170467    170 232043\n",
      "   81134    139     22 194151  26359      4     99 144282     17  82739\n",
      "     203  34872   1368  31182      5   4311      7   2320   6704      4]\n",
      " [ 16148     22   1937     60  56852  22688  27633    171    233  50281\n",
      "     592    139  26521  19175  97978   3350   1507    149  51167    449\n",
      "     824      6  87772    109   1401  40099     53    341   3405  19738]\n",
      " [    20   1731   1063   7830     40  47256  82729      4     60    668\n",
      "    1063   1440   7830     40   1693   2432  82729      5   1575     72\n",
      "      91  17052      4  20363   9920   1446    590   9858   5159    115]\n",
      " [   503      8   2918  29382    588     22  63039     60 191239  33764\n",
      "   45701  35072  10729     71  50081      9    461    133  45701  35072\n",
      "      12   1840     72      8 129401    824  29382      1      1      1]\n",
      " [  4804 221502  93487      7 154982     56 132199     42    604     82\n",
      "    1528      4   2328    115    128   5015 202787    203    308    372\n",
      "     233    139    209  14251    109    209  93016    209  14251    109]\n",
      " [   427  14299      4    124   3491  36418  54572    124  57219    184\n",
      "      17    149   7076 190605    112     60   8311  66950      4    182\n",
      "   36903      6  32761      7   2146  23447      7    592   2331  23447]\n",
      " [ 16148  57513   1755 151847      9      7   1334     42    645  52522\n",
      "   94924   1428     72 151927    515    107  55449    495   3728    124\n",
      "      17   4265   4172     33      4     60    149     72     22    100]\n",
      " [ 76188  16446     56     60  52436   3491  70893    126     20     60\n",
      "     139 117673   1630  27820    126     12 107503    115   3005     93\n",
      "       9 109694     32  58923      7   5945      9   1478    162    282]\n",
      " [  1575 179762   2118  28111  45310     90  41664 127663      9   6378\n",
      "   62182   1728  21309    233  44900     17    168  96634     91  67259\n",
      "   33653      5    579     72  13259  20714    171      9    671   1872]]\n",
      "batch_y: torch.Size([1, 11]), values: tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "Batch 12 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[     0      0      0 ...      0      0      0]\n",
      " [     0      0      0 ...      0      0      0]\n",
      " [     0      0      0 ...      0      0      0]\n",
      " ...\n",
      " [138719     33    616 ...  60747    261  32452]\n",
      " [   579   1134    545 ...     12  38458    545]\n",
      " [  1575  12532   5044 ...  19787  81134      4]]\n",
      "pred_input_title: (1, 8, 30) Value in first row: [[  7370      7    170  14936  15534     92  63865   1063    765   2430\n",
      "      86   2472   5331     17  23946      4   2328    777     72    139\n",
      "    1803     18    100  42696   1743 151380    142 115514     18    100]\n",
      " [   159     76  11439    171 188547   1755  82230    182   3648    126\n",
      "  202312      5  78702    720  99579    315  44296  14953    474    233\n",
      "   78702    720    139  30395     12 124895     72     22 116805  14953]\n",
      " [ 48891    168 136058    171  57038     17 188676 174462     72 190441\n",
      "       4     72    168  42648    126     17    149 183740     13  81170\n",
      "  102831   9173   1760  92809   1357  24270   1873 208942     13    139]\n",
      " [ 27865 127935   2529    182 106686    880  10761      7    170  14936\n",
      "    1760   1205  23228  15711  36377      5   1111    149 184048    112\n",
      "      22   3082  88048     99   1587    168 106686  16148  74224    261]\n",
      " [  1775     75 100038    109 122571    170  84322  15366  12909    588\n",
      "  142716   2811   1840    592      6 242511     42   6799    315   2926\n",
      "     272   1390  15366  12909      6 242511     18     12  48267     60]\n",
      " [146646 178239     13  13594  14964    139     99      6 242511   4343\n",
      "   24674    261 186808    261    109   2993      7   1442      5   1429\n",
      "     182  31066      7  83666  74258     13 167639    109      4   8928]\n",
      " [  1575  36669  41542  55028     60 121739    261  67722     33 135909\n",
      "   27414  49558  18413    820  19716    124  20338  11364 128006    100\n",
      "  123949     17 181916  19507      9    763   1881     32 181916   1042]\n",
      " [   579    203  28117    128     99  11504     22  63039   5324    987\n",
      "   16719    588 192536  74161  46466      4    453    149   1063  15161\n",
      "     605     25      7  21861  39046   1679      4  30492  27473  49035]]\n",
      "batch_y: torch.Size([1, 8]), values: tensor([[0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "Batch 13 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[157168  17250    112 ...    100      8  18678]\n",
      " [    62   8996  77462 ...   1346   3509      5]\n",
      " [149746   9038  40592 ...    472   6236   3667]\n",
      " ...\n",
      " [   262  16471  40830 ... 187453    126  33791]\n",
      " [ 45567   5077  47640 ...   5129    588   1832]\n",
      " [  1004  51213  18043 ...    100     22  52311]]\n",
      "pred_input_title: (1, 5, 30) Value in first row: [[ 48205     56   3232  22000     18    182   8311    645   6520   1015\n",
      "   13069  33977     18  81180  43040    128  68544     19    109   3610\n",
      "       5    579  13594   1440 121540   5180 145315     11     33  45122]\n",
      " [   579    285    545    949  29083   1357     60   6499  88759      7\n",
      "       4    122   3491    600  13384    139  31931   1405     17  91781\n",
      "  149746 166949   1872     12  25066    820    128      6  86760      1]\n",
      " [108341  50142     19  48176 182391    180     13  78200   3232  24684\n",
      "      56   3491     17  68883   2993    139  12227  10729    112      5\n",
      "      87 156258      7      6  40080    285   1926   5262   4642   3916]\n",
      " [    87   8839   1272  78475     72   4475    472  14936     13  53726\n",
      "  220770     99    100      7   2082    112   1872    261    149  27844\n",
      "     341   3405  19738    472  14936     13  53726      7      9   1176]\n",
      " [119420   1205  76264   3521    663  65735  23968   1134   6106  25005\n",
      "      17  16195     71   1015    100     22  26521  19175      9  51602\n",
      "      17   9020    663  65735  23968     72    600  44517      9  39046]]\n",
      "batch_y: torch.Size([1, 5]), values: tensor([[0., 1., 0., 0., 0.]])\n",
      "Batch 14 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[   579 151927     13 ...     66   1042  41406]\n",
      " [  9626   1661  12447 ...   5222  36903  76529]\n",
      " [   717  37505   6378 ...      1      1      1]\n",
      " ...\n",
      " [111347 140852    933 ...  46327   1144   1226]\n",
      " [  8115   1872  53724 ...     13 116850    107]\n",
      " [  8694     39   5828 ...  28949    109  93387]]\n",
      "pred_input_title: (1, 31, 30) Value in first row: [[   579  16471 197956 141040     13      9  16200    182  13259    186\n",
      "  140656     18   1144 125041    109      6  48599   5343     26      7\n",
      "    2663  12897    645      8  13635  16401     17  13957      4   3564]\n",
      " [  1575  16867 130178 129657     18   5071     60  15889   5071     17\n",
      "   54114    301    126  14384 184151    545    645    219   1205  28337\n",
      "       4  20363  96424     56   2331  40322     33   1379  76003   8831]\n",
      " [ 19413    168    600  17137   4196  13950     56  51602   3288  52828\n",
      "       7  38485   8793  65134      7    242    127   7997    334   6238\n",
      "      25      4   5756 181161      7   1353      4     22      6 108714]\n",
      " [165458  57747  28394     23 217315     42      4     99    777    182\n",
      "   15763     22 231404    128     22  12532  98222  26076      9  17052\n",
      "      18     12     20   1731   9038     22 231404      1      1      1]\n",
      " [  1775  74224  56726     18  76423  22913   1063   1872 101515      4\n",
      "   48327  32226  57241    122     72  77304    139   6799 109311   1466\n",
      "       5  33539    203     22  19879  16471  36656     40   6474    139]\n",
      " [ 20261    306  20904     60 167361    182    100   6616     18    149\n",
      "  191510 139338   6378      4   1134      8  14872    588  15948    109\n",
      "   19521     60  92003      5   1840    203    115  42049   2641    171]\n",
      " [ 98411      9 123373  89389  48205     56   3232  22000     18   1063\n",
      "    2855   1205      8  80145   6854  18951   2224    177     17  29630\n",
      "   79233  15866   1379  55125  12613 103371 121156      4     72   3814]\n",
      " [130794   3491     91  22000     18    261     47   3794      4  11530\n",
      "      22  72207  67850   9038   5423   2057   5015    109      6 140548\n",
      "    3196      5   1111    149   9038 130794    545      4     60    315]\n",
      " [ 36061  19507    182  51580     22  34137  56856      7  25249    139\n",
      "  222717  62558  99986  45095      4    122  12532  50825  40130    109\n",
      "  152486     60     72 115303   4196   1144    124      6 132546    261]\n",
      " [  1575  47508  13732  74777   8079  97530      7    285   3059    545\n",
      "     139     99  25005    100    109    845  30319  16326  43957  31019\n",
      "   46466   2548  28780     56    321  84265      1      1      1      1]\n",
      " [  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "     182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "    1111    122     72  32376     82  54392   6799    495   3728  10750]\n",
      " [111347 140852    933 200178   4317 154982  62859  31178   4539    645\n",
      "  138550      7  12801  87696      4   2328   1391    162     60  57501\n",
      "   79949   1015   9038     22 177625     18  20459  80259   1746  14000]\n",
      " [  3658     67    241  16466     60      8 114598   3986  53306    261\n",
      "   16965   4028  20358  50971    112    845  30319  16326  43957    128\n",
      "     228   6947   1746  10674  15267   6639   8710   4034    109   8395]\n",
      " [ 12574      4   5815     60   8451  74224    112   8311   5465 156258\n",
      "      17   4475  80244     42    100     99  82729  44759     19    124\n",
      "   10761   1755  13635  18493  66456 159713  33267     56  18097     17]\n",
      " [127394    182  13069    109  69243   3986      6 233168 101394     42\n",
      "     128  30673      4    124 123039    100  44296      6 102831    128\n",
      "   34806     13      4  83666     60 112874     56 127394     72 101087]\n",
      " [ 35583   2992    587    434     60  14978    241    236  24911     56\n",
      "   44339   1368    109 177950  13440   1914    776 164689      4    453\n",
      "     149    182    545 126198  45375    139     75   1353  18097 124078]\n",
      " [ 71595   1681     33    182  13069 111059   1067    100  65526      4\n",
      "     124  50825  46466  20928     67    109  19609  36012    139  12944\n",
      "   24408     17  45378     62  12944  24408   7980    139  49838  19175]\n",
      " [  1310     72   2641    100   4610  11768    109   3059  52436     60\n",
      "  129693     17    600   6432      4  13613   4475    142  28295   1357\n",
      "       5 147015    126     72      4    171     40   3196     72  16993]\n",
      " [  1310    285 238251   4642     17   7594   3196     17   2248     25\n",
      "    3196      4   2328    332  33618  19787   3963  21825    139  41198\n",
      "       9  13576    671   6520   8993  46204   1405     17  22805     60]\n",
      " [151927    515    107      9  47405     86   9038    495   4343 232440\n",
      "      42 119769      4     99      8  21241  40130  16719   4444   1953\n",
      "       4     99    233  50281   5828   3491  94889  50825 118995   2331]\n",
      " [  1575  16799    203    147  13282  40308     72     82  52849 140692\n",
      "  142687 203352   1572    203  18893  21825    139 194872      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [ 51032    372  33252     72    171  30542  69871    100  57263   2365\n",
      "   72790      4    124  40130  14457   2752    128   9018   3038  23359\n",
      "     109  72413    170  74494   8395   2777   1746    315     12   2548]\n",
      " [   159    170  14936    555      6 126107     12 103978  52821  16861\n",
      "   30673   1151   6157 126436      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [ 30382  80999     56  13594    545   2432  26143    100     99 115331\n",
      "   11269 114306      4     99   1926   3271 100070      7   6106      5\n",
      "     579 114598    112  44296  81170    100   6121      7 120375    126]\n",
      " [ 51032    170    115      4  57687     32      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [ 12612     56    128   1773     33   4188  80145  22654      4  38220\n",
      "  209525     13      4  99579   1872    171 132730    100     99  11504\n",
      "   54903    933    100      7  64289     60    149 225665      7   9518]\n",
      " [   357   6478      9  48951  14134     72  20714    285    126  21769\n",
      "     933    420   3405    449      7   1974     17  11476  93016      5\n",
      "    2548     72   1144   3263    100     99    765  52238  56603     60]\n",
      " [ 45950  18118  22500    182 149014    545  36903  20377    171  74464\n",
      "       4    495    315    182   1926  49050  22378     17   7777  22338\n",
      "   23625  74464     12     20   1310     72    741      6 108396     17]\n",
      " [   636     86   7473     56     60  44296   9018    182  11736   7247\n",
      "   16719    139  32555     20     60    149     72    545 122003 192940\n",
      "     720  40164    139  32555     12   3810   4610  93006   1926      1]\n",
      " [ 62558  99986  45095    100   7121    814 222717    100  54114    301\n",
      "     126      4   1953    149  61100     72  20714  94889     18      4\n",
      "      99    777    182  36903  10024    645   7221   9674    261 126220]\n",
      " [ 92937    563  56856  71832  12711     56    149 105083     13 123684\n",
      "       5   9578  41575 132048    182 167261    126   1144   2752    109\n",
      "   25257      4    453    563  56856  71832 156896    720     99 118804]]\n",
      "batch_y: torch.Size([1, 31]), values: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 15 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[  1575 116850  69686 ...     33  14014  52639]\n",
      " [171342   9638  19006 ...      1      1      1]\n",
      " [   579  46490    112 ...      5    503      8]\n",
      " ...\n",
      " [  1310   7400  38552 ...      1      1      1]\n",
      " [164017   3271  22378 ...  11969   2480      4]\n",
      " [ 50110    261      8 ...     25     19     25]]\n",
      "pred_input_title: (1, 5, 30) Value in first row: [[   242 144890 163710 130891     25   9038  85085  19080  22845    171\n",
      "  184195   5252     17    149  69064   7853      5  33539    285  19080\n",
      "   96321      7  53630    271 184195      4    453    149    285    545]\n",
      " [  4344  64736   3080    233  50281  72083    588 151927    515    107\n",
      "    1134    124  15440   1712    146   8460      7 141532   2118     17\n",
      "   44339 141918   3561  12060   1872     12   4344   1873   2563     17]\n",
      " [    87   1368   1134  82739      9  21673     33    765  77398 129238\n",
      "   16471  43067  64006     56      5 193424   1368   1134   9896     33\n",
      "     765    139  27184 105091    209      4    617 129238  26470      5]\n",
      " [   908     19   2186 215228  14384  21825   1661   8292  95649     60\n",
      "     100  22333  94961      4  13613   2878 123373 156005  25766     13\n",
      "   37962  36621      5   3183    149    182    777 194616  25257  25766]\n",
      " [ 79231   2811  76924 162288   4498 119769  42648     17 167500  36621\n",
      "     109   1496   8557      5 147016    285 183509     33     82  42648\n",
      "     109  50396 130026   5178    139    807  72083     12  51032  46327]]\n",
      "batch_y: torch.Size([1, 5]), values: tensor([[0., 0., 1., 0., 0.]])\n",
      "Batch 16 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[111347 140852    933 ...   1305     33    124]\n",
      " [  1310     72    472 ...  25075   5631   1029]\n",
      " [ 22805   7400 179285 ...      9  16091      7]\n",
      " ...\n",
      " [   357  26073 187073 ...  15198  33532   8520]\n",
      " [157168   8793    168 ...      1      1      1]\n",
      " [   384   7797  44109 ...    242  54494  12227]]\n",
      "pred_input_title: (1, 30, 30) Value in first row: [[ 39170 157282  36323 146874   1191 180801     60 121739  70189  22513\n",
      "      19     72  80459     13     17  52945  43769      4    233  14907\n",
      "      56    168 116850   7829  11214     56     12  52945 131720     42]\n",
      " [  2777  77306 203350   3491     17 154759   6530  18951 242988    100\n",
      "      99   3568   3405    372    168  14134      4    122   9038  52238\n",
      "   56603  25257      5   1429     72  22378  36069   5408      4     60]\n",
      " [   357 124030  28983   3960    520   1872    139     99 145632   1144\n",
      "   14027     17   3817  28246     60  25269      4  16237  22282    341\n",
      "   25471   3405  33516  28983     56   1927   3132     17  95567      7]\n",
      " [ 16148  57513   1755 151847      9      7   1334     42    645  52522\n",
      "   94924   1428     72 151927    515    107  55449    495   3728    124\n",
      "      17   4265   4172     33      4     60    149     72     22    100]\n",
      " [ 11214     13     12    436  56856   2189    109  40207    619    581\n",
      "    3314   2980      9  82957      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [  1775   5178  12924      9   3667  50399   5426      4    122   7400\n",
      "   75818  75281   1824    261  82217  18700     42      4     72  14872\n",
      "     588    495 107736      4    124  58558   3675   3428    126 232756]\n",
      " [ 45095  52849     67 138251   1111   8831      7      9    192     34\n",
      "   40777    126     17     22  28995    223    645    100      6 171233\n",
      "      13      4  23606   1205 107919     13  45095 103899    603    139]\n",
      " [ 10453 109563    112    880  81170    109  50029   4498      5  21519\n",
      "     171     22   2993      7  10204  33328    141   5557   1953   4539\n",
      "    5919    139   8167  16145  52982     12     20  47824  18097     33]\n",
      " [   579  79047   9427   3564   5684  16471  26470     99  41275    805\n",
      "   96634  26470      5    579     72  28778    824  17019   3916   8057\n",
      "  108396     19  60222  46941     13     17  10296      6 128157     20]\n",
      " [   893 212935   7274     72  63926   1953 239604  75281     13 117986\n",
      "      56  15925  22201     22   2926  12909  49043    109  43229      7\n",
      "   80988   9578  17551  32089  30450  19656    142  78131      1      1]\n",
      " [   427  14299      4    124   3491  36418  54572    124  57219    184\n",
      "      17    149   7076 190605    112     60   8311  66950      4    182\n",
      "   36903      6  32761      7   2146  23447      7    592   2331  23447]\n",
      " [     6     26    594   6752    668   6799   1587  10024  30827 114541\n",
      "     604     32     26      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [    87  12574     72    122   2918  60016      4   4925    115   7830\n",
      "    1063  93473  65817  35535    126  91402    122 127448     60  31576\n",
      "      13     17      6 113359   1409  27844    128   6157  22666   1909]\n",
      " [ 84188     71   1872    261  31066      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [130189     13     22  16568 147819    109      6 129226  49043    109\n",
      "   43229   3196     17 123949     60  82739    285    149  79429     22\n",
      "   50094      4    122  13594  41494   9054     18    139     99  12403]\n",
      " [ 34608  78147  70189  19513  77170 143735     56    109   6275     17\n",
      "    2714    254   3405   6581  55118  27633     60     72 149014  68331\n",
      "       7   1334   2264    124 168758  29630 121376     17  25674  40024]\n",
      " [    87    168  96634 143557    261    242  89272     71    128    807\n",
      "      25    182     22  53705  32089  30450  19656   3082   1928 152486\n",
      "       5    262   3491  10269  43468  38595  14486  10266    261  67428]\n",
      " [  1650      9  24658  79570  36621    261  57947      9 137644      7\n",
      "   10901   1977  18413   6850 175471     18 156344     17 112874 114541\n",
      "   42990   1236 114541      7      9  27097      7     12 135240   6850]\n",
      " [ 85287     56 215253     19     17 112923     33  60804    112  57513\n",
      "   55028  12018      4     60    149    520    315   1872    139      4\n",
      "      99  75212    169  82261   9120  33759    168 136058 182291    341]\n",
      " [ 45421  73657 100332      7  48267     60   4804  12655    571  37214\n",
      "      72    139 111241   1226  59980  58948   1277   1953     22    100\n",
      "   11951  22019    112  76529    588     22   2160   6850 149746   5535]\n",
      " [153517  13285    285    171  16307     17     82  12227      4  20459\n",
      "    7997    372   5077   2060  35535      4    122  13594  37993    261\n",
      "    4842   6977   3814  35535   1226    602  29203     33   6096    820]\n",
      " [   242  30347   1134     22  45555    109    616  16167     25      1\n",
      "       1      1      1      1      1      1      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [    20   1731   1063   7830     40  47256  82729      4     60    668\n",
      "    1063   1440   7830     40   1693   2432  82729      5   1575     72\n",
      "      91  17052      4  20363   9920   1446    590   9858   5159    115]\n",
      " [ 83035  15083  29987    759  54569    242  16091      7  41946  55983\n",
      "      25  15948    112     17  78414     60    128     82 215611   1067\n",
      "    1100   9617    124     22    261  25538   3646   1953    538    824]\n",
      " [   357  25240  48951  36656   3491  19110  25531   1368  79329  67623\n",
      "      17     22   2193   1379    131   3667   1226   8599   1505  42233\n",
      "       5   8022   6977 114306    285  44296   7777  84265      5  75882]\n",
      " [ 14355   1505  28398     13   9162   1144   2355   2936    139     99\n",
      "   20252   1809  26583     56   1953    880  93487      7  27633      5\n",
      "    1326    545    495  74138   3916  43144    777  32790   2432    109]\n",
      " [  1310   7400   4949  47979  60605   2852    261 157715      9     92\n",
      "  132546   1444  74991  18097      4     48  65134    182    261  70338\n",
      "     126    149     20  33618  19787    109   8749    261    604     42]\n",
      " [138719 123373    100 123949      7 150884  28274 170467    170 232043\n",
      "   81134    139     22 194151  26359      4     99 144282     17  82739\n",
      "     203  34872   1368  31182      5   4311      7   2320   6704      4]\n",
      " [  9865  16723    186 125082     18     17     91  67259  40005      7\n",
      "    8749    420  12366     71   6919     82    261    149  96634 210300\n",
      "   97537    824      6  98705     20    168  74224  45804  19314   6316]\n",
      " [ 45950  18118  22500    182 149014    545  36903  20377    171  74464\n",
      "       4    495    315    182   1926  49050  22378     17   7777  22338\n",
      "   23625  74464     12     20   1310     72    741      6 108396     17]]\n",
      "batch_y: torch.Size([1, 30]), values: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 17 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[   357  77199    171 ...  37566     86  32832]\n",
      " [ 60592  49049 149727 ...  22772    172  73896]\n",
      " [  1575 140785  22180 ...   2967    233    310]\n",
      " ...\n",
      " [149746    182    142 ...      1      1      1]\n",
      " [ 45567   5077  47640 ...   5129    588   1832]\n",
      " [   357  26073 187073 ...  15198  33532   8520]]\n",
      "pred_input_title: (1, 11, 30) Value in first row: [[159469 128743   3080      8      6 171233     90    908     19   2186\n",
      "  215228    182  13069    495  38788     18      4     99    149    182\n",
      "   36903   4475 110557    139     99 128139  28295     13   1144     60]\n",
      " [  8934      9  78147   4246    712   2548   1771     17 154759 242988\n",
      "     109  36709   8460    100 136476     60     75  53909     71 152815\n",
      "      18  50029     18      6  86875  16977    109   6478      9  78147]\n",
      " [   357   3445     72    142  78131     17  22378      4    453    122\n",
      "      72  21309     22    100  61170     18   4155   6977  30816    109\n",
      "    5129   8282      4  49355    149    588  73104  38436     12   1520]\n",
      " [ 15161  22805   9038   3728   4642     17  12853     56  70952     86\n",
      "      17    122   1272    126    109 239936  96870      4     60    149\n",
      "   79047    315  65134   1039  63260  26470  15161  22805   1873  74224]\n",
      " [138719     33     22  19326  19879  39390  16471    107    182  39809\n",
      "     128  14016  40277    109  31973      5    579     72  90757    495\n",
      "    2918    124    100   6854   1368   3916  50110  14650    149     12]\n",
      " [ 31933     33    285      6  53599    261  25121   5974    603    139\n",
      "   15161   7370      7    170  14936   1760      4     48  15161  22805\n",
      "   74161  46466  26508    112   1144    149  16471  74991  18097  74573]\n",
      " [107526   5262 108961      7     72  20714    146     18   1872     17\n",
      "     242    571    934   5436   8676     25      4    453    149   1630\n",
      "     545    588 171010  64672    671 124895      4    124     72      8]\n",
      " [ 20491  13384   5178    100    168 126957   9060    343  10033      5\n",
      "      87   3278   1630   2923   9365   9674    261    168   9060      4\n",
      "     122   3491  75818     17  12574  32790    588   3530   3923      9]\n",
      " [   357  10183  36656    100  56987   4196     99  36770     13      6\n",
      "  181675   8715  26470    139  56467  34592   8715  26470    109     22\n",
      "      24     18      5  10453  13594   3059  13259  98628    588  11789]\n",
      " [ 48033 146113 208382     42   6799    315  16471    107    139     99\n",
      "  195979   7247 185632      9  11322  64712    588   5614  39289    384\n",
      "   17379    321 185632      9    319   5416     12    387  34592  26470]\n",
      " [ 78196  14431      7  10325  89485     72     22  33618   4475  33925\n",
      "     128      6  11714  13116    171     99   1712  20714  48683  17704\n",
      "       4    124 126458   1144   6474     17    600    241   3089      9]]\n",
      "batch_y: torch.Size([1, 11]), values: tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 18 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 46771   1357    109 ...      1      1      1]\n",
      " [ 16148  94412    720 ...   4922    170      9]\n",
      " [ 60592  49049 149727 ...  22772    172  73896]\n",
      " ...\n",
      " [  5120   8884  17250 ...    100  28779 119470]\n",
      " [  6121    510   1755 ...      1      1      1]\n",
      " [  1429  44177   8395 ...   1144     17  34592]]\n",
      "pred_input_title: (1, 6, 30) Value in first row: [[   353  12216    139  74161  52478  15492  26879  48951 134726   2752\n",
      "      17     82  27535  39046   1226   9578  27971  24259      5   2548\n",
      "      72     17 109057      4    453   9260 128129  26879  48951 134726]\n",
      " [    87    645   1360   1872    261  11476  58926     72  55987     33\n",
      "    1379  33532   1409   2841  70574    126    384  17379   2432     12\n",
      "    1840   3017      8  49520   4896  16471    107      1      1      1]\n",
      " [ 48861  27646      7   1909     24    708   1746  84537  61514    124\n",
      "   18782   2811  37205  12746      4  20363    777     60 183841  22184\n",
      "   45772 138290    126  14434      9   2434  49690   3405    520     24]\n",
      " [   353    837   3196  77170  28949    139  73104  15270  79329  67623\n",
      "      17   3438   3267  39607     18 190890      1      1      1      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [   579     72  60932      4     99 149745    261  30205  82957 173756\n",
      "      17  10740      5   1111  40308    265   1687  32843 100500  41406\n",
      "  175530 113578  82957    308   1297   5225    510     60   2683  28778]\n",
      " [  1575   3787  30205  44860   1134  85085    139  37304  76539     17\n",
      "  221450      4   2328    168  24607      7     99  11504 154915 178614\n",
      "      72    149  16026     12  56657    149     38      1      1      1]]\n",
      "batch_y: torch.Size([1, 6]), values: tensor([[1., 0., 0., 0., 0., 0.]])\n",
      "Batch 19 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[  1775      6  21769 ... 204447     67   2500]\n",
      " [ 14851   4200  40550 ...  49217  13594  19780]\n",
      " [199613  46466    182 ...      1      1      1]\n",
      " ...\n",
      " [ 16692   5879  89596 ...     18   1144     23]\n",
      " [    87     82  33683 ...    294  33752 100306]\n",
      " [  1204  11439 159249 ... 159249  93156   1991]]\n",
      "pred_input_title: (1, 5, 30) Value in first row: [[124895  73359   2432 114224  11783   1144    128   1100      4     98\n",
      "    2628     60 121950  73895     56      4    122  95815    139    128\n",
      "      99  18381  44296  12441  33215  12444     17    185     13      5]\n",
      " [ 31984   1953     99  93264    131  12530   1760     18    285 133328\n",
      "    1496   1368      4   3491    777      6  68413     18    109   7897\n",
      "       7  16401    109    880    151   5204    109 132989     73   3196]\n",
      " [219877     13   2878     56     17 221450   8793   6157    168   3787\n",
      "   77199      4    122  63688      7     99  18413    112  55924    615\n",
      "   19110  44339   1368 219877     13   2878     56  16993     12   1429]\n",
      " [  1326  64974  22652   4602      4     99     82 131644    810     56\n",
      "   35121    233  27184     13   1144 124030     18     17 130579    645\n",
      "     149  45421    875     90  13282  31206      5   1429 126667  33758]\n",
      " [ 41267   3683  81421  67858   1755    182    109 150342   1144  71274\n",
      "      13   1581    820   1953     82  33791     18   1379  93487     60\n",
      "      72  23286     17  20045    872  17275  11770 164403   1746 141120]]\n",
      "batch_y: torch.Size([1, 5]), values: tensor([[0., 0., 0., 0., 1.]])\n",
      "Batch 20 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[ 34491  23129     13 ...      1      1      1]\n",
      " [   357  36799     56 ...   1144   3263    100]\n",
      " [  1575 126957  58483 ...  82739    261  72468]\n",
      " ...\n",
      " [123949   1063    545 ...  16673   1357    242]\n",
      " [123949   1063    545 ...  16673   1357    242]\n",
      " [  1529   2480    872 ...    579     72    682]]\n",
      "pred_input_title: (1, 15, 30) Value in first row: [[   717    139   1803     67  30673      7 102919   1363    261   6432\n",
      "   85862     60 175564   1100 195642     22   3082    146    261     22\n",
      "   38074  17454 100431   8167  16145  43764      5    159   4867  36947]\n",
      " [ 14355   1505  28398     13 127232   1144    645      4     99  99442\n",
      "   21139   1681  49217     72  19716   1226     22  12801    159   3719\n",
      "    1950  51580  76529    139  99442     12   3314  42108    645 182291]\n",
      " [   636     86   7473     56     60  44296   9018    182  11736   7247\n",
      "   16719    139  32555     20     60    149     72    545 122003 192940\n",
      "     720  40164    139  32555     12   3810   4610  93006   1926      1]\n",
      " [  1204  92153    285    348   5844   5077    109  27535    139  41267\n",
      "      33      4    186  78965    149 116850  30395  17189  10729  13384\n",
      "    9458    261   9318  14251     24    708      9    265  73341      1]\n",
      " [130189     13   4475  19035     56    203  24270     86  21350   1712\n",
      "      17 120149  42648  33326  16732   1728    171   9060  88131     12\n",
      "     908   7864     18     38      1      1      1      1      1      1]\n",
      " [ 33365    329  61240   7400   9226  89700   1179     17     82   5178\n",
      "   97537     18   3661  10453     72  19716     38  33365    329  61240\n",
      "    9226  89700   1444      1      1      1      1      1      1      1]\n",
      " [   341  56856      4     75  78475    118  69593     60  30911    261\n",
      "     156   5293 113285      4   3486    592    282   4759     60   3115\n",
      "    1234    133  97943     56      5   1840     72   2641      4    115]\n",
      " [147016 140232  12018     60 100307  37873 177149     56      6 154759\n",
      "     100   8796  60306   5557      4  52238   2811     22  36656     60\n",
      "  140993 101133    603   2811     22  24830     17  50029      6  72752]\n",
      " [  1326      7  72083    182     22 165141    109    149 184657     13\n",
      "     242    724  67688    497    177   5155     25      9  12654  41684\n",
      "   33539  77781    112     22  14134    168   7530   1442   6106     60]\n",
      " [   357 205439 194636     72  20714 242312    261 100592   1042    186\n",
      "    4922  44549      4    124    182  13969     18     22 194151 182770\n",
      "   49043    109      6  81100     19    139  82739 182517   8349     12]\n",
      " [ 26467     85   3962    182    109   1587  32053  11736     82 175530\n",
      "   32226    177    109   7247    315   1953   6616     67   7829   6378\n",
      "      17  63667     56      5   4440    128  98990    503  26467     85]\n",
      " [  4961   2811  24314    109 116850   1872 175680    261 142209    107\n",
      "     182 123949   2752  27184      6  81100    100 116850  61634     56\n",
      "      60    352  13482      7 119769  49083   2822   1824    261    352]\n",
      " [  1496  34592  13285  21962  20691    495 205077     67    100  22255\n",
      "  166954     56      4     99      8  97269   1728     56     99 109563\n",
      "   14027      4   1939  81523  11783   5178  22282  29630  19327    606]\n",
      " [  1310   7400   4949  47979  60605   2852    261 157715      9     92\n",
      "  132546   1444  74991  18097      4     48  65134    182    261  70338\n",
      "     126    149     20  33618  19787    109   8749    261    604     42]\n",
      " [ 83035  15083  29987    759  54569    242  16091      7  41946  55983\n",
      "      25  15948    112     17  78414     60    128     82 215611   1067\n",
      "    1100   9617    124     22    261  25538   3646   1953    538    824]]\n",
      "batch_y: torch.Size([1, 15]), values: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "Batch 21 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " ...\n",
      " [   87    82 33683 ...    12    20   582]\n",
      " [   87    82 33683 ...    12    20   582]\n",
      " [ 1310    72   211 ...     1     1     1]]\n",
      "pred_input_title: (1, 8, 30) Value in first row: [[   579  16471  13736  15429   1596      4      6  80020      4     72\n",
      "   33832     17 104310   2811  27808   1953  18154    171  73391     92\n",
      "   39916    112  36024  29017   1596     17  93669 129857     12     20]\n",
      " [ 11617  13594  76529    588 117160      4    171     99    777   3271\n",
      "   30646   1357   6107     25     33   3080   2795     19   6651      5\n",
      "    1111      8  51580     13   2057     22 127623      9 167098   5281]\n",
      " [ 78201  24727  65918      6 161449     67  57513  24645  13683     60\n",
      "   77170  44867  25538 156224     33     17    228  15592 161449      4\n",
      "     124    777   2432   9038  11736   1461  15592 161449  41946  70166]\n",
      " [   391  19611  21070    171   7270   3491  43468    139   3749  19040\n",
      "      18    109   8749    261   2265 120608     60 105774  16148     82\n",
      "  146073   1368     12  25066   3055  19716    139  12574      1      1]\n",
      " [  1843    555     60  69959     19   3196     72  67702    139  50825\n",
      "   20714  16993    171     22 228659  77199    171     99 207745   4602\n",
      "      25      7  53630  80430 145187   1843    555     60  69959     86]\n",
      " [118405   1409     44  73903 175870    116     58   1823    545    139\n",
      "      99 216861  15198  39406    933   4200      7     60  47208   5342\n",
      "   50825   1953  52658     14   6889  57513  46466 118405    429    588]\n",
      " [ 14355   1505  28398     13    285  65889    139     99  34137  56856\n",
      "    1205    880 193428  99442  21139   1681      4     48   1926  57933\n",
      "   14486  22201   1144    139  17042 113877     33     17  85190   6389]\n",
      " [ 29616    271     47   3491 242312     60   4475   3491    495   2264\n",
      "    1226 128827 143027     66  53631   2811  82739      7 163662  50825\n",
      "      24     18  51211   6581 143027     66  53631   2811 149222  50825]]\n",
      "batch_y: torch.Size([1, 8]), values: tensor([[0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 22 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[   527   3405   1515 ...  15918      5   1429]\n",
      " [204876    341  25445 ...    262    203    545]\n",
      " [130207  48267    186 ...  22805 149746   1953]\n",
      " ...\n",
      " [ 51661   6815  22193 ...   1134  18381     86]\n",
      " [   527 187631    350 ...     95   4249   2193]\n",
      " [ 57204   4794    165 ...      1      1      1]]\n",
      "pred_input_title: (1, 7, 30) Value in first row: [[  1575  17659  78147   3491  19489  47000  10266 111326 190852      5\n",
      "   67959     72  71559   3196      4    122  63299   2057     17   6867\n",
      "       4  20714  13584  34881    159  83842    126     17   6157    497]\n",
      " [  3974  19175      9  33870     33   8793  15198  17151 136691      7\n",
      "    8321     60      8  21715  42822   3112  82729    107    261      6\n",
      "  113877     33      4 107578      4    122 233896  77170  30749  14098]\n",
      " [147160 126957  76875 192000     42   3268  70869      7    139  59657\n",
      "    2811  82739      5   1775  18413     92    588     22  30501     18\n",
      "   19507      4    122  14742   1144   2752     17     22  24830 196943]\n",
      " [ 11584  50142     19 114411     72  10269  33618  20592  62728     86\n",
      "      17     22    600  59036      9   8551      4    124   1873  22184\n",
      "     261    142  28295   3196 242236   7274   3438    433  42108 114411]\n",
      " [144503    139 102980     22  34608  48951  13019   2189  38264  11862\n",
      "   62542  24265   2472   3267  79943     42   2811  20627 147016      6\n",
      "  222101    139  36232    645    805 151889    645  53631   2811  20627]\n",
      " [ 26076      9  17052    510   1529     93  53417  58744    446    182\n",
      "  106686   1661 190890     17  19893   7030    159  14936   1505    239\n",
      "   19129     11      9   6378      1      1      1      1      1      1]\n",
      " [  1575  12532   3551 109331   1679  21504  18043  19528    309 193220\n",
      "      72 132199     18    124    600  21861  39046   1679     17  11399\n",
      "   45421  38486  42373   3196  21504  18043  19528    309 193220  28780]]\n",
      "batch_y: torch.Size([1, 7]), values: tensor([[0., 0., 0., 0., 0., 0., 1.]])\n",
      "Batch 23 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[  1775      6  21769 ... 204447     67   2500]\n",
      " [ 14851   4200  40550 ...  49217  13594  19780]\n",
      " [199613  46466    182 ...      1      1      1]\n",
      " ...\n",
      " [ 16692   5879  89596 ...     18   1144     23]\n",
      " [    87     82  33683 ...    294  33752 100306]\n",
      " [  1204  11439 159249 ... 159249  93156   1991]]\n",
      "pred_input_title: (1, 8, 30) Value in first row: [[ 14355   1505  28398     13  83499 114411   5177   9802      7     17\n",
      "    5262 107677    261  85190   6389   3666      4    453  55888  57169\n",
      "     109 106210   5252    345   3038  23359   5077 159153     12  15912]\n",
      " [ 16148   5756  44339   3661      4    242   3957  10348 180423     25\n",
      "       4     72    168   4067   4063  75019   4196   1346 206603   5813\n",
      "      19   2311  45501  78244  80459    128     99  28778   1346 209833]\n",
      " [    87 128291   6999     67    332  74161   4039      4    418  60323\n",
      "   23604   1272   6999     56 216397  22255     17    805   1368      1\n",
      "       1      1      1      1      1      1      1      1      1      1]\n",
      " [   262  43144    139   5159   8460      7  79958      4    453  11377\n",
      "     315     82  18738   1224  36791      5   3183  13457    261    745\n",
      "       4    124    285     17  18738   1224  36791      4 185502    315]\n",
      " [  1840   1873    115 130715     33    109      4   5916    115  77304\n",
      "  199169     20     60  44867   1440   1873    168  13635   1100   5371\n",
      "     128     20    149  36656   3986  52702    141 106379  31252    145]\n",
      " [  1575  74166  10952  53630    271   6494  33618  19787  95475     86\n",
      "     171     99  28778    139     22  49619  28995    223    139     22\n",
      "   29892  18873    261 105920   4922    170  19893    335  15555    820]\n",
      " [  4265   4172      9   2146  50281  72083    588 151927    515    107\n",
      "   67199  57263  27512   2208     18      4    122  60804     42    139\n",
      "  214862   1953      6 222112  50825  23604   1600     12 110679  74224]\n",
      " [122571      9     60  23146 100332      7  48267  48024  55028     86\n",
      "     139     82  19576  39696   2281    272    265   1515      4    124\n",
      "       8    182    186   7112  26322      4    233  14907     56      8]]\n",
      "batch_y: torch.Size([1, 8]), values: tensor([[0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "Batch 24 with batch_size: 1\n",
      "his_input_title: (1, 50, 30) Value in first row: [[   717  79668     72 ...     71   5084  52658]\n",
      " [161781     67 166003 ...  54655 161781  41618]\n",
      " [181810  23850    128 ...    645      1      1]\n",
      " ...\n",
      " [    87     82  33683 ...     12     20    582]\n",
      " [ 52888      7  58483 ...  33276    262    294]\n",
      " [   527 187631    350 ...     95   4249   2193]]\n",
      "pred_input_title: (1, 5, 30) Value in first row: [[130189     13   4831    182 161950  70237   4932      7   3787  55028\n",
      "      13  91177     56    171     99   3438  40272   2101      6  54085\n",
      "   44466     56    302     18  51216      9   9802  38407     56   2101]\n",
      " [  2132  24251  52821    947      7     19 145739    588 113852   7400\n",
      "   99442  21139  42182   5262 203377     56     17   9963     91   3719\n",
      "       9 113877     33  92265  13527   1840     72  21139  42182 203377]\n",
      " [211857 162288      4     99  87085 168423     56   1063  11504    770\n",
      "    8349     18    261 204253  25389    669   2679  31019      5 117655\n",
      "     177    720    100  74161   1326      7  14068  26343     17 160197]\n",
      " [ 50110  50094     42 139747 186044     33  65528     13  27303   1015\n",
      "      72  20714   7895   4164 132508    124 170931   5918  10266     60\n",
      "      22  96541    139    324   7655    334   1428  80460     56   1872]\n",
      " [ 27303   2460  78821  20928     67   2563   3564     22  19879  26470\n",
      "      17  72392     60  25779   4343  24674    261  19985    165  17052\n",
      "      13 136348     20    453    122     72    186  46686    109  27535]]\n",
      "batch_y: torch.Size([1, 5]), values: tensor([[1., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=dataset.df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False, # Is true in EBREC, but then it does not work\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "for batch in tqdm(test_dataloader, desc=\"Test\"):\n",
    "        (inputs, labels) = batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:  12%|█▏        | 3/25 [00:00<00:00, 22.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his_input_title: (10, 50, 30), values: [[[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [  4804  14299     72 ... 242511     18     17]\n",
      "  [   581  52305  19114 ... 113349   1205 158023]\n",
      "  [   360  16741  17938 ... 140852    933 105367]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [  4804  14299     72 ... 242511     18     17]\n",
      "  [   581  52305  19114 ... 113349   1205 158023]\n",
      "  [   360  16741  17938 ... 140852    933 105367]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [  4804  14299     72 ... 242511     18     17]\n",
      "  [   581  52305  19114 ... 113349   1205 158023]\n",
      "  [   360  16741  17938 ... 140852    933 105367]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [  4804  14299     72 ... 242511     18     17]\n",
      "  [   581  52305  19114 ... 113349   1205 158023]\n",
      "  [   360  16741  17938 ... 140852    933 105367]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [  4804  14299     72 ... 242511     18     17]\n",
      "  [   581  52305  19114 ... 113349   1205 158023]\n",
      "  [   360  16741  17938 ... 140852    933 105367]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [  4804  14299     72 ... 242511     18     17]\n",
      "  [   581  52305  19114 ... 113349   1205 158023]\n",
      "  [   360  16741  17938 ... 140852    933 105367]]]\n",
      "pred_input_title: (10, 1, 30), values: [[[ 35583  17859   3648   4196  88722  33870     33   1226  43084     17\n",
      "    16307    510   2706      4   2328    777  13594    472  55413    261\n",
      "   131644     13  59246  15521  39988  29630 156052     71  19611     39]]\n",
      "\n",
      " [[ 99442  21139   1681  30003     22 175351 152035   5256  27633   2811\n",
      "    96634  12969   5095 163933  21836      5  78287   3683   2752  52454\n",
      "       42  59138    139  92265  13527      7  17042 113877    159 143662]]\n",
      "\n",
      " [[ 73831   6769 157282     33     72   9525    100    156   1505     60\n",
      "    95874     18  92003      4     60  65817 154806     33 205700     42\n",
      "        4     99    149  97353   1144      5   1111     82  20807  67013]]\n",
      "\n",
      " [[   262    182  34592    261     40   1357      4    453   2328   4610\n",
      "   185502      8  29935    109     99 180046   1100  51169   9872     56\n",
      "       32    579   1873    115   2752  45190     17    604    579 185502]]\n",
      "\n",
      " [[ 16148   4475 230745     56    182     22 102516  36656    588  88880\n",
      "    59205     18    880   4343 100339    109    168  20951 146106  51602\n",
      "        4   2328   2536  13732  30673   1063    765   1100    128  25257]]\n",
      "\n",
      " [[138087  19824    285    149 174854     13   8753    109    149 174854\n",
      "       13  16077     17    845  30319      4   2328   1550    820   1872\n",
      "    24705  18066    588  30622   1067   7639  15912   2415      7  67623]]\n",
      "\n",
      " [[ 14949  27303   1015  28338   4196    233    128     22  37773  30793\n",
      "        4     48  30749  14098  26508    112   1144     22  47621     17\n",
      "     2663  11565     60  49838  19175      9   1743  55329     17  44339]]\n",
      "\n",
      " [[ 25330  14384    115  84872      6  33926  27472     32 115745  22255\n",
      "       56   1134    149    765     32   3183  36566   1134  13457  18485\n",
      "       56     17      6  33926  27472  29935  60108     90    139     32]]\n",
      "\n",
      " [[  1910    116    182  38552    126    139     17  25531 152262     60\n",
      "    16237    315  14355   1505  28398     90 115456      4   2683    777\n",
      "       72  33618 148372     86    139     99  82729  92265  13527   1910]]\n",
      "\n",
      " [[  4669      9  48951      6 154759     12   2548   3271 135768  17819\n",
      "      261 102991      1      1      1      1      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]]\n",
      "batch_y: torch.Size([10, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [4.8040e+03, 1.4299e+04, 7.2000e+01,  ..., 2.4251e+05, 1.8000e+01,\n",
      "         1.7000e+01],\n",
      "        [5.8100e+02, 5.2305e+04, 1.9114e+04,  ..., 1.1335e+05, 1.2050e+03,\n",
      "         1.5802e+05],\n",
      "        [3.6000e+02, 1.6741e+04, 1.7938e+04,  ..., 1.4085e+05, 9.3300e+02,\n",
      "         1.0537e+05]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (18, 50, 30), values: [[[ 1310 40130 57491 ...    48 27376     9]\n",
      "  [  357  4271 24906 ...  6369    12   438]\n",
      "  [ 2548  3491 17461 ...   246 14580    12]\n",
      "  ...\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [  391 18148     9 ...    99  1129  2661]\n",
      "  [26729  3263   100 ...     1     1     1]]\n",
      "\n",
      " [[ 1310 40130 57491 ...    48 27376     9]\n",
      "  [  357  4271 24906 ...  6369    12   438]\n",
      "  [ 2548  3491 17461 ...   246 14580    12]\n",
      "  ...\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [  391 18148     9 ...    99  1129  2661]\n",
      "  [26729  3263   100 ...     1     1     1]]\n",
      "\n",
      " [[ 1310 40130 57491 ...    48 27376     9]\n",
      "  [  357  4271 24906 ...  6369    12   438]\n",
      "  [ 2548  3491 17461 ...   246 14580    12]\n",
      "  ...\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [  391 18148     9 ...    99  1129  2661]\n",
      "  [26729  3263   100 ...     1     1     1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1310 40130 57491 ...    48 27376     9]\n",
      "  [  357  4271 24906 ...  6369    12   438]\n",
      "  [ 2548  3491 17461 ...   246 14580    12]\n",
      "  ...\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [  391 18148     9 ...    99  1129  2661]\n",
      "  [26729  3263   100 ...     1     1     1]]\n",
      "\n",
      " [[ 1310 40130 57491 ...    48 27376     9]\n",
      "  [  357  4271 24906 ...  6369    12   438]\n",
      "  [ 2548  3491 17461 ...   246 14580    12]\n",
      "  ...\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [  391 18148     9 ...    99  1129  2661]\n",
      "  [26729  3263   100 ...     1     1     1]]\n",
      "\n",
      " [[ 1310 40130 57491 ...    48 27376     9]\n",
      "  [  357  4271 24906 ...  6369    12   438]\n",
      "  [ 2548  3491 17461 ...   246 14580    12]\n",
      "  ...\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [  391 18148     9 ...    99  1129  2661]\n",
      "  [26729  3263   100 ...     1     1     1]]]\n",
      "pred_input_title: (18, 1, 30), values: [[[118843  50142     19    182  62896  66373    109 104776     19      4\n",
      "      453     17   4343  42373   1515  43881      7  95445     72    777\n",
      "    21309    168   7530  12227   6369     42      4    124   1926  18893]]\n",
      "\n",
      " [[   845  30319  16326  43957    182 137044     18 239604  96691      7\n",
      "    16294  63466    109   8749    261  52238   5084 217128    139  10674\n",
      "       56   1326   1063    112     12   8651   9653  25445    588   8395]]\n",
      "\n",
      " [[ 45331   1205  33276  33759   2752     17  23146    107    563   3405\n",
      "      449   1428     17  22805     47  39851    171 156258    139  56852\n",
      "      265  26652     60    770  17454     67    112  54903 172717     60]]\n",
      "\n",
      " [[ 10935 156457  44339  21562  67199 147644     86    139   4265   4172\n",
      "       33      4   1823   2918  19035     56     60  80998   9468  22201\n",
      "     8646     56     17 181215  26076      9  50142     42     17 181215]]\n",
      "\n",
      " [[  4669      9  48951  14134      4    124     17   1049  40130    444\n",
      "      685     60 242312     13     22  67013     60     22   2265 108714\n",
      "        4   1063    765     82   5178   7334      5  69367    315  88613]]\n",
      "\n",
      " [[ 50224  78147  94084     13   1391    162    182    139  31685    126\n",
      "       99    765 242312    880  81170     60   5504  13384      8  36650\n",
      "    13282  53306    109     22   7223  32977  12126  36012  22865   5084]]\n",
      "\n",
      " [[ 73831   6769 157282     33     72   9525    100    156   1505     60\n",
      "    95874     18  92003      4     60  65817 154806     33 205700     42\n",
      "        4     99    149  97353   1144      5   1111     82  20807  67013]]\n",
      "\n",
      " [[   360  18026   6620    982    182   5129    126    139    880  24792\n",
      "    52152   2506  84265    239  13944  68809  73860   1129  42108     12\n",
      "    10453  62046     79      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 57263  74352   3834    203  74161     20   6106      4   6106     20\n",
      "    28778   1380  12620    100  15161  22805   2907   4227     86     72\n",
      "    19716    100  15161    605      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 95769    195 118335    702     60    423   1063  75162    109     88\n",
      "       17    168  16420   3986    146    261  12574   1712  26948  14819\n",
      "   122679    117  14251  10686     18      9   6032  10729  13384     38]]\n",
      "\n",
      " [[   717 132177     56     72  20714      6  72490    824     18      4\n",
      "     1953     99     22   7799    271  50825    109  86373  15492     22\n",
      "    53705    128    387 132177     56     17   8451    884   3104   1746]]\n",
      "\n",
      " [[  1575  12532     62  79035      9  47405 156005 141731 132178     13\n",
      "    31019    233     17  83983     17 174090      4     48    777     72\n",
      "     1144   3263    100     99    765  52478   3198    100  43468     60]]\n",
      "\n",
      " [[ 20387    316      9  40042      7 140993  38982    202    236    810\n",
      "       67    112    339  30992     25   1357      5   4843    334  54903\n",
      "   172717     72     17 154759  36709   1961  12444 242988     17     22]]\n",
      "\n",
      " [[   353  12216    139  50825  83497     67     22  27345  24490     99\n",
      "        6 114839    261    588  15653      7  15429    510      5    579\n",
      "    40130  98099    495   3728  10746    145   5386 139699     17   2428]]\n",
      "\n",
      " [[ 56101      6 151612    214    182 204522   3900  86654    133 137550\n",
      "       99 107865     17  36656      9  67132   3196      5    262     72\n",
      "    10269  52809   1779   1518   1772     86     17   8608     33    100]]\n",
      "\n",
      " [[ 93264 165501  19521     18     17 138550   1661  19787      6  40080\n",
      "       17 200178    116   2669     17 141918     60    645  82628   5262\n",
      "   132255     17  74991 105922  29630 121376     17 138550     12     20]]\n",
      "\n",
      " [[   357  14134   1630  16719    139   1661   8675     60 125503    112\n",
      "        4     99    149   9038  13069    186    837    126    261     22\n",
      "   152836     17   4475  34346   4960  11063     85  76330     17    159]]\n",
      "\n",
      " [[138014  47192    478 141731      4    122   3491 124664    124  78155\n",
      "    17052     18      4     48   1926   2432    285     82   4140      4\n",
      "       72  20714   2993      5   1429  16237   1926  81170     33   6474]]]\n",
      "batch_y: torch.Size([18, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[1.3100e+03, 4.0130e+04, 5.7491e+04,  ..., 4.8000e+01, 2.7376e+04,\n",
      "         9.0000e+00],\n",
      "        [3.5700e+02, 4.2710e+03, 2.4906e+04,  ..., 6.3690e+03, 1.2000e+01,\n",
      "         4.3800e+02],\n",
      "        [2.5480e+03, 3.4910e+03, 1.7461e+04,  ..., 2.4600e+02, 1.4580e+04,\n",
      "         1.2000e+01],\n",
      "        ...,\n",
      "        [3.6000e+02, 5.5500e+02, 2.2000e+01,  ..., 1.3680e+03, 4.0000e+00,\n",
      "         1.1380e+04],\n",
      "        [3.9100e+02, 1.8148e+04, 9.0000e+00,  ..., 9.9000e+01, 1.1290e+03,\n",
      "         2.6610e+03],\n",
      "        [2.6729e+04, 3.2630e+03, 1.0000e+02,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (15, 50, 30), values: [[[  5976  43943   1176 ... 100592   1205  20627]\n",
      "  [199613    182  73104 ...  43764     12 149746]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  ...\n",
      "  [ 82739    142  53631 ...    126 123949     12]\n",
      "  [   579    182      6 ...     22  48433   1434]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[  5976  43943   1176 ... 100592   1205  20627]\n",
      "  [199613    182  73104 ...  43764     12 149746]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  ...\n",
      "  [ 82739    142  53631 ...    126 123949     12]\n",
      "  [   579    182      6 ...     22  48433   1434]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[  5976  43943   1176 ... 100592   1205  20627]\n",
      "  [199613    182  73104 ...  43764     12 149746]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  ...\n",
      "  [ 82739    142  53631 ...    126 123949     12]\n",
      "  [   579    182      6 ...     22  48433   1434]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  5976  43943   1176 ... 100592   1205  20627]\n",
      "  [199613    182  73104 ...  43764     12 149746]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  ...\n",
      "  [ 82739    142  53631 ...    126 123949     12]\n",
      "  [   579    182      6 ...     22  48433   1434]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[  5976  43943   1176 ... 100592   1205  20627]\n",
      "  [199613    182  73104 ...  43764     12 149746]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  ...\n",
      "  [ 82739    142  53631 ...    126 123949     12]\n",
      "  [   579    182      6 ...     22  48433   1434]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[  5976  43943   1176 ... 100592   1205  20627]\n",
      "  [199613    182  73104 ...  43764     12 149746]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  ...\n",
      "  [ 82739    142  53631 ...    126 123949     12]\n",
      "  [   579    182      6 ...     22  48433   1434]\n",
      "  [   345    555 105920 ...     12  82739  43144]]]\n",
      "pred_input_title: (15, 1, 30), values: [[[ 38692   7325   7182    100  15123    820    545      8 105791   1368\n",
      "        4    168  12532    242 115411    837     14     25    182  15763\n",
      "       17    168  16471  15918 169074      4    453   4925    777  13594]]\n",
      "\n",
      " [[   717    139   1803     67  30673      7 102919   1363    261   6432\n",
      "    85862     60 175564   1100 195642     22   3082    146    261     22\n",
      "    38074  17454 100431   8167  16145  43764      5    159   4867  36947]]\n",
      "\n",
      " [[ 99678   3019     12   8694    157     12    341   3405     39  17648\n",
      "     3366     17   4602     20    315    203    149  21177     17   3974\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 33365    329  61240   7400   9226  89700   1179     17     82   5178\n",
      "    97537     18   3661  10453     72  19716     38  33365    329  61240\n",
      "     9226  89700   1444      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 21667     42    115   1953  58709  76852  18485     56      4    495\n",
      "      203    115  59393 109516    242  20706     25    109   4504   1053\n",
      "      764    112  65296      9    299  48535   3621    747    173  16123]]\n",
      "\n",
      " [[  1784  14985    603   1823    139     99    261 126550      4  40003\n",
      "      122  88032  77304    588  57513   1755 152035   1363     17 138550\n",
      "   107526 136449  57933     12  23757  54076     18  49043      1      1]]\n",
      "\n",
      " [[  1496  34592  13285  21962  20691    495 205077     67    100  22255\n",
      "   166954     56      4     99      8  97269   1728     56     99 109563\n",
      "    14027      4   1939  81523  11783   5178  22282  29630  19327    606]]\n",
      "\n",
      " [[ 83035  15083  29987    759  54569    242  16091      7  41946  55983\n",
      "       25  15948    112     17  78414     60    128     82 215611   1067\n",
      "     1100   9617    124     22    261  25538   3646   1953    538    824]]\n",
      "\n",
      " [[   636     86   7473     56     60  44296   9018    182  11736   7247\n",
      "    16719    139  32555     20     60    149     72    545 122003 192940\n",
      "      720  40164    139  32555     12   3810   4610  93006   1926      1]]\n",
      "\n",
      " [[144503  46466   3271    122  45692 107224     56    139  28235      9\n",
      "    96321    242  37455   4227   1303    320     25      5  50110    261\n",
      "        8     40   1357      4    122  36418     67      4  77781    112]]\n",
      "\n",
      " [[ 99442  21139   1681     60  12969   5095 163933  21836  13594     75\n",
      "    62489     18  52849   1379   7247 152035   5256  27633    139  85190\n",
      "     6389   3666    345  62489     18  53630    271    109 131969     12]]\n",
      "\n",
      " [[   579    203   1712  10024    261     22  65172    133     99   9881\n",
      "     1872    261      4   8928    115   3434  21537    321 217785     56\n",
      "     2721    139  13440    100  93008      5 156433     86     72  32790]]\n",
      "\n",
      " [[   341  41453   9088    647  82521  20345    568     12    503    747\n",
      "     8530   3196   1226     22  61100    261  78131   4067   1674  45530\n",
      "      100   3733  50142     42  13261  50142     42      6  65853   3667]]\n",
      "\n",
      " [[   341  56856      4     75  78475    118  69593     60  30911    261\n",
      "      156   5293 113285      4   3486    592    282   4759     60   3115\n",
      "     1234    133  97943     56      5   1840     72   2641      4    115]]\n",
      "\n",
      " [[ 91781     72   3082  66609    217    139     99  17250   1144     17\n",
      "     2704   3196   2811  25052    724      4     60   4925      8   1823\n",
      "      122   3675      4  13613  26328  27512     18  66965      4     99]]]\n",
      "batch_y: torch.Size([15, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[5.9760e+03, 4.3943e+04, 1.1760e+03,  ..., 1.0059e+05, 1.2050e+03,\n",
      "         2.0627e+04],\n",
      "        [1.9961e+05, 1.8200e+02, 7.3104e+04,  ..., 4.3764e+04, 1.2000e+01,\n",
      "         1.4975e+05],\n",
      "        [1.3100e+03, 7.2000e+01, 7.5000e+01,  ..., 1.2000e+01, 1.2395e+05,\n",
      "         3.4800e+02],\n",
      "        ...,\n",
      "        [8.2739e+04, 1.4200e+02, 5.3631e+04,  ..., 1.2600e+02, 1.2395e+05,\n",
      "         1.2000e+01],\n",
      "        [5.7900e+02, 1.8200e+02, 6.0000e+00,  ..., 2.2000e+01, 4.8433e+04,\n",
      "         1.4340e+03],\n",
      "        [3.4500e+02, 5.5500e+02, 1.0592e+05,  ..., 1.2000e+01, 8.2739e+04,\n",
      "         4.3144e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (19, 50, 30), values: [[[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  2471   2061  26181 ...      1      1      1]\n",
      "  [241627    947   1409 ... 226063      5  51032]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  2471   2061  26181 ...      1      1      1]\n",
      "  [241627    947   1409 ... 226063      5  51032]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  2471   2061  26181 ...      1      1      1]\n",
      "  [241627    947   1409 ... 226063      5  51032]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  2471   2061  26181 ...      1      1      1]\n",
      "  [241627    947   1409 ... 226063      5  51032]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  2471   2061  26181 ...      1      1      1]\n",
      "  [241627    947   1409 ... 226063      5  51032]]\n",
      "\n",
      " [[     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  [     0      0      0 ...      0      0      0]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  2471   2061  26181 ...      1      1      1]\n",
      "  [241627    947   1409 ... 226063      5  51032]]]\n",
      "pred_input_title: (19, 1, 30), values: [[[ 16148   4475      6  57350    171   2265    115  44287     72 121739\n",
      "       33    100 158167 106265 122168    315  80459    124 113885     13\n",
      "    21861  16148  52238   5084  22184     12  40606   8349     72  80459]]\n",
      "\n",
      " [[   357  71596  40080     56 109563    112     17  10740  14027     17\n",
      "     5262  65578   3986      6 152621   5073  53631     17  53185      5\n",
      "   107689     33     72  11736    100     22 193014   9343  26391    182]]\n",
      "\n",
      " [[ 27303   2460  78821  20928     67   2563   3564     22  19879  26470\n",
      "       17  72392     60  25779   4343  24674    261  19985    165  17052\n",
      "       13 136348     20    453    122     72    186  46686    109  27535]]\n",
      "\n",
      " [[  1650      9  24658  79570  36621    261  57947      9 137644      7\n",
      "    10901   1977  18413   6850 175471     18 156344     17 112874 114541\n",
      "    42990   1236 114541      7      9  27097      7     12 135240   6850]]\n",
      "\n",
      " [[  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "      182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "     1111    122     72  32376     82  54392   6799    495   3728  10750]]\n",
      "\n",
      " [[ 89253   3347   3137     72  94889     18  94396  22370  16148  99675\n",
      "        9  32041   1579     12  22193     56   4475  75281     13  34592\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 12944 219833     72     17      6 108396     60   1134  21537   6275\n",
      "      100     99   5535   5222  62182    588   3438  50281   6977 139917\n",
      "       86      4   5101  35988     72   6244   3473    139 182291      4]]\n",
      "\n",
      " [[  2132  24251  52821    947      7     19 145739    588 113852   7400\n",
      "    99442  21139  42182   5262 203377     56     17   9963     91   3719\n",
      "        9 113877     33  92265  13527   1840     72  21139  42182 203377]]\n",
      "\n",
      " [[  3868   8749    261 215245      7  68211  88607     42 130207 211857\n",
      "       22    261   6634  17042    761     56      5    579   1063   8337\n",
      "      100      7  14068  26343 130207 211857  88607     42  74104     17]]\n",
      "\n",
      " [[  4804 221502  93487      7 154982     56 132199     42    604     82\n",
      "     1528      4   2328    115    128   5015 202787    203    308    372\n",
      "      233    139    209  14251    109    209  93016    209  14251    109]]\n",
      "\n",
      " [[149746     72  31019   5535  34881   1872    139     22  80330  14014\n",
      "       75 125652  50094     17  91781   2646      7  16749   9458     12\n",
      "    54231     71  11946    109  81198      1      1      1      1      1]]\n",
      "\n",
      " [[ 99442  21139   1681  45667    820      4     99    149    182  13069\n",
      "    21113     99   1712  25257     17    168  80145   2936  10656     56\n",
      "     1872    171   3082   3438    987     12     20   1310   3278  13457]]\n",
      "\n",
      " [[130189     13   4831    182 161950  70237   4932      7   3787  55028\n",
      "       13  91177     56    171     99   3438  40272   2101      6  54085\n",
      "    44466     56    302     18  51216      9   9802  38407     56   2101]]\n",
      "\n",
      " [[ 48267     60   8796  48820      7   1179     72    109  25429      4\n",
      "     2328     47  79668     72  52478   3198   5371  74227   4371  52478\n",
      "      109   7155     12 174893   4271   8828     39     18      1      1]]\n",
      "\n",
      " [[  1413   1192      7    286   2199     86  34377  54981  14880   1679\n",
      "     9384      4    453    109    845  30319  16326  43957    285   1926\n",
      "   159004     18    124  51339     56    242    919  11999  69358     25]]\n",
      "\n",
      " [[130189     13  73213     72    149    315    645   2358   9674    261\n",
      "     1261    761   5245 134550      4    124  21962   1379 107179   3815\n",
      "        7  81100     19   3430   1098    820  32407     12   2668  11732]]\n",
      "\n",
      " [[211857 162288      4     99  87085 168423     56   1063  11504    770\n",
      "     8349     18    261 204253  25389    669   2679  31019      5 117655\n",
      "      177    720    100  74161   1326      7  14068  26343     17 160197]]\n",
      "\n",
      " [[ 50110  50094     42 139747 186044     33  65528     13  27303   1015\n",
      "       72  20714   7895   4164 132508    124 170931   5918  10266     60\n",
      "       22  96541    139    324   7655    334   1428  80460     56   1872]]\n",
      "\n",
      " [[124895  10300     11 199719      7 130970    285     99    308    372\n",
      "     1053  14251      5    579  63926     13   2563    671   9427    124\n",
      "     1226     82   9790   1229   7112      4     60   3564     85  13440]]]\n",
      "batch_y: torch.Size([19, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [3.6558e+04, 9.0000e+00, 6.0000e+01,  ..., 1.2081e+05, 1.8030e+03,\n",
      "         1.0630e+03],\n",
      "        [2.4710e+03, 2.0610e+03, 2.6181e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [2.4163e+05, 9.4700e+02, 1.4090e+03,  ..., 2.2606e+05, 5.0000e+00,\n",
      "         5.1032e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (9, 50, 30), values: [[[ 99442  21139   1681 ...   3749  19040     18]\n",
      "  [  8301    332   7830 ...     15 207612    247]\n",
      "  [  1575   2789      9 ...  45555      4   1134]\n",
      "  ...\n",
      "  [123949   1063    545 ...  16673   1357    242]\n",
      "  [   893  22666    261 ...    271  20807      6]\n",
      "  [ 99442  21139   1681 ...  41830     12  99442]]\n",
      "\n",
      " [[ 99442  21139   1681 ...   3749  19040     18]\n",
      "  [  8301    332   7830 ...     15 207612    247]\n",
      "  [  1575   2789      9 ...  45555      4   1134]\n",
      "  ...\n",
      "  [123949   1063    545 ...  16673   1357    242]\n",
      "  [   893  22666    261 ...    271  20807      6]\n",
      "  [ 99442  21139   1681 ...  41830     12  99442]]\n",
      "\n",
      " [[ 99442  21139   1681 ...   3749  19040     18]\n",
      "  [  8301    332   7830 ...     15 207612    247]\n",
      "  [  1575   2789      9 ...  45555      4   1134]\n",
      "  ...\n",
      "  [123949   1063    545 ...  16673   1357    242]\n",
      "  [   893  22666    261 ...    271  20807      6]\n",
      "  [ 99442  21139   1681 ...  41830     12  99442]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 99442  21139   1681 ...   3749  19040     18]\n",
      "  [  8301    332   7830 ...     15 207612    247]\n",
      "  [  1575   2789      9 ...  45555      4   1134]\n",
      "  ...\n",
      "  [123949   1063    545 ...  16673   1357    242]\n",
      "  [   893  22666    261 ...    271  20807      6]\n",
      "  [ 99442  21139   1681 ...  41830     12  99442]]\n",
      "\n",
      " [[ 99442  21139   1681 ...   3749  19040     18]\n",
      "  [  8301    332   7830 ...     15 207612    247]\n",
      "  [  1575   2789      9 ...  45555      4   1134]\n",
      "  ...\n",
      "  [123949   1063    545 ...  16673   1357    242]\n",
      "  [   893  22666    261 ...    271  20807      6]\n",
      "  [ 99442  21139   1681 ...  41830     12  99442]]\n",
      "\n",
      " [[ 99442  21139   1681 ...   3749  19040     18]\n",
      "  [  8301    332   7830 ...     15 207612    247]\n",
      "  [  1575   2789      9 ...  45555      4   1134]\n",
      "  ...\n",
      "  [123949   1063    545 ...  16673   1357    242]\n",
      "  [   893  22666    261 ...    271  20807      6]\n",
      "  [ 99442  21139   1681 ...  41830     12  99442]]]\n",
      "pred_input_title: (9, 1, 30), values: [[[  7244      7   8749  40272     42      4  19893 126507      4    182\n",
      "     2394    429      9  35414    126    747  11476 141918     56    261\n",
      "    28235     25      7 105367  23134    242 113469   1409     25  19893]]\n",
      "\n",
      " [[  2888  24792  66373     60  44192     17  30038    126    109  86373\n",
      "    15492     22  34608  48951  14134     82  18413      5   2548      6\n",
      "   123645      7    100 141120     19      4   2328     22  22958  48951]]\n",
      "\n",
      " [[ 23888      7 195430  99579     17   3787 137331     56    171  88701\n",
      "        9   4594 124895  16690     71     17   3209     12   1429  92846\n",
      "     1926      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[   884   1342  44924     72  18597  74138   2060    139  11476  38436\n",
      "        9  33863  34609   4343      6  48045     12   7325    124  19251\n",
      "        9  48951      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[167637  16787    563    841      9 123373  89389    159   2810  14949\n",
      "     1015  45667    820    315 227758    171      4     99    777    545\n",
      "   148770    139 102572   8676  24116  30719      7     75  70154    112]]\n",
      "\n",
      " [[130189     13   7042 102831 150587  17978   9060  98705     17   7370\n",
      "      157  27616    109   8749    261      6  59631   4588    261     75\n",
      "   125652  53559  15985   9060  98705   7400 150587  10266    124  23092]]\n",
      "\n",
      " [[   717   1011     18      9  16200    261   1803     67      4     99\n",
      "    59657   3271  28117    382  17376      5  16148 178745     72 105791\n",
      "    64736     17 154759      6  23920  24347   1679      4     60  32630]]\n",
      "\n",
      " [[ 35583  14949   1015     72  43040  36140  36140    261  19985      5\n",
      "     2548   3491   8017  18891   1379     22  93487      4   3491  52478\n",
      "     3198    109  17986    126     60    182    315  36903  67018   1264]]\n",
      "\n",
      " [[   262  16471  63841    982    720 173756   1953   3787  41036   5256\n",
      "     1803     17   3974   9578   2701  24700  42648     17  41036   1363\n",
      "       12   1429 173756  14457     33      1      1      1      1      1]]]\n",
      "batch_y: torch.Size([9, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "Inputs\n",
      "tensor([[9.9442e+04, 2.1139e+04, 1.6810e+03,  ..., 3.7490e+03, 1.9040e+04,\n",
      "         1.8000e+01],\n",
      "        [8.3010e+03, 3.3200e+02, 7.8300e+03,  ..., 1.5000e+01, 2.0761e+05,\n",
      "         2.4700e+02],\n",
      "        [1.5750e+03, 2.7890e+03, 9.0000e+00,  ..., 4.5555e+04, 4.0000e+00,\n",
      "         1.1340e+03],\n",
      "        ...,\n",
      "        [1.2395e+05, 1.0630e+03, 5.4500e+02,  ..., 1.6673e+04, 1.3570e+03,\n",
      "         2.4200e+02],\n",
      "        [8.9300e+02, 2.2666e+04, 2.6100e+02,  ..., 2.7100e+02, 2.0807e+04,\n",
      "         6.0000e+00],\n",
      "        [9.9442e+04, 2.1139e+04, 1.6810e+03,  ..., 4.1830e+04, 1.2000e+01,\n",
      "         9.9442e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (27, 50, 30), values: [[[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [ 1775  8629 35121 ...   109    82  2536]\n",
      "  [ 1326  1205   107 ...   425     9 76294]\n",
      "  [ 1326  1205   107 ...   425     9 76294]]\n",
      "\n",
      " [[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [ 1775  8629 35121 ...   109    82  2536]\n",
      "  [ 1326  1205   107 ...   425     9 76294]\n",
      "  [ 1326  1205   107 ...   425     9 76294]]\n",
      "\n",
      " [[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [ 1775  8629 35121 ...   109    82  2536]\n",
      "  [ 1326  1205   107 ...   425     9 76294]\n",
      "  [ 1326  1205   107 ...   425     9 76294]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [ 1775  8629 35121 ...   109    82  2536]\n",
      "  [ 1326  1205   107 ...   425     9 76294]\n",
      "  [ 1326  1205   107 ...   425     9 76294]]\n",
      "\n",
      " [[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [ 1775  8629 35121 ...   109    82  2536]\n",
      "  [ 1326  1205   107 ...   425     9 76294]\n",
      "  [ 1326  1205   107 ...   425     9 76294]]\n",
      "\n",
      " [[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [ 1775  8629 35121 ...   109    82  2536]\n",
      "  [ 1326  1205   107 ...   425     9 76294]\n",
      "  [ 1326  1205   107 ...   425     9 76294]]]\n",
      "pred_input_title: (27, 1, 30), values: [[[   159    170  14936    555      6 126107     12 103978  52821  16861\n",
      "    30673   1151   6157 126436      1      1      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 54114    301   1205 177986      7  15866     56  13613      4     99\n",
      "   117287   3041   4626     72     82  22344    261 222717  45095      7\n",
      "     4070   3679  16787 189891  54114    301    126     12 166629  67199]]\n",
      "\n",
      " [[   159   1491  87210  26222     86  51580     13  37226     76    601\n",
      "        5  53983  41347   1015  19246   1314   2160  16723    100   2955\n",
      "     3986  38702    139   1144   2432    588   2902    112  18837   6892]]\n",
      "\n",
      " [[   262  44339   4572  21991    203   1712 175351    100      4   5916\n",
      "   132258      9  17103 114306 110224  70867   1823   1144      4   1953\n",
      "      777 101441    112     17     22  71274 141120 132258      9  50142]]\n",
      "\n",
      " [[ 13975  13806    242    568     72  64366  52454     25      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 17570 140429    203  64475  63934  14071  28117     17   2663      9\n",
      "      118    645      8 158609    824   5614      9 113639  27802 161927\n",
      "     6999     18    261    391  10101    391  10101     12  54132   7400]]\n",
      "\n",
      " [[ 11584   3911   1974  13594    502  74877     19    139     99  42648\n",
      "       13    128   1379   5077  27970  23046  20106  10674    109    845\n",
      "    30319  16326  43957  31019  46466  11214     76  88894    720     56]]\n",
      "\n",
      " [[  1575  16867 130178 129657     18   5071     60  15889   5071     17\n",
      "    54114    301    126  14384 184151    545    645    219   1205  28337\n",
      "        4  20363  96424     56   2331  40322     33   1379  76003   8831]]\n",
      "\n",
      " [[  1575  95715    807     56 122150  58372    182    545 126198    233\n",
      "      109   6106     99   9096    128     17    242  89272     71    128\n",
      "      807     25    335  11150  58026    588    261   1910  15573   1731]]\n",
      "\n",
      " [[ 51032    372  33252     72    171  30542  69871    100  57263   2365\n",
      "    72790      4    124  40130  14457   2752    128   9018   3038  23359\n",
      "      109  72413    170  74494   8395   2777   1746    315     12   2548]]\n",
      "\n",
      " [[124895  73359   2432 114224  11783   1144    128   1100      4     98\n",
      "     2628     60 121950  73895     56      4    122  95815    139    128\n",
      "       99  18381  44296  12441  33215  12444     17    185     13      5]]\n",
      "\n",
      " [[147756    182 160770   1144      4    453    545    139    149   9866\n",
      "        4     60  23182   5071    645     71  81447    112   3445  36377\n",
      "       17    845  30319 235262    128    100  24705   1974 151433      1]]\n",
      "\n",
      " [[ 29217   1205  66663  12439  25660  77170    348   5844   5077     22\n",
      "    15161    384  11697     67      9   7260  51169  16401   4223   1015\n",
      "     1953 157715     25 110449   3668  50825 157715      9  50142    444]]\n",
      "\n",
      " [[111347 140852    933 200178   4317 154982  62859  31178   4539    645\n",
      "   138550      7  12801  87696      4   2328   1391    162     60  57501\n",
      "    79949   1015   9038     22 177625     18  20459  80259   1746  14000]]\n",
      "\n",
      " [[ 22805     20     22    390     17  53698   1015      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[  4859      9  78147  82217    241  56262   2907  14631    600    820\n",
      "     3082  17474    109  87293   7260      7      4    453    122     72\n",
      "       22   6157   8752    261 156052     19  50715    987   1226  87293]]\n",
      "\n",
      " [[   353  12216    139  74161  51580     13 123949    100    177   3405\n",
      "     3132 143027     42     60  18025  34759   2811  82739      7 163662\n",
      "        4   8667   4371   8667   4371  60145      7    261   6281 126957]]\n",
      "\n",
      " [[  1310     72     22    600   1346    109  27535     17    149  47508\n",
      "    11062  82772      7      9  49545      5   1575    954  51080   1346\n",
      "       17  37505     19      4  62624  82772      7     12  24116     13]]\n",
      "\n",
      " [[  1775  74224  56726     18  76423  22913   1063   1872 101515      4\n",
      "    48327  32226  57241    122     72  77304    139   6799 109311   1466\n",
      "        5  33539    203     22  19879  16471  36656     40   6474    139]]\n",
      "\n",
      " [[ 19893    478    241  92308     72  18413     18    261  20273    171\n",
      "      149  95649      4   1926   3278     17      5   1429  11380  14936\n",
      "      820   1926   1872    109    745      4    122 176361  15786     56]]\n",
      "\n",
      " [[ 89389  61370    141  26463      4    122     72    128     17  25674\n",
      "    28398      7  65609  45462      4    186   3964  88755      4     99\n",
      "    19732    126    182  21113   1226     99    139  71898  13732  25674]]\n",
      "\n",
      " [[ 21415     13  27472 234719   1144    128  32407     67 116095   1238\n",
      "     4227      4   2683      8   8796     56   1144    109     99   1712\n",
      "    32089   6865     67      4  13613 103339   1076     92     60 139338]]\n",
      "\n",
      " [[ 99442  21139   1681   9038  22338   6259   3667  56522    233      4\n",
      "      453    149 111442     22  27194  32209 229694  48304     13 144380\n",
      "       42     12  99442    332     56    139   2062      1      1      1]]\n",
      "\n",
      " [[ 14355   1505  28398     13 127232   1144    645    880  45314 169439\n",
      "       17  85190   6389   3666   5533  44013  25538  50142     42     12\n",
      "   202387     18     99     40      1      1      1      1      1      1]]\n",
      "\n",
      " [[  1843    555     60  85283    147  29178    182  36903      8  25531\n",
      "    42461    109  47621     17  77199     19      4    124    315 122403\n",
      "    14014    139  58941   1015   1843    555     60  85283    147  29178]]\n",
      "\n",
      " [[ 14934  24674    261  70754   5481     33   1063   1712 145157    100\n",
      "    27431     17  92549    261   8514 110930      9    161    232     12\n",
      "    25674  28398  15925  11783   4475  33640     17  31066      1      1]]\n",
      "\n",
      " [[ 50110 203653     13  20627    142  40772     90   5371    128  56852\n",
      "      265  26652  64954  48218      5  52445    592  93006    233 142404\n",
      "      128  26508    112  38016     56  52445    592   8858 203653     13]]]\n",
      "batch_y: torch.Size([27, 1]), values: tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.7750e+03, 8.6290e+03, 3.5121e+04,  ..., 1.0900e+02, 8.2000e+01,\n",
      "         2.5360e+03],\n",
      "        [1.3260e+03, 1.2050e+03, 1.0700e+02,  ..., 4.2500e+02, 9.0000e+00,\n",
      "         7.6294e+04],\n",
      "        [1.3260e+03, 1.2050e+03, 1.0700e+02,  ..., 4.2500e+02, 9.0000e+00,\n",
      "         7.6294e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:  40%|████      | 10/25 [00:00<00:00, 24.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (12, 50, 30), values: [[[   357  36799     56 ...   1144   3263    100]\n",
      "  [  2371  14299     72 ...     18  20704    820]\n",
      "  [   357  36799     56 ...   1144   3263    100]\n",
      "  ...\n",
      "  [174090  15161  20363 ...      1      1      1]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[   357  36799     56 ...   1144   3263    100]\n",
      "  [  2371  14299     72 ...     18  20704    820]\n",
      "  [   357  36799     56 ...   1144   3263    100]\n",
      "  ...\n",
      "  [174090  15161  20363 ...      1      1      1]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[   357  36799     56 ...   1144   3263    100]\n",
      "  [  2371  14299     72 ...     18  20704    820]\n",
      "  [   357  36799     56 ...   1144   3263    100]\n",
      "  ...\n",
      "  [174090  15161  20363 ...      1      1      1]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   357  36799     56 ...   1144   3263    100]\n",
      "  [  2371  14299     72 ...     18  20704    820]\n",
      "  [   357  36799     56 ...   1144   3263    100]\n",
      "  ...\n",
      "  [174090  15161  20363 ...      1      1      1]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[   357  36799     56 ...   1144   3263    100]\n",
      "  [  2371  14299     72 ...     18  20704    820]\n",
      "  [   357  36799     56 ...   1144   3263    100]\n",
      "  ...\n",
      "  [174090  15161  20363 ...      1      1      1]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[   357  36799     56 ...   1144   3263    100]\n",
      "  [  2371  14299     72 ...     18  20704    820]\n",
      "  [   357  36799     56 ...   1144   3263    100]\n",
      "  ...\n",
      "  [174090  15161  20363 ...      1      1      1]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [   345    555 105920 ...     12  82739  43144]]]\n",
      "pred_input_title: (12, 1, 30), values: [[[  3868  11113    319  53693   4498 141632    112     22   8651      9\n",
      "    48951  14134     82 230068    133   5465  41993  47196    348    107\n",
      "     4626    261 230068    133     12    527    783    139   2811     66]]\n",
      "\n",
      " [[ 16148   5756  44339   3661      4    242   3957  10348 180423     25\n",
      "        4     72    168   4067   4063  75019   4196   1346 206603   5813\n",
      "       19   2311  45501  78244  80459    128     99  28778   1346 209833]]\n",
      "\n",
      " [[  5815     60 188381    182   1379 217429     22  77199    171     99\n",
      "    47556 134690     19    261  27179    109  31206 103431  16148   7370\n",
      "        6 115061      9   5447  13158   6889     12    239    814    600]]\n",
      "\n",
      " [[122571      9     60  23146 100332      7  48267  48024  55028     86\n",
      "      139     82  19576  39696   2281    272    265   1515      4    124\n",
      "        8    182    186   7112  26322      4    233  14907     56      8]]\n",
      "\n",
      " [[   503   8812   3196     62  79035  49043    109 156052     42   1953\n",
      "   182291     17 174090      1      1      1      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 24289     33    109    168  96634  46941     13    182  10296   5423\n",
      "    13259  13069    495  30896      4    124    168     72    315      5\n",
      "      579    203    807  72083  24911     13  10765     13    261      5]]\n",
      "\n",
      " [[130189     13 121739    100  13527  11388   3362  10544    669 195642\n",
      "    20045    872 196288     22  78552   1428   2811  34511  22381    109\n",
      "    64262    128  34627  42853    776     60     22 115203    266  12563]]\n",
      "\n",
      " [[   579  93006   1774  96788     60   7619      4   4925    115   1063\n",
      "        8    645    420 138948   3112  14251    139  36709   7391   4642\n",
      "      100    747      4    453    149    203  93473   1144  16167      5]]\n",
      "\n",
      " [[  4265   4172      9   2146  50281  72083    588 151927    515    107\n",
      "    67199  57263  27512   2208     18      4    122  60804     42    139\n",
      "   214862   1953      6 222112  50825  23604   1600     12 110679  74224]]\n",
      "\n",
      " [[   579 173756  44630    545     17   2355  36650      4     99    122\n",
      "      315     72   9427 118819    100  98628 237844     42    109  62321\n",
      "     2676     12  21689   3196   6534     56    645  96642   6683      1]]\n",
      "\n",
      " [[  5345   2356 138059   1063     17  13645  39289 121701    880 168423\n",
      "       56    171     99  11504    173   4249  18597  12403  80928  25066\n",
      "   102831   1063    173    236   6634 168423     56      1      1      1]]\n",
      "\n",
      " [[   579     72  28591     18     99   5535   5222     17   4265   4172\n",
      "       33     20 151927    515    107  33783   1134 153112  10296  19879\n",
      "      372  40080     17     99    233 132130     13    149  18561  46893]]]\n",
      "batch_y: torch.Size([12, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[3.5700e+02, 3.6799e+04, 5.6000e+01,  ..., 1.1440e+03, 3.2630e+03,\n",
      "         1.0000e+02],\n",
      "        [2.3710e+03, 1.4299e+04, 7.2000e+01,  ..., 1.8000e+01, 2.0704e+04,\n",
      "         8.2000e+02],\n",
      "        [3.5700e+02, 3.6799e+04, 5.6000e+01,  ..., 1.1440e+03, 3.2630e+03,\n",
      "         1.0000e+02],\n",
      "        ...,\n",
      "        [1.7409e+05, 1.5161e+04, 2.0363e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [8.3010e+03, 3.3200e+02, 1.3662e+05,  ..., 1.0040e+03, 1.4900e+02,\n",
      "         4.4075e+04],\n",
      "        [3.4500e+02, 5.5500e+02, 1.0592e+05,  ..., 1.2000e+01, 8.2739e+04,\n",
      "         4.3144e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (6, 50, 30), values: [[[    20  68912     56 ...    170     12     20]\n",
      "  [ 47131      7 226063 ... 204447     67   2500]\n",
      "  [  4804  14963  45661 ... 156301     12  36939]\n",
      "  ...\n",
      "  [  1310   7400  38552 ...      1      1      1]\n",
      "  [ 73165  14098      7 ...      1      1      1]\n",
      "  [ 24856   3786    408 ...     12   3786    408]]\n",
      "\n",
      " [[    20  68912     56 ...    170     12     20]\n",
      "  [ 47131      7 226063 ... 204447     67   2500]\n",
      "  [  4804  14963  45661 ... 156301     12  36939]\n",
      "  ...\n",
      "  [  1310   7400  38552 ...      1      1      1]\n",
      "  [ 73165  14098      7 ...      1      1      1]\n",
      "  [ 24856   3786    408 ...     12   3786    408]]\n",
      "\n",
      " [[    20  68912     56 ...    170     12     20]\n",
      "  [ 47131      7 226063 ... 204447     67   2500]\n",
      "  [  4804  14963  45661 ... 156301     12  36939]\n",
      "  ...\n",
      "  [  1310   7400  38552 ...      1      1      1]\n",
      "  [ 73165  14098      7 ...      1      1      1]\n",
      "  [ 24856   3786    408 ...     12   3786    408]]\n",
      "\n",
      " [[    20  68912     56 ...    170     12     20]\n",
      "  [ 47131      7 226063 ... 204447     67   2500]\n",
      "  [  4804  14963  45661 ... 156301     12  36939]\n",
      "  ...\n",
      "  [  1310   7400  38552 ...      1      1      1]\n",
      "  [ 73165  14098      7 ...      1      1      1]\n",
      "  [ 24856   3786    408 ...     12   3786    408]]\n",
      "\n",
      " [[    20  68912     56 ...    170     12     20]\n",
      "  [ 47131      7 226063 ... 204447     67   2500]\n",
      "  [  4804  14963  45661 ... 156301     12  36939]\n",
      "  ...\n",
      "  [  1310   7400  38552 ...      1      1      1]\n",
      "  [ 73165  14098      7 ...      1      1      1]\n",
      "  [ 24856   3786    408 ...     12   3786    408]]\n",
      "\n",
      " [[    20  68912     56 ...    170     12     20]\n",
      "  [ 47131      7 226063 ... 204447     67   2500]\n",
      "  [  4804  14963  45661 ... 156301     12  36939]\n",
      "  ...\n",
      "  [  1310   7400  38552 ...      1      1      1]\n",
      "  [ 73165  14098      7 ...      1      1      1]\n",
      "  [ 24856   3786    408 ...     12   3786    408]]]\n",
      "pred_input_title: (6, 1, 30), values: [[[ 14355   1505  28398     13     72   3082  66609    217    139   1661\n",
      "     5262 107677      9   2146 142404     17  92265  13527      5   1575\n",
      "    16471      6  50142 114805    168      6 225200  78475     13  67681]]\n",
      "\n",
      " [[ 10935 102057      9  37210     18 137550  45355     56   1872    109\n",
      "    52565    272  28115      4   7400    149    128    168 116850   1601\n",
      "    79466      7    735  71216 184828    109 126191   1390      5   7868]]\n",
      "\n",
      " [[ 10255    334  50118     14     60  84265     19  51652     42    139\n",
      "   155888      4   2328      8  32630   1134  93195  19115  63341    588\n",
      "    19952    139  16026   5828    261  10574     17   1368  25066   3055]]\n",
      "\n",
      " [[   357    600  33908     13    261  82685 118357 148497  21713  43932\n",
      "   178239    128 127123 146491    109      8  11129  37749  23888  13388\n",
      "      261  37254     13  62182   1728    233  44900      1      1      1]]\n",
      "\n",
      " [[204049    107   3033      9 242230     13  58923    436      5    182\n",
      "     2918   5111     19     17    211    555      4    453 170931     56\n",
      "      545     99   5015   3438    261    168   8749      5  10453     72]]\n",
      "\n",
      " [[   357   7621      9  48951  14134   3491  74161    142  78131      4\n",
      "     1953     99    765      6  68413     18   2811     47  17666    177\n",
      "     3405   1515    128     22  17177   1434  26391  46605     71 106543]]]\n",
      "batch_y: torch.Size([6, 1]), values: tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[2.0000e+01, 6.8912e+04, 5.6000e+01,  ..., 1.7000e+02, 1.2000e+01,\n",
      "         2.0000e+01],\n",
      "        [4.7131e+04, 7.0000e+00, 2.2606e+05,  ..., 2.0445e+05, 6.7000e+01,\n",
      "         2.5000e+03],\n",
      "        [4.8040e+03, 1.4963e+04, 4.5661e+04,  ..., 1.5630e+05, 1.2000e+01,\n",
      "         3.6939e+04],\n",
      "        ...,\n",
      "        [1.3100e+03, 7.4000e+03, 3.8552e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [7.3165e+04, 1.4098e+04, 7.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [2.4856e+04, 3.7860e+03, 4.0800e+02,  ..., 1.2000e+01, 3.7860e+03,\n",
      "         4.0800e+02]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[1.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (5, 50, 30), values: [[[   717    261  17042 ...  16852   1144 160612]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  [171342   9638  19006 ...      1      1      1]\n",
      "  ...\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[   717    261  17042 ...  16852   1144 160612]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  [171342   9638  19006 ...      1      1      1]\n",
      "  ...\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[   717    261  17042 ...  16852   1144 160612]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  [171342   9638  19006 ...      1      1      1]\n",
      "  ...\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[   717    261  17042 ...  16852   1144 160612]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  [171342   9638  19006 ...      1      1      1]\n",
      "  ...\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[   717    261  17042 ...  16852   1144 160612]\n",
      "  [  1310     72     75 ...     12 123949    348]\n",
      "  [171342   9638  19006 ...      1      1      1]\n",
      "  ...\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [ 50715     18  14936 ...      1      1      1]]]\n",
      "pred_input_title: (5, 1, 30), values: [[[  6565   2069  10760   1063  88607      8    534 135344  57896   1277\n",
      "        9  94355     56      5 142000   7400     47  46394      7 199304\n",
      "       56    142 139550  10266   6565   2069  10760  88607     42   2536]]\n",
      "\n",
      " [[ 14949  27303   1015  28338   4196    233    128     22  37773  30793\n",
      "        4     48  30749  14098  26508    112   1144     22  47621     17\n",
      "     2663  11565     60  49838  19175      9   1743  55329     17  44339]]\n",
      "\n",
      " [[ 11246    334   1409     53   2319    519   8848     73  81134     17\n",
      "       82   5178  33683      4     99 142092      9  40042    182 159548\n",
      "     2563   3564  74686   7334     17  59657    171 174857    528   6850]]\n",
      "\n",
      " [[   357   1346  49024    261    261  41575     13  27571    588   1575\n",
      "    48033   3847  29897      6 132546   4067    100   1346  29897   8551\n",
      "       60  13732  12348     56  29630   1346      6 132546   3082   4067]]\n",
      "\n",
      " [[   579 111442  79429 180575     33    261     82   5178   9879  60404\n",
      "        4     99   7674  18891   1823   1872    261  72392    128     82\n",
      "     1379  68413 116182    126     72 194517  10266     12    884   3986]]]\n",
      "batch_y: torch.Size([5, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[7.1700e+02, 2.6100e+02, 1.7042e+04,  ..., 1.6852e+04, 1.1440e+03,\n",
      "         1.6061e+05],\n",
      "        [1.3100e+03, 7.2000e+01, 7.5000e+01,  ..., 1.2000e+01, 1.2395e+05,\n",
      "         3.4800e+02],\n",
      "        [1.7134e+05, 9.6380e+03, 1.9006e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [5.0715e+04, 1.8000e+01, 1.4936e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [3.5700e+02, 3.0820e+03, 1.3036e+04,  ..., 1.2800e+02, 2.1861e+04,\n",
      "         3.9046e+04],\n",
      "        [5.0715e+04, 1.8000e+01, 1.4936e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [1.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (14, 50, 30), values: [[[  1910      9  33378 ...     33   3271  82729]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  ...\n",
      "  [  1004   2069  60485 ...     17      8  40118]\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [  1575  16471  15918 ...   1134 100070      7]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  ...\n",
      "  [  1004   2069  60485 ...     17      8  40118]\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [  1575  16471  15918 ...   1134 100070      7]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  ...\n",
      "  [  1004   2069  60485 ...     17      8  40118]\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [  1575  16471  15918 ...   1134 100070      7]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  ...\n",
      "  [  1004   2069  60485 ...     17      8  40118]\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [  1575  16471  15918 ...   1134 100070      7]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  ...\n",
      "  [  1004   2069  60485 ...     17      8  40118]\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [  1575  16471  15918 ...   1134 100070      7]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  [111347 140852    933 ...   1305     33    124]\n",
      "  ...\n",
      "  [  1004   2069  60485 ...     17      8  40118]\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [  1575  16471  15918 ...   1134 100070      7]]]\n",
      "pred_input_title: (14, 1, 30), values: [[[ 14355   1505  28398     13     72  21351    261     99  33617      4\n",
      "       99   2902  24273   7465  14580      7    182      6 157597   1144\n",
      "    14355   1505  28398     13  16673  11783    109    681     92      9]]\n",
      "\n",
      " [[  1575  12532  82217 222717 186592      7   6799    315    100      6\n",
      "   164108    261  55301  14486  22201  99602  11214     13     12   5879\n",
      "    45667    820    109  26232 197681     99    765    186  78131   8816]]\n",
      "\n",
      " [[  1310   1823     22  73483   1042  11389    261   5962  79489    242\n",
      "     3957  12133     25      5   9593     14  60089   5550     71   1134\n",
      "    17250 136873    124  21861      4    124  94069     53   8022  78453]]\n",
      "\n",
      " [[   357   4442      9  48951  81493  14134     72   1144   3263    100\n",
      "   105282  70534  49392      4   1953     99    777  68315   2752    139\n",
      "       22  24830  14134  10729  13384  11380  39607   4207    109  32216]]\n",
      "\n",
      " [[ 18118    449   1272      9  47405     86    182 126198  35992   1151\n",
      "       22  40213   1067  22338      4   2683      8    109  57513  74224\n",
      "       42    100 141632  11971     17   4265   4172     33 105566    112]]\n",
      "\n",
      " [[ 99442  21139   1681  26508    112   1144  53396  14014  64367    674\n",
      "     1226  92265  13527      4    453  16471    982  25779    765  20746\n",
      "       17  15198   5262     60  19787 100768   1310  40130     82   8089]]\n",
      "\n",
      " [[ 36851      9   4613   3675     85 117215     13   9486      9    397\n",
      "      302    588    602   6407     18 154157     13  22845    128   9342\n",
      "      109      6 109361  15534     92      5 164017     72    122   2563]]\n",
      "\n",
      " [[ 42473   6468  20106   9038    168 152836     13  14134  23286   1144\n",
      "     1226   3916    261    168  34108  78147     60    604  38669  45299\n",
      "     3263   1661   1379   9617  34108  48951  36656   1959   3405     19]]\n",
      "\n",
      " [[ 99442  21139   1681  83499 143352    127 226719     60     72  14014\n",
      "      139  37304 107677     17  85190   6389   3666    786   1873    362\n",
      "      139     99  97443      4  99442     38      1      1      1      1]]\n",
      "\n",
      " [[107578      6 132546   3974  19175   1953 182291    645   8321     17\n",
      "       22 183293  22688      4    122  25779    261 126550      7     17\n",
      "   106393      7  10237      7   1716   2971     42   6620 107578      6]]\n",
      "\n",
      " [[ 25941     42 168039  13177  68991     72  61100  33832  16719   1953\n",
      "    57219  54569     60 183293     13    233  55329     42    261  74643\n",
      "     8967  96321    242 156673  82055     33     25 122810  23134   1379]]\n",
      "\n",
      " [[  2646      7 189158  35326     56   1144    171    168  83383      9\n",
      "   236322     13  94993  12018  17038   1004  51707   1391   5829      4\n",
      "      122  69538    100      7  24705     18   9683  87998   1379     22]]\n",
      "\n",
      " [[ 20261    306   8057  35485  78905     14   3316  21070     15    294\n",
      "       16   6799    182  79329    611 129238     60  95829   4475    366\n",
      "    21992   1067 163640      4    495    203    807  72083 131556   2641]]\n",
      "\n",
      " [[   527    973    583   7465  14580      7   3271  29935  39711  14355\n",
      "     1505  28398     13     17    787 107677    261  92265  13527      4\n",
      "      453  63606 114306    182   9325  53396  46466    128  45833      4]]]\n",
      "batch_y: torch.Size([14, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[1.9100e+03, 9.0000e+00, 3.3378e+04,  ..., 3.3000e+01, 3.2710e+03,\n",
      "         8.2729e+04],\n",
      "        [1.1135e+05, 1.4085e+05, 9.3300e+02,  ..., 1.3050e+03, 3.3000e+01,\n",
      "         1.2400e+02],\n",
      "        [1.1135e+05, 1.4085e+05, 9.3300e+02,  ..., 1.3050e+03, 3.3000e+01,\n",
      "         1.2400e+02],\n",
      "        ...,\n",
      "        [1.0040e+03, 2.0690e+03, 6.0485e+04,  ..., 1.7000e+01, 8.0000e+00,\n",
      "         4.0118e+04],\n",
      "        [5.0110e+04, 2.6100e+02, 8.0000e+00,  ..., 2.5000e+01, 1.9000e+01,\n",
      "         2.5000e+01],\n",
      "        [1.5750e+03, 1.6471e+04, 1.5918e+04,  ..., 1.1340e+03, 1.0007e+05,\n",
      "         7.0000e+00]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (17, 50, 30), values: [[[ 14978 181689   1015 ...  70514 133535   1314]\n",
      "  [   579   3963   1712 ...      6  65853   3667]\n",
      "  [130189     13    581 ...      1      1      1]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [ 42926   1314   2465 ... 175471   2811  55329]]\n",
      "\n",
      " [[ 14978 181689   1015 ...  70514 133535   1314]\n",
      "  [   579   3963   1712 ...      6  65853   3667]\n",
      "  [130189     13    581 ...      1      1      1]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [ 42926   1314   2465 ... 175471   2811  55329]]\n",
      "\n",
      " [[ 14978 181689   1015 ...  70514 133535   1314]\n",
      "  [   579   3963   1712 ...      6  65853   3667]\n",
      "  [130189     13    581 ...      1      1      1]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [ 42926   1314   2465 ... 175471   2811  55329]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 14978 181689   1015 ...  70514 133535   1314]\n",
      "  [   579   3963   1712 ...      6  65853   3667]\n",
      "  [130189     13    581 ...      1      1      1]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [ 42926   1314   2465 ... 175471   2811  55329]]\n",
      "\n",
      " [[ 14978 181689   1015 ...  70514 133535   1314]\n",
      "  [   579   3963   1712 ...      6  65853   3667]\n",
      "  [130189     13    581 ...      1      1      1]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [ 42926   1314   2465 ... 175471   2811  55329]]\n",
      "\n",
      " [[ 14978 181689   1015 ...  70514 133535   1314]\n",
      "  [   579   3963   1712 ...      6  65853   3667]\n",
      "  [130189     13    581 ...      1      1      1]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [ 42926   1314   2465 ... 175471   2811  55329]]]\n",
      "pred_input_title: (17, 1, 30), values: [[[  1204  92153    285    348   5844   5077    109  27535    139  41267\n",
      "       33      4    186  78965    149 116850  30395  17189  10729  13384\n",
      "     9458    261   9318  14251     24    708      9    265  73341      1]]\n",
      "\n",
      " [[ 45950  18118  22500    182 149014    545  36903  20377    171  74464\n",
      "        4    495    315    182   1926  49050  22378     17   7777  22338\n",
      "    23625  74464     12     20   1310     72    741      6 108396     17]]\n",
      "\n",
      " [[  1310   7400   4949  47979  60605   2852    261 157715      9     92\n",
      "   132546   1444  74991  18097      4     48  65134    182    261  70338\n",
      "      126    149     20  33618  19787    109   8749    261    604     42]]\n",
      "\n",
      " [[  8064   1042  18493   1953 126692  48861  27646      7    100    233\n",
      "      379  44549    139   1902      4   1953     99    777   1909     24\n",
      "      708   1746  84537  61514     17  10271  14434    133  23200   1953]]\n",
      "\n",
      " [[142711     72    100   4444    139     82    311    112   5077   1100\n",
      "     9617    128    149   7530    109   8026     33   6797   4642      4\n",
      "     4271  70338     42  39282  78147 159249     60  22911  78147 135497]]\n",
      "\n",
      " [[   503      8   2918  29382    588     22  63039     60 191239  33764\n",
      "    45701  35072  10729     71  50081      9    461    133  45701  35072\n",
      "       12   1840     72      8 129401    824  29382      1      1      1]]\n",
      "\n",
      " [[  1310  72328  66311   2319   1205     22   7594   6063   1872   5465\n",
      "      149 230837     13      4   2683 102115  76145    124    600 167942\n",
      "     4196      6   4532   5508   1205  66749  57513  30003      6 222112]]\n",
      "\n",
      " [[ 14355   1505  28398     13 127232   1144    645      4     99  99442\n",
      "    21139   1681  49217     72  19716   1226     22  12801    159   3719\n",
      "     1950  51580  76529    139  99442     12   3314  42108    645 182291]]\n",
      "\n",
      " [[ 34608  78147  70189  19513  77170 143735     56    109   6275     17\n",
      "     2714    254   3405   6581  55118  27633     60     72 149014  68331\n",
      "        7   1334   2264    124 168758  29630 121376     17  25674  40024]]\n",
      "\n",
      " [[141598  78464  80988    182  36903   1581    820      4   1953     99\n",
      "       47 143027     42 154157     13     22  48915    365   6889      4\n",
      "      233  14907     56  58483   8349 182517   8349     12    717 143027]]\n",
      "\n",
      " [[  7880   1236   4475  35365    588  30896   2265  45462    182 136222\n",
      "     2187     56      4    122  62182   1728 173363      4  16237  16568\n",
      "   112491      7 131484 136222   2187     56 146289     42   5371    128]]\n",
      "\n",
      " [[149746 234729     42      4     99    149     72  85336  25304     99\n",
      "    30338  19915     60  24674   1959   3405     19  24700  18716    261\n",
      "     2528  16148 126692   1959   3405     19  24700  29382     12    159]]\n",
      "\n",
      " [[ 35583   2992    587    434     60  14978    241    236  24911     56\n",
      "    44339   1368    109 177950  13440   1914    776 164689      4    453\n",
      "      149    182    545 126198  45375    139     75   1353  18097 124078]]\n",
      "\n",
      " [[ 33365    329  61240   7400   9226  89700   1179     17     82   5178\n",
      "    97537     18   3661  10453     72  19716     38  33365    329  61240\n",
      "     9226  89700   1444      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[  1496  34592  13285  21962  20691    495 205077     67    100  22255\n",
      "   166954     56      4     99      8  97269   1728     56     99 109563\n",
      "    14027      4   1939  81523  11783   5178  22282  29630  19327    606]]\n",
      "\n",
      " [[  2888 218193    139 111347 140852    933      6  93646    592    261\n",
      "    22378    171    168    100  61170    112    131   5518      7  46320\n",
      "       18    588  88986   6369      4    124     72  54879   3263    139]]\n",
      "\n",
      " [[165656     60  50825   7400   3115  41542  34346  64475    391  10101\n",
      "    12264    184   8748     33    807     56      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]]\n",
      "batch_y: torch.Size([17, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[1.4978e+04, 1.8169e+05, 1.0150e+03,  ..., 7.0514e+04, 1.3354e+05,\n",
      "         1.3140e+03],\n",
      "        [5.7900e+02, 3.9630e+03, 1.7120e+03,  ..., 6.0000e+00, 6.5853e+04,\n",
      "         3.6670e+03],\n",
      "        [1.3019e+05, 1.3000e+01, 5.8100e+02,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [1.5750e+03, 8.2217e+04, 6.0790e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [1.4290e+03, 4.4177e+04, 8.3950e+03,  ..., 1.1440e+03, 1.7000e+01,\n",
      "         3.4592e+04],\n",
      "        [4.2926e+04, 1.3140e+03, 2.4650e+03,  ..., 1.7547e+05, 2.8110e+03,\n",
      "         5.5329e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (5, 50, 30), values: [[[ 14934  45661    820 ...     39     18 214016]\n",
      "  [ 50110  18700     42 ...     12 238102     33]\n",
      "  [ 15786     18    149 ...  58066      9 187911]\n",
      "  ...\n",
      "  [ 52888      7  58483 ...  33276    262    294]\n",
      "  [   527 187631    350 ...     95   4249   2193]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]]\n",
      "\n",
      " [[ 14934  45661    820 ...     39     18 214016]\n",
      "  [ 50110  18700     42 ...     12 238102     33]\n",
      "  [ 15786     18    149 ...  58066      9 187911]\n",
      "  ...\n",
      "  [ 52888      7  58483 ...  33276    262    294]\n",
      "  [   527 187631    350 ...     95   4249   2193]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]]\n",
      "\n",
      " [[ 14934  45661    820 ...     39     18 214016]\n",
      "  [ 50110  18700     42 ...     12 238102     33]\n",
      "  [ 15786     18    149 ...  58066      9 187911]\n",
      "  ...\n",
      "  [ 52888      7  58483 ...  33276    262    294]\n",
      "  [   527 187631    350 ...     95   4249   2193]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]]\n",
      "\n",
      " [[ 14934  45661    820 ...     39     18 214016]\n",
      "  [ 50110  18700     42 ...     12 238102     33]\n",
      "  [ 15786     18    149 ...  58066      9 187911]\n",
      "  ...\n",
      "  [ 52888      7  58483 ...  33276    262    294]\n",
      "  [   527 187631    350 ...     95   4249   2193]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]]\n",
      "\n",
      " [[ 14934  45661    820 ...     39     18 214016]\n",
      "  [ 50110  18700     42 ...     12 238102     33]\n",
      "  [ 15786     18    149 ...  58066      9 187911]\n",
      "  ...\n",
      "  [ 52888      7  58483 ...  33276    262    294]\n",
      "  [   527 187631    350 ...     95   4249   2193]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]]]\n",
      "pred_input_title: (5, 1, 30), values: [[[   357   5252      7  63844    182  36903   2752 217429     17  24702\n",
      "    18749      4     99 143739    545  52293   1063    765  12574 137448\n",
      "     1872    261  88701    357   5252      7  63844     17 120484  46390]]\n",
      "\n",
      " [[ 65528     13  27303   1015   1134    545  52293   1712 186044    100\n",
      "    22338  65665     92 132546     86     17  73165  14098      5    579\n",
      "      233  14907     56  65134  74161  29630   2663  39046   1679  80459]]\n",
      "\n",
      " [[   503   8812   3196     12  74573   4626  21962     17  18118    449\n",
      "     1272     12  25330    285    777  63039     38      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[    87   8839   1272  78475     72   4475    472  14936     13  53726\n",
      "   220770     99    100      7   2082    112   1872    261    149  27844\n",
      "      341   3405  19738    472  14936     13  53726      7      9   1176]]\n",
      "\n",
      " [[   436   2118  41974  14437      4   8057 226063     17    357   5252\n",
      "        7  63844      4      6  78965    315     22  56852  22184    261\n",
      "    78905     14  76271  18241    653 109713   2285      6  67181  38669]]]\n",
      "batch_y: torch.Size([5, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "Inputs\n",
      "tensor([[1.4934e+04, 4.5661e+04, 8.2000e+02,  ..., 3.9000e+01, 1.8000e+01,\n",
      "         2.1402e+05],\n",
      "        [5.0110e+04, 1.8700e+04, 4.2000e+01,  ..., 1.2000e+01, 2.3810e+05,\n",
      "         3.3000e+01],\n",
      "        [1.5786e+04, 1.8000e+01, 1.4900e+02,  ..., 5.8066e+04, 9.0000e+00,\n",
      "         1.8791e+05],\n",
      "        ...,\n",
      "        [5.2888e+04, 7.0000e+00, 5.8483e+04,  ..., 3.3276e+04, 2.6200e+02,\n",
      "         2.9400e+02],\n",
      "        [5.2700e+02, 1.8763e+05, 3.5000e+02,  ..., 9.5000e+01, 4.2490e+03,\n",
      "         2.1930e+03],\n",
      "        [5.1661e+04, 6.8150e+03, 2.2193e+04,  ..., 1.1340e+03, 1.8381e+04,\n",
      "         8.6000e+01]])\n",
      "50\n",
      "torch.Size([50, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:  64%|██████▍   | 16/25 [00:00<00:00, 26.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [1.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (6, 50, 30), values: [[[  1910      9  33378 ...     33   3271  82729]\n",
      "  [  1910      9  33378 ...     33   3271  82729]\n",
      "  [105920   4922    170 ...  80050     18    341]\n",
      "  ...\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [    87     82  33683 ...    294  33752 100306]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [  1910      9  33378 ...     33   3271  82729]\n",
      "  [105920   4922    170 ...  80050     18    341]\n",
      "  ...\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [    87     82  33683 ...    294  33752 100306]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [  1910      9  33378 ...     33   3271  82729]\n",
      "  [105920   4922    170 ...  80050     18    341]\n",
      "  ...\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [    87     82  33683 ...    294  33752 100306]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [  1910      9  33378 ...     33   3271  82729]\n",
      "  [105920   4922    170 ...  80050     18    341]\n",
      "  ...\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [    87     82  33683 ...    294  33752 100306]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [  1910      9  33378 ...     33   3271  82729]\n",
      "  [105920   4922    170 ...  80050     18    341]\n",
      "  ...\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [    87     82  33683 ...    294  33752 100306]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]]\n",
      "\n",
      " [[  1910      9  33378 ...     33   3271  82729]\n",
      "  [  1910      9  33378 ...     33   3271  82729]\n",
      "  [105920   4922    170 ...  80050     18    341]\n",
      "  ...\n",
      "  [  1429  44177   8395 ...   1144     17  34592]\n",
      "  [    87     82  33683 ...    294  33752 100306]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]]]\n",
      "pred_input_title: (6, 1, 30), values: [[[   357   7621      9  48951  14134   3491  74161    142  78131      4\n",
      "     1953     99    765      6  68413     18   2811     47  17666    177\n",
      "     3405   1515    128     22  17177   1434  26391  46605     71 106543]]\n",
      "\n",
      " [[ 20261    306   1815  26837 105083     18 101930    128  49966     17\n",
      "     1815  11356      4    182    122 100500  13069    242    191     71\n",
      "    19209     18     25  52849   5659 177556  22201    109   3952      9]]\n",
      "\n",
      " [[204049    107   3033      9 242230     13  58923    436      5    182\n",
      "     2918   5111     19     17    211    555      4    453 170931     56\n",
      "      545     99   5015   3438    261    168   8749      5  10453     72]]\n",
      "\n",
      " [[  2646   7344    107   1517  24500   1098     72  85085 118995  20714\n",
      "    32226   3794    261     22  37505     75 100038      5  31143  17413\n",
      "    33640     72    168   4749 241627      6  21769     67   2500     17]]\n",
      "\n",
      " [[   357    600  33908     13    261  82685 118357 148497  21713  43932\n",
      "   178239    128 127123 146491    109      8  11129  37749  23888  13388\n",
      "      261  37254     13  62182   1728    233  44900      1      1      1]]\n",
      "\n",
      " [[ 36061  19507    182    100   5262   4642   3916 143027     66  53631\n",
      "     1151     17  43390  85085  16673  10266      5   1575 126957 222717\n",
      "       72 147481    128  17177 129871    126      4     60    280   1505]]]\n",
      "batch_y: torch.Size([6, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[1.9100e+03, 9.0000e+00, 3.3378e+04,  ..., 3.3000e+01, 3.2710e+03,\n",
      "         8.2729e+04],\n",
      "        [1.9100e+03, 9.0000e+00, 3.3378e+04,  ..., 3.3000e+01, 3.2710e+03,\n",
      "         8.2729e+04],\n",
      "        [1.0592e+05, 4.9220e+03, 1.7000e+02,  ..., 8.0050e+04, 1.8000e+01,\n",
      "         3.4100e+02],\n",
      "        ...,\n",
      "        [1.4290e+03, 4.4177e+04, 8.3950e+03,  ..., 1.1440e+03, 1.7000e+01,\n",
      "         3.4592e+04],\n",
      "        [8.7000e+01, 8.2000e+01, 3.3683e+04,  ..., 2.9400e+02, 3.3752e+04,\n",
      "         1.0031e+05],\n",
      "        [2.6076e+04, 9.0000e+00, 1.0980e+03,  ..., 5.7280e+04, 1.2000e+01,\n",
      "         3.8100e+03]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [1.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (11, 50, 30), values: [[[    87  19110  40130 ...    223  41921      5]\n",
      "  [  3868     82  30501 ... 129238    139 128924]\n",
      "  [149746     72    139 ...  13384  21769    933]\n",
      "  ...\n",
      "  [  1575  16471  15918 ...   1134 100070      7]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]\n",
      "  [   384   7797  44109 ...    242  54494  12227]]\n",
      "\n",
      " [[    87  19110  40130 ...    223  41921      5]\n",
      "  [  3868     82  30501 ... 129238    139 128924]\n",
      "  [149746     72    139 ...  13384  21769    933]\n",
      "  ...\n",
      "  [  1575  16471  15918 ...   1134 100070      7]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]\n",
      "  [   384   7797  44109 ...    242  54494  12227]]\n",
      "\n",
      " [[    87  19110  40130 ...    223  41921      5]\n",
      "  [  3868     82  30501 ... 129238    139 128924]\n",
      "  [149746     72    139 ...  13384  21769    933]\n",
      "  ...\n",
      "  [  1575  16471  15918 ...   1134 100070      7]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]\n",
      "  [   384   7797  44109 ...    242  54494  12227]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[    87  19110  40130 ...    223  41921      5]\n",
      "  [  3868     82  30501 ... 129238    139 128924]\n",
      "  [149746     72    139 ...  13384  21769    933]\n",
      "  ...\n",
      "  [  1575  16471  15918 ...   1134 100070      7]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]\n",
      "  [   384   7797  44109 ...    242  54494  12227]]\n",
      "\n",
      " [[    87  19110  40130 ...    223  41921      5]\n",
      "  [  3868     82  30501 ... 129238    139 128924]\n",
      "  [149746     72    139 ...  13384  21769    933]\n",
      "  ...\n",
      "  [  1575  16471  15918 ...   1134 100070      7]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]\n",
      "  [   384   7797  44109 ...    242  54494  12227]]\n",
      "\n",
      " [[    87  19110  40130 ...    223  41921      5]\n",
      "  [  3868     82  30501 ... 129238    139 128924]\n",
      "  [149746     72    139 ...  13384  21769    933]\n",
      "  ...\n",
      "  [  1575  16471  15918 ...   1134 100070      7]\n",
      "  [ 26076      9   1098 ...  57280     12   3810]\n",
      "  [   384   7797  44109 ...    242  54494  12227]]]\n",
      "pred_input_title: (11, 1, 30), values: [[[ 14355   1505  28398     13 114805  47640  46466  69704   7465  14580\n",
      "        7    109  85190   6389   3666      9  98705   3794      7  52341\n",
      "   143464      9 171126  25388  14355   1505   1134  17250    109    168]]\n",
      "\n",
      " [[ 35583  14949   1015     72  43040  36140  36140    261  19985      5\n",
      "     2548   3491   8017  18891   1379     22  93487      4   3491  52478\n",
      "     3198    109  17986    126     60    182    315  36903  67018   1264]]\n",
      "\n",
      " [[   357    261  62172  16799  79507    107   1379  31958  34592    261\n",
      "       40   1357    109  19591    618    685      5   1429  16237   1926\n",
      "     1661 128489     13  22282   6474     60  81134      4   2328   4610]]\n",
      "\n",
      " [[ 20204     33    109   1172   2512      6 182524     13   2407  91568\n",
      "       72  42648    126    128   3912   9674   3916  18951  91290     18\n",
      "        4  14742  30395     18  37757  71595  38644  75162    109      6]]\n",
      "\n",
      " [[  2888  24792  66373     60  44192     17  30038    126    109  86373\n",
      "    15492     22  34608  48951  14134     82  18413      5   2548      6\n",
      "   123645      7    100 141120     19      4   2328     22  22958  48951]]\n",
      "\n",
      " [[   262    182  34592    261     40   1357      4    453   2328   4610\n",
      "   185502      8  29935    109     99 180046   1100  51169   9872     56\n",
      "       32    579   1873    115   2752  45190     17    604    579 185502]]\n",
      "\n",
      " [[100700  73359    182  15763  29727     33    139     99   1712 184195\n",
      "    51169   2528      4   3916    777    285   1360  12216   1368      5\n",
      "     2548   1226   3728      4     99    149    203   1712   3817      6]]\n",
      "\n",
      " [[   884   1342  44924     72  18597  74138   2060    139  11476  38436\n",
      "        9  33863  34609   4343      6  48045     12   7325    124  19251\n",
      "        9  48951      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[   262  16471  63841    982    720 173756   1953   3787  41036   5256\n",
      "     1803     17   3974   9578   2701  24700  42648     17  41036   1363\n",
      "       12   1429 173756  14457     33      1      1      1      1      1]]\n",
      "\n",
      " [[  1840   1873    115 130715     33    109      4   5916    115  77304\n",
      "   199169     20     60  44867   1440   1873    168  13635   1100   5371\n",
      "      128     20    149  36656   3986  52702    141 106379  31252    145]]\n",
      "\n",
      " [[   717   1011     18      9  16200    261   1803     67      4     99\n",
      "    59657   3271  28117    382  17376      5  16148 178745     72 105791\n",
      "    64736     17 154759      6  23920  24347   1679      4     60  32630]]]\n",
      "batch_y: torch.Size([11, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[8.7000e+01, 1.9110e+04, 4.0130e+04,  ..., 2.2300e+02, 4.1921e+04,\n",
      "         5.0000e+00],\n",
      "        [3.8680e+03, 8.2000e+01, 3.0501e+04,  ..., 1.2924e+05, 1.3900e+02,\n",
      "         1.2892e+05],\n",
      "        [1.4975e+05, 7.2000e+01, 1.3900e+02,  ..., 1.3384e+04, 2.1769e+04,\n",
      "         9.3300e+02],\n",
      "        ...,\n",
      "        [1.5750e+03, 1.6471e+04, 1.5918e+04,  ..., 1.1340e+03, 1.0007e+05,\n",
      "         7.0000e+00],\n",
      "        [2.6076e+04, 9.0000e+00, 1.0980e+03,  ..., 5.7280e+04, 1.2000e+01,\n",
      "         3.8100e+03],\n",
      "        [3.8400e+02, 7.7970e+03, 4.4109e+04,  ..., 2.4200e+02, 5.4494e+04,\n",
      "         1.2227e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (5, 50, 30), values: [[[210302      7  23324 ...      1      1      1]\n",
      "  [130189     13  78155 ...  94412    592      5]\n",
      "  [138719     33    616 ...  60747    261  32452]\n",
      "  ...\n",
      "  [  1575   7245   5614 ...  36740  48951  62859]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[210302      7  23324 ...      1      1      1]\n",
      "  [130189     13  78155 ...  94412    592      5]\n",
      "  [138719     33    616 ...  60747    261  32452]\n",
      "  ...\n",
      "  [  1575   7245   5614 ...  36740  48951  62859]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[210302      7  23324 ...      1      1      1]\n",
      "  [130189     13  78155 ...  94412    592      5]\n",
      "  [138719     33    616 ...  60747    261  32452]\n",
      "  ...\n",
      "  [  1575   7245   5614 ...  36740  48951  62859]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[210302      7  23324 ...      1      1      1]\n",
      "  [130189     13  78155 ...  94412    592      5]\n",
      "  [138719     33    616 ...  60747    261  32452]\n",
      "  ...\n",
      "  [  1575   7245   5614 ...  36740  48951  62859]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   345    555 105920 ...     12  82739  43144]]\n",
      "\n",
      " [[210302      7  23324 ...      1      1      1]\n",
      "  [130189     13  78155 ...  94412    592      5]\n",
      "  [138719     33    616 ...  60747    261  32452]\n",
      "  ...\n",
      "  [  1575   7245   5614 ...  36740  48951  62859]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [   345    555 105920 ...     12  82739  43144]]]\n",
      "pred_input_title: (5, 1, 30), values: [[[ 62151     92      6  42853    776 195933    261  72468      4     99\n",
      "    12574   3271    765   1953  48150   5386     82  20377    109  65889\n",
      "    54504    261    953    203  64712  62151     92      6  42853    776]]\n",
      "\n",
      " [[ 14355   1505  28398     13     72  21351    261     99  33617      4\n",
      "       99   2902  24273   7465  14580      7    182      6 157597   1144\n",
      "    14355   1505  28398     13  16673  11783    109    681     92      9]]\n",
      "\n",
      " [[ 40933 150033   1015   1823    545     17      6  72752     17  44339\n",
      "    54655      4    453    777 162288     99   3963 107865     17     22\n",
      "        6 113877     17  13645  40933 150033   1015 166949    588    139]]\n",
      "\n",
      " [[  7948  16666     71   1679   5054    765  80513    107  40530   2264\n",
      "      139     99    233  65856    272    149  22370    112  36103      4\n",
      "      122     17  25620   3491    261  85771   2811   2057      5    579]]\n",
      "\n",
      " [[    20   1731     72 220770     99  36433     99   3963 146614      6\n",
      "   185705     60   1712    495 203653      4     99    668  88607     42\n",
      "     2057   2536      8  71039      4   2328    668   5054   5015    139]]]\n",
      "batch_y: torch.Size([5, 1]), values: tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[2.1030e+05, 7.0000e+00, 2.3324e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [1.3019e+05, 1.3000e+01, 7.8155e+04,  ..., 9.4412e+04, 5.9200e+02,\n",
      "         5.0000e+00],\n",
      "        [1.3872e+05, 3.3000e+01, 6.1600e+02,  ..., 6.0747e+04, 2.6100e+02,\n",
      "         3.2452e+04],\n",
      "        ...,\n",
      "        [1.5750e+03, 7.2450e+03, 5.6140e+03,  ..., 3.6740e+04, 4.8951e+04,\n",
      "         6.2859e+04],\n",
      "        [5.0715e+04, 1.8000e+01, 1.4936e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [3.4500e+02, 5.5500e+02, 1.0592e+05,  ..., 1.2000e+01, 8.2739e+04,\n",
      "         4.3144e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[1.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (10, 50, 30), values: [[[ 79231    712   8599 ...    139  45833    400]\n",
      "  [199613  46466    182 ...      1      1      1]\n",
      "  [ 16148   4317  50775 ... 205463     42 104776]\n",
      "  ...\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [  1004  51213  18043 ...    100     22  52311]]\n",
      "\n",
      " [[ 79231    712   8599 ...    139  45833    400]\n",
      "  [199613  46466    182 ...      1      1      1]\n",
      "  [ 16148   4317  50775 ... 205463     42 104776]\n",
      "  ...\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [  1004  51213  18043 ...    100     22  52311]]\n",
      "\n",
      " [[ 79231    712   8599 ...    139  45833    400]\n",
      "  [199613  46466    182 ...      1      1      1]\n",
      "  [ 16148   4317  50775 ... 205463     42 104776]\n",
      "  ...\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [  1004  51213  18043 ...    100     22  52311]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 79231    712   8599 ...    139  45833    400]\n",
      "  [199613  46466    182 ...      1      1      1]\n",
      "  [ 16148   4317  50775 ... 205463     42 104776]\n",
      "  ...\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [  1004  51213  18043 ...    100     22  52311]]\n",
      "\n",
      " [[ 79231    712   8599 ...    139  45833    400]\n",
      "  [199613  46466    182 ...      1      1      1]\n",
      "  [ 16148   4317  50775 ... 205463     42 104776]\n",
      "  ...\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [  1004  51213  18043 ...    100     22  52311]]\n",
      "\n",
      " [[ 79231    712   8599 ...    139  45833    400]\n",
      "  [199613  46466    182 ...      1      1      1]\n",
      "  [ 16148   4317  50775 ... 205463     42 104776]\n",
      "  ...\n",
      "  [   357   3082  13036 ...    128  21861  39046]\n",
      "  [  8301    332 136617 ...   1004    149  44075]\n",
      "  [  1004  51213  18043 ...    100     22  52311]]]\n",
      "pred_input_title: (10, 1, 30), values: [[[161436   4935      4  62172  73119   3196     60  59215     72    545\n",
      "       17  97809     12  57687  14663   5761   1063 136709     67    745\n",
      "       17  24906    128  41275     18    261    203  64712    588    168]]\n",
      "\n",
      " [[ 19957  67983      9  38672   1357  37420     56 149014      4  64475\n",
      "     3787   2776    588 122513      7  10135  34922      5   1111    168\n",
      "    48915    365  29888      6 166954    261  82628 130794   5828 156301]]\n",
      "\n",
      " [[   579  23801   1953     22 182291    645  96634  12969   5095 163933\n",
      "    21836  99442  21139   1681   7980    139  92265  13527      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[  4804 221502  93487      7 154982     56 132199     42    604     82\n",
      "     1528      4   2328    115    128   5015 202787    203    308    372\n",
      "      233    139    209  14251    109    209  93016    209  14251    109]]\n",
      "\n",
      " [[  3145 144137     12   5976     71   5084   1202  16237      4   5916\n",
      "    88034  53437      9 128743  16673  22201      4     48    149   1630\n",
      "     6474      4     99     22  88034  53437      9  25389    285   1239]]\n",
      "\n",
      " [[   357  17739  48951  14134    182    139  31685    126    880  67411\n",
      "       17  19576  70465  43764      5   2548    182  14014   5037    532\n",
      "     1974    645   5390  14251      6  86760  17739  48951     17 154759]]\n",
      "\n",
      " [[    20    579      4    881   2060  14009      4    285   2536  16323\n",
      "       18    645 105791   1368  31182      4    453    777  95652   4196\n",
      "    14872  19576  24337     17 202312   6474    100     17  12574      4]]\n",
      "\n",
      " [[157646     13  31307  34922    182    109   5331     18     82  93084\n",
      "       99    233  56261     13  47662    128     22  22473   6581  27915\n",
      "      171  32555    261  19957  67983 116182    261 154426     13  31307]]\n",
      "\n",
      " [[   579  16471 197956      9  71713   6669      9 190872   1336    275\n",
      "    40130   2923 102991     17   1118 113877     33    313  43379     60\n",
      "     1873  44867    168  77304 103339   3986    233 125461      4  18597]]\n",
      "\n",
      " [[ 26729   3263    100   9653 167304    261  45555     60    104  16977\n",
      "      109  55598    478  19513    182   2430     86   2472   5331      5\n",
      "     9578    805     72    142  28295     18    100     99  66450     13]]]\n",
      "batch_y: torch.Size([10, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[7.9231e+04, 7.1200e+02, 8.5990e+03,  ..., 1.3900e+02, 4.5833e+04,\n",
      "         4.0000e+02],\n",
      "        [1.9961e+05, 4.6466e+04, 1.8200e+02,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [1.6148e+04, 4.3170e+03, 5.0775e+04,  ..., 2.0546e+05, 4.2000e+01,\n",
      "         1.0478e+05],\n",
      "        ...,\n",
      "        [3.5700e+02, 3.0820e+03, 1.3036e+04,  ..., 1.2800e+02, 2.1861e+04,\n",
      "         3.9046e+04],\n",
      "        [8.3010e+03, 3.3200e+02, 1.3662e+05,  ..., 1.0040e+03, 1.4900e+02,\n",
      "         4.4075e+04],\n",
      "        [1.0040e+03, 5.1213e+04, 1.8043e+04,  ..., 1.0000e+02, 2.2000e+01,\n",
      "         5.2311e+04]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (11, 50, 30), values: [[[   357  30038    872 ...    261 107628    720]\n",
      "  [146393   5153    184 ...    982  79329      1]\n",
      "  [ 17703     33  18522 ...     86  37868   2189]\n",
      "  ...\n",
      "  [164460  91865   3963 ... 186831      9  47405]\n",
      "  [  1204  11439 159249 ... 159249  93156   1991]\n",
      "  [    20   8301  28337 ...      4    122    545]]\n",
      "\n",
      " [[   357  30038    872 ...    261 107628    720]\n",
      "  [146393   5153    184 ...    982  79329      1]\n",
      "  [ 17703     33  18522 ...     86  37868   2189]\n",
      "  ...\n",
      "  [164460  91865   3963 ... 186831      9  47405]\n",
      "  [  1204  11439 159249 ... 159249  93156   1991]\n",
      "  [    20   8301  28337 ...      4    122    545]]\n",
      "\n",
      " [[   357  30038    872 ...    261 107628    720]\n",
      "  [146393   5153    184 ...    982  79329      1]\n",
      "  [ 17703     33  18522 ...     86  37868   2189]\n",
      "  ...\n",
      "  [164460  91865   3963 ... 186831      9  47405]\n",
      "  [  1204  11439 159249 ... 159249  93156   1991]\n",
      "  [    20   8301  28337 ...      4    122    545]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   357  30038    872 ...    261 107628    720]\n",
      "  [146393   5153    184 ...    982  79329      1]\n",
      "  [ 17703     33  18522 ...     86  37868   2189]\n",
      "  ...\n",
      "  [164460  91865   3963 ... 186831      9  47405]\n",
      "  [  1204  11439 159249 ... 159249  93156   1991]\n",
      "  [    20   8301  28337 ...      4    122    545]]\n",
      "\n",
      " [[   357  30038    872 ...    261 107628    720]\n",
      "  [146393   5153    184 ...    982  79329      1]\n",
      "  [ 17703     33  18522 ...     86  37868   2189]\n",
      "  ...\n",
      "  [164460  91865   3963 ... 186831      9  47405]\n",
      "  [  1204  11439 159249 ... 159249  93156   1991]\n",
      "  [    20   8301  28337 ...      4    122    545]]\n",
      "\n",
      " [[   357  30038    872 ...    261 107628    720]\n",
      "  [146393   5153    184 ...    982  79329      1]\n",
      "  [ 17703     33  18522 ...     86  37868   2189]\n",
      "  ...\n",
      "  [164460  91865   3963 ... 186831      9  47405]\n",
      "  [  1204  11439 159249 ... 159249  93156   1991]\n",
      "  [    20   8301  28337 ...      4    122    545]]]\n",
      "pred_input_title: (11, 1, 30), values: [[[ 10255   2082    112 133857      7    100    177  14936    112    112\n",
      "    11269  12018     23 217315     42    315      4     99    777     72\n",
      "   129500    139  53185    242   2472     99    100  61711   3787  60016]]\n",
      "\n",
      " [[138087  19824    285    149 174854     13   8753    109    149 174854\n",
      "       13  16077     17    845  30319      4   2328   1550    820   1872\n",
      "    24705  18066    588  30622   1067   7639  15912   2415      7  67623]]\n",
      "\n",
      " [[   262  80145  93016     72 120356   4861 212401  22772  74291      7\n",
      "    65172    133      4 149674      4  23047  92051      4 218334      4\n",
      "      540  61356      4 191019      4 190537     60  82167    100    139]]\n",
      "\n",
      " [[  5316 151927    515    107      9   7260      7 160025  30003   4223\n",
      "     1015     60   2119  31178      8  20951   2536     13  10729    112\n",
      "    28302     42     12     20  94954     42    824   1442     17    491]]\n",
      "\n",
      " [[207975      7  48267    182  57513  46466  36903     22 128989    171\n",
      "       22  52238  24347   5386    139  31931   1405    126     17  91781\n",
      "   185590    171  52238  24347   5386    139  31931   1405     17  91781]]\n",
      "\n",
      " [[142711     72    100   4444    139     82    311    112   5077   1100\n",
      "     9617    128    149   7530    109   8026     33   6797   4642      4\n",
      "     4271  70338     42  39282  78147 159249     60  22911  78147 135497]]\n",
      "\n",
      " [[ 25330  14384    115  84872      6  33926  27472     32 115745  22255\n",
      "       56   1134    149    765     32   3183  36566   1134  13457  18485\n",
      "       56     17      6  33926  27472  29935  60108     90    139     32]]\n",
      "\n",
      " [[  1326   5262   4642 161927    182     22  36656  63299   9342    100\n",
      "        8    600   1674    549  63905  93324     56   1226 140232 153803\n",
      "      126 180834    177  63926   5159      1      1      1      1      1]]\n",
      "\n",
      " [[144503    285    149     82   1368   3916      4     99 128048     33\n",
      "    31681   1261  20514  40130   9653      5  15745    100  25003    112\n",
      "       72  21309    545  33832   1144    645    149    681     92  16787]]\n",
      "\n",
      " [[109383     53  20255  72089   1272    261  72468      4     99   1926\n",
      "   148770    139 165458  57747  28394      7 231404    128     22  18714\n",
      "    14134    588   5044      9  97416     33      5     87  25429  20363]]\n",
      "\n",
      " [[  1004   2069  60485   1760    182  13946  36376   3817 107526  30003\n",
      "       60 107526  13732  30003     17  26521  19175 180834    177  63926\n",
      "     5159     12  60485   1760  33759  32630  24270      1      1      1]]]\n",
      "batch_y: torch.Size([11, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[3.5700e+02, 3.0038e+04, 8.7200e+02,  ..., 2.6100e+02, 1.0763e+05,\n",
      "         7.2000e+02],\n",
      "        [1.4639e+05, 5.1530e+03, 1.8400e+02,  ..., 9.8200e+02, 7.9329e+04,\n",
      "         1.0000e+00],\n",
      "        [1.7703e+04, 3.3000e+01, 1.8522e+04,  ..., 8.6000e+01, 3.7868e+04,\n",
      "         2.1890e+03],\n",
      "        ...,\n",
      "        [1.6446e+05, 9.1865e+04, 3.9630e+03,  ..., 1.8683e+05, 9.0000e+00,\n",
      "         4.7405e+04],\n",
      "        [1.2040e+03, 1.1439e+04, 1.5925e+05,  ..., 1.5925e+05, 9.3156e+04,\n",
      "         1.9910e+03],\n",
      "        [2.0000e+01, 8.3010e+03, 2.8337e+04,  ..., 4.0000e+00, 1.2200e+02,\n",
      "         5.4500e+02]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (9, 50, 30), values: [[[ 26076      9  17052 ...   6634  45513     13]\n",
      "  [109352  33378     14 ...      1      1      1]\n",
      "  [  6765 209723   9038 ...     17   9020   6765]\n",
      "  ...\n",
      "  [   384   7797  44109 ...    242  54494  12227]\n",
      "  [   262   6530   7223 ...     60     40   1144]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[ 26076      9  17052 ...   6634  45513     13]\n",
      "  [109352  33378     14 ...      1      1      1]\n",
      "  [  6765 209723   9038 ...     17   9020   6765]\n",
      "  ...\n",
      "  [   384   7797  44109 ...    242  54494  12227]\n",
      "  [   262   6530   7223 ...     60     40   1144]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[ 26076      9  17052 ...   6634  45513     13]\n",
      "  [109352  33378     14 ...      1      1      1]\n",
      "  [  6765 209723   9038 ...     17   9020   6765]\n",
      "  ...\n",
      "  [   384   7797  44109 ...    242  54494  12227]\n",
      "  [   262   6530   7223 ...     60     40   1144]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 26076      9  17052 ...   6634  45513     13]\n",
      "  [109352  33378     14 ...      1      1      1]\n",
      "  [  6765 209723   9038 ...     17   9020   6765]\n",
      "  ...\n",
      "  [   384   7797  44109 ...    242  54494  12227]\n",
      "  [   262   6530   7223 ...     60     40   1144]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[ 26076      9  17052 ...   6634  45513     13]\n",
      "  [109352  33378     14 ...      1      1      1]\n",
      "  [  6765 209723   9038 ...     17   9020   6765]\n",
      "  ...\n",
      "  [   384   7797  44109 ...    242  54494  12227]\n",
      "  [   262   6530   7223 ...     60     40   1144]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[ 26076      9  17052 ...   6634  45513     13]\n",
      "  [109352  33378     14 ...      1      1      1]\n",
      "  [  6765 209723   9038 ...     17   9020   6765]\n",
      "  ...\n",
      "  [   384   7797  44109 ...    242  54494  12227]\n",
      "  [   262   6530   7223 ...     60     40   1144]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]]\n",
      "pred_input_title: (9, 1, 30), values: [[[ 55598  52917  10528  68933     60  47801   2512  22964     19   7997\n",
      "   128354    184    285  69538    109  27535  78007      7    645 181916\n",
      "      109  45355     56     87  36709  44937     12  48033   5044      9]]\n",
      "\n",
      " [[ 51211  13282  81929    395    567   1132     92  19521     18     17\n",
      "      918 227450    124  48807  47405      5   1429  60804     42   1926\n",
      "    69686    761     33   1872    128    128   8695   2536  19787  10729]]\n",
      "\n",
      " [[149746  25779  47640   5535   5222   1872    139 204049   9173  22381\n",
      "        4     48     22   6478      9  48951  62896  14134    645  41993\n",
      "       18     22    307   5386  46406     17 204049   9173  22381     12]]\n",
      "\n",
      " [[ 99442  21139   1681    285   6534   2285    645      4     99  64262\n",
      "      246   6947     33   3491   1226    128     99      6 123645   8282\n",
      "   187073    109  25257  21139   1681     17     54   6947      9 106543]]\n",
      "\n",
      " [[ 11584   3911   1974  13594    502  74877     19    139     99  42648\n",
      "       13    128   1379   5077  27970  23046  20106  10674    109    845\n",
      "    30319  16326  43957  31019  46466  11214     76  88894    720     56]]\n",
      "\n",
      " [[  3868  74161   1134    122   6106      6 242511      7    261    100\n",
      "       99  20031   8557  78112      7  40080   1357    203 162855   1144\n",
      "        5    579  23801     17   6854    390     56      4    453    182]]\n",
      "\n",
      " [[ 53379     19    182  79329  16077     17  24906    128     22  18493\n",
      "     2146  42504    159  33880      6 222101  52478   3198    139 128139\n",
      "    27472      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[  1575  47508  13732  74777   8079  97530      7    285   3059    545\n",
      "      139     99  25005    100    109    845  30319  16326  43957  31019\n",
      "    46466   2548  28780     56    321  84265      1      1      1      1]]\n",
      "\n",
      " [[   845    334  33781    170   2319    519    169  10884 126982  47640\n",
      "        4     99 142092      9  40042    182    109    372  78015  13384\n",
      "      880    456  39046     67    588  15082    127  14311      5 123949]]]\n",
      "batch_y: torch.Size([9, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[2.6076e+04, 9.0000e+00, 1.7052e+04,  ..., 6.6340e+03, 4.5513e+04,\n",
      "         1.3000e+01],\n",
      "        [1.0935e+05, 3.3378e+04, 1.4000e+01,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [6.7650e+03, 2.0972e+05, 9.0380e+03,  ..., 1.7000e+01, 9.0200e+03,\n",
      "         6.7650e+03],\n",
      "        ...,\n",
      "        [3.8400e+02, 7.7970e+03, 4.4109e+04,  ..., 2.4200e+02, 5.4494e+04,\n",
      "         1.2227e+04],\n",
      "        [2.6200e+02, 6.5300e+03, 7.2230e+03,  ..., 6.0000e+01, 4.0000e+01,\n",
      "         1.1440e+03],\n",
      "        [9.9070e+03, 9.1464e+04, 1.8720e+03,  ..., 1.0026e+05, 1.3000e+01,\n",
      "         3.7870e+03]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:  88%|████████▊ | 22/25 [00:00<00:00, 23.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his_input_title: (18, 50, 30), values: [[[15161  7370     7 ...  4172  1755  2663]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  873  1042  3405 ... 99918    33     1]\n",
      "  ...\n",
      "  [  893 22666   261 ...   271 20807     6]\n",
      "  [   87    22     6 ... 36137 52344 13282]\n",
      "  [  262  6530  7223 ...    60    40  1144]]\n",
      "\n",
      " [[15161  7370     7 ...  4172  1755  2663]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  873  1042  3405 ... 99918    33     1]\n",
      "  ...\n",
      "  [  893 22666   261 ...   271 20807     6]\n",
      "  [   87    22     6 ... 36137 52344 13282]\n",
      "  [  262  6530  7223 ...    60    40  1144]]\n",
      "\n",
      " [[15161  7370     7 ...  4172  1755  2663]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  873  1042  3405 ... 99918    33     1]\n",
      "  ...\n",
      "  [  893 22666   261 ...   271 20807     6]\n",
      "  [   87    22     6 ... 36137 52344 13282]\n",
      "  [  262  6530  7223 ...    60    40  1144]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[15161  7370     7 ...  4172  1755  2663]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  873  1042  3405 ... 99918    33     1]\n",
      "  ...\n",
      "  [  893 22666   261 ...   271 20807     6]\n",
      "  [   87    22     6 ... 36137 52344 13282]\n",
      "  [  262  6530  7223 ...    60    40  1144]]\n",
      "\n",
      " [[15161  7370     7 ...  4172  1755  2663]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  873  1042  3405 ... 99918    33     1]\n",
      "  ...\n",
      "  [  893 22666   261 ...   271 20807     6]\n",
      "  [   87    22     6 ... 36137 52344 13282]\n",
      "  [  262  6530  7223 ...    60    40  1144]]\n",
      "\n",
      " [[15161  7370     7 ...  4172  1755  2663]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  873  1042  3405 ... 99918    33     1]\n",
      "  ...\n",
      "  [  893 22666   261 ...   271 20807     6]\n",
      "  [   87    22     6 ... 36137 52344 13282]\n",
      "  [  262  6530  7223 ...    60    40  1144]]]\n",
      "pred_input_title: (18, 1, 30), values: [[[   579   7400  77261   1950     19   9370      4    124   1953  21562\n",
      "     1134   2965    416    112  49240    124 147407 119949     17  37757\n",
      "   128283  37757 128283    142 155462    600 147407 119949      1      1]]\n",
      "\n",
      " [[ 99442  21139   1681  30003     22 175351 152035   5256  27633   2811\n",
      "    96634  12969   5095 163933  21836      5  78287   3683   2752  52454\n",
      "       42  59138    139  92265  13527      7  17042 113877    159 143662]]\n",
      "\n",
      " [[  6478      9  78147  87193  24299   3491      6  68413     18    109\n",
      "     7897      7  16401    261    880  11269  12018    100  95445     86\n",
      "      261 143622      4    122   9790  32502     13   2057    171     99]]\n",
      "\n",
      " [[  1310     72   8796     17     22      6  80988     17 117288  78685\n",
      "        5  23243     33     72   1379   7619  23243     17 117288  78685\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[  2548   1823    588     82  12447    124  73213      9  19057   1192\n",
      "    79650     17 234702     60    139  39046    820   3080    391  15639\n",
      "      615  13557  27303 195000  21407 160235   7400    600    391  15639]]\n",
      "\n",
      " [[  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "      182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "     1111    122     72  32376     82  54392   6799    495   3728  10750]]\n",
      "\n",
      " [[119154    285    168   4949  33640     99   9881      5   1111    315\n",
      "     1873  47173      7    242  25267   9014  45327     25 100500     22\n",
      "    47621     17    168  61706  85805      9   8551      5   3183    149]]\n",
      "\n",
      " [[ 20261    306   9173     85  12981     39  61100     72  20714  11001\n",
      "        4   8793     22    600  84265    545 113885    109  47367  63844\n",
      "       17 183828  16148  21113  89827     12  72621     56    545 100339]]\n",
      "\n",
      " [[ 45122  26076  87369   9896      4 110588  13453   4727    516      4\n",
      "       72   2160  34881     60   2160  34881      4   3916    168 148770\n",
      "     8057  12018  39318  58653  68900    100     47   1368   3916 129956]]\n",
      "\n",
      " [[    87  20491    272    182      8   4949    915      9 100781    720\n",
      "       20     60   7262  26837 175471     18      5   3810    100     22\n",
      "   163568    555   4642      7  43822  40130   7223 115484    126     17]]\n",
      "\n",
      " [[   579     72    315  20714 205700     18      4     99   1600   1916\n",
      "        9 154759     13  23698    717  10186    588 192050  13534    182\n",
      "    67714   2811   1661   6092  16401   2907   4227   2415 205700     18]]\n",
      "\n",
      " [[ 14949  46231    379    182 106686   4842 108829  38692    587  27331\n",
      "        7    139  81264  46231    379      9  18066    416 106686    139\n",
      "    67722      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 56233 108829     72  80459     18      4     60    139  19952    203\n",
      "   117090   3196  41275   8409      6 137844     60  74112     17    149\n",
      "     3787 155253      5  94954  15666   7188   7400  59277     18      5]]\n",
      "\n",
      " [[  1910    116    182  38552    126    139     17  25531 152262     60\n",
      "    16237    315  14355   1505  28398     90 115456      4   2683    777\n",
      "       72  33618 148372     86    139     99  82729  92265  13527   1910]]\n",
      "\n",
      " [[ 16148   4475 230745     56    182     22 102516  36656    588  88880\n",
      "    59205     18    880   4343 100339    109    168  20951 146106  51602\n",
      "        4   2328   2536  13732  30673   1063    765   1100    128  25257]]\n",
      "\n",
      " [[  1910    116     25      7      6 203014   2517  22772   2918   1368\n",
      "   100092   2994     92  25335   8858 171010     99  11504    186 125082\n",
      "       18    671   1485     18   1910   4720  58395 205700     42     12]]\n",
      "\n",
      " [[ 31143  30827  21555   2661      9  47405     13  42648     18    171\n",
      "      109 131969      4     48   3488    555    171  30542  13969     67\n",
      "    76420      5   1111    149   9162   3728   6015    880   2936   3000]]\n",
      "\n",
      " [[   357   3059     47   1368  27194  45555  25779    109 128139  27472\n",
      "     1953     99    765  79329     22  34777     13    109     22   2412\n",
      "     1277     56 102733      4   2328  38016     33    285    109   2130]]]\n",
      "batch_y: torch.Size([18, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[1.5161e+04, 7.3700e+03, 7.0000e+00,  ..., 4.1720e+03, 1.7550e+03,\n",
      "         2.6630e+03],\n",
      "        [1.9528e+04, 5.5500e+02, 6.0000e+01,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [8.7300e+02, 1.0420e+03, 3.4050e+03,  ..., 9.9918e+04, 3.3000e+01,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [8.9300e+02, 2.2666e+04, 2.6100e+02,  ..., 2.7100e+02, 2.0807e+04,\n",
      "         6.0000e+00],\n",
      "        [8.7000e+01, 2.2000e+01, 6.0000e+00,  ..., 3.6137e+04, 5.2344e+04,\n",
      "         1.3282e+04],\n",
      "        [2.6200e+02, 6.5300e+03, 7.2230e+03,  ..., 6.0000e+01, 4.0000e+01,\n",
      "         1.1440e+03]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (8, 50, 30), values: [[[ 4804   881    56 ...  7997  3196 50483]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  242   841  7997 ...     1     1     1]\n",
      "  ...\n",
      "  [16692  5879 89596 ...    18  1144    23]\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [16692  5879 89596 ...    18  1144    23]]\n",
      "\n",
      " [[ 4804   881    56 ...  7997  3196 50483]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  242   841  7997 ...     1     1     1]\n",
      "  ...\n",
      "  [16692  5879 89596 ...    18  1144    23]\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [16692  5879 89596 ...    18  1144    23]]\n",
      "\n",
      " [[ 4804   881    56 ...  7997  3196 50483]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  242   841  7997 ...     1     1     1]\n",
      "  ...\n",
      "  [16692  5879 89596 ...    18  1144    23]\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [16692  5879 89596 ...    18  1144    23]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4804   881    56 ...  7997  3196 50483]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  242   841  7997 ...     1     1     1]\n",
      "  ...\n",
      "  [16692  5879 89596 ...    18  1144    23]\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [16692  5879 89596 ...    18  1144    23]]\n",
      "\n",
      " [[ 4804   881    56 ...  7997  3196 50483]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  242   841  7997 ...     1     1     1]\n",
      "  ...\n",
      "  [16692  5879 89596 ...    18  1144    23]\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [16692  5879 89596 ...    18  1144    23]]\n",
      "\n",
      " [[ 4804   881    56 ...  7997  3196 50483]\n",
      "  [19528   555    60 ...     1     1     1]\n",
      "  [  242   841  7997 ...     1     1     1]\n",
      "  ...\n",
      "  [16692  5879 89596 ...    18  1144    23]\n",
      "  [  360   555    22 ...  1368     4 11380]\n",
      "  [16692  5879 89596 ...    18  1144    23]]]\n",
      "pred_input_title: (8, 1, 30), values: [[[    87    149      6 108396   2198     67   3082  30090   6406  23146\n",
      "   156301  39809     86      5   1429  88607     42  27585   7831    563\n",
      "     7997  24371   1440  23604  30090     17      6 108396     12    563]]\n",
      "\n",
      " [[ 14355   1505  28398     13     72   3082  66609    217    139   1661\n",
      "     5262 107677      9   2146 142404     17  92265  13527      5   1575\n",
      "    16471      6  50142 114805    168      6 225200  78475     13  67681]]\n",
      "\n",
      " [[  2646   7344    107   1517  24500   1098     72  85085 118995  20714\n",
      "    32226   3794    261     22  37505     75 100038      5  31143  17413\n",
      "    33640     72    168   4749 241627      6  21769     67   2500     17]]\n",
      "\n",
      " [[ 36061  19507    182    100   5262   4642   3916 143027     66  53631\n",
      "     1151     17  43390  85085  16673  10266      5   1575 126957 222717\n",
      "       72 147481    128  17177 129871    126      4     60    280   1505]]\n",
      "\n",
      " [[   357  22175  48951  14134     72      6 154759    100     99    765\n",
      "   193393    126    645  53631   2811    880 207695     13  19326  42373\n",
      "     1515     60     22  24830   9427  48951  22175  48951   1873    645]]\n",
      "\n",
      " [[204049    107   3033      9 242230     13  58923    436      5    182\n",
      "     2918   5111     19     17    211    555      4    453 170931     56\n",
      "      545     99   5015   3438    261    168   8749      5  10453     72]]\n",
      "\n",
      " [[ 19669  13906  74583    837    927  33384  59277    112     22  14878\n",
      "    11364 129357      4     48    777  77170  39096    379 232043     17\n",
      "     6854 100768   1226  92265  13527   5174   1972  16749 129357     12]]\n",
      "\n",
      " [[ 32768  39668     76  81134      4     99 140993 101133    603    588\n",
      "       40   3196    285     22    261 163038   3196    139      4     99\n",
      "     1926  86272     99    100  22333    242  68996  13038   2452   3132]]]\n",
      "batch_y: torch.Size([8, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "Inputs\n",
      "tensor([[4.8040e+03, 8.8100e+02, 5.6000e+01,  ..., 7.9970e+03, 3.1960e+03,\n",
      "         5.0483e+04],\n",
      "        [1.9528e+04, 5.5500e+02, 6.0000e+01,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [2.4200e+02, 8.4100e+02, 7.9970e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [1.6692e+04, 5.8790e+03, 8.9596e+04,  ..., 1.8000e+01, 1.1440e+03,\n",
      "         2.3000e+01],\n",
      "        [3.6000e+02, 5.5500e+02, 2.2000e+01,  ..., 1.3680e+03, 4.0000e+00,\n",
      "         1.1380e+04],\n",
      "        [1.6692e+04, 5.8790e+03, 8.9596e+04,  ..., 1.8000e+01, 1.1440e+03,\n",
      "         2.3000e+01]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (5, 50, 30), values: [[[ 95769    195   3514 ...     17  14000     33]\n",
      "  [  1575  12532 239936 ...      1      1      1]\n",
      "  [ 94743     42 163028 ...      9   3035 136348]\n",
      "  ...\n",
      "  [   391  69466    182 ...  67059      7 123373]\n",
      "  [ 56159 106094   7136 ...      1      1      1]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[ 95769    195   3514 ...     17  14000     33]\n",
      "  [  1575  12532 239936 ...      1      1      1]\n",
      "  [ 94743     42 163028 ...      9   3035 136348]\n",
      "  ...\n",
      "  [   391  69466    182 ...  67059      7 123373]\n",
      "  [ 56159 106094   7136 ...      1      1      1]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[ 95769    195   3514 ...     17  14000     33]\n",
      "  [  1575  12532 239936 ...      1      1      1]\n",
      "  [ 94743     42 163028 ...      9   3035 136348]\n",
      "  ...\n",
      "  [   391  69466    182 ...  67059      7 123373]\n",
      "  [ 56159 106094   7136 ...      1      1      1]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[ 95769    195   3514 ...     17  14000     33]\n",
      "  [  1575  12532 239936 ...      1      1      1]\n",
      "  [ 94743     42 163028 ...      9   3035 136348]\n",
      "  ...\n",
      "  [   391  69466    182 ...  67059      7 123373]\n",
      "  [ 56159 106094   7136 ...      1      1      1]\n",
      "  [ 50715     18  14936 ...      1      1      1]]\n",
      "\n",
      " [[ 95769    195   3514 ...     17  14000     33]\n",
      "  [  1575  12532 239936 ...      1      1      1]\n",
      "  [ 94743     42 163028 ...      9   3035 136348]\n",
      "  ...\n",
      "  [   391  69466    182 ...  67059      7 123373]\n",
      "  [ 56159 106094   7136 ...      1      1      1]\n",
      "  [ 50715     18  14936 ...      1      1      1]]]\n",
      "pred_input_title: (5, 1, 30), values: [[[155941     72    109  19261     17   4265   4172     33  74161      4\n",
      "     2328    122   3817    203  45692     22  74991     60     22   3438\n",
      "     1294   6850      5   8019  39607   6475    203   1440  11504 205077]]\n",
      "\n",
      " [[   436   2118  41974  14437      4   8057 226063     17    357   5252\n",
      "        7  63844      4      6  78965    315     22  56852  22184    261\n",
      "    78905     14  76271  18241    653 109713   2285      6  67181  38669]]\n",
      "\n",
      " [[    87   8839   1272  78475     72   4475    472  14936     13  53726\n",
      "   220770     99    100      7   2082    112   1872    261    149  27844\n",
      "      341   3405  19738    472  14936     13  53726      7      9   1176]]\n",
      "\n",
      " [[242236   7274    182      6  85939   3667   4539    645  67714    581\n",
      "    47443    111     70  21434      7     12   2016  53071      4    122\n",
      "       72   6799    139     99  14050   2506     17   5919  31004  42009]]\n",
      "\n",
      " [[ 65528     13  27303   1015   1134    545  52293   1712 186044    100\n",
      "    22338  65665     92 132546     86     17  73165  14098      5    579\n",
      "      233  14907     56  65134  74161  29630   2663  39046   1679  80459]]]\n",
      "batch_y: torch.Size([5, 1]), values: tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[9.5769e+04, 1.9500e+02, 3.5140e+03,  ..., 1.7000e+01, 1.4000e+04,\n",
      "         3.3000e+01],\n",
      "        [1.5750e+03, 1.2532e+04, 2.3994e+05,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [9.4743e+04, 4.2000e+01, 1.6303e+05,  ..., 9.0000e+00, 3.0350e+03,\n",
      "         1.3635e+05],\n",
      "        ...,\n",
      "        [3.9100e+02, 6.9466e+04, 1.8200e+02,  ..., 6.7059e+04, 7.0000e+00,\n",
      "         1.2337e+05],\n",
      "        [5.6159e+04, 1.0609e+05, 7.1360e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [5.0715e+04, 1.8000e+01, 1.4936e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[1.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (31, 50, 30), values: [[[  1775    366   3491 ...    685    335  11150]\n",
      "  [  6610   2986     86 ...      7    149      4]\n",
      "  [   663   2595   2242 ...   1953  22688   2844]\n",
      "  ...\n",
      "  [  5586     33      6 ...     18  44547     18]\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [178614    203    115 ...  13440  29036     25]]\n",
      "\n",
      " [[  1775    366   3491 ...    685    335  11150]\n",
      "  [  6610   2986     86 ...      7    149      4]\n",
      "  [   663   2595   2242 ...   1953  22688   2844]\n",
      "  ...\n",
      "  [  5586     33      6 ...     18  44547     18]\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [178614    203    115 ...  13440  29036     25]]\n",
      "\n",
      " [[  1775    366   3491 ...    685    335  11150]\n",
      "  [  6610   2986     86 ...      7    149      4]\n",
      "  [   663   2595   2242 ...   1953  22688   2844]\n",
      "  ...\n",
      "  [  5586     33      6 ...     18  44547     18]\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [178614    203    115 ...  13440  29036     25]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  1775    366   3491 ...    685    335  11150]\n",
      "  [  6610   2986     86 ...      7    149      4]\n",
      "  [   663   2595   2242 ...   1953  22688   2844]\n",
      "  ...\n",
      "  [  5586     33      6 ...     18  44547     18]\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [178614    203    115 ...  13440  29036     25]]\n",
      "\n",
      " [[  1775    366   3491 ...    685    335  11150]\n",
      "  [  6610   2986     86 ...      7    149      4]\n",
      "  [   663   2595   2242 ...   1953  22688   2844]\n",
      "  ...\n",
      "  [  5586     33      6 ...     18  44547     18]\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [178614    203    115 ...  13440  29036     25]]\n",
      "\n",
      " [[  1775    366   3491 ...    685    335  11150]\n",
      "  [  6610   2986     86 ...      7    149      4]\n",
      "  [   663   2595   2242 ...   1953  22688   2844]\n",
      "  ...\n",
      "  [  5586     33      6 ...     18  44547     18]\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [178614    203    115 ...  13440  29036     25]]]\n",
      "pred_input_title: (31, 1, 30), values: [[[  1575  16799    203    147  13282  40308     72     82  52849 140692\n",
      "   142687 203352   1572    203  18893  21825    139 194872      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 53752    285  51169     47  39851     17  43084      9  33870     33\n",
      "     2811  25730      4    124  68315    149   2923    109  47621     17\n",
      "    37304  28009    128   1360   6999  25730      7     83  91621  59464]]\n",
      "\n",
      " [[    20    579    285  10024  63039     18      4   8928  41576   8064\n",
      "     1681 184048    112    100     99   9096    139  12574    100     99\n",
      "    55032     13      4     72  91870     42   6300   5516  12530    133]]\n",
      "\n",
      " [[   357   6478      9  48951  14134     72  20714    285    126  21769\n",
      "      933    420   3405    449      7   1974     17  11476  93016      5\n",
      "     2548     72   1144   3263    100     99    765  52238  56603     60]]\n",
      "\n",
      " [[  1913  53752     72     22  19389  24507    112  12729   2320      4\n",
      "      182      8  21241  16471    107   6015  20691 125503     18      5\n",
      "     1111    122     72  32376     82  54392   6799    495   3728  10750]]\n",
      "\n",
      " [[ 22805     20     22    390     17  53698   1015      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[  1775  74224  56726     18  76423  22913   1063   1872 101515      4\n",
      "    48327  32226  57241    122     72  77304    139   6799 109311   1466\n",
      "        5  33539    203     22  19879  16471  36656     40   6474    139]]\n",
      "\n",
      " [[  1572     72 124095    139     99    914  40099     17 138550      4\n",
      "     2683    332  44177  14872  19716      4   4271  70338     42   1391\n",
      "      162      9  16091      7  23914   9319  27822     56   1953    149]]\n",
      "\n",
      " [[ 62558  99986  45095    100   7121    814 222717    100  54114    301\n",
      "      126      4   1953    149  61100     72  20714  94889     18      4\n",
      "       99    777    182  36903  10024    645   7221   9674    261 126220]]\n",
      "\n",
      " [[  8268 151071 108609     42     91 120375    126    100      8   8818\n",
      "       56      4   1926    200  21407   1953   3080    880  44339  14134\n",
      "     1840     72    168     12  13472  23677  63844    139    168  44339]]\n",
      "\n",
      " [[151927    515    107      9  47405     86   9038    495   4343 232440\n",
      "       42 119769      4     99      8  21241  40130  16719   4444   1953\n",
      "        4     99    233  50281   5828   3491  94889  50825 118995   2331]]\n",
      "\n",
      " [[118843  50142     19    182  62896  66373    109 104776     19      4\n",
      "      453     17   4343  42373   1515  43881      7  95445     72    777\n",
      "    21309    168   7530  12227   6369     42      4    124   1926  18893]]\n",
      "\n",
      " [[ 12574      4   5815     60   8451  74224    112   8311   5465 156258\n",
      "       17   4475  80244     42    100     99  82729  44759     19    124\n",
      "    10761   1755  13635  18493  66456 159713  33267     56  18097     17]]\n",
      "\n",
      " [[  4961  28111  64527 114805    332   2918  17413  13285   6797  30469\n",
      "     1442     60   1823   1872     17   2918 204414   1067 167629      5\n",
      "    16148   6854   1368    124  17997    182 127394   3564     85  25779]]\n",
      "\n",
      " [[   357  14134   1630  16719    139   1661   8675     60 125503    112\n",
      "        4     99    149   9038  13069    186    837    126    261     22\n",
      "   152836     17   4475  34346   4960  11063     85  76330     17    159]]\n",
      "\n",
      " [[ 50110 203653     13  20627    142  40772     90   5371    128  56852\n",
      "      265  26652  64954  48218      5  52445    592  93006    233 142404\n",
      "      128  26508    112  38016     56  52445    592   8858 203653     13]]\n",
      "\n",
      " [[   345    112   6121  77339  59277    112 134252   1379  41494  27805\n",
      "    93198      4     60    845  30319  17075  54568    112   2536  55924\n",
      "      139   7822   3263   4792  87998    131   5518    109   1550   1042]]\n",
      "\n",
      " [[ 18118    449   1272 147424  51602    203  28475  19716    139  62172\n",
      "    24830  13635  37505      4     60    149      6  11364   3964     56\n",
      "   121739     33      4    122  28891  59146     22  25121    254   2186]]\n",
      "\n",
      " [[   335 104158    634   1486     60 187559  83497     67    100    177\n",
      "     3405   3132     99  18381 179805    126    171    239  17703     17\n",
      "     6867      4    453   3491  94877     18    261  73015 187559   5535]]\n",
      "\n",
      " [[  3323    100      7   1783  36376   9683  87998      4   5159    777\n",
      "     3491  79329 242312  11617 242312     60  17202     18   3438     12\n",
      "     1429     72    122   5178     17  22378      1      1      1      1]]\n",
      "\n",
      " [[  1843    555     60  85283    147  29178    182  36903      8  25531\n",
      "    42461    109  47621     17  77199     19      4    124    315 122403\n",
      "    14014    139  58941   1015   1843    555     60  85283    147  29178]]\n",
      "\n",
      " [[ 30382  80999     56  13594    545   2432  26143    100     99 115331\n",
      "    11269 114306      4     99   1926   3271 100070      7   6106      5\n",
      "      579 114598    112  44296  81170    100   6121      7 120375    126]]\n",
      "\n",
      " [[   159   1491  87210  26222     86  51580     13  37226     76    601\n",
      "        5  53983  41347   1015  19246   1314   2160  16723    100   2955\n",
      "     3986  38702    139   1144   2432    588   2902    112  18837   6892]]\n",
      "\n",
      " [[ 29217   1205  66663  12439  25660  77170    348   5844   5077     22\n",
      "    15161    384  11697     67      9   7260  51169  16401   4223   1015\n",
      "     1953 157715     25 110449   3668  50825 157715      9  50142    444]]\n",
      "\n",
      " [[  1575  16867 130178 129657     18   5071     60  15889   5071     17\n",
      "    54114    301    126  14384 184151    545    645    219   1205  28337\n",
      "        4  20363  96424     56   2331  40322     33   1379  76003   8831]]\n",
      "\n",
      " [[ 23888  82412 124895  93264   1015    261  72468     82  65318  66698\n",
      "        9   1409  12654      5    582   8793  32790  21309 102020    242\n",
      "    45898      7   2317   4343 127797  43574  13534  25681     17  82222]]\n",
      "\n",
      " [[181793  62046   2923     47  15102  16787   7829  33863    820   2060\n",
      "     2601    109  16010  28566      4     48   5755   8351   1334  18066\n",
      "    86441  75399 174720     18     12  52639     56  62046   2060   2601]]\n",
      "\n",
      " [[   579  16471 197956 141040     13      9  16200    182  13259    186\n",
      "   140656     18   1144 125041    109      6  48599   5343     26      7\n",
      "     2663  12897    645      8  13635  16401     17  13957      4   3564]]\n",
      "\n",
      " [[147756    182 160770   1144      4    453    545    139    149   9866\n",
      "        4     60  23182   5071    645     71  81447    112   3445  36377\n",
      "       17    845  30319 235262    128    100  24705   1974 151433      1]]\n",
      "\n",
      " [[   947   1409    171 165458  57747  28394      7  11862    139     22\n",
      "    18714  14134   7400  33061    107     60  33061    107      5     87\n",
      "     1442    203     22  22473   6581  26359 205700      4     99   5044]]\n",
      "\n",
      " [[140195    568  20345      9  12351  61784  68341     12    579    203\n",
      "     3728   1712      4     99  22688   2407  70574    126    261  50081\n",
      "    96321    242 101865  51222  18481     25    495 177376  73657     60]]]\n",
      "batch_y: torch.Size([31, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[1.7750e+03, 3.6600e+02, 3.4910e+03,  ..., 6.8500e+02, 3.3500e+02,\n",
      "         1.1150e+04],\n",
      "        [6.6100e+03, 2.9860e+03, 8.6000e+01,  ..., 7.0000e+00, 1.4900e+02,\n",
      "         4.0000e+00],\n",
      "        [6.6300e+02, 2.5950e+03, 2.2420e+03,  ..., 1.9530e+03, 2.2688e+04,\n",
      "         2.8440e+03],\n",
      "        ...,\n",
      "        [5.5860e+03, 3.3000e+01, 6.0000e+00,  ..., 1.8000e+01, 4.4547e+04,\n",
      "         1.8000e+01],\n",
      "        [1.5750e+03, 8.2217e+04, 6.0790e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [1.7861e+05, 2.0300e+02, 1.1500e+02,  ..., 1.3440e+04, 2.9036e+04,\n",
      "         2.5000e+01]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 25/25 [00:01<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his_input_title: (16, 50, 30), values: [[[   357  53705  32089 ...  19656  11380   3405]\n",
      "  [ 61201  45709  30426 ...     12     20  23757]\n",
      "  [  1310     72  94396 ...  38486     17 164658]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[   357  53705  32089 ...  19656  11380   3405]\n",
      "  [ 61201  45709  30426 ...     12     20  23757]\n",
      "  [  1310     72  94396 ...  38486     17 164658]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[   357  53705  32089 ...  19656  11380   3405]\n",
      "  [ 61201  45709  30426 ...     12     20  23757]\n",
      "  [  1310     72  94396 ...  38486     17 164658]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   357  53705  32089 ...  19656  11380   3405]\n",
      "  [ 61201  45709  30426 ...     12     20  23757]\n",
      "  [  1310     72  94396 ...  38486     17 164658]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[   357  53705  32089 ...  19656  11380   3405]\n",
      "  [ 61201  45709  30426 ...     12     20  23757]\n",
      "  [  1310     72  94396 ...  38486     17 164658]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]\n",
      "\n",
      " [[   357  53705  32089 ...  19656  11380   3405]\n",
      "  [ 61201  45709  30426 ...     12     20  23757]\n",
      "  [  1310     72  94396 ...  38486     17 164658]\n",
      "  ...\n",
      "  [  1575  82217   6079 ...      1      1      1]\n",
      "  [ 51661   6815  22193 ...   1134  18381     86]\n",
      "  [  9907  91464   1872 ... 100265     13   3787]]]\n",
      "pred_input_title: (16, 1, 30), values: [[[ 11584   3911   1974  13594    502  74877     19    139     99  42648\n",
      "       13    128   1379   5077  27970  23046  20106  10674    109    845\n",
      "    30319  16326  43957  31019  46466  11214     76  88894    720     56]]\n",
      "\n",
      " [[    20   4344 194533     72    681     92  22201      4    100    279\n",
      "   148770   2057    124 102629  10266     60      6  97101   2146 156330\n",
      "     2285      4  20363  34703  25389  10729  13384  90757   9617     12]]\n",
      "\n",
      " [[200178    106     26      7  12247    824   7175 111645     17 138550\n",
      "     1661   3252      5   9963   5293    425      5   1840     72 108605\n",
      "     7086     13 143004     13 152262    350     60  74468     56  50079]]\n",
      "\n",
      " [[  4669      9  48951      6 154759     12   2548   3271 135768  17819\n",
      "      261 102991      1      1      1      1      1      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[122571     17  15161 130207   1063    112  69721  27633 102674     22\n",
      "      261  65134      7   6064  38575   1357     99   3963     40     22\n",
      "    28117    109   1661  32209      7   6865  22012  16148  32209      7]]\n",
      "\n",
      " [[ 90752 159249  12439  78488  81134    604      4   5916    115    203\n",
      "       40      4    171  28337  66450     56   1144    171   1466     20\n",
      "      671  32556   3564     85  17532     56     22  81711  16155    100]]\n",
      "\n",
      " [[ 30749  14098    182   4343  67049    100  91613      7  12302  27808\n",
      "    13388      4     60      8 199433     42  33618  19787 154502      9\n",
      "    13784      7  30854    982  20904   2734     13  11214     13     12]]\n",
      "\n",
      " [[ 53379     19    182  79329  16077     17  24906    128     22  18493\n",
      "     2146  42504    159  33880      6 222101  52478   3198    139 128139\n",
      "    27472      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[149746  25779  47640   5535   5222   1872    139 204049   9173  22381\n",
      "        4     48     22   6478      9  48951  62896  14134    645  41993\n",
      "       18     22    307   5386  46406     17 204049   9173  22381     12]]\n",
      "\n",
      " [[ 48267  72752     56   1379  72444    261   3939   5877    109  78007\n",
      "        7    261   7370  98241      7 223724    285     22  17474      4\n",
      "    20363  27345  18493   3939   5877     17   3082      6  72752     12]]\n",
      "\n",
      " [[  2609   1390    139   2704     33     17  92265  13527    520   2355\n",
      "     1872    100  14355   1505  28398     13      5   1111  81299     19\n",
      "     7400    545  13440  24153 165205      4  13613  69686 154982  11617]]\n",
      "\n",
      " [[ 96180 153355      4 102572  11872   4293     60  40914   1459  34734\n",
      "      434  13534     72  33618  37505     19    261  20636      4    122\n",
      "    21309   8793 117287  16342   6328      4   1953      8    182  11377]]\n",
      "\n",
      " [[165458  57747  28394     23 217315     42      4     99    777    182\n",
      "    15763     22 231404    128     22  12532  98222  26076      9  17052\n",
      "       18     12     20   1731   9038     22 231404      1      1      1]]\n",
      "\n",
      " [[   845    334  33781    170   2319    519    169  10884 126982  47640\n",
      "        4     99 142092      9  40042    182    109    372  78015  13384\n",
      "      880    456  39046     67    588  15082    127  14311      5 123949]]\n",
      "\n",
      " [[111347 140852     18    182    261     71 151350      4   5916 190784\n",
      "       56 172582 175471     13   2993   5983      9     60  24030   4517\n",
      "    33150    139  33618   2528   2536  13732  13285      5 149746  97353]]\n",
      "\n",
      " [[ 55598  52917  10528  68933     60  47801   2512  22964     19   7997\n",
      "   128354    184    285  69538    109  27535  78007      7    645 181916\n",
      "      109  45355     56     87  36709  44937     12  48033   5044      9]]]\n",
      "batch_y: torch.Size([16, 1]), values: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[3.5700e+02, 5.3705e+04, 3.2089e+04,  ..., 1.9656e+04, 1.1380e+04,\n",
      "         3.4050e+03],\n",
      "        [6.1201e+04, 4.5709e+04, 3.0426e+04,  ..., 1.2000e+01, 2.0000e+01,\n",
      "         2.3757e+04],\n",
      "        [1.3100e+03, 7.2000e+01, 9.4396e+04,  ..., 3.8486e+04, 1.7000e+01,\n",
      "         1.6466e+05],\n",
      "        ...,\n",
      "        [1.5750e+03, 8.2217e+04, 6.0790e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [5.1661e+04, 6.8150e+03, 2.2193e+04,  ..., 1.1340e+03, 1.8381e+04,\n",
      "         8.6000e+01],\n",
      "        [9.9070e+03, 9.1464e+04, 1.8720e+03,  ..., 1.0026e+05, 1.3000e+01,\n",
      "         3.7870e+03]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (5, 50, 30), values: [[[ 73165  14098      7 ...      1      1      1]\n",
      "  [   357  50094    261 ...    588   3835   4516]\n",
      "  [  8934      9  48951 ...   3491  61446  10266]\n",
      "  ...\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [  5879    182  53396 ... 171646   1755 148520]]\n",
      "\n",
      " [[ 73165  14098      7 ...      1      1      1]\n",
      "  [   357  50094    261 ...    588   3835   4516]\n",
      "  [  8934      9  48951 ...   3491  61446  10266]\n",
      "  ...\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [  5879    182  53396 ... 171646   1755 148520]]\n",
      "\n",
      " [[ 73165  14098      7 ...      1      1      1]\n",
      "  [   357  50094    261 ...    588   3835   4516]\n",
      "  [  8934      9  48951 ...   3491  61446  10266]\n",
      "  ...\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [  5879    182  53396 ... 171646   1755 148520]]\n",
      "\n",
      " [[ 73165  14098      7 ...      1      1      1]\n",
      "  [   357  50094    261 ...    588   3835   4516]\n",
      "  [  8934      9  48951 ...   3491  61446  10266]\n",
      "  ...\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [  5879    182  53396 ... 171646   1755 148520]]\n",
      "\n",
      " [[ 73165  14098      7 ...      1      1      1]\n",
      "  [   357  50094    261 ...    588   3835   4516]\n",
      "  [  8934      9  48951 ...   3491  61446  10266]\n",
      "  ...\n",
      "  [ 50110    261      8 ...     25     19     25]\n",
      "  [ 50715     18  14936 ...      1      1      1]\n",
      "  [  5879    182  53396 ... 171646   1755 148520]]]\n",
      "pred_input_title: (5, 1, 30), values: [[[  4961   2811  24314    109 116850   1872 175680    261 142209    107\n",
      "      182 123949   2752  27184      6  81100    100 116850  61634     56\n",
      "       60    352  13482      7 119769  49083   2822   1824    261    352]]\n",
      "\n",
      " [[   579    203   1712  10024    261     22  65172    133     99   9881\n",
      "     1872    261      4   8928    115   3434  21537    321 217785     56\n",
      "     2721    139  13440    100  93008      5 156433     86     72  32790]]\n",
      "\n",
      " [[ 99678   3019     12   8694    157     12    341   3405     39  17648\n",
      "     3366     17   4602     20    315    203    149  21177     17   3974\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[130189     13   4475  19035     56    203  24270     86  21350   1712\n",
      "       17 120149  42648  33326  16732   1728    171   9060  88131     12\n",
      "      908   7864     18     38      1      1      1      1      1      1]]\n",
      "\n",
      " [[ 38692   7325   7182    100  15123    820    545      8 105791   1368\n",
      "        4    168  12532    242 115411    837     14     25    182  15763\n",
      "       17    168  16471  15918 169074      4    453   4925    777  13594]]]\n",
      "batch_y: torch.Size([5, 1]), values: tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[7.3165e+04, 1.4098e+04, 7.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [3.5700e+02, 5.0094e+04, 2.6100e+02,  ..., 5.8800e+02, 3.8350e+03,\n",
      "         4.5160e+03],\n",
      "        [8.9340e+03, 9.0000e+00, 4.8951e+04,  ..., 3.4910e+03, 6.1446e+04,\n",
      "         1.0266e+04],\n",
      "        ...,\n",
      "        [5.0110e+04, 2.6100e+02, 8.0000e+00,  ..., 2.5000e+01, 1.9000e+01,\n",
      "         2.5000e+01],\n",
      "        [5.0715e+04, 1.8000e+01, 1.4936e+04,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [5.8790e+03, 1.8200e+02, 5.3396e+04,  ..., 1.7165e+05, 1.7550e+03,\n",
      "         1.4852e+05]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[1.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "his_input_title: (5, 50, 30), values: [[[  3311     33  15082 ...   9843    261     22]\n",
      "  [ 90266      7  15429 ... 219723 149746 127123]\n",
      "  [111323   5084  22381 ...  16852      1      1]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  4841  21493  87884 ... 194727  74188 111645]\n",
      "  [    87  31464     72 ...  12060   2752    109]]\n",
      "\n",
      " [[  3311     33  15082 ...   9843    261     22]\n",
      "  [ 90266      7  15429 ... 219723 149746 127123]\n",
      "  [111323   5084  22381 ...  16852      1      1]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  4841  21493  87884 ... 194727  74188 111645]\n",
      "  [    87  31464     72 ...  12060   2752    109]]\n",
      "\n",
      " [[  3311     33  15082 ...   9843    261     22]\n",
      "  [ 90266      7  15429 ... 219723 149746 127123]\n",
      "  [111323   5084  22381 ...  16852      1      1]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  4841  21493  87884 ... 194727  74188 111645]\n",
      "  [    87  31464     72 ...  12060   2752    109]]\n",
      "\n",
      " [[  3311     33  15082 ...   9843    261     22]\n",
      "  [ 90266      7  15429 ... 219723 149746 127123]\n",
      "  [111323   5084  22381 ...  16852      1      1]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  4841  21493  87884 ... 194727  74188 111645]\n",
      "  [    87  31464     72 ...  12060   2752    109]]\n",
      "\n",
      " [[  3311     33  15082 ...   9843    261     22]\n",
      "  [ 90266      7  15429 ... 219723 149746 127123]\n",
      "  [111323   5084  22381 ...  16852      1      1]\n",
      "  ...\n",
      "  [ 36558      9     60 ... 120807   1803   1063]\n",
      "  [  4841  21493  87884 ... 194727  74188 111645]\n",
      "  [    87  31464     72 ...  12060   2752    109]]]\n",
      "pred_input_title: (5, 1, 30), values: [[[   786    203  59393 131556   2641    171      8    616  26470   1429\n",
      "    88032 168423   3196    100  14950   1674  24716      1      1      1\n",
      "        1      1      1      1      1      1      1      1      1      1]]\n",
      "\n",
      " [[219877     13   2878     56     17 221450   8793   6157    168   3787\n",
      "    77199      4    122  63688      7     99  18413    112  55924    615\n",
      "    19110  44339   1368 219877     13   2878     56  16993     12   1429]]\n",
      "\n",
      " [[ 99442  21139   1681   1823    109     22     91  17052  22180     17\n",
      "      787 107677    261  92265  13527      4   2328 143352    127 226719\n",
      "    72328      5  84163    233 126550     18   6799    604    159 143662]]\n",
      "\n",
      " [[ 29169     13  88131     60  41036   1363  30501     42 197331      7\n",
      "   105712      4     60    149   1873  65005    100 130983    261 131980\n",
      "       60  63451 164886 197331      7 105712   1063 207745  24270     86]]\n",
      "\n",
      " [[ 48267     17 177163   7373     33   1239 110760     56     22  36656\n",
      "      100     99    765    645 140521     18  14964    128  85336   2198\n",
      "      282    109    233   2811    209   1368  29630  36656    142  78131]]]\n",
      "batch_y: torch.Size([5, 1]), values: tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Inputs\n",
      "tensor([[3.3110e+03, 3.3000e+01, 1.5082e+04,  ..., 9.8430e+03, 2.6100e+02,\n",
      "         2.2000e+01],\n",
      "        [9.0266e+04, 7.0000e+00, 1.5429e+04,  ..., 2.1972e+05, 1.4975e+05,\n",
      "         1.2712e+05],\n",
      "        [1.1132e+05, 5.0840e+03, 2.2381e+04,  ..., 1.6852e+04, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [3.6558e+04, 9.0000e+00, 6.0000e+01,  ..., 1.2081e+05, 1.8030e+03,\n",
      "         1.0630e+03],\n",
      "        [4.8410e+03, 2.1493e+04, 8.7884e+04,  ..., 1.9473e+05, 7.4188e+04,\n",
      "         1.1164e+05],\n",
      "        [8.7000e+01, 3.1464e+04, 7.2000e+01,  ..., 1.2060e+04, 2.7520e+03,\n",
      "         1.0900e+02]])\n",
      "50\n",
      "torch.Size([50, 30])\n",
      "Output\n",
      "[[1.0], [1.0], [1.0], [1.0], [1.0]]\n",
      "Labels\n",
      "[[1.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC: 100%|█████████████████████████████████████| 25/25 [00:00<00:00, 337.04it/s]\n",
      "AUC: 100%|████████████████████████████████████| 25/25 [00:00<00:00, 6249.71it/s]\n",
      "AUC: 100%|████████████████████████████████████| 25/25 [00:00<00:00, 5546.85it/s]\n",
      "AUC: 100%|███████████████████████████████████| 25/25 [00:00<00:00, 12496.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "BATCH_SIZE_TEST = 1 # Currently onoy supports batch size 1\n",
    "\n",
    "dataset.setup_test_data(dataset_path = DATAPATH, datasplit = DATASET, history_size = HISTORY_SIZE, columns = COLS, fraction = FRACTION, seed = SEED)\n",
    "\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=dataset.df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=cs.DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True, # Is true in EBREC, but then it does not work\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")\n",
    "\n",
    "# go from [[a], [b], [c]] to [a, b, c]\n",
    "def convert_to_list(l):\n",
    "    return [(item) for sublist in l for item in sublist]\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "pred_test = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Test\"):\n",
    "        (inputs, labels) = batch\n",
    "        print(\"Inputs\")\n",
    "\n",
    "        his_input_title, pred_input_title = inputs\n",
    "        print(his_input_title[0])\n",
    "        print(len(his_input_title[0]))\n",
    "        print(his_input_title[0].shape)\n",
    "\n",
    "\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pred_input_title, his_input_title)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        print(\"Output\")\n",
    "        print(outputs.tolist())\n",
    "        print(\"Labels\")\n",
    "        print(labels.tolist())\n",
    "        list = convert_to_list(outputs.tolist())\n",
    "        print(list)\n",
    "        print(\"\")\n",
    "\n",
    "        \n",
    "        \n",
    "        pred_test.append(list)\n",
    "\n",
    "from from_ebrec.evaluation import MetricEvaluator\n",
    "from from_ebrec.evaluation import AucScore, MrrScore, NdcgScore\n",
    "metrics = MetricEvaluator(\n",
    "    labels = dataset.df_test[\"labels\"].to_list(),\n",
    "    predictions= pred_test,\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()\n",
    "test_loss /= len(test_dataloader)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 predictions vs labels:\n",
      "Article 0\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "1.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "\n",
      "Article 1\n",
      "0.010 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.793 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.189 vs 0.000\n",
      "0.007 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 2\n",
      "0.001 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.782 vs 0.000\n",
      "0.217 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 3\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.915 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.004 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.080 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 4\n",
      "0.037 vs 1.000\n",
      "0.133 vs 0.000\n",
      "0.002 vs 0.000\n",
      "0.827 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.001 vs 0.000\n",
      "\n",
      "Article 5\n",
      "0.000 vs 0.000\n",
      "1.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 6\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.149 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.749 vs 0.000\n",
      "0.101 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 7\n",
      "0.000 vs 0.000\n",
      "0.999 vs 1.000\n",
      "0.001 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 8\n",
      "0.955 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.043 vs 0.000\n",
      "\n",
      "Article 9\n",
      "0.000 vs 0.000\n",
      "0.001 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.007 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.002 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.907 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.004 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.076 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 10\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "1.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 11\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.788 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.002 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.209 vs 0.000\n",
      "\n",
      "Article 12\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.003 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.002 vs 0.000\n",
      "0.043 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.227 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.725 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 13\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.008 vs 0.000\n",
      "0.033 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.003 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.011 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.890 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.052 vs 0.000\n",
      "0.002 vs 0.000\n",
      "\n",
      "Article 14\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.623 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.009 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.002 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.365 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 15\n",
      "0.082 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.872 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.046 vs 0.000\n",
      "\n",
      "Article 16\n",
      "0.000 vs 0.000\n",
      "0.012 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.988 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 17\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.009 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.967 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.002 vs 1.000\n",
      "0.000 vs 0.000\n",
      "0.022 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n",
      "Article 18\n",
      "0.778 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 1.000\n",
      "0.222 vs 0.000\n",
      "\n",
      "Article 19\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.985 vs 1.000\n",
      "0.015 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "0.000 vs 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_to_print = 20\n",
    "print(\"Top %d predictions vs labels:\" % number_to_print)\n",
    "labels = dataset.df_test[\"labels\"].to_list()\n",
    "for i in range(number_to_print):\n",
    "    print(f\"Article {i}\")\n",
    "    for j in range(len(pred_test[i])):\n",
    "        print(f\"{pred_test[i][j]:.3f} vs {labels[i][j]:.3f}\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[26222  2121]\n",
      " [ 2203   338]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Flatten the data for analysis\n",
    "predicted_probabilities = [prob for article in pred_test for prob in article]\n",
    "true_values = [val for article in labels[:len(pred_test)] for val in article]\n",
    "\n",
    "\n",
    "# Set a threshold (commonly 0.5) to classify probabilities as 0 or 1\n",
    "threshold = 0.5\n",
    "predicted_classes = [1 if p >= threshold else 0 for p in predicted_probabilities]\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_values, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate AUC and ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(true_values, predicted_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve with AUC value explicitly highlighted\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label=\"Random Guess\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
